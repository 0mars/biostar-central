INPUT_DATA = {{data.value}}
INPUT_SAMPLE_INFO = {{sampleinfo.value}}
THREADS ={{ threads.value}}

#
# Internal parameters after this.
#

ANALYSIS_DIR = analysis
RESULT_DIR  = results
ERR_LOG = stderr.txt

FASTQC_DIR =$(ANALYSIS_DIR)/fastqc
PTRIM_DIR = $(ANALYSIS_DIR)/trim/trimp
QTRIM_DIR = $(ANALYSIS_DIR)/trim/trimq
UPDATED_SAMPLE_INFO = updated_sampleinfo.txt


all: trim_quality
	@echo "executes all commands"

#
# ============== Update sample sheet ==============
# Read1 and Read2 file names will be added to updated samplesheet.
#

updated_sample_info:
	#
	# Make new sample sheet named $(UPDATED_SAMPLE_INFO)
	#
	python -m pipeline.data.samplesheet $(INPUT_SAMPLE_INFO) $(INPUT_DATA) > $(UPDATED_SAMPLE_INFO)

#
# ============== Quality reports ==============
#


fastqc: updated_sample_info
	#
	# create fastqc reports of all samples.
	#
	mkdir -p $(FASTQC_DIR)
	cat $(UPDATED_SAMPLE_INFO) | parallel --verbose --progress -j $(THREADS) --header : --colsep '\t' fastqc \
	--nogroup -o $(FASTQC_DIR) $(INPUT_DATA)/{file1} $(INPUT_DATA)/{file2}

multiqc: fastqc
	#
	# run multiqc to create an aggregate report
	#
	mkdir -p $(RESULT_DIR)
	multiqc -f -n input_multiqc -o $(FASTQC_DIR) $(FASTQC_DIR)
	cp $(FASTQC_DIR)/input_multiqc.html $(RESULT_DIR)
	#
	# clean
	#
	#rm -f $(FASTQC_DIR)/*fastqc.zip

#
# =============== Primer and Barcode trimming =============
# Trim primer and barcode sequence included in the samplesheet.
#

trim_primer: multiqc
	#
	mkdir -p $(PTRIM_DIR)/logs
	mkdir -p $(RESULT_DIR)
	#
	# trim left primer
	mkdir -p $(RESULT_DIR)
	cat $(UPDATED_SAMPLE_INFO) |parallel --verbose --progress -j $(THREADS)  --header : --colsep '\t' bbduk.sh \
	in1=$(INPUT_DATA)/{file1} in2=$(INPUT_DATA)/{file2} \
	out1=$(PTRIM_DIR)/{sample_name}_fwd1_trim.fq.gz \
	out2=$(PTRIM_DIR)/{sample_name}_fwd2_trim.fq.gz \
	literal={barcode}{fwd_primer} ktrim=l k=23 hdist=1 tpe tbo overwrite=true \
	overwrite=t skipr2=t stats=$(PTRIM_DIR)/logs/{sample_name}_fwd_stats.txt

	#
	# trim right primer
	#
	cat $(UPDATED_SAMPLE_INFO) | parallel --verbose --progress -j $(THREADS) --header : --colsep '\t' bbduk.sh  \
	in1=$(PTRIM_DIR)/{sample_name}_fwd1_trim.fq.gz \
	in2=$(PTRIM_DIR)/{sample_name}_fwd2_trim.fq.gz \
	out1=$(PTRIM_DIR)/{sample_name}_R1_trimp.fq.gz \
	out2=$(PTRIM_DIR)/{sample_name}_R2_trimp.fq.gz  \
	literal={barcode}{rev_primer} ktrim=l k=28 hdist=1 tpe tbo overwrite=true \
	skipr1=t stats=$(PTRIM_DIR)/logs/{sample_name}_rev_stats.txt
	#
	# clean
	#
	cat $(PTRIM_DIR)/logs/*stats.txt > $(RESULT_DIR)/trimp_stats.txt
	#rm -f $(PTRIM_DIR)/*trimfwd*

#
# =============== Quality trimming ===================
# Trim reads to user specified threshold value.
#

trim_quality: trim_primer
	mkdir -p $(QTRIM_DIR)/logs
	cat  $(UPDATED_SAMPLE_INFO) |parallel --verbose --progress -j $(THREADS) --header : --colsep '\t' bbduk.sh \
	in1=$(PTRIM_DIR)/{sample_name}_R1_trimp.fq.gz in2=$(PTRIM_DIR)/{sample_name}_R2_trimp.fq.gz \
	qtrim=rl trimq={{trim_quality.value}}  minlength=35 overwrite=true \
	out1=$(QTRIM_DIR)/{sample_name}_R1_trim.fq.gz \
	out2=$(QTRIM_DIR)/{sample_name}_R2_trim.fq.gz stats=$(QTRIM_DIR)/logs/{sample_name}_stats.txt
	cat $(QTRIM_DIR)/logs/*stats.txt > $(RESULT_DIR)/trimq_stats.txt
	#
	# quality report
	#
	ls $(QTRIM_DIR)/*gz | parallel --verbose --progress -j 8 fastqc --nogroup {} -o $(QTRIM_DIR)
	multiqc -n trim_multiqc --force -o $(QTRIM_DIR) $(QTRIM_DIR)
	cp $(QTRIM_DIR)/trim_multiqc.html $(RESULT_DIR)

