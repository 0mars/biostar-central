[{"pk": 1, "model": "auth.user", "fields": {"username": "u2", "first_name": "Istvan", "last_name": "Albert", "is_active": true, "is_superuser": true, "is_staff": true, "last_login": "2011-11-24 14:54:00", "groups": [], "user_permissions": [], "password": "sha1$a25d7$f234f7faacd069746b308380895e20046ebfa701", "email": "istvan.albert@gmail.com", "date_joined": "2009-09-30 13:30:39"}}, {"pk": 2, "model": "auth.user", "fields": {"username": "u3", "first_name": "Fabio", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2009-10-05 15:43:12", "groups": [], "user_permissions": [], "password": "", "email": "nomail@for.me", "date_joined": "2009-09-30 16:09:06"}}, {"pk": 3, "model": "auth.user", "fields": {"username": "u4", "first_name": "Jason", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-04 14:45:04", "groups": [], "user_permissions": [], "password": "", "email": "jem482@psu.edu", "date_joined": "2009-09-30 17:10:54"}}, {"pk": 4, "model": "auth.user", "fields": {"username": "u5", "first_name": "Zhenhai Zhang", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-06 17:44:55", "groups": [], "user_permissions": [], "password": "", "email": "zhenhai.zhang@gmail.com", "date_joined": "2009-09-30 18:48:08"}}, {"pk": 5, "model": "auth.user", "fields": {"username": "u6", "first_name": "Tom Koerber", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2009-09-30 19:32:29", "groups": [], "user_permissions": [], "password": "", "email": "rtk138@psu.edu", "date_joined": "2009-09-30 19:32:29"}}, {"pk": 6, "model": "auth.user", "fields": {"username": "u7", "first_name": "suk211", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-07 03:32:47", "groups": [], "user_permissions": [], "password": "", "email": "sushant.mishraz@gmail.com", "date_joined": "2009-09-30 19:35:27"}}, {"pk": 7, "model": "auth.user", "fields": {"username": "u8", "first_name": "lemon", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-10-13 23:59:00", "groups": [], "user_permissions": [], "password": "", "email": "lemon027@gmail.com", "date_joined": "2009-10-03 03:02:07"}}, {"pk": 8, "model": "auth.user", "fields": {"username": "u9", "first_name": "Wubin Qu", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 07:20:57", "groups": [], "user_permissions": [], "password": "", "email": "quwubin@gmail.com", "date_joined": "2009-10-03 10:15:52"}}, {"pk": 9, "model": "auth.user", "fields": {"username": "u10", "first_name": "Question Bot", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-11 04:00:18", "groups": [], "user_permissions": [], "password": "", "email": "istvan.albert@yahoo.com", "date_joined": "2009-10-05 15:44:30"}}, {"pk": 10, "model": "auth.user", "fields": {"username": "u11", "first_name": "Reka Albert", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2009-10-05 16:47:25", "groups": [], "user_permissions": [], "password": "", "email": "reka.albert@gmail.com", "date_joined": "2009-10-05 16:47:25"}}, {"pk": 11, "model": "auth.user", "fields": {"username": "u12", "first_name": "Yang Yang", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2009-10-07 01:45:15", "groups": [], "user_permissions": [], "password": "", "email": "yuy4@psu.edu", "date_joined": "2009-10-06 18:58:10"}}, {"pk": 12, "model": "auth.user", "fields": {"username": "u13", "first_name": "Gue Su Chang", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2009-10-07 13:04:30", "groups": [], "user_permissions": [], "password": "", "email": "guesu@bx.psu.edu", "date_joined": "2009-10-06 22:04:41"}}, {"pk": 13, "model": "auth.user", "fields": {"username": "u14", "first_name": "Zhaorong", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-28 22:18:27", "groups": [], "user_permissions": [], "password": "", "email": "mazhaorong@gmail.com", "date_joined": "2009-10-09 02:54:13"}}, {"pk": 14, "model": "auth.user", "fields": {"username": "u15", "first_name": "nickey", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2009-10-18 03:22:53", "groups": [], "user_permissions": [], "password": "", "email": "mccuskeremma@yahoo.co.nz", "date_joined": "2009-10-18 03:22:53"}}, {"pk": 15, "model": "auth.user", "fields": {"username": "u16", "first_name": "Renee", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-02-20 21:13:56", "groups": [], "user_permissions": [], "password": "", "email": "xiaowu1007@gmail.com", "date_joined": "2009-10-23 17:40:27"}}, {"pk": 16, "model": "auth.user", "fields": {"username": "u17", "first_name": "Yu", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 23:19:01", "groups": [], "user_permissions": [], "password": "", "email": "zhouyubio@gmail.com", "date_joined": "2009-11-04 18:39:12"}}, {"pk": 17, "model": "auth.user", "fields": {"username": "u18", "first_name": "Gue Su", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2009-12-01 16:51:54", "groups": [], "user_permissions": [], "password": "", "email": "gxc187@gmail.com", "date_joined": "2009-12-01 14:57:35"}}, {"pk": 18, "model": "auth.user", "fields": {"username": "u19", "first_name": "Mohammed Islaih", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2009-12-08 21:45:54", "groups": [], "user_permissions": [], "password": "", "email": "mislaih@iupui.edu", "date_joined": "2009-12-08 21:45:54"}}, {"pk": 19, "model": "auth.user", "fields": {"username": "u20", "first_name": "Alex Reynolds", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-23 01:08:55", "groups": [], "user_permissions": [], "password": "", "email": "alexpreynolds@gmail.com", "date_joined": "2009-12-23 01:10:22"}}, {"pk": 20, "model": "auth.user", "fields": {"username": "u21", "first_name": "User 21", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2009-12-28 13:56:46", "groups": [], "user_permissions": [], "password": "", "email": "u21", "date_joined": "2009-12-28 13:56:46"}}, {"pk": 21, "model": "auth.user", "fields": {"username": "u22", "first_name": "User 22", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-10 02:15:19", "groups": [], "user_permissions": [], "password": "", "email": "u22", "date_joined": "2009-12-31 13:26:29"}}, {"pk": 22, "model": "auth.user", "fields": {"username": "u23", "first_name": "Giovanni M Dall'Olio", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 16:00:49", "groups": [], "user_permissions": [], "password": "", "email": "dalloliogm@gmail.com", "date_joined": "2010-01-18 15:43:55"}}, {"pk": 23, "model": "auth.user", "fields": {"username": "u24", "first_name": "etal", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-10 16:52:10", "groups": [], "user_permissions": [], "password": "", "email": "eric.talevich@gmail.com", "date_joined": "2010-01-23 17:01:47"}}, {"pk": 24, "model": "auth.user", "fields": {"username": "u25", "first_name": "Fabio", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-01-27 00:38:35", "groups": [], "user_permissions": [], "password": "", "email": "nomail@for.me", "date_joined": "2010-01-26 23:42:13"}}, {"pk": 25, "model": "auth.user", "fields": {"username": "u26", "first_name": "Nicojo", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-28 06:58:08", "groups": [], "user_permissions": [], "password": "", "email": "njoannin@yahoo.com", "date_joined": "2010-02-12 21:29:24"}}, {"pk": 26, "model": "auth.user", "fields": {"username": "u27", "first_name": "Allen Yu", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-11 02:42:46", "groups": [], "user_permissions": [], "password": "", "email": "allenyuchishing@gmail.com", "date_joined": "2010-02-19 07:25:13"}}, {"pk": 27, "model": "auth.user", "fields": {"username": "u28", "first_name": "Curious George", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-02-19 19:35:30", "groups": [], "user_permissions": [], "password": "", "email": "nomail@for.me.com", "date_joined": "2010-02-19 13:33:45"}}, {"pk": 28, "model": "auth.user", "fields": {"username": "u29", "first_name": "User 29", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-03-17 05:18:47", "groups": [], "user_permissions": [], "password": "", "email": "u29", "date_joined": "2010-02-22 03:24:18"}}, {"pk": 29, "model": "auth.user", "fields": {"username": "u30", "first_name": "Pierre Lindenbaum", "last_name": "", "is_active": true, "is_superuser": true, "is_staff": true, "last_login": "2011-11-22 21:46:26", "groups": [], "user_permissions": [], "password": "", "email": "plindenbaum@yahoo.fr", "date_joined": "2010-02-25 17:27:15"}}, {"pk": 30, "model": "auth.user", "fields": {"username": "u31", "first_name": "Marcos de Carvalho", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-11 20:05:42", "groups": [], "user_permissions": [], "password": "", "email": "marcos.carvalho@gmail.com", "date_joined": "2010-02-25 17:42:49"}}, {"pk": 31, "model": "auth.user", "fields": {"username": "u32", "first_name": "Gustavo Costa", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-02-25 18:22:10", "groups": [], "user_permissions": [], "password": "", "email": "glacerda@lge.ibi.unicamp.br", "date_joined": "2010-02-25 18:22:10"}}, {"pk": 32, "model": "auth.user", "fields": {"username": "u33", "first_name": "User 33", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-02-26 00:09:01", "groups": [], "user_permissions": [], "password": "", "email": "u33", "date_joined": "2010-02-25 18:28:54"}}, {"pk": 33, "model": "auth.user", "fields": {"username": "u34", "first_name": "Paul J. Davis", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-06-09 20:08:05", "groups": [], "user_permissions": [], "password": "", "email": "paul.joseph.davis@gmail.com", "date_joined": "2010-02-25 18:31:12"}}, {"pk": 34, "model": "auth.user", "fields": {"username": "u35", "first_name": "David Nusinow", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-13 19:33:29", "groups": [], "user_permissions": [], "password": "", "email": "dnusinow@gmail.com", "date_joined": "2010-02-25 21:30:36"}}, {"pk": 35, "model": "auth.user", "fields": {"username": "u36", "first_name": "brentp", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-23 01:21:21", "groups": [], "user_permissions": [], "password": "", "email": "bpederse@gmail.com", "date_joined": "2010-02-25 21:33:47"}}, {"pk": 36, "model": "auth.user", "fields": {"username": "u37", "first_name": "razor", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-21 15:27:38", "groups": [], "user_permissions": [], "password": "", "email": "endre.sebestyen@gmail.com", "date_joined": "2010-02-26 07:58:44"}}, {"pk": 37, "model": "auth.user", "fields": {"username": "u38", "first_name": "Simon Cockell", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 16:52:23", "groups": [], "user_permissions": [], "password": "", "email": "sjcockell@gmail.com", "date_joined": "2010-02-26 09:26:42"}}, {"pk": 38, "model": "auth.user", "fields": {"username": "u39", "first_name": "konrad", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 19:55:36", "groups": [], "user_permissions": [], "password": "", "email": "konrad@foerstner.org", "date_joined": "2010-02-26 13:01:06"}}, {"pk": 39, "model": "auth.user", "fields": {"username": "u40", "first_name": "biorelated", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 19:04:17", "groups": [], "user_permissions": [], "password": "", "email": "georgkam@gmail.com", "date_joined": "2010-02-26 13:06:05"}}, {"pk": 40, "model": "auth.user", "fields": {"username": "u41", "first_name": "Yann Abraham", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-05 08:27:23", "groups": [], "user_permissions": [], "password": "", "email": "yann.abraham@gmail.com", "date_joined": "2010-02-26 13:37:34"}}, {"pk": 41, "model": "auth.user", "fields": {"username": "u42", "first_name": "Fernando Mu\u00f1iz", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-02-26 14:26:41", "groups": [], "user_permissions": [], "password": "", "email": "fernando.muniz@upf.edu", "date_joined": "2010-02-26 13:47:41"}}, {"pk": 42, "model": "auth.user", "fields": {"username": "u43", "first_name": "User 43", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-02-26 14:47:27", "groups": [], "user_permissions": [], "password": "", "email": "u43", "date_joined": "2010-02-26 14:47:27"}}, {"pk": 43, "model": "auth.user", "fields": {"username": "u44", "first_name": "andrew", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-15 15:18:55", "groups": [], "user_permissions": [], "password": "", "email": "agagne@gmail.com", "date_joined": "2010-02-26 15:49:18"}}, {"pk": 44, "model": "auth.user", "fields": {"username": "u45", "first_name": "Alex", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-09 22:07:11", "groups": [], "user_permissions": [], "password": "", "email": "u45", "date_joined": "2010-02-26 16:06:54"}}, {"pk": 45, "model": "auth.user", "fields": {"username": "u46", "first_name": "Owen", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-21 00:41:18", "groups": [], "user_permissions": [], "password": "", "email": "opierce@gmail.com", "date_joined": "2010-02-26 16:54:23"}}, {"pk": 46, "model": "auth.user", "fields": {"username": "u47", "first_name": "Chris", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-15 13:38:38", "groups": [], "user_permissions": [], "password": "", "email": "schaefer@rostlab.org", "date_joined": "2010-02-26 16:57:13"}}, {"pk": 47, "model": "auth.user", "fields": {"username": "u48", "first_name": "Kelly O.", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-17 17:54:53", "groups": [], "user_permissions": [], "password": "", "email": "kelly.oakeson@utah.edu", "date_joined": "2010-02-26 17:38:01"}}, {"pk": 48, "model": "auth.user", "fields": {"username": "u49", "first_name": "User 49", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-02-26 18:20:47", "groups": [], "user_permissions": [], "password": "", "email": "u49", "date_joined": "2010-02-26 18:20:47"}}, {"pk": 49, "model": "auth.user", "fields": {"username": "u50", "first_name": "Greg", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-01 17:25:38", "groups": [], "user_permissions": [], "password": "", "email": "u50", "date_joined": "2010-02-26 18:38:07"}}, {"pk": 50, "model": "auth.user", "fields": {"username": "u51", "first_name": "pedrobeltrao", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-20 20:16:04", "groups": [], "user_permissions": [], "password": "", "email": "pedrobeltrao@gmail.com", "date_joined": "2010-02-26 18:51:02"}}, {"pk": 51, "model": "auth.user", "fields": {"username": "u52", "first_name": "Liam Thompson", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-06-27 07:20:27", "groups": [], "user_permissions": [], "password": "", "email": "dejmail@gmail.com", "date_joined": "2010-02-26 19:00:28"}}, {"pk": 52, "model": "auth.user", "fields": {"username": "u53", "first_name": "Michael Barton", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-18 18:06:24", "groups": [], "user_permissions": [], "password": "", "email": "mail@michaelbarton.me.uk", "date_joined": "2010-02-26 19:59:50"}}, {"pk": 53, "model": "auth.user", "fields": {"username": "u54", "first_name": "Schrodinger's Cat", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-07 10:47:03", "groups": [], "user_permissions": [], "password": "", "email": "philosof@tx.technion.ac.il", "date_joined": "2010-02-27 19:19:21"}}, {"pk": 54, "model": "auth.user", "fields": {"username": "u55", "first_name": "Michael Dondrup", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 22:36:27", "groups": [], "user_permissions": [], "password": "", "email": "mdondrup@googlemail.com", "date_joined": "2010-02-27 21:00:55"}}, {"pk": 55, "model": "auth.user", "fields": {"username": "u56", "first_name": "Brad Chapman", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 20:39:08", "groups": [], "user_permissions": [], "password": "", "email": "chapmanb@50mail.com", "date_joined": "2010-02-28 22:41:45"}}, {"pk": 56, "model": "auth.user", "fields": {"username": "u57", "first_name": "paulati", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-01 13:31:45", "groups": [], "user_permissions": [], "password": "", "email": "paulati@gmail.com", "date_joined": "2010-03-01 13:31:45"}}, {"pk": 57, "model": "auth.user", "fields": {"username": "u58", "first_name": "Dave Bridges", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 20:17:35", "groups": [], "user_permissions": [], "password": "", "email": "dave.bridges@gmail.com", "date_joined": "2010-03-01 16:58:57"}}, {"pk": 58, "model": "auth.user", "fields": {"username": "u59", "first_name": "Daniel Swan", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 12:23:30", "groups": [], "user_permissions": [], "password": "", "email": "d.c.swan@gmail.com", "date_joined": "2010-03-01 17:03:24"}}, {"pk": 59, "model": "auth.user", "fields": {"username": "u60", "first_name": "lukfor", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-04-23 12:38:38", "groups": [], "user_permissions": [], "password": "", "email": "lukas@forer.net", "date_joined": "2010-03-01 19:18:00"}}, {"pk": 60, "model": "auth.user", "fields": {"username": "u61", "first_name": "Chris Fields", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-15 19:18:52", "groups": [], "user_permissions": [], "password": "", "email": "cjfields@bioperl.org", "date_joined": "2010-03-02 05:11:16"}}, {"pk": 61, "model": "auth.user", "fields": {"username": "u62", "first_name": "darked89", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-09 14:24:34", "groups": [], "user_permissions": [], "password": "", "email": "u62", "date_joined": "2010-03-02 10:25:56"}}, {"pk": 62, "model": "auth.user", "fields": {"username": "u63", "first_name": "lmartinho", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-03-18 10:15:05", "groups": [], "user_permissions": [], "password": "", "email": "lmartinho@gmail.com", "date_joined": "2010-03-03 00:34:39"}}, {"pk": 63, "model": "auth.user", "fields": {"username": "u64", "first_name": "Manuel Corpas", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-30 15:53:26", "groups": [], "user_permissions": [], "password": "", "email": "mc@manuelcorpas.com", "date_joined": "2010-03-03 17:17:23"}}, {"pk": 64, "model": "auth.user", "fields": {"username": "u65", "first_name": "Abhishek Tiwari", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-24 08:41:17", "groups": [], "user_permissions": [], "password": "", "email": "abhishek.twr@gmail.com", "date_joined": "2010-03-03 21:18:31"}}, {"pk": 65, "model": "auth.user", "fields": {"username": "u66", "first_name": "neilfws", "last_name": "", "is_active": true, "is_superuser": true, "is_staff": true, "last_login": "2011-11-23 01:27:43", "groups": [], "user_permissions": [], "password": "", "email": "neilfws@gmail.com", "date_joined": "2010-03-04 07:55:19"}}, {"pk": 66, "model": "auth.user", "fields": {"username": "u67", "first_name": "Piotr Byzia", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-08 18:08:29", "groups": [], "user_permissions": [], "password": "", "email": "piotr.byzia@gmail.com", "date_joined": "2010-03-04 09:00:00"}}, {"pk": 67, "model": "auth.user", "fields": {"username": "u68", "first_name": "Jeroen Van Goey", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-13 21:29:52", "groups": [], "user_permissions": [], "password": "", "email": "jeroen.vangoey@gmail.com", "date_joined": "2010-03-04 09:23:54"}}, {"pk": 68, "model": "auth.user", "fields": {"username": "u69", "first_name": "Vince", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-14 20:09:57", "groups": [], "user_permissions": [], "password": "", "email": "vsbuffalo@gmail.com", "date_joined": "2010-03-04 09:49:54"}}, {"pk": 69, "model": "auth.user", "fields": {"username": "u70", "first_name": "Tom Walsh", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 15:29:35", "groups": [], "user_permissions": [], "password": "", "email": "walshtp@gmail.com", "date_joined": "2010-03-04 12:26:30"}}, {"pk": 70, "model": "auth.user", "fields": {"username": "u71", "first_name": "Egon Willighagen", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 11:36:24", "groups": [], "user_permissions": [], "password": "", "email": "egon.willighagen@gmail.com", "date_joined": "2010-03-04 15:17:25"}}, {"pk": 71, "model": "auth.user", "fields": {"username": "u72", "first_name": "mndoci", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-19 08:00:08", "groups": [], "user_permissions": [], "password": "", "email": "mndoci@mndoci.com", "date_joined": "2010-03-04 15:17:55"}}, {"pk": 72, "model": "auth.user", "fields": {"username": "u73", "first_name": "Jeremy Leipzig", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-23 01:26:56", "groups": [], "user_permissions": [], "password": "", "email": "leipzig@gmail.com", "date_joined": "2010-03-04 15:31:15"}}, {"pk": 73, "model": "auth.user", "fields": {"username": "u74", "first_name": "mmarchin", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 19:52:03", "groups": [], "user_permissions": [], "password": "", "email": "madelaine@gmail.com", "date_joined": "2010-03-04 15:35:18"}}, {"pk": 74, "model": "auth.user", "fields": {"username": "u75", "first_name": "Paolo", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-11 12:44:33", "groups": [], "user_permissions": [], "password": "", "email": "paolo.sonego@gmail.com", "date_joined": "2010-03-04 16:33:40"}}, {"pk": 75, "model": "auth.user", "fields": {"username": "u76", "first_name": "Andrew", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-26 14:55:47", "groups": [], "user_permissions": [], "password": "", "email": "yee@post.harvard.edu", "date_joined": "2010-03-04 16:42:20"}}, {"pk": 76, "model": "auth.user", "fields": {"username": "u77", "first_name": "Eleanor Howe", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-13 20:55:19", "groups": [], "user_permissions": [], "password": "", "email": "eleanorahowe@gmail.com", "date_joined": "2010-03-04 16:53:55"}}, {"pk": 77, "model": "auth.user", "fields": {"username": "u78", "first_name": "JBoveda", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-20 23:56:49", "groups": [], "user_permissions": [], "password": "", "email": "jose.boveda@gmail.com", "date_joined": "2010-03-04 18:05:38"}}, {"pk": 78, "model": "auth.user", "fields": {"username": "u79", "first_name": "Tim", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-15 15:26:22", "groups": [], "user_permissions": [], "password": "", "email": "timtebeek@gmail.com", "date_joined": "2010-03-04 18:08:31"}}, {"pk": 79, "model": "auth.user", "fields": {"username": "u80", "first_name": "Daniel Jurczak", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-16 15:03:23", "groups": [], "user_permissions": [], "password": "", "email": "danjurczak@gmail.com", "date_joined": "2010-03-04 18:30:00"}}, {"pk": 80, "model": "auth.user", "fields": {"username": "u81", "first_name": "User 81", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-22 18:28:10", "groups": [], "user_permissions": [], "password": "", "email": "u81", "date_joined": "2010-03-04 19:06:35"}}, {"pk": 81, "model": "auth.user", "fields": {"username": "u82", "first_name": "geoffjentry", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-06-16 18:05:52", "groups": [], "user_permissions": [], "password": "", "email": "u82", "date_joined": "2010-03-04 19:56:05"}}, {"pk": 82, "model": "auth.user", "fields": {"username": "u83", "first_name": "User 83", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-18 17:41:22", "groups": [], "user_permissions": [], "password": "", "email": "u83", "date_joined": "2010-03-04 20:11:58"}}, {"pk": 83, "model": "auth.user", "fields": {"username": "u84", "first_name": "anshu", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-12 15:52:48", "groups": [], "user_permissions": [], "password": "", "email": "u84", "date_joined": "2010-03-04 20:36:50"}}, {"pk": 84, "model": "auth.user", "fields": {"username": "u85", "first_name": "Bryan Maloney", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-04 20:49:12", "groups": [], "user_permissions": [], "password": "", "email": "man_of_maggie@yahoo.com", "date_joined": "2010-03-04 20:49:12"}}, {"pk": 85, "model": "auth.user", "fields": {"username": "u86", "first_name": "Andrew Su", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-19 00:57:14", "groups": [], "user_permissions": [], "password": "", "email": "asu@scripps.edu", "date_joined": "2010-03-04 23:27:54"}}, {"pk": 86, "model": "auth.user", "fields": {"username": "u87", "first_name": "Khader Shameer", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 22:37:12", "groups": [], "user_permissions": [], "password": "", "email": "skhadar@gmail.com", "date_joined": "2010-03-05 02:42:56"}}, {"pk": 87, "model": "auth.user", "fields": {"username": "u88", "first_name": "Pierre", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-06 12:37:42", "groups": [], "user_permissions": [], "password": "", "email": "pierre.luisi@upf.edu", "date_joined": "2010-03-05 15:59:48"}}, {"pk": 88, "model": "auth.user", "fields": {"username": "u89", "first_name": "Yuri", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-14 15:12:11", "groups": [], "user_permissions": [], "password": "", "email": "yuk4pub@gmail.com", "date_joined": "2010-03-06 01:42:33"}}, {"pk": 89, "model": "auth.user", "fields": {"username": "u90", "first_name": "allPowerde", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-16 23:06:49", "groups": [], "user_permissions": [], "password": "", "email": "gravatar@allpower.de", "date_joined": "2010-03-06 05:12:19"}}, {"pk": 90, "model": "auth.user", "fields": {"username": "u91", "first_name": "Mikael Huss", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 23:49:32", "groups": [], "user_permissions": [], "password": "", "email": "mikael.huss@gmail.com", "date_joined": "2010-03-06 14:53:00"}}, {"pk": 91, "model": "auth.user", "fields": {"username": "u92", "first_name": "Perry", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-13 17:41:02", "groups": [], "user_permissions": [], "password": "", "email": "evansjp@mail.med.upenn.edu", "date_joined": "2010-03-06 15:35:50"}}, {"pk": 92, "model": "auth.user", "fields": {"username": "u93", "first_name": "User 93", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-06 16:01:05", "groups": [], "user_permissions": [], "password": "", "email": "u93", "date_joined": "2010-03-06 16:01:05"}}, {"pk": 93, "model": "auth.user", "fields": {"username": "u94", "first_name": "Nir London", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-13 09:58:45", "groups": [], "user_permissions": [], "password": "", "email": "nir@rosettadesigngroup.com", "date_joined": "2010-03-06 17:26:09"}}, {"pk": 94, "model": "auth.user", "fields": {"username": "u95", "first_name": "BioInfo", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-15 21:19:41", "groups": [], "user_permissions": [], "password": "", "email": "jjohnson@edgebio.com", "date_joined": "2010-03-06 17:49:08"}}, {"pk": 95, "model": "auth.user", "fields": {"username": "u96", "first_name": "JC", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-14 18:10:50", "groups": [], "user_permissions": [], "password": "", "email": "jchen1981@gmail.com", "date_joined": "2010-03-06 18:07:27"}}, {"pk": 96, "model": "auth.user", "fields": {"username": "u97", "first_name": "Michael Hoffman", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-27 21:33:36", "groups": [], "user_permissions": [], "password": "", "email": "e32z5jbg3v@snkmail.com", "date_joined": "2010-03-06 18:14:15"}}, {"pk": 97, "model": "auth.user", "fields": {"username": "u98", "first_name": "Nancy Parmalee", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-13 16:41:08", "groups": [], "user_permissions": [], "password": "", "email": "nlp2104@columbia.edu", "date_joined": "2010-03-06 18:20:20"}}, {"pk": 98, "model": "auth.user", "fields": {"username": "u99", "first_name": "avilella", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 20:08:25", "groups": [], "user_permissions": [], "password": "", "email": "avilella@gmail.com", "date_joined": "2010-03-06 18:20:28"}}, {"pk": 99, "model": "auth.user", "fields": {"username": "u100", "first_name": "Ryan", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-06 19:03:07", "groups": [], "user_permissions": [], "password": "", "email": "ryan59361@gmail.com", "date_joined": "2010-03-06 19:03:07"}}, {"pk": 100, "model": "auth.user", "fields": {"username": "u101", "first_name": "ruphos", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-01 23:56:07", "groups": [], "user_permissions": [], "password": "", "email": "apokruphos@gmail.com", "date_joined": "2010-03-06 19:10:15"}}, {"pk": 101, "model": "auth.user", "fields": {"username": "u102", "first_name": "John Davey", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-07 20:31:44", "groups": [], "user_permissions": [], "password": "", "email": "johnomics@gmail.com", "date_joined": "2010-03-07 00:14:37"}}, {"pk": 102, "model": "auth.user", "fields": {"username": "u103", "first_name": "hongiiv", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-01-03 09:34:57", "groups": [], "user_permissions": [], "password": "", "email": "hongiiv@gmail.com", "date_joined": "2010-03-07 09:35:10"}}, {"pk": 103, "model": "auth.user", "fields": {"username": "u104", "first_name": "mfenner", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-07 09:45:45", "groups": [], "user_permissions": [], "password": "", "email": "fenner.martin@mh-hannover.de", "date_joined": "2010-03-07 09:45:45"}}, {"pk": 104, "model": "auth.user", "fields": {"username": "u105", "first_name": "Dan", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-19 23:37:48", "groups": [], "user_permissions": [], "password": "", "email": "dan.bolser@gmail.com", "date_joined": "2010-03-07 12:52:52"}}, {"pk": 105, "model": "auth.user", "fields": {"username": "u106", "first_name": "Sujai Kumar", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-18 10:20:20", "groups": [], "user_permissions": [], "password": "", "email": "sujaikumar@gmail.com", "date_joined": "2010-03-07 16:09:44"}}, {"pk": 106, "model": "auth.user", "fields": {"username": "u107", "first_name": "Eric", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-05 16:48:29", "groups": [], "user_permissions": [], "password": "", "email": "suchire@gmail.com", "date_joined": "2010-03-07 19:56:46"}}, {"pk": 107, "model": "auth.user", "fields": {"username": "u108", "first_name": "Konrad", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-04-06 10:36:28", "groups": [], "user_permissions": [], "password": "", "email": "konrad_rudolph@madrat.net", "date_joined": "2010-03-07 23:34:37"}}, {"pk": 108, "model": "auth.user", "fields": {"username": "u109", "first_name": "Martijn van Iersel", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-25 16:12:53", "groups": [], "user_permissions": [], "password": "", "email": "mvaniersel@gmail.com", "date_joined": "2010-03-08 11:15:39"}}, {"pk": 109, "model": "auth.user", "fields": {"username": "u110", "first_name": "Sashi Kiran Challa", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-18 21:32:39", "groups": [], "user_permissions": [], "password": "", "email": "cr.sashikiran@gmail.com", "date_joined": "2010-03-08 12:36:22"}}, {"pk": 110, "model": "auth.user", "fields": {"username": "u111", "first_name": "User 111", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-15 09:35:54", "groups": [], "user_permissions": [], "password": "", "email": "u111", "date_joined": "2010-03-08 16:57:24"}}, {"pk": 111, "model": "auth.user", "fields": {"username": "u112", "first_name": "Walter Jessen", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-05 19:29:17", "groups": [], "user_permissions": [], "password": "", "email": "walter@walterjessen.com", "date_joined": "2010-03-08 19:09:20"}}, {"pk": 112, "model": "auth.user", "fields": {"username": "u113", "first_name": "jmanning2k", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-15 18:44:00", "groups": [], "user_permissions": [], "password": "", "email": "jmanning2k@gmail.com", "date_joined": "2010-03-08 19:17:31"}}, {"pk": 113, "model": "auth.user", "fields": {"username": "u114", "first_name": "gotgenes", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-21 18:19:30", "groups": [], "user_permissions": [], "password": "", "email": "chris.lasher@gmail.com", "date_joined": "2010-03-08 20:05:10"}}, {"pk": 114, "model": "auth.user", "fields": {"username": "u115", "first_name": "Jan van Haarst", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 09:33:00", "groups": [], "user_permissions": [], "password": "", "email": "jan.vanhaarst@wur.nl", "date_joined": "2010-03-08 21:07:49"}}, {"pk": 115, "model": "auth.user", "fields": {"username": "u116", "first_name": "Melanie", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-02 22:16:38", "groups": [], "user_permissions": [], "password": "", "email": "melanie_renee_nelson@yahoo.com", "date_joined": "2010-03-08 22:08:45"}}, {"pk": 116, "model": "auth.user", "fields": {"username": "u117", "first_name": "Chris Miller", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 21:56:22", "groups": [], "user_permissions": [], "password": "", "email": "chrisamiller@gmail.com", "date_joined": "2010-03-09 04:59:55"}}, {"pk": 117, "model": "auth.user", "fields": {"username": "u118", "first_name": "enlavin", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-14 11:57:04", "groups": [], "user_permissions": [], "password": "", "email": "u118", "date_joined": "2010-03-09 08:44:42"}}, {"pk": 118, "model": "auth.user", "fields": {"username": "u119", "first_name": "PhiS", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 14:13:29", "groups": [], "user_permissions": [], "password": "", "email": "u119", "date_joined": "2010-03-09 12:02:41"}}, {"pk": 119, "model": "auth.user", "fields": {"username": "u120", "first_name": "CassJ", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-28 11:52:51", "groups": [], "user_permissions": [], "password": "", "email": "caroline.johnston@kcl.ac.uk", "date_joined": "2010-03-10 22:48:36"}}, {"pk": 120, "model": "auth.user", "fields": {"username": "u121", "first_name": "John", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 00:39:40", "groups": [], "user_permissions": [], "password": "", "email": "johncumbers@gmail.com", "date_joined": "2010-03-10 23:46:35"}}, {"pk": 121, "model": "auth.user", "fields": {"username": "u122", "first_name": "Will", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-08 04:29:17", "groups": [], "user_permissions": [], "password": "", "email": "judowill@gmail.com", "date_joined": "2010-03-11 00:56:37"}}, {"pk": 122, "model": "auth.user", "fields": {"username": "u123", "first_name": "Charles E. Grant", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-23 01:47:19", "groups": [], "user_permissions": [], "password": "", "email": "cegrant@u.washington.edu", "date_joined": "2010-03-11 19:32:40"}}, {"pk": 123, "model": "auth.user", "fields": {"username": "u124", "first_name": "Alex", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 16:47:15", "groups": [], "user_permissions": [], "password": "", "email": "ad3002@gmail.com", "date_joined": "2010-03-12 00:42:51"}}, {"pk": 124, "model": "auth.user", "fields": {"username": "u125", "first_name": "Tal Galili", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-02-04 15:31:20", "groups": [], "user_permissions": [], "password": "", "email": "tal.galili@gmail.com", "date_joined": "2010-03-12 13:49:05"}}, {"pk": 125, "model": "auth.user", "fields": {"username": "u126", "first_name": "Matt Parker", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-08 21:53:13", "groups": [], "user_permissions": [], "password": "", "email": "mattmparker@gmail.com", "date_joined": "2010-03-12 21:18:53"}}, {"pk": 126, "model": "auth.user", "fields": {"username": "u127", "first_name": "Paulo Nuin", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-13 13:56:29", "groups": [], "user_permissions": [], "password": "", "email": "nuin@genedrift.org", "date_joined": "2010-03-13 04:36:35"}}, {"pk": 127, "model": "auth.user", "fields": {"username": "u128", "first_name": "rvidal", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-19 15:18:27", "groups": [], "user_permissions": [], "password": "", "email": "rvidal@gmail.com", "date_joined": "2010-03-13 16:29:26"}}, {"pk": 128, "model": "auth.user", "fields": {"username": "u129", "first_name": "Andriyev", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-27 19:26:55", "groups": [], "user_permissions": [], "password": "", "email": "andriyev.aaron@gmail.com", "date_joined": "2010-03-13 16:39:39"}}, {"pk": 129, "model": "auth.user", "fields": {"username": "u130", "first_name": "User 130", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-20 03:17:55", "groups": [], "user_permissions": [], "password": "", "email": "u130", "date_joined": "2010-03-13 21:08:40"}}, {"pk": 130, "model": "auth.user", "fields": {"username": "u131", "first_name": "Rajarshi Guha", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 15:10:30", "groups": [], "user_permissions": [], "password": "", "email": "rajarshi.guha@gmail.com", "date_joined": "2010-03-14 16:23:01"}}, {"pk": 131, "model": "auth.user", "fields": {"username": "u132", "first_name": "pogonomyrmex", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-14 21:16:09", "groups": [], "user_permissions": [], "password": "", "email": "mate.zec@gmail.com", "date_joined": "2010-03-14 21:16:09"}}, {"pk": 132, "model": "auth.user", "fields": {"username": "u133", "first_name": "Keith", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-18 14:13:25", "groups": [], "user_permissions": [], "password": "", "email": "keithshep@gmail.com", "date_joined": "2010-03-14 21:16:48"}}, {"pk": 133, "model": "auth.user", "fields": {"username": "u134", "first_name": "Ben Blackburne", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-21 13:47:45", "groups": [], "user_permissions": [], "password": "", "email": "bpb@lysozyme.net", "date_joined": "2010-03-14 22:06:40"}}, {"pk": 134, "model": "auth.user", "fields": {"username": "u135", "first_name": "MarkF", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-23 00:26:25", "groups": [], "user_permissions": [], "password": "", "email": "mark.fiers.42@gmail.com", "date_joined": "2010-03-15 00:26:43"}}, {"pk": 135, "model": "auth.user", "fields": {"username": "u136", "first_name": "brandstaetter", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-31 08:12:51", "groups": [], "user_permissions": [], "password": "", "email": "gravatar@hannes.oib.com", "date_joined": "2010-03-15 07:05:27"}}, {"pk": 136, "model": "auth.user", "fields": {"username": "u137", "first_name": "othercriteria", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-15 18:34:54", "groups": [], "user_permissions": [], "password": "", "email": "othercriteria@gmail.com", "date_joined": "2010-03-15 11:31:25"}}, {"pk": 137, "model": "auth.user", "fields": {"username": "u138", "first_name": "Marcin Cieslik", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-07 15:21:41", "groups": [], "user_permissions": [], "password": "", "email": "mpc4p@virginia.edu", "date_joined": "2010-03-15 12:35:59"}}, {"pk": 138, "model": "auth.user", "fields": {"username": "u139", "first_name": "User 139", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-15 14:32:17", "groups": [], "user_permissions": [], "password": "", "email": "u139", "date_joined": "2010-03-15 14:32:17"}}, {"pk": 139, "model": "auth.user", "fields": {"username": "u140", "first_name": "fergycool", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-26 14:34:01", "groups": [], "user_permissions": [], "password": "", "email": "ferg@scotgate.org", "date_joined": "2010-03-15 16:29:21"}}, {"pk": 140, "model": "auth.user", "fields": {"username": "u141", "first_name": "Yannick Wurm", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-18 05:10:51", "groups": [], "user_permissions": [], "password": "", "email": "yannick.wurm@unil.ch", "date_joined": "2010-03-15 17:03:27"}}, {"pk": 141, "model": "auth.user", "fields": {"username": "u142", "first_name": "Fred FLECHE", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 06:27:17", "groups": [], "user_permissions": [], "password": "", "email": "frederic.fleche@gmail.com", "date_joined": "2010-03-15 21:45:56"}}, {"pk": 142, "model": "auth.user", "fields": {"username": "u143", "first_name": "User 143", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-06-10 10:35:04", "groups": [], "user_permissions": [], "password": "", "email": "satnam.surae@hotmail.co.uk", "date_joined": "2010-03-15 23:18:59"}}, {"pk": 143, "model": "auth.user", "fields": {"username": "u144", "first_name": "User 144", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-16 08:16:54", "groups": [], "user_permissions": [], "password": "", "email": "u144", "date_joined": "2010-03-16 08:16:54"}}, {"pk": 144, "model": "auth.user", "fields": {"username": "u145", "first_name": "Oli", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-18 09:18:37", "groups": [], "user_permissions": [], "password": "", "email": "olalonde@gmail.com", "date_joined": "2010-03-16 10:36:59"}}, {"pk": 145, "model": "auth.user", "fields": {"username": "u146", "first_name": "Peter", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-19 15:01:25", "groups": [], "user_permissions": [], "password": "", "email": "p.j.a.cock@googlemail.com", "date_joined": "2010-03-16 11:34:45"}}, {"pk": 146, "model": "auth.user", "fields": {"username": "u147", "first_name": "User 147", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-26 01:06:46", "groups": [], "user_permissions": [], "password": "", "email": "dilanste@gmail.com", "date_joined": "2010-03-16 20:49:01"}}, {"pk": 147, "model": "auth.user", "fields": {"username": "u148", "first_name": "Jarretinha", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-03 17:41:11", "groups": [], "user_permissions": [], "password": "", "email": "jarretinha@gmail.com", "date_joined": "2010-03-16 22:23:55"}}, {"pk": 148, "model": "auth.user", "fields": {"username": "u149", "first_name": "Ewan Birney", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-17 08:40:50", "groups": [], "user_permissions": [], "password": "", "email": "birney@ebi.ac.uk", "date_joined": "2010-03-17 08:40:50"}}, {"pk": 149, "model": "auth.user", "fields": {"username": "u150", "first_name": "User 150", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-07 16:32:55", "groups": [], "user_permissions": [], "password": "", "email": "u150", "date_joined": "2010-03-17 12:26:25"}}, {"pk": 150, "model": "auth.user", "fields": {"username": "u151", "first_name": "Jelle", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-10-12 13:02:00", "groups": [], "user_permissions": [], "password": "", "email": "j.scholtalbers@gmail.com", "date_joined": "2010-03-18 08:13:21"}}, {"pk": 151, "model": "auth.user", "fields": {"username": "u152", "first_name": "Rob Syme", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 06:41:39", "groups": [], "user_permissions": [], "password": "", "email": "rob.syme@gmail.com", "date_joined": "2010-03-19 03:05:06"}}, {"pk": 152, "model": "auth.user", "fields": {"username": "u153", "first_name": "Xtof", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-24 10:07:40", "groups": [], "user_permissions": [], "password": "", "email": "christophe.malabat@gmail.com", "date_joined": "2010-03-20 10:34:06"}}, {"pk": 153, "model": "auth.user", "fields": {"username": "u154", "first_name": "Kirsley", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-16 18:49:28", "groups": [], "user_permissions": [], "password": "", "email": "c.kirsley@yahoo.fr", "date_joined": "2010-03-20 10:45:51"}}, {"pk": 154, "model": "auth.user", "fields": {"username": "u155", "first_name": "User 155", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-20 12:38:17", "groups": [], "user_permissions": [], "password": "", "email": "u155", "date_joined": "2010-03-20 12:38:17"}}, {"pk": 155, "model": "auth.user", "fields": {"username": "u156", "first_name": "Joachim", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 14:35:16", "groups": [], "user_permissions": [], "password": "", "email": "joachim.baran@gmail.com", "date_joined": "2010-03-20 14:29:31"}}, {"pk": 156, "model": "auth.user", "fields": {"username": "u157", "first_name": "Magali Michaut", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-13 18:18:31", "groups": [], "user_permissions": [], "password": "", "email": "magali.michaut@iscb.org", "date_joined": "2010-03-21 17:27:14"}}, {"pk": 157, "model": "auth.user", "fields": {"username": "u158", "first_name": "User 158", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-11-15 14:35:24", "groups": [], "user_permissions": [], "password": "", "email": "u158", "date_joined": "2010-03-22 08:20:07"}}, {"pk": 158, "model": "auth.user", "fields": {"username": "u159", "first_name": "Fred", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 10:36:01", "groups": [], "user_permissions": [], "password": "", "email": "lemoine.frederic@gmail.com", "date_joined": "2010-03-22 08:29:14"}}, {"pk": 159, "model": "auth.user", "fields": {"username": "u160", "first_name": "Dave Gerrard", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-23 01:52:54", "groups": [], "user_permissions": [], "password": "", "email": "davetgerrard@gmail.com", "date_joined": "2010-03-22 09:23:49"}}, {"pk": 160, "model": "auth.user", "fields": {"username": "u161", "first_name": "Antony", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-22 16:00:35", "groups": [], "user_permissions": [], "password": "", "email": "antony.lebechec@uni.lu", "date_joined": "2010-03-22 10:30:54"}}, {"pk": 161, "model": "auth.user", "fields": {"username": "u162", "first_name": "dooguy", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-23 09:11:03", "groups": [], "user_permissions": [], "password": "", "email": "dooguy@gmail.com", "date_joined": "2010-03-22 13:45:23"}}, {"pk": 162, "model": "auth.user", "fields": {"username": "u163", "first_name": "handstad", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-28 10:50:48", "groups": [], "user_permissions": [], "password": "", "email": "tony.handstad@gmail.com", "date_joined": "2010-03-22 14:41:33"}}, {"pk": 163, "model": "auth.user", "fields": {"username": "u164", "first_name": "Roderic Page", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-15 12:37:27", "groups": [], "user_permissions": [], "password": "", "email": "r.page@bio.gla.ac.uk", "date_joined": "2010-03-22 17:43:40"}}, {"pk": 164, "model": "auth.user", "fields": {"username": "u165", "first_name": "User 165", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-22 20:21:07", "groups": [], "user_permissions": [], "password": "", "email": "u165", "date_joined": "2010-03-22 20:21:07"}}, {"pk": 165, "model": "auth.user", "fields": {"username": "u166", "first_name": "Joseph Hughes", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-23 02:02:11", "groups": [], "user_permissions": [], "password": "", "email": "hughes.joseph@gmail.com", "date_joined": "2010-03-23 14:29:45"}}, {"pk": 166, "model": "auth.user", "fields": {"username": "u167", "first_name": "DavidOSomething", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-02-04 03:07:15", "groups": [], "user_permissions": [], "password": "", "email": "awsoma@gmail.com", "date_joined": "2010-03-23 14:53:55"}}, {"pk": 167, "model": "auth.user", "fields": {"username": "u168", "first_name": "kraut", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-29 18:32:02", "groups": [], "user_permissions": [], "password": "", "email": "adamnkraut@gmail.com", "date_joined": "2010-03-23 18:00:55"}}, {"pk": 168, "model": "auth.user", "fields": {"username": "u169", "first_name": "Ian Simpson", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-19 16:05:18", "groups": [], "user_permissions": [], "password": "", "email": "ian.simpson@ed.ac.uk", "date_joined": "2010-03-23 22:58:53"}}, {"pk": 169, "model": "auth.user", "fields": {"username": "u170", "first_name": "Roman Valls Guimer\u00e0", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 16:26:23", "groups": [], "user_permissions": [], "password": "", "email": "brainstorm@nopcode.org", "date_joined": "2010-03-24 06:51:38"}}, {"pk": 170, "model": "auth.user", "fields": {"username": "u171", "first_name": "Jan Oosting", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-18 18:57:03", "groups": [], "user_permissions": [], "password": "", "email": "jan.oosting@gmail.com", "date_joined": "2010-03-24 08:59:49"}}, {"pk": 171, "model": "auth.user", "fields": {"username": "u172", "first_name": "Simon Penel", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-03-03 08:58:42", "groups": [], "user_permissions": [], "password": "", "email": "penel@biomserv.univ-lyon1.fr", "date_joined": "2010-03-24 09:09:02"}}, {"pk": 172, "model": "auth.user", "fields": {"username": "u173", "first_name": "Leo Goodstadt", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-09-01 13:59:38", "groups": [], "user_permissions": [], "password": "", "email": "ruffus@llew.org.uk", "date_joined": "2010-03-24 10:23:24"}}, {"pk": 173, "model": "auth.user", "fields": {"username": "u174", "first_name": "Tom", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-24 12:40:19", "groups": [], "user_permissions": [], "password": "", "email": "tomtubbs@mac.com", "date_joined": "2010-03-24 12:40:19"}}, {"pk": 174, "model": "auth.user", "fields": {"username": "u175", "first_name": "User 175", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-24 13:15:29", "groups": [], "user_permissions": [], "password": "", "email": "u175", "date_joined": "2010-03-24 13:15:29"}}, {"pk": 175, "model": "auth.user", "fields": {"username": "u176", "first_name": "noyk", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-31 15:02:30", "groups": [], "user_permissions": [], "password": "", "email": "kiekyon.huang@gmail.com", "date_joined": "2010-03-24 14:22:41"}}, {"pk": 176, "model": "auth.user", "fields": {"username": "u177", "first_name": "bertrand", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-31 11:19:06", "groups": [], "user_permissions": [], "password": "", "email": "bservin@gmail.com", "date_joined": "2010-03-24 14:44:20"}}, {"pk": 177, "model": "auth.user", "fields": {"username": "u178", "first_name": "Charles", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-16 12:38:59", "groups": [], "user_permissions": [], "password": "", "email": "charles.hefer@gmail.com", "date_joined": "2010-03-24 15:46:35"}}, {"pk": 178, "model": "auth.user", "fields": {"username": "u179", "first_name": "Scott", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-26 15:06:54", "groups": [], "user_permissions": [], "password": "", "email": "stjohnson@waketech.edu", "date_joined": "2010-03-24 16:00:03"}}, {"pk": 179, "model": "auth.user", "fields": {"username": "u180", "first_name": "Rutger Vos", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-24 20:46:40", "groups": [], "user_permissions": [], "password": "", "email": "rutgeraldo@gmail.com", "date_joined": "2010-03-24 20:46:40"}}, {"pk": 180, "model": "auth.user", "fields": {"username": "u181", "first_name": "Jukka Matilainen", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-25 10:03:52", "groups": [], "user_permissions": [], "password": "", "email": "jackem@gmail.com", "date_joined": "2010-03-24 21:03:27"}}, {"pk": 181, "model": "auth.user", "fields": {"username": "u182", "first_name": "agrimaldi", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-26 10:11:23", "groups": [], "user_permissions": [], "password": "", "email": "alexis.grimaldi@gmail.com", "date_joined": "2010-03-24 23:24:34"}}, {"pk": 182, "model": "auth.user", "fields": {"username": "u183", "first_name": "mt", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-05 20:21:27", "groups": [], "user_permissions": [], "password": "", "email": "mt@alum.mit.edu", "date_joined": "2010-03-25 00:02:13"}}, {"pk": 183, "model": "auth.user", "fields": {"username": "u184", "first_name": "Bosco Ho", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-23 14:35:03", "groups": [], "user_permissions": [], "password": "", "email": "apposite@gmail.com", "date_joined": "2010-03-25 03:40:45"}}, {"pk": 184, "model": "auth.user", "fields": {"username": "u185", "first_name": "noyk", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-05 07:49:30", "groups": [], "user_permissions": [], "password": "", "email": "kiekyon.huang@gmail.com", "date_joined": "2010-03-25 07:34:14"}}, {"pk": 185, "model": "auth.user", "fields": {"username": "u186", "first_name": "Emmanuelle Morin", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-12 16:11:01", "groups": [], "user_permissions": [], "password": "", "email": "u186", "date_joined": "2010-03-25 16:21:47"}}, {"pk": 186, "model": "auth.user", "fields": {"username": "u187", "first_name": "panos", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-13 23:01:20", "groups": [], "user_permissions": [], "password": "", "email": "panos.ioannidis@gmail.com", "date_joined": "2010-03-26 08:10:40"}}, {"pk": 187, "model": "auth.user", "fields": {"username": "u188", "first_name": "Kristian Rother", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-26 10:39:30", "groups": [], "user_permissions": [], "password": "", "email": "krother@rubor.de", "date_joined": "2010-03-26 10:39:30"}}, {"pk": 188, "model": "auth.user", "fields": {"username": "u189", "first_name": "Colin", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-07 08:05:05", "groups": [], "user_permissions": [], "password": "", "email": "colin.green57@ntlworld.com", "date_joined": "2010-03-26 11:22:59"}}, {"pk": 189, "model": "auth.user", "fields": {"username": "u190", "first_name": "User 190", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-26 16:55:58", "groups": [], "user_permissions": [], "password": "", "email": "u190", "date_joined": "2010-03-26 13:01:51"}}, {"pk": 190, "model": "auth.user", "fields": {"username": "u191", "first_name": "seidel", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 23:58:15", "groups": [], "user_permissions": [], "password": "", "email": "seidel@pangloss.com", "date_joined": "2010-03-27 06:05:01"}}, {"pk": 191, "model": "auth.user", "fields": {"username": "u192", "first_name": "selflessGene", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-23 18:46:22", "groups": [], "user_permissions": [], "password": "", "email": "djones@phoenixintlcapital.com", "date_joined": "2010-03-27 14:38:08"}}, {"pk": 192, "model": "auth.user", "fields": {"username": "u193", "first_name": "Burke Squires", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-15 15:56:40", "groups": [], "user_permissions": [], "password": "", "email": "burkesquires@gmail.com", "date_joined": "2010-03-28 02:09:10"}}, {"pk": 193, "model": "auth.user", "fields": {"username": "u194", "first_name": "Jeff  Kiefer", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-28 21:47:06", "groups": [], "user_permissions": [], "password": "", "email": "kiefer89@me.com", "date_joined": "2010-03-28 21:47:06"}}, {"pk": 194, "model": "auth.user", "fields": {"username": "u195", "first_name": "Gregor Rot", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 09:25:49", "groups": [], "user_permissions": [], "password": "", "email": "gregor.rot@gmail.com", "date_joined": "2010-03-29 07:12:11"}}, {"pk": 195, "model": "auth.user", "fields": {"username": "u196", "first_name": "swapnil", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-29 13:59:33", "groups": [], "user_permissions": [], "password": "", "email": "swamukh1985in@rediffmail.com", "date_joined": "2010-03-29 13:59:33"}}, {"pk": 196, "model": "auth.user", "fields": {"username": "u197", "first_name": "Jess", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-03-29 13:59:49", "groups": [], "user_permissions": [], "password": "", "email": "hs569@york.ac.uk", "date_joined": "2010-03-29 13:59:49"}}, {"pk": 197, "model": "auth.user", "fields": {"username": "u198", "first_name": "SB3", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-11 08:54:09", "groups": [], "user_permissions": [], "password": "", "email": "sbatty@gmail.com", "date_joined": "2010-03-29 14:42:37"}}, {"pk": 198, "model": "auth.user", "fields": {"username": "u199", "first_name": "tony", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 21:48:48", "groups": [], "user_permissions": [], "password": "", "email": "ferraria@gmail.com", "date_joined": "2010-03-30 13:01:11"}}, {"pk": 199, "model": "auth.user", "fields": {"username": "u200", "first_name": "biomed", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-15 18:36:22", "groups": [], "user_permissions": [], "password": "", "email": "msincan@gmail.com", "date_joined": "2010-03-31 03:23:33"}}, {"pk": 200, "model": "auth.user", "fields": {"username": "u201", "first_name": "susan", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-06 07:47:22", "groups": [], "user_permissions": [], "password": "", "email": "u201", "date_joined": "2010-03-31 06:17:29"}}, {"pk": 201, "model": "auth.user", "fields": {"username": "u202", "first_name": "darrenjw", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-02-21 17:06:27", "groups": [], "user_permissions": [], "password": "", "email": "darrenjwilkinson@btinternet.com", "date_joined": "2010-03-31 17:02:00"}}, {"pk": 202, "model": "auth.user", "fields": {"username": "u203", "first_name": "Adrian ", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 20:28:03", "groups": [], "user_permissions": [], "password": "", "email": "aheilbut@gmail.com", "date_joined": "2010-03-31 19:42:45"}}, {"pk": 203, "model": "auth.user", "fields": {"username": "u204", "first_name": "Cedric Dalmasso", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-02 14:57:24", "groups": [], "user_permissions": [], "password": "", "email": "cedric.dalmasso@activeeon.com", "date_joined": "2010-04-02 14:57:24"}}, {"pk": 204, "model": "auth.user", "fields": {"username": "u205", "first_name": "bilouweb", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 22:36:10", "groups": [], "user_permissions": [], "password": "", "email": "bilouweb@free.fr", "date_joined": "2010-04-02 21:50:33"}}, {"pk": 205, "model": "auth.user", "fields": {"username": "u206", "first_name": "ma_ko", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-01 00:51:07", "groups": [], "user_permissions": [], "password": "", "email": "ma.kohda@gmail.com", "date_joined": "2010-04-03 04:00:22"}}, {"pk": 206, "model": "auth.user", "fields": {"username": "u207", "first_name": "User 207", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-09 10:37:59", "groups": [], "user_permissions": [], "password": "", "email": "u207", "date_joined": "2010-04-05 16:40:26"}}, {"pk": 207, "model": "auth.user", "fields": {"username": "u208", "first_name": "Anthony Kong", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-31 01:08:55", "groups": [], "user_permissions": [], "password": "", "email": "u208", "date_joined": "2010-04-05 17:25:00"}}, {"pk": 208, "model": "auth.user", "fields": {"username": "u209", "first_name": "Vincent", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-05 19:06:40", "groups": [], "user_permissions": [], "password": "", "email": "vincent@vincentdavis.net", "date_joined": "2010-04-05 19:06:40"}}, {"pk": 209, "model": "auth.user", "fields": {"username": "u210", "first_name": "Tomasz", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-07 19:09:30", "groups": [], "user_permissions": [], "password": "", "email": "tomasz.adamusiak@gmail.com", "date_joined": "2010-04-06 09:32:48"}}, {"pk": 210, "model": "auth.user", "fields": {"username": "u211", "first_name": "Blackbox", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-06 12:05:16", "groups": [], "user_permissions": [], "password": "", "email": "u211", "date_joined": "2010-04-06 12:05:16"}}, {"pk": 211, "model": "auth.user", "fields": {"username": "u212", "first_name": "dma_k", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-06 19:27:28", "groups": [], "user_permissions": [], "password": "", "email": "dma_k@mail.ru", "date_joined": "2010-04-06 19:27:28"}}, {"pk": 212, "model": "auth.user", "fields": {"username": "u213", "first_name": "pansapiens", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-27 00:39:42", "groups": [], "user_permissions": [], "password": "", "email": "ajperry@pansapiens.com", "date_joined": "2010-04-07 07:01:34"}}, {"pk": 213, "model": "auth.user", "fields": {"username": "u214", "first_name": "Rob", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-06-16 05:45:11", "groups": [], "user_permissions": [], "password": "", "email": "robert@fearthecow.net", "date_joined": "2010-04-08 04:42:00"}}, {"pk": 214, "model": "auth.user", "fields": {"username": "u215", "first_name": "noyk", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-29 15:46:20", "groups": [], "user_permissions": [], "password": "", "email": "kiekyon.huang@gmail.com", "date_joined": "2010-04-08 11:36:06"}}, {"pk": 215, "model": "auth.user", "fields": {"username": "u216", "first_name": "Eric Normandeau", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-23 00:19:00", "groups": [], "user_permissions": [], "password": "", "email": "eric_normandeau@hotmail.com", "date_joined": "2010-04-08 16:30:37"}}, {"pk": 216, "model": "auth.user", "fields": {"username": "u217", "first_name": "Louis Letourneau", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-18 15:49:12", "groups": [], "user_permissions": [], "password": "", "email": "louis.letourneau@mail.mcgill.ca", "date_joined": "2010-04-08 18:21:40"}}, {"pk": 217, "model": "auth.user", "fields": {"username": "u218", "first_name": "Stew", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 14:51:57", "groups": [], "user_permissions": [], "password": "", "email": "stewart.macarthur@gmail.com", "date_joined": "2010-04-08 21:09:30"}}, {"pk": 218, "model": "auth.user", "fields": {"username": "u219", "first_name": "Tim Rayner", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-18 16:52:45", "groups": [], "user_permissions": [], "password": "", "email": "tfrayner@gmail.com", "date_joined": "2010-04-09 11:08:03"}}, {"pk": 219, "model": "auth.user", "fields": {"username": "u220", "first_name": "Ljxue", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-24 03:17:17", "groups": [], "user_permissions": [], "password": "", "email": "ljxue@sibs.ac.cn", "date_joined": "2010-04-11 07:38:00"}}, {"pk": 220, "model": "auth.user", "fields": {"username": "u222", "first_name": "Mehraj", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-12 14:18:44", "groups": [], "user_permissions": [], "password": "", "email": "mehrajv@yahoo.com", "date_joined": "2010-04-12 14:18:44"}}, {"pk": 221, "model": "auth.user", "fields": {"username": "u223", "first_name": "Daniel Standage", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 20:35:30", "groups": [], "user_permissions": [], "password": "", "email": "daniel.standage@gmail.com", "date_joined": "2010-04-12 17:18:46"}}, {"pk": 222, "model": "auth.user", "fields": {"username": "u224", "first_name": "Nico", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-10 14:00:05", "groups": [], "user_permissions": [], "password": "", "email": "nico.maillet@gmail.com", "date_joined": "2010-04-12 20:05:45"}}, {"pk": 223, "model": "auth.user", "fields": {"username": "u225", "first_name": "Fr\u00e9d\u00e9ric Mah\u00e9", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 18:59:00", "groups": [], "user_permissions": [], "password": "", "email": "frederic.mahe@sb-roscoff.fr", "date_joined": "2010-04-13 07:58:15"}}, {"pk": 224, "model": "auth.user", "fields": {"username": "u226", "first_name": "BioCh'ti", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 16:52:04", "groups": [], "user_permissions": [], "password": "", "email": "tophersurlenet@yahoo.fr", "date_joined": "2010-04-13 13:13:57"}}, {"pk": 225, "model": "auth.user", "fields": {"username": "u227", "first_name": "Dave Lunt", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 18:47:46", "groups": [], "user_permissions": [], "password": "", "email": "dave.lunt@gmail.com", "date_joined": "2010-04-13 13:56:05"}}, {"pk": 226, "model": "auth.user", "fields": {"username": "u228", "first_name": "User 228", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-13 19:56:41", "groups": [], "user_permissions": [], "password": "", "email": "u228", "date_joined": "2010-04-13 19:56:41"}}, {"pk": 227, "model": "auth.user", "fields": {"username": "u229", "first_name": "User 229", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-13 20:49:05", "groups": [], "user_permissions": [], "password": "", "email": "u229", "date_joined": "2010-04-13 20:49:05"}}, {"pk": 228, "model": "auth.user", "fields": {"username": "u230", "first_name": "Abhi", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-17 00:06:20", "groups": [], "user_permissions": [], "password": "", "email": "abhishek.vit@gmail.com", "date_joined": "2010-04-13 21:35:12"}}, {"pk": 229, "model": "auth.user", "fields": {"username": "u231", "first_name": "ratonfilo", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-12 22:14:23", "groups": [], "user_permissions": [], "password": "", "email": "wladimir@gmail.com", "date_joined": "2010-04-13 22:03:40"}}, {"pk": 230, "model": "auth.user", "fields": {"username": "u232", "first_name": "D W", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-04-04 20:48:25", "groups": [], "user_permissions": [], "password": "", "email": "denilw@yahoo.com", "date_joined": "2010-04-13 23:55:38"}}, {"pk": 231, "model": "auth.user", "fields": {"username": "u233", "first_name": "Jason Winget", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-15 05:06:52", "groups": [], "user_permissions": [], "password": "", "email": "jwinget@gmail.com", "date_joined": "2010-04-14 01:30:38"}}, {"pk": 232, "model": "auth.user", "fields": {"username": "u234", "first_name": "yvan", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-03-07 21:37:36", "groups": [], "user_permissions": [], "password": "", "email": "yvan.strahm@uni.no", "date_joined": "2010-04-14 07:03:16"}}, {"pk": 233, "model": "auth.user", "fields": {"username": "u235", "first_name": "Michael Kuhn", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 15:47:09", "groups": [], "user_permissions": [], "password": "", "email": "michael.kuhn@gmail.com", "date_joined": "2010-04-14 09:36:17"}}, {"pk": 234, "model": "auth.user", "fields": {"username": "u236", "first_name": "Nathan Harmston", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-06 12:07:53", "groups": [], "user_permissions": [], "password": "", "email": "iwanttobebadger@gmail.com", "date_joined": "2010-04-14 15:12:55"}}, {"pk": 235, "model": "auth.user", "fields": {"username": "u237", "first_name": "Asen Nenov", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-14 15:38:22", "groups": [], "user_permissions": [], "password": "", "email": "senski@gmail.com", "date_joined": "2010-04-14 15:38:22"}}, {"pk": 236, "model": "auth.user", "fields": {"username": "u238", "first_name": "alexa", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-14 15:47:37", "groups": [], "user_permissions": [], "password": "", "email": "u238", "date_joined": "2010-04-14 15:47:37"}}, {"pk": 237, "model": "auth.user", "fields": {"username": "u239", "first_name": "Zach Stednick", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 05:12:15", "groups": [], "user_permissions": [], "password": "", "email": "stednick@gmail.com", "date_joined": "2010-04-14 18:22:35"}}, {"pk": 238, "model": "auth.user", "fields": {"username": "u240", "first_name": "User 240", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-15 13:09:45", "groups": [], "user_permissions": [], "password": "", "email": "u240", "date_joined": "2010-04-15 13:09:45"}}, {"pk": 239, "model": "auth.user", "fields": {"username": "u241", "first_name": "xiechao", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-15 16:06:12", "groups": [], "user_permissions": [], "password": "", "email": "xiechaos@gmail.com", "date_joined": "2010-04-15 16:06:12"}}, {"pk": 240, "model": "auth.user", "fields": {"username": "u242", "first_name": "suhail", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-16 07:37:53", "groups": [], "user_permissions": [], "password": "", "email": "suhail_anwar_khan@yahoo.com", "date_joined": "2010-04-16 07:37:53"}}, {"pk": 241, "model": "auth.user", "fields": {"username": "u243", "first_name": "bow", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-01 21:08:14", "groups": [], "user_permissions": [], "password": "", "email": "w.arindrarto@gmail.com", "date_joined": "2010-04-16 08:26:18"}}, {"pk": 242, "model": "auth.user", "fields": {"username": "u244", "first_name": "Pedro Lopes", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-19 22:42:16", "groups": [], "user_permissions": [], "password": "", "email": "pdrlps@gmail.com", "date_joined": "2010-04-16 15:00:14"}}, {"pk": 243, "model": "auth.user", "fields": {"username": "u245", "first_name": "Alex", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-16 11:01:41", "groups": [], "user_permissions": [], "password": "", "email": "alejandrorojas2@gmail.com", "date_joined": "2010-04-16 19:16:35"}}, {"pk": 244, "model": "auth.user", "fields": {"username": "u246", "first_name": "Andreas", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-23 01:23:00", "groups": [], "user_permissions": [], "password": "", "email": "andreas.wilm@gmail.com", "date_joined": "2010-04-17 10:36:31"}}, {"pk": 245, "model": "auth.user", "fields": {"username": "u247", "first_name": "Leo Martins", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-19 18:00:43", "groups": [], "user_permissions": [], "password": "", "email": "leomrtns@gmail.com", "date_joined": "2010-04-17 19:09:10"}}, {"pk": 246, "model": "auth.user", "fields": {"username": "u248", "first_name": "User 248", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-19 14:04:24", "groups": [], "user_permissions": [], "password": "", "email": "u248", "date_joined": "2010-04-18 13:38:35"}}, {"pk": 247, "model": "auth.user", "fields": {"username": "u249", "first_name": "Ning-yi Shao", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 08:49:19", "groups": [], "user_permissions": [], "password": "", "email": "shaoningyi@gmail.com", "date_joined": "2010-04-18 15:17:34"}}, {"pk": 248, "model": "auth.user", "fields": {"username": "u250", "first_name": "ria", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-20 05:57:37", "groups": [], "user_permissions": [], "password": "", "email": "rias129@gmail.com", "date_joined": "2010-04-19 06:41:00"}}, {"pk": 249, "model": "auth.user", "fields": {"username": "u251", "first_name": "Barry Wark", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-04-18 16:50:21", "groups": [], "user_permissions": [], "password": "", "email": "barrywark@gmail.com", "date_joined": "2010-04-19 17:08:16"}}, {"pk": 250, "model": "auth.user", "fields": {"username": "u252", "first_name": "ChristianK", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-11-14 15:02:45", "groups": [], "user_permissions": [], "password": "", "email": "u252", "date_joined": "2010-04-19 17:57:53"}}, {"pk": 251, "model": "auth.user", "fields": {"username": "u253", "first_name": "Anar", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-30 23:25:40", "groups": [], "user_permissions": [], "password": "", "email": "anar.khan@agresearch.co.nz", "date_joined": "2010-04-19 20:13:25"}}, {"pk": 252, "model": "auth.user", "fields": {"username": "u254", "first_name": "Gurado", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-01 02:29:37", "groups": [], "user_permissions": [], "password": "", "email": "gurado@gmx.de", "date_joined": "2010-04-20 03:33:07"}}, {"pk": 253, "model": "auth.user", "fields": {"username": "u255", "first_name": "Samat", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-04 03:30:34", "groups": [], "user_permissions": [], "password": "", "email": "samat@samat.org", "date_joined": "2010-04-20 03:36:26"}}, {"pk": 254, "model": "auth.user", "fields": {"username": "u256", "first_name": "Gentle Yang", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-25 09:56:00", "groups": [], "user_permissions": [], "password": "", "email": "nodexy@gmail.com", "date_joined": "2010-04-20 03:47:51"}}, {"pk": 255, "model": "auth.user", "fields": {"username": "u257", "first_name": "Markus Krupp", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 10:36:42", "groups": [], "user_permissions": [], "password": "", "email": "markus.krupp@unimedizin-mainz.de", "date_joined": "2010-04-20 08:22:14"}}, {"pk": 256, "model": "auth.user", "fields": {"username": "u258", "first_name": "jvb", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 13:29:19", "groups": [], "user_permissions": [], "password": "", "email": "jvb@cs.nott.ac.uk", "date_joined": "2010-04-20 08:49:40"}}, {"pk": 257, "model": "auth.user", "fields": {"username": "u259", "first_name": "Paul Gardner", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-23 01:40:26", "groups": [], "user_permissions": [], "password": "", "email": "ppgardner@gmail.com", "date_joined": "2010-04-20 11:59:58"}}, {"pk": 258, "model": "auth.user", "fields": {"username": "u260", "first_name": "User 260", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-20 21:11:24", "groups": [], "user_permissions": [], "password": "", "email": "u260", "date_joined": "2010-04-20 21:11:24"}}, {"pk": 259, "model": "auth.user", "fields": {"username": "u261", "first_name": "conny", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-11 19:18:23", "groups": [], "user_permissions": [], "password": "", "email": "u261", "date_joined": "2010-04-20 22:23:51"}}, {"pk": 260, "model": "auth.user", "fields": {"username": "u262", "first_name": "nakao", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-06 09:14:37", "groups": [], "user_permissions": [], "password": "", "email": "mitsuteru.nakao@gmail.com", "date_joined": "2010-04-21 06:36:03"}}, {"pk": 261, "model": "auth.user", "fields": {"username": "u263", "first_name": "Nate", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-21 16:00:55", "groups": [], "user_permissions": [], "password": "", "email": "n.r.street@gmail.com", "date_joined": "2010-04-21 16:00:55"}}, {"pk": 262, "model": "auth.user", "fields": {"username": "u264", "first_name": "Tim", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-24 11:14:10", "groups": [], "user_permissions": [], "password": "", "email": "kollinz55@hotmail.com", "date_joined": "2010-04-22 08:39:45"}}, {"pk": 263, "model": "auth.user", "fields": {"username": "u265", "first_name": "Nagarajan Paramasivam", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 18:06:28", "groups": [], "user_permissions": [], "password": "", "email": "naga.rna@gmail.com", "date_joined": "2010-04-22 17:27:47"}}, {"pk": 264, "model": "auth.user", "fields": {"username": "u266", "first_name": "Paul Tang", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-02-21 17:12:38", "groups": [], "user_permissions": [], "password": "", "email": "tanglingfung@gmail.com", "date_joined": "2010-04-22 17:46:35"}}, {"pk": 265, "model": "auth.user", "fields": {"username": "u267", "first_name": "malcolm.cook", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 03:55:48", "groups": [], "user_permissions": [], "password": "", "email": "malcolm.cook@gmail.com", "date_joined": "2010-04-23 01:06:32"}}, {"pk": 266, "model": "auth.user", "fields": {"username": "u268", "first_name": "Adam Ewing", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-29 17:07:12", "groups": [], "user_permissions": [], "password": "", "email": "adam.ewing@gmail.com", "date_joined": "2010-04-23 02:04:44"}}, {"pk": 267, "model": "auth.user", "fields": {"username": "u269", "first_name": "wishva", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-16 08:22:31", "groups": [], "user_permissions": [], "password": "", "email": "wishvamalli@gmail.com", "date_joined": "2010-04-23 04:09:14"}}, {"pk": 268, "model": "auth.user", "fields": {"username": "u270", "first_name": "Nico", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 18:43:26", "groups": [], "user_permissions": [], "password": "", "email": "u270", "date_joined": "2010-04-23 14:37:42"}}, {"pk": 269, "model": "auth.user", "fields": {"username": "u271", "first_name": "User 271", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-03-25 09:14:38", "groups": [], "user_permissions": [], "password": "", "email": "u271", "date_joined": "2010-04-23 15:36:54"}}, {"pk": 270, "model": "auth.user", "fields": {"username": "u272", "first_name": "Heather Piwowar", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-09 18:58:12", "groups": [], "user_permissions": [], "password": "", "email": "hpiwowar@gmail.com", "date_joined": "2010-04-24 14:16:15"}}, {"pk": 271, "model": "auth.user", "fields": {"username": "u273", "first_name": "Jean-Claude Bradley", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-26 13:13:39", "groups": [], "user_permissions": [], "password": "", "email": "bradlejc@drexel.edu", "date_joined": "2010-04-24 19:02:59"}}, {"pk": 272, "model": "auth.user", "fields": {"username": "u274", "first_name": "Amro", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-21 21:11:10", "groups": [], "user_permissions": [], "password": "", "email": "amroamroamro@gmail.com", "date_joined": "2010-04-25 18:11:42"}}, {"pk": 273, "model": "auth.user", "fields": {"username": "u275", "first_name": "Haibao Tang", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 16:16:55", "groups": [], "user_permissions": [], "password": "", "email": "tanghaibao@gmail.com", "date_joined": "2010-04-25 19:25:40"}}, {"pk": 274, "model": "auth.user", "fields": {"username": "u276", "first_name": "Casbon", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-11 18:46:05", "groups": [], "user_permissions": [], "password": "", "email": "casbon@gmail.com", "date_joined": "2010-04-26 09:25:16"}}, {"pk": 275, "model": "auth.user", "fields": {"username": "u277", "first_name": "cboettig", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-31 21:03:48", "groups": [], "user_permissions": [], "password": "", "email": "cboettig@gmail.com", "date_joined": "2010-04-26 17:28:48"}}, {"pk": 276, "model": "auth.user", "fields": {"username": "u278", "first_name": "John Eargle", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-28 17:38:05", "groups": [], "user_permissions": [], "password": "", "email": "u278", "date_joined": "2010-04-26 18:18:19"}}, {"pk": 277, "model": "auth.user", "fields": {"username": "u279", "first_name": "Abhiman", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-04 16:29:25", "groups": [], "user_permissions": [], "password": "", "email": "abhi13yagna@gmail.com", "date_joined": "2010-04-26 20:07:32"}}, {"pk": 278, "model": "auth.user", "fields": {"username": "u280", "first_name": "cupton", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-26 22:14:40", "groups": [], "user_permissions": [], "password": "", "email": "cupton@uvic.ca", "date_joined": "2010-04-26 22:14:40"}}, {"pk": 279, "model": "auth.user", "fields": {"username": "u281", "first_name": "kaiw", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-26 03:53:21", "groups": [], "user_permissions": [], "password": "", "email": "kai.willadsen@gmail.com", "date_joined": "2010-04-27 05:01:10"}}, {"pk": 280, "model": "auth.user", "fields": {"username": "u282", "first_name": "echo", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-04-04 13:17:33", "groups": [], "user_permissions": [], "password": "", "email": "echowuhao@gmail.com", "date_joined": "2010-04-28 03:26:46"}}, {"pk": 281, "model": "auth.user", "fields": {"username": "u283", "first_name": "Wilka", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-29 11:07:12", "groups": [], "user_permissions": [], "password": "", "email": "wilka.hudson@gmail.com", "date_joined": "2010-04-28 09:57:49"}}, {"pk": 282, "model": "auth.user", "fields": {"username": "u284", "first_name": "KurtB", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-28 13:40:52", "groups": [], "user_permissions": [], "password": "", "email": "u284", "date_joined": "2010-04-28 13:40:52"}}, {"pk": 283, "model": "auth.user", "fields": {"username": "u285", "first_name": "OMathew", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-01 09:36:12", "groups": [], "user_permissions": [], "password": "", "email": "oommenkm@gmail.com", "date_joined": "2010-04-28 18:01:04"}}, {"pk": 284, "model": "auth.user", "fields": {"username": "u286", "first_name": "Ryan Thompson", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-19 02:50:44", "groups": [], "user_permissions": [], "password": "", "email": "rct+biostar@thompsonclan.org", "date_joined": "2010-04-29 03:08:20"}}, {"pk": 285, "model": "auth.user", "fields": {"username": "u287", "first_name": "HOB", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-29 06:06:38", "groups": [], "user_permissions": [], "password": "", "email": "1232@gmail.com", "date_joined": "2010-04-29 06:06:38"}}, {"pk": 286, "model": "auth.user", "fields": {"username": "u288", "first_name": "Sean Davis", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 23:29:28", "groups": [], "user_permissions": [], "password": "", "email": "seandavi@gmail.com", "date_joined": "2010-04-29 12:37:32"}}, {"pk": 287, "model": "auth.user", "fields": {"username": "u289", "first_name": "psilva", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-30 21:50:44", "groups": [], "user_permissions": [], "password": "", "email": "pedro.alex.silva@gmail.com", "date_joined": "2010-04-29 17:27:37"}}, {"pk": 288, "model": "auth.user", "fields": {"username": "u290", "first_name": "User 290", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-30 08:34:20", "groups": [], "user_permissions": [], "password": "", "email": "u290", "date_joined": "2010-04-30 08:34:20"}}, {"pk": 289, "model": "auth.user", "fields": {"username": "u291", "first_name": "User 291", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-18 09:23:12", "groups": [], "user_permissions": [], "password": "", "email": "malross@gmail.com", "date_joined": "2010-04-30 14:34:33"}}, {"pk": 290, "model": "auth.user", "fields": {"username": "u292", "first_name": "heuermh", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-04-30 21:34:38", "groups": [], "user_permissions": [], "password": "", "email": "u292", "date_joined": "2010-04-30 21:03:48"}}, {"pk": 291, "model": "auth.user", "fields": {"username": "u293", "first_name": "Tam\u00e1s", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-12-14 18:27:09", "groups": [], "user_permissions": [], "password": "", "email": "ntamas@gmail.com", "date_joined": "2010-05-01 09:57:35"}}, {"pk": 292, "model": "auth.user", "fields": {"username": "u294", "first_name": "User 294", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-01 10:46:08", "groups": [], "user_permissions": [], "password": "", "email": "u294", "date_joined": "2010-05-01 10:46:08"}}, {"pk": 293, "model": "auth.user", "fields": {"username": "u295", "first_name": "zacharyvoase", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-03 00:12:39", "groups": [], "user_permissions": [], "password": "", "email": "z@zacharyvoase.com", "date_joined": "2010-05-03 00:12:39"}}, {"pk": 294, "model": "auth.user", "fields": {"username": "u297", "first_name": "cotsapas", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-02 05:34:56", "groups": [], "user_permissions": [], "password": "", "email": "cotsapas@gmail.com", "date_joined": "2010-05-03 17:09:16"}}, {"pk": 295, "model": "auth.user", "fields": {"username": "u298", "first_name": "jschnable", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-04 19:32:59", "groups": [], "user_permissions": [], "password": "", "email": "jschnable@berkeley.edu", "date_joined": "2010-05-04 01:34:17"}}, {"pk": 296, "model": "auth.user", "fields": {"username": "u299", "first_name": "behindtherabbit", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-01 18:01:34", "groups": [], "user_permissions": [], "password": "", "email": "driscoll451@gmail.com", "date_joined": "2010-05-04 14:10:00"}}, {"pk": 297, "model": "auth.user", "fields": {"username": "u300", "first_name": "kmejia", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-20 13:20:47", "groups": [], "user_permissions": [], "password": "", "email": "bioquimicamk@gmail.com", "date_joined": "2010-05-04 18:14:20"}}, {"pk": 298, "model": "auth.user", "fields": {"username": "u301", "first_name": "JoshM", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-18 21:56:49", "groups": [], "user_permissions": [], "password": "", "email": "joshua.n.miller@gmail.com", "date_joined": "2010-05-05 18:34:17"}}, {"pk": 299, "model": "auth.user", "fields": {"username": "u302", "first_name": "Mike Dewar", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-12-26 04:53:25", "groups": [], "user_permissions": [], "password": "", "email": "mike.dewar@columbia.edu", "date_joined": "2010-05-05 18:43:25"}}, {"pk": 300, "model": "auth.user", "fields": {"username": "u303", "first_name": "Girma", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-14 10:02:15", "groups": [], "user_permissions": [], "password": "", "email": "u303", "date_joined": "2010-05-05 20:01:54"}}, {"pk": 301, "model": "auth.user", "fields": {"username": "u304", "first_name": "Vlinxify", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-01-07 21:47:34", "groups": [], "user_permissions": [], "password": "", "email": "gtstarted120@gmail.com", "date_joined": "2010-05-05 23:59:31"}}, {"pk": 302, "model": "auth.user", "fields": {"username": "u305", "first_name": "harley", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-06 01:30:38", "groups": [], "user_permissions": [], "password": "", "email": "cutie235689@yahoo.com", "date_joined": "2010-05-06 01:30:38"}}, {"pk": 303, "model": "auth.user", "fields": {"username": "u306", "first_name": "Aaron Statham", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-23 01:48:14", "groups": [], "user_permissions": [], "password": "", "email": "aaron.l.statham@gmail.com", "date_joined": "2010-05-06 09:45:44"}}, {"pk": 304, "model": "auth.user", "fields": {"username": "u307", "first_name": "barjaron", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-08 03:58:33", "groups": [], "user_permissions": [], "password": "", "email": "burak_kutlu@yahoo.com", "date_joined": "2010-05-06 16:09:02"}}, {"pk": 305, "model": "auth.user", "fields": {"username": "u308", "first_name": "gawp", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 15:39:28", "groups": [], "user_permissions": [], "password": "", "email": "gpalidwor@yahoo.com", "date_joined": "2010-05-06 22:48:49"}}, {"pk": 306, "model": "auth.user", "fields": {"username": "u309", "first_name": "biosidd", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-18 03:03:33", "groups": [], "user_permissions": [], "password": "", "email": "biosidd@gmail.com", "date_joined": "2010-05-08 02:45:57"}}, {"pk": 307, "model": "auth.user", "fields": {"username": "u310", "first_name": "shilda", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-24 18:18:16", "groups": [], "user_permissions": [], "password": "", "email": "shilda.bioinfo@gmail.com", "date_joined": "2010-05-08 14:22:40"}}, {"pk": 308, "model": "auth.user", "fields": {"username": "u311", "first_name": "Michiel de Hoon", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-15 11:00:17", "groups": [], "user_permissions": [], "password": "", "email": "mjldehoon@yahoo.com", "date_joined": "2010-05-09 07:18:15"}}, {"pk": 309, "model": "auth.user", "fields": {"username": "u312", "first_name": "harsh", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-10 06:14:57", "groups": [], "user_permissions": [], "password": "", "email": "harshob@gmail.com", "date_joined": "2010-05-10 06:14:57"}}, {"pk": 310, "model": "auth.user", "fields": {"username": "u313", "first_name": "User 313", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-11 08:48:47", "groups": [], "user_permissions": [], "password": "", "email": "u313", "date_joined": "2010-05-11 08:48:47"}}, {"pk": 311, "model": "auth.user", "fields": {"username": "u314", "first_name": "divya", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-26 04:49:26", "groups": [], "user_permissions": [], "password": "", "email": "london_birds@yahoo.co.in", "date_joined": "2010-05-11 09:46:43"}}, {"pk": 312, "model": "auth.user", "fields": {"username": "u315", "first_name": "Thaman", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-20 10:15:08", "groups": [], "user_permissions": [], "password": "", "email": "thamanchand@yahoo.com", "date_joined": "2010-05-11 13:25:54"}}, {"pk": 313, "model": "auth.user", "fields": {"username": "u316", "first_name": "Casey Bergman", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 21:59:03", "groups": [], "user_permissions": [], "password": "", "email": "casey.bergman@manchester.ac.uk", "date_joined": "2010-05-11 20:25:44"}}, {"pk": 314, "model": "auth.user", "fields": {"username": "u317", "first_name": "Ryan", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-29 13:53:47", "groups": [], "user_permissions": [], "password": "", "email": "u317", "date_joined": "2010-05-12 02:31:13"}}, {"pk": 315, "model": "auth.user", "fields": {"username": "u318", "first_name": "dhivya", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-14 06:55:52", "groups": [], "user_permissions": [], "password": "", "email": "london_birds@yahoo.co.in", "date_joined": "2010-05-12 05:25:21"}}, {"pk": 316, "model": "auth.user", "fields": {"username": "u319", "first_name": "Mylex", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-12 10:43:03", "groups": [], "user_permissions": [], "password": "", "email": "bohmbohm@gmail.com", "date_joined": "2010-05-12 08:36:25"}}, {"pk": 317, "model": "auth.user", "fields": {"username": "u320", "first_name": "Cymon", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-26 16:03:13", "groups": [], "user_permissions": [], "password": "", "email": "cymon.cox@googlemail.com", "date_joined": "2010-05-12 14:35:48"}}, {"pk": 318, "model": "auth.user", "fields": {"username": "u321", "first_name": "vamin", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-25 15:09:39", "groups": [], "user_permissions": [], "password": "", "email": "victor.amin@gmail.com", "date_joined": "2010-05-13 18:22:01"}}, {"pk": 319, "model": "auth.user", "fields": {"username": "u322", "first_name": "Reece", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-18 02:43:59", "groups": [], "user_permissions": [], "password": "", "email": "reece@harts.net", "date_joined": "2010-05-13 19:07:45"}}, {"pk": 320, "model": "auth.user", "fields": {"username": "u323", "first_name": "audyyy", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-10 19:00:07", "groups": [], "user_permissions": [], "password": "", "email": "harekrishna@gmail.com", "date_joined": "2010-05-14 02:45:52"}}, {"pk": 321, "model": "auth.user", "fields": {"username": "u324", "first_name": "Hazel", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-14 04:39:51", "groups": [], "user_permissions": [], "password": "", "email": "hazelinee@gmail.com", "date_joined": "2010-05-14 04:07:34"}}, {"pk": 322, "model": "auth.user", "fields": {"username": "u325", "first_name": "Brandon Bodn\u00e1r", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-15 20:29:39", "groups": [], "user_permissions": [], "password": "", "email": "bodnarbm@gmail.com", "date_joined": "2010-05-15 20:29:39"}}, {"pk": 323, "model": "auth.user", "fields": {"username": "u326", "first_name": "dhivi", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-17 11:03:23", "groups": [], "user_permissions": [], "password": "", "email": "london_birds@yahoo.co.in", "date_joined": "2010-05-17 11:03:23"}}, {"pk": 324, "model": "auth.user", "fields": {"username": "u327", "first_name": "Hanif Khalak", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-05 04:47:27", "groups": [], "user_permissions": [], "password": "", "email": "hanif.khalak@gmail.com", "date_joined": "2010-05-17 12:01:17"}}, {"pk": 325, "model": "auth.user", "fields": {"username": "u328", "first_name": "rks", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-24 13:00:26", "groups": [], "user_permissions": [], "password": "", "email": "ramgagan@gmail.com", "date_joined": "2010-05-17 14:31:21"}}, {"pk": 326, "model": "auth.user", "fields": {"username": "u329", "first_name": "TheKaptain", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-19 18:29:56", "groups": [], "user_permissions": [], "password": "", "email": "kellyrob@gmail.com", "date_joined": "2010-05-17 22:01:29"}}, {"pk": 327, "model": "auth.user", "fields": {"username": "u330", "first_name": "Young", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-20 05:32:13", "groups": [], "user_permissions": [], "password": "", "email": "zjuyx@zju.edu.cn", "date_joined": "2010-05-18 01:17:32"}}, {"pk": 328, "model": "auth.user", "fields": {"username": "u331", "first_name": "Sanchari", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-07 09:30:28", "groups": [], "user_permissions": [], "password": "", "email": "sancharisircar24@gmail.com", "date_joined": "2010-05-18 10:21:49"}}, {"pk": 329, "model": "auth.user", "fields": {"username": "u332", "first_name": "gabs", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-11-13 20:52:09", "groups": [], "user_permissions": [], "password": "", "email": "gabbyteku@gmail.com", "date_joined": "2010-05-18 12:32:52"}}, {"pk": 330, "model": "auth.user", "fields": {"username": "u333", "first_name": "Meng", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-20 14:50:53", "groups": [], "user_permissions": [], "password": "", "email": "mengma2@gmail.com", "date_joined": "2010-05-18 16:58:15"}}, {"pk": 331, "model": "auth.user", "fields": {"username": "u334", "first_name": "User 334", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-19 16:20:56", "groups": [], "user_permissions": [], "password": "", "email": "u334", "date_joined": "2010-05-18 21:01:57"}}, {"pk": 332, "model": "auth.user", "fields": {"username": "u335", "first_name": "typing-faster-than-before", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-19 19:17:06", "groups": [], "user_permissions": [], "password": "", "email": "hyperneato@gmail.com", "date_joined": "2010-05-19 05:08:23"}}, {"pk": 333, "model": "auth.user", "fields": {"username": "u336", "first_name": "cheng zhongshan", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-03 14:41:13", "groups": [], "user_permissions": [], "password": "", "email": "276049820@qq.com", "date_joined": "2010-05-19 06:11:42"}}, {"pk": 334, "model": "auth.user", "fields": {"username": "u337", "first_name": "Mikhail Pyatnitskiy", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-26 09:59:08", "groups": [], "user_permissions": [], "password": "", "email": "mpyat@yandex.ru", "date_joined": "2010-05-20 14:30:21"}}, {"pk": 335, "model": "auth.user", "fields": {"username": "u338", "first_name": "PaulN", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-21 00:06:25", "groups": [], "user_permissions": [], "password": "", "email": "paul.nicol@classicsnetwork.com", "date_joined": "2010-05-20 23:04:50"}}, {"pk": 336, "model": "auth.user", "fields": {"username": "u339", "first_name": "B\u00e9reng\u00e8re", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-21 08:58:57", "groups": [], "user_permissions": [], "password": "", "email": "berengere.genin@yahoo.fr", "date_joined": "2010-05-21 08:58:57"}}, {"pk": 337, "model": "auth.user", "fields": {"username": "u340", "first_name": "DStan", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-24 15:02:40", "groups": [], "user_permissions": [], "password": "", "email": "byuhobbes@gmail.com", "date_joined": "2010-05-21 13:20:47"}}, {"pk": 338, "model": "auth.user", "fields": {"username": "u341", "first_name": "wjeck", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-09 20:23:30", "groups": [], "user_permissions": [], "password": "", "email": "william.jeck@gmail.com", "date_joined": "2010-05-21 13:24:40"}}, {"pk": 339, "model": "auth.user", "fields": {"username": "u342", "first_name": "User 342", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-06-29 08:46:17", "groups": [], "user_permissions": [], "password": "", "email": "u342", "date_joined": "2010-05-21 13:46:25"}}, {"pk": 340, "model": "auth.user", "fields": {"username": "u343", "first_name": "nico80", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-06-11 13:41:43", "groups": [], "user_permissions": [], "password": "", "email": "romano.nicola@gmail.com", "date_joined": "2010-05-21 13:48:52"}}, {"pk": 341, "model": "auth.user", "fields": {"username": "u344", "first_name": "andrewjgrimm", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-04 22:22:19", "groups": [], "user_permissions": [], "password": "", "email": "andrew.j.grimm@gmail.com", "date_joined": "2010-05-22 08:51:07"}}, {"pk": 342, "model": "auth.user", "fields": {"username": "u345", "first_name": "Gregory Miles", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-22 17:15:02", "groups": [], "user_permissions": [], "password": "", "email": "milesgr@umdnj.edu", "date_joined": "2010-05-22 15:56:28"}}, {"pk": 343, "model": "auth.user", "fields": {"username": "u346", "first_name": "Stefano Berri", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 23:34:06", "groups": [], "user_permissions": [], "password": "", "email": "s.berri@leeds.ac.uk", "date_joined": "2010-05-22 17:35:49"}}, {"pk": 344, "model": "auth.user", "fields": {"username": "u347", "first_name": "User 347", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-16 08:25:00", "groups": [], "user_permissions": [], "password": "", "email": "u347", "date_joined": "2010-05-23 17:19:28"}}, {"pk": 345, "model": "auth.user", "fields": {"username": "u348", "first_name": "Crocodile", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-25 09:18:51", "groups": [], "user_permissions": [], "password": "", "email": "serene_911@hotmail.com", "date_joined": "2010-05-24 01:14:50"}}, {"pk": 346, "model": "auth.user", "fields": {"username": "u349", "first_name": "Hazelin", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-18 06:59:54", "groups": [], "user_permissions": [], "password": "", "email": "hazeeel-@hotmail.com", "date_joined": "2010-05-24 01:21:10"}}, {"pk": 347, "model": "auth.user", "fields": {"username": "u350", "first_name": "Hazel", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-25 01:24:13", "groups": [], "user_permissions": [], "password": "", "email": "hazelinee@gmail.com", "date_joined": "2010-05-24 01:27:42"}}, {"pk": 348, "model": "auth.user", "fields": {"username": "u351", "first_name": "paulN", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-26 08:33:47", "groups": [], "user_permissions": [], "password": "", "email": "paul.nicol@classicsnetwork.com", "date_joined": "2010-05-24 11:25:59"}}, {"pk": 349, "model": "auth.user", "fields": {"username": "u352", "first_name": "hiberbear", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-17 08:29:54", "groups": [], "user_permissions": [], "password": "", "email": "xshining@gmail.com", "date_joined": "2010-05-24 14:59:41"}}, {"pk": 350, "model": "auth.user", "fields": {"username": "u353", "first_name": "Alex Twyford", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-11 15:35:33", "groups": [], "user_permissions": [], "password": "", "email": "a.twyford@rbge.org.uk", "date_joined": "2010-05-24 21:56:59"}}, {"pk": 351, "model": "auth.user", "fields": {"username": "u354", "first_name": "david w", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 03:44:00", "groups": [], "user_permissions": [], "password": "", "email": "david.winter@gmail.com", "date_joined": "2010-05-25 09:26:20"}}, {"pk": 352, "model": "auth.user", "fields": {"username": "u355", "first_name": "Jorge de la Barrera", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-20 14:39:09", "groups": [], "user_permissions": [], "password": "", "email": "jorge.de.la.barrera@gmail.com", "date_joined": "2010-05-25 10:24:42"}}, {"pk": 353, "model": "auth.user", "fields": {"username": "u356", "first_name": "Philip Zimmermann", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-25 10:35:59", "groups": [], "user_permissions": [], "password": "", "email": "phz@nebion.com", "date_joined": "2010-05-25 10:35:59"}}, {"pk": 354, "model": "auth.user", "fields": {"username": "u357", "first_name": "andeyatz", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-09 09:37:32", "groups": [], "user_permissions": [], "password": "", "email": "u357", "date_joined": "2010-05-25 13:10:04"}}, {"pk": 355, "model": "auth.user", "fields": {"username": "u358", "first_name": "You", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-25 13:46:16", "groups": [], "user_permissions": [], "password": "", "email": "xyang619@126.com", "date_joined": "2010-05-25 13:15:59"}}, {"pk": 356, "model": "auth.user", "fields": {"username": "u359", "first_name": "Arnaud TIERANT", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-25 13:22:59", "groups": [], "user_permissions": [], "password": "", "email": "tipunk@gmail.com", "date_joined": "2010-05-25 13:22:59"}}, {"pk": 357, "model": "auth.user", "fields": {"username": "u360", "first_name": "Brandon Walts", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-19 15:39:58", "groups": [], "user_permissions": [], "password": "", "email": "waltsb@gmail.com", "date_joined": "2010-05-25 13:47:47"}}, {"pk": 358, "model": "auth.user", "fields": {"username": "u361", "first_name": "Krab", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-03 06:57:56", "groups": [], "user_permissions": [], "password": "", "email": "xkcd@seznam.cz", "date_joined": "2010-05-25 19:55:03"}}, {"pk": 359, "model": "auth.user", "fields": {"username": "u362", "first_name": "Melissa", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-26 19:34:27", "groups": [], "user_permissions": [], "password": "", "email": "mam1121@psu.edu", "date_joined": "2010-05-26 14:08:27"}}, {"pk": 360, "model": "auth.user", "fields": {"username": "u363", "first_name": "Alexandre Kuhn", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-26 22:08:54", "groups": [], "user_permissions": [], "password": "", "email": "alexandre.m.kuhn@gmail.com", "date_joined": "2010-05-26 22:08:54"}}, {"pk": 361, "model": "auth.user", "fields": {"username": "u364", "first_name": "Dario Corrada", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-17 08:19:20", "groups": [], "user_permissions": [], "password": "", "email": "dario.corrada@gmail.com", "date_joined": "2010-05-27 08:44:18"}}, {"pk": 362, "model": "auth.user", "fields": {"username": "u365", "first_name": "Daniel Mietchen", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-27 12:20:55", "groups": [], "user_permissions": [], "password": "", "email": "daniel.mietchen@googlemail.com", "date_joined": "2010-05-27 12:20:55"}}, {"pk": 363, "model": "auth.user", "fields": {"username": "u366", "first_name": "Gaurav", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-04-11 05:05:01", "groups": [], "user_permissions": [], "password": "", "email": "gaurav@ggvaidya.com", "date_joined": "2010-05-27 12:22:43"}}, {"pk": 364, "model": "auth.user", "fields": {"username": "u367", "first_name": "jandot", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-20 16:59:18", "groups": [], "user_permissions": [], "password": "", "email": "jan.aerts@gmail.com", "date_joined": "2010-05-27 14:21:50"}}, {"pk": 365, "model": "auth.user", "fields": {"username": "u368", "first_name": "Timothy Bailey", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-28 01:18:59", "groups": [], "user_permissions": [], "password": "", "email": "meme@nbcr.net", "date_joined": "2010-05-28 01:18:59"}}, {"pk": 366, "model": "auth.user", "fields": {"username": "u369", "first_name": "Jo\u00e3o Rodrigues", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 09:52:00", "groups": [], "user_permissions": [], "password": "", "email": "anaryin@gmail.com", "date_joined": "2010-05-28 06:45:26"}}, {"pk": 367, "model": "auth.user", "fields": {"username": "u370", "first_name": "User 370", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-05-28 18:37:50", "groups": [], "user_permissions": [], "password": "", "email": "u370", "date_joined": "2010-05-28 18:37:50"}}, {"pk": 368, "model": "auth.user", "fields": {"username": "u371", "first_name": "User 371", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-03 13:41:51", "groups": [], "user_permissions": [], "password": "", "email": "u371", "date_joined": "2010-05-30 08:48:18"}}, {"pk": 369, "model": "auth.user", "fields": {"username": "u372", "first_name": "ep", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-26 23:29:27", "groups": [], "user_permissions": [], "password": "", "email": "eli.papa@gmail.com", "date_joined": "2010-05-30 13:17:51"}}, {"pk": 370, "model": "auth.user", "fields": {"username": "u373", "first_name": "Kevin", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-17 15:08:20", "groups": [], "user_permissions": [], "password": "", "email": "aboulia@gmail.com", "date_joined": "2010-05-31 09:54:44"}}, {"pk": 371, "model": "auth.user", "fields": {"username": "u374", "first_name": "walkytalky", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-04-08 08:25:41", "groups": [], "user_permissions": [], "password": "", "email": "mattcaldwell@mac.com", "date_joined": "2010-05-31 15:03:22"}}, {"pk": 372, "model": "auth.user", "fields": {"username": "u375", "first_name": "christelle", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-10 06:37:20", "groups": [], "user_permissions": [], "password": "", "email": "muradvernay_00@hotmail.com", "date_joined": "2010-06-01 05:17:01"}}, {"pk": 373, "model": "auth.user", "fields": {"username": "u376", "first_name": "dhivya", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-01 10:31:33", "groups": [], "user_permissions": [], "password": "", "email": "dhivyamohan86@yahoo.in", "date_joined": "2010-06-01 05:39:19"}}, {"pk": 374, "model": "auth.user", "fields": {"username": "u377", "first_name": "Jorge Amigo", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 14:47:00", "groups": [], "user_permissions": [], "password": "", "email": "alpof@yahoo.com", "date_joined": "2010-06-01 07:04:48"}}, {"pk": 375, "model": "auth.user", "fields": {"username": "u378", "first_name": "tam", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-09 07:32:21", "groups": [], "user_permissions": [], "password": "", "email": "lahav008@gmai.com", "date_joined": "2010-06-01 08:39:33"}}, {"pk": 376, "model": "auth.user", "fields": {"username": "u379", "first_name": "Sergej Andrejev", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-30 17:09:27", "groups": [], "user_permissions": [], "password": "", "email": "sandrejev@gmail.com", "date_joined": "2010-06-01 11:27:12"}}, {"pk": 377, "model": "auth.user", "fields": {"username": "u380", "first_name": "CorinY", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-06-15 16:27:45", "groups": [], "user_permissions": [], "password": "", "email": "yeats@biochem.ucl.ac.uk", "date_joined": "2010-06-01 13:12:08"}}, {"pk": 378, "model": "auth.user", "fields": {"username": "u381", "first_name": "Andrew Clegg", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-10-16 13:42:34", "groups": [], "user_permissions": [], "password": "", "email": "andrew.clegg@gmail.com", "date_joined": "2010-06-01 13:16:16"}}, {"pk": 379, "model": "auth.user", "fields": {"username": "u382", "first_name": "Eugene", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-02 23:53:07", "groups": [], "user_permissions": [], "password": "", "email": "yqxiong71@gmail.com", "date_joined": "2010-06-01 22:43:37"}}, {"pk": 380, "model": "auth.user", "fields": {"username": "u383", "first_name": "Tanya Cashorali", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-02 14:55:16", "groups": [], "user_permissions": [], "password": "", "email": "tanyacash@gmail.com", "date_joined": "2010-06-02 14:55:16"}}, {"pk": 381, "model": "auth.user", "fields": {"username": "u384", "first_name": "User 384", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-14 23:02:06", "groups": [], "user_permissions": [], "password": "", "email": "u384", "date_joined": "2010-06-02 16:08:49"}}, {"pk": 382, "model": "auth.user", "fields": {"username": "u385", "first_name": "cbouyio", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-14 10:44:44", "groups": [], "user_permissions": [], "password": "", "email": "k.bouyioukos@uea.ac.uk", "date_joined": "2010-06-02 16:16:35"}}, {"pk": 383, "model": "auth.user", "fields": {"username": "u386", "first_name": "cariaso", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-17 16:54:59", "groups": [], "user_permissions": [], "password": "", "email": "cariaso@snpedia.com", "date_joined": "2010-06-03 08:53:31"}}, {"pk": 384, "model": "auth.user", "fields": {"username": "u387", "first_name": "User 387", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-11-17 05:49:07", "groups": [], "user_permissions": [], "password": "", "email": "u387", "date_joined": "2010-06-03 14:02:35"}}, {"pk": 385, "model": "auth.user", "fields": {"username": "u388", "first_name": "gilesc", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-04 03:57:48", "groups": [], "user_permissions": [], "password": "", "email": "u388", "date_joined": "2010-06-04 03:21:50"}}, {"pk": 386, "model": "auth.user", "fields": {"username": "u389", "first_name": "bkmacy", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-06-08 01:24:34", "groups": [], "user_permissions": [], "password": "", "email": "bkmacy@hotmail.com", "date_joined": "2010-06-04 19:50:09"}}, {"pk": 387, "model": "auth.user", "fields": {"username": "u390", "first_name": "zhongshan", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-02-25 02:19:25", "groups": [], "user_permissions": [], "password": "", "email": "276049820@qq.com", "date_joined": "2010-06-05 02:13:18"}}, {"pk": 388, "model": "auth.user", "fields": {"username": "u391", "first_name": "Ranjita", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-05 15:56:20", "groups": [], "user_permissions": [], "password": "", "email": "kranjita87@yahoo.com", "date_joined": "2010-06-05 12:09:01"}}, {"pk": 389, "model": "auth.user", "fields": {"username": "u392", "first_name": "aaronQuinlan", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 23:43:35", "groups": [], "user_permissions": [], "password": "", "email": "aaronquinlan@gmail.com", "date_joined": "2010-06-06 18:53:01"}}, {"pk": 390, "model": "auth.user", "fields": {"username": "u393", "first_name": "Keeney", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-09-16 03:57:10", "groups": [], "user_permissions": [], "password": "", "email": "jonathon.keeney@gmail.com", "date_joined": "2010-06-06 20:58:23"}}, {"pk": 391, "model": "auth.user", "fields": {"username": "u394", "first_name": "Jerry", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-07 04:41:00", "groups": [], "user_permissions": [], "password": "", "email": "jgrant@imagenix.com", "date_joined": "2010-06-07 04:41:00"}}, {"pk": 392, "model": "auth.user", "fields": {"username": "u395", "first_name": "Chia-Lang Hsu", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-03-31 06:48:48", "groups": [], "user_permissions": [], "password": "", "email": "u395", "date_joined": "2010-06-07 05:29:50"}}, {"pk": 393, "model": "auth.user", "fields": {"username": "u396", "first_name": "Ranjita", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-08 04:38:15", "groups": [], "user_permissions": [], "password": "", "email": "kranjita87@yahoo.com", "date_joined": "2010-06-08 04:38:15"}}, {"pk": 394, "model": "auth.user", "fields": {"username": "u397", "first_name": "Gabor", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-08 08:42:59", "groups": [], "user_permissions": [], "password": "", "email": "csardi.gabor@gmail.com", "date_joined": "2010-06-08 08:42:59"}}, {"pk": 395, "model": "auth.user", "fields": {"username": "u398", "first_name": "ametire", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-09 13:30:36", "groups": [], "user_permissions": [], "password": "", "email": "ametire@gmail.com", "date_joined": "2010-06-08 10:18:37"}}, {"pk": 396, "model": "auth.user", "fields": {"username": "u399", "first_name": "Greg Tyrelle", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-17 17:16:37", "groups": [], "user_permissions": [], "password": "", "email": "greg@nodalpoint.org", "date_joined": "2010-06-08 12:32:35"}}, {"pk": 397, "model": "auth.user", "fields": {"username": "u400", "first_name": "Anna Nikulina", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 09:46:41", "groups": [], "user_permissions": [], "password": "", "email": "nikulina.a.a@gmail.com", "date_joined": "2010-06-08 14:23:51"}}, {"pk": 398, "model": "auth.user", "fields": {"username": "u401", "first_name": "seq_GA", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-02-09 08:03:55", "groups": [], "user_permissions": [], "password": "", "email": "gopu_36@yahoo.com", "date_joined": "2010-06-09 03:15:13"}}, {"pk": 399, "model": "auth.user", "fields": {"username": "u402", "first_name": "Ira", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-05 04:41:46", "groups": [], "user_permissions": [], "password": "", "email": "iracooke@gmail.com", "date_joined": "2010-06-09 05:29:02"}}, {"pk": 400, "model": "auth.user", "fields": {"username": "u403", "first_name": "dole", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-02-18 13:10:18", "groups": [], "user_permissions": [], "password": "", "email": "u403", "date_joined": "2010-06-09 09:24:06"}}, {"pk": 401, "model": "auth.user", "fields": {"username": "u404", "first_name": "flxlex", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-02 14:00:40", "groups": [], "user_permissions": [], "password": "", "email": "lex.nederbragt@bio.uio.no", "date_joined": "2010-06-09 12:03:42"}}, {"pk": 402, "model": "auth.user", "fields": {"username": "u405", "first_name": "User 405", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-29 10:42:59", "groups": [], "user_permissions": [], "password": "", "email": "u405", "date_joined": "2010-06-09 12:35:18"}}, {"pk": 403, "model": "auth.user", "fields": {"username": "u406", "first_name": "wouter", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-09 13:54:31", "groups": [], "user_permissions": [], "password": "", "email": "u406", "date_joined": "2010-06-09 13:54:31"}}, {"pk": 404, "model": "auth.user", "fields": {"username": "u407", "first_name": "Emma", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-10 09:40:10", "groups": [], "user_permissions": [], "password": "", "email": "freezefire666@yahoo.com", "date_joined": "2010-06-09 14:13:37"}}, {"pk": 405, "model": "auth.user", "fields": {"username": "u408", "first_name": "User 408", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-30 07:55:49", "groups": [], "user_permissions": [], "password": "", "email": "u408", "date_joined": "2010-06-10 02:02:29"}}, {"pk": 406, "model": "auth.user", "fields": {"username": "u409", "first_name": "Satish Gupta", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-24 19:36:12", "groups": [], "user_permissions": [], "password": "", "email": "satish1482@gmail.com", "date_joined": "2010-06-10 09:31:50"}}, {"pk": 407, "model": "auth.user", "fields": {"username": "u410", "first_name": "User 410", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-10 17:13:24", "groups": [], "user_permissions": [], "password": "", "email": "u410", "date_joined": "2010-06-10 17:13:24"}}, {"pk": 408, "model": "auth.user", "fields": {"username": "u411", "first_name": "Jordan  Willis", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-11 16:26:30", "groups": [], "user_permissions": [], "password": "", "email": "jordan.r.willis@vanderbilt.edu", "date_joined": "2010-06-11 02:50:09"}}, {"pk": 409, "model": "auth.user", "fields": {"username": "u412", "first_name": "Jayant Maini", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-11 10:13:33", "groups": [], "user_permissions": [], "password": "", "email": "jayantmaini@gmail.com", "date_joined": "2010-06-11 10:13:33"}}, {"pk": 410, "model": "auth.user", "fields": {"username": "u413", "first_name": "Ranjita", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-11 16:04:00", "groups": [], "user_permissions": [], "password": "", "email": "kranjita@ibab.ac.in", "date_joined": "2010-06-11 11:32:19"}}, {"pk": 411, "model": "auth.user", "fields": {"username": "u414", "first_name": "Michael Dunn", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-17 22:14:32", "groups": [], "user_permissions": [], "password": "", "email": "micdunn@mpi.nl", "date_joined": "2010-06-11 12:52:37"}}, {"pk": 412, "model": "auth.user", "fields": {"username": "u415", "first_name": "rlong", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 22:45:29", "groups": [], "user_permissions": [], "password": "", "email": "sartorius.snouth@gmail.com", "date_joined": "2010-06-11 20:16:32"}}, {"pk": 413, "model": "auth.user", "fields": {"username": "u416", "first_name": "Joel Hoff", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-12-19 15:09:10", "groups": [], "user_permissions": [], "password": "", "email": "hoff@hcp.med.harvard.edu", "date_joined": "2010-06-13 16:24:13"}}, {"pk": 414, "model": "auth.user", "fields": {"username": "u417", "first_name": "Jussi", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-03 17:41:42", "groups": [], "user_permissions": [], "password": "", "email": "jussi.volanen@euformatics.com", "date_joined": "2010-06-14 06:42:26"}}, {"pk": 415, "model": "auth.user", "fields": {"username": "u418", "first_name": "Dror", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-01-27 14:47:28", "groups": [], "user_permissions": [], "password": "", "email": "dror.hilman@mail.huji.ac.il", "date_joined": "2010-06-14 11:51:20"}}, {"pk": 416, "model": "auth.user", "fields": {"username": "u419", "first_name": "leojlee", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-03 17:54:29", "groups": [], "user_permissions": [], "password": "", "email": "ljlee@psi.toronto.edu", "date_joined": "2010-06-14 15:13:32"}}, {"pk": 417, "model": "auth.user", "fields": {"username": "u420", "first_name": "huggie", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-12 07:09:37", "groups": [], "user_permissions": [], "password": "", "email": "2huggie@gmail.com", "date_joined": "2010-06-15 07:35:13"}}, {"pk": 418, "model": "auth.user", "fields": {"username": "u421", "first_name": "Michael Schubert", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 21:38:44", "groups": [], "user_permissions": [], "password": "", "email": "mschu.dev@gmail.com", "date_joined": "2010-06-15 13:43:06"}}, {"pk": 419, "model": "auth.user", "fields": {"username": "u422", "first_name": "shigeta", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-20 04:54:02", "groups": [], "user_permissions": [], "password": "", "email": "rtshigeta@yahoo.com", "date_joined": "2010-06-15 19:11:29"}}, {"pk": 420, "model": "auth.user", "fields": {"username": "u423", "first_name": "Kyra", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-07 15:47:48", "groups": [], "user_permissions": [], "password": "", "email": "kleimert@gmail.com", "date_joined": "2010-06-15 20:51:23"}}, {"pk": 421, "model": "auth.user", "fields": {"username": "u424", "first_name": "Scott", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-16 14:01:28", "groups": [], "user_permissions": [], "password": "", "email": "scott+biostar@scottcain.net", "date_joined": "2010-06-16 14:01:28"}}, {"pk": 422, "model": "auth.user", "fields": {"username": "u425", "first_name": "Lucas", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-16 21:13:42", "groups": [], "user_permissions": [], "password": "", "email": "lucasbrouwers@gmail.com", "date_joined": "2010-06-16 21:13:42"}}, {"pk": 423, "model": "auth.user", "fields": {"username": "u426", "first_name": "Sean", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-17 09:01:40", "groups": [], "user_permissions": [], "password": "", "email": "u426", "date_joined": "2010-06-17 04:34:42"}}, {"pk": 424, "model": "auth.user", "fields": {"username": "u427", "first_name": "Ranjita", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-17 12:01:43", "groups": [], "user_permissions": [], "password": "", "email": "kranjita87@yahoo.com", "date_joined": "2010-06-17 12:01:43"}}, {"pk": 425, "model": "auth.user", "fields": {"username": "u428", "first_name": "Sukhdeep Singh", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-01 16:36:11", "groups": [], "user_permissions": [], "password": "", "email": "sukhdeepsingh.bio@gmail.com", "date_joined": "2010-06-17 19:55:02"}}, {"pk": 426, "model": "auth.user", "fields": {"username": "u429", "first_name": "Gao Wang", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-18 15:53:46", "groups": [], "user_permissions": [], "password": "", "email": "gaow@rice.edu", "date_joined": "2010-06-17 22:21:17"}}, {"pk": 427, "model": "auth.user", "fields": {"username": "u430", "first_name": "Sushma Grellscheid", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-11-19 15:32:05", "groups": [], "user_permissions": [], "password": "", "email": "u430", "date_joined": "2010-06-17 23:26:59"}}, {"pk": 428, "model": "auth.user", "fields": {"username": "u431", "first_name": "Shefali", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-24 14:19:46", "groups": [], "user_permissions": [], "password": "", "email": "shefali.setia@gmail.com", "date_joined": "2010-06-18 19:55:24"}}, {"pk": 429, "model": "auth.user", "fields": {"username": "u432", "first_name": "Robert Edgar", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-27 00:34:16", "groups": [], "user_permissions": [], "password": "", "email": "robert@drive5.com", "date_joined": "2010-06-19 01:12:43"}}, {"pk": 430, "model": "auth.user", "fields": {"username": "u433", "first_name": "Dror", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-22 19:29:37", "groups": [], "user_permissions": [], "password": "", "email": "dror.hilman@mail.huji.ac.il", "date_joined": "2010-06-21 04:04:04"}}, {"pk": 431, "model": "auth.user", "fields": {"username": "u434", "first_name": "Will", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-21 11:00:11", "groups": [], "user_permissions": [], "password": "", "email": "u434", "date_joined": "2010-06-21 11:00:11"}}, {"pk": 432, "model": "auth.user", "fields": {"username": "u435", "first_name": "phwd", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-21 15:51:10", "groups": [], "user_permissions": [], "password": "", "email": "philippe.harewood@gmail.com", "date_joined": "2010-06-21 15:51:10"}}, {"pk": 433, "model": "auth.user", "fields": {"username": "u436", "first_name": "Steve Moss", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-23 15:23:13", "groups": [], "user_permissions": [], "password": "", "email": "gawbul@gmail.com", "date_joined": "2010-06-21 22:59:57"}}, {"pk": 434, "model": "auth.user", "fields": {"username": "u437", "first_name": "User 437", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-22 11:38:53", "groups": [], "user_permissions": [], "password": "", "email": "u437", "date_joined": "2010-06-22 11:38:53"}}, {"pk": 435, "model": "auth.user", "fields": {"username": "u438", "first_name": "fiamh", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-28 13:12:58", "groups": [], "user_permissions": [], "password": "", "email": "ohofmann@hsph.harvard.edu", "date_joined": "2010-06-22 21:09:12"}}, {"pk": 436, "model": "auth.user", "fields": {"username": "u439", "first_name": "User 439", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-01-26 22:03:27", "groups": [], "user_permissions": [], "password": "", "email": "u439", "date_joined": "2010-06-22 21:33:11"}}, {"pk": 437, "model": "auth.user", "fields": {"username": "u440", "first_name": "User 440", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-19 00:41:48", "groups": [], "user_permissions": [], "password": "", "email": "u440", "date_joined": "2010-06-23 20:55:45"}}, {"pk": 438, "model": "auth.user", "fields": {"username": "u441", "first_name": "bamyasi", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-31 04:43:13", "groups": [], "user_permissions": [], "password": "", "email": "iadzhubey@rics.bwh.harvard.edu", "date_joined": "2010-06-24 04:17:41"}}, {"pk": 439, "model": "auth.user", "fields": {"username": "u442", "first_name": "Owen", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-09-09 21:31:59", "groups": [], "user_permissions": [], "password": "", "email": "u442", "date_joined": "2010-06-24 18:24:41"}}, {"pk": 440, "model": "auth.user", "fields": {"username": "u443", "first_name": "David Grellscheid", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-25 11:44:18", "groups": [], "user_permissions": [], "password": "", "email": "d.grellscheid@gmail.com", "date_joined": "2010-06-24 20:01:33"}}, {"pk": 441, "model": "auth.user", "fields": {"username": "u444", "first_name": "Phil Goetz", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-24 20:34:03", "groups": [], "user_permissions": [], "password": "", "email": "phil_goetz@yahoo.com", "date_joined": "2010-06-24 20:34:03"}}, {"pk": 442, "model": "auth.user", "fields": {"username": "u445", "first_name": "Kevin Crowell", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-02-15 00:24:53", "groups": [], "user_permissions": [], "password": "", "email": "kevkon3@gmail.com", "date_joined": "2010-06-28 22:06:12"}}, {"pk": 443, "model": "auth.user", "fields": {"username": "u446", "first_name": "Maik", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-29 08:48:24", "groups": [], "user_permissions": [], "password": "", "email": "rg.maik@gmail.com", "date_joined": "2010-06-29 08:48:24"}}, {"pk": 444, "model": "auth.user", "fields": {"username": "u447", "first_name": "atalon1", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-02 14:15:24", "groups": [], "user_permissions": [], "password": "", "email": "atalon1@gmail.com", "date_joined": "2010-06-29 09:41:50"}}, {"pk": 445, "model": "auth.user", "fields": {"username": "u448", "first_name": "gawbul", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-26 14:38:25", "groups": [], "user_permissions": [], "password": "", "email": "gawbul@gmail.com", "date_joined": "2010-06-29 15:19:08"}}, {"pk": 446, "model": "auth.user", "fields": {"username": "u449", "first_name": "Radwen", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-06-29 17:17:25", "groups": [], "user_permissions": [], "password": "", "email": "aradwen@gmail.com", "date_joined": "2010-06-29 17:17:25"}}, {"pk": 447, "model": "auth.user", "fields": {"username": "u450", "first_name": "Craig", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-07 16:47:21", "groups": [], "user_permissions": [], "password": "", "email": "hs569@york.ac.uk", "date_joined": "2010-06-29 22:56:21"}}, {"pk": 448, "model": "auth.user", "fields": {"username": "u451", "first_name": "User 451", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-02 07:25:01", "groups": [], "user_permissions": [], "password": "", "email": "u451", "date_joined": "2010-06-30 02:00:34"}}, {"pk": 449, "model": "auth.user", "fields": {"username": "u452", "first_name": "foreveremain", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 18:54:16", "groups": [], "user_permissions": [], "password": "", "email": "foreveremain@gmail.com", "date_joined": "2010-06-30 09:37:56"}}, {"pk": 450, "model": "auth.user", "fields": {"username": "u453", "first_name": "Wendy", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-01 02:25:13", "groups": [], "user_permissions": [], "password": "", "email": "wendy_young2004@yahoo.com", "date_joined": "2010-07-01 02:25:13"}}, {"pk": 451, "model": "auth.user", "fields": {"username": "u454", "first_name": "Ian", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 09:19:50", "groups": [], "user_permissions": [], "password": "", "email": "donaldson.ij@gmail.com", "date_joined": "2010-07-01 11:41:54"}}, {"pk": 452, "model": "auth.user", "fields": {"username": "u455", "first_name": "Haji", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-25 12:33:09", "groups": [], "user_permissions": [], "password": "", "email": "hagayenav@gmail.com", "date_joined": "2010-07-01 11:51:54"}}, {"pk": 453, "model": "auth.user", "fields": {"username": "u456", "first_name": "Ruchira", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-03 00:05:43", "groups": [], "user_permissions": [], "password": "", "email": "ruchira.datta@gmail.com", "date_joined": "2010-07-01 22:50:32"}}, {"pk": 454, "model": "auth.user", "fields": {"username": "u457", "first_name": "Harpal", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-01 23:28:28", "groups": [], "user_permissions": [], "password": "", "email": "hs569@york.ac.uk", "date_joined": "2010-07-01 22:51:08"}}, {"pk": 455, "model": "auth.user", "fields": {"username": "u458", "first_name": "User 458", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-21 05:51:53", "groups": [], "user_permissions": [], "password": "", "email": "u458", "date_joined": "2010-07-02 05:29:59"}}, {"pk": 456, "model": "auth.user", "fields": {"username": "u459", "first_name": "User 459", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-02 07:02:21", "groups": [], "user_permissions": [], "password": "", "email": "u459", "date_joined": "2010-07-02 07:02:21"}}, {"pk": 457, "model": "auth.user", "fields": {"username": "u460", "first_name": "David Quigley", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 16:07:18", "groups": [], "user_permissions": [], "password": "", "email": "david.a.quigley@gmail.com", "date_joined": "2010-07-02 20:30:31"}}, {"pk": 458, "model": "auth.user", "fields": {"username": "u461", "first_name": "User 461", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-04 20:07:32", "groups": [], "user_permissions": [], "password": "", "email": "kramj01@yahoo.com", "date_joined": "2010-07-04 18:12:14"}}, {"pk": 459, "model": "auth.user", "fields": {"username": "u462", "first_name": "User 462", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-21 11:51:38", "groups": [], "user_permissions": [], "password": "", "email": "u462", "date_joined": "2010-07-05 10:57:03"}}, {"pk": 460, "model": "auth.user", "fields": {"username": "u463", "first_name": "Katrine", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-10-01 20:57:35", "groups": [], "user_permissions": [], "password": "", "email": "katrinewhiteson@gmail.com", "date_joined": "2010-07-05 11:51:14"}}, {"pk": 461, "model": "auth.user", "fields": {"username": "u464", "first_name": "kanagarajadurai", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-10 01:44:48", "groups": [], "user_permissions": [], "password": "", "email": "kanaksvet@gmail.com", "date_joined": "2010-07-05 15:22:31"}}, {"pk": 462, "model": "auth.user", "fields": {"username": "u465", "first_name": "Protostome", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-06 08:39:34", "groups": [], "user_permissions": [], "password": "", "email": "liorz1984@gmail.com", "date_joined": "2010-07-06 08:39:34"}}, {"pk": 463, "model": "auth.user", "fields": {"username": "u466", "first_name": "fgibson", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-10-05 08:01:21", "groups": [], "user_permissions": [], "password": "", "email": "fgibson@gmail.com", "date_joined": "2010-07-06 09:11:39"}}, {"pk": 464, "model": "auth.user", "fields": {"username": "u467", "first_name": "olebebo", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-06 16:14:55", "groups": [], "user_permissions": [], "password": "", "email": "assaf.faragy@mail.huji.ac.il", "date_joined": "2010-07-06 16:14:55"}}, {"pk": 465, "model": "auth.user", "fields": {"username": "u468", "first_name": "Lance", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-15 22:47:02", "groups": [], "user_permissions": [], "password": "", "email": "lparsons@yahoo.com", "date_joined": "2010-07-06 16:41:12"}}, {"pk": 466, "model": "auth.user", "fields": {"username": "u469", "first_name": "JoshM", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-11-03 19:07:48", "groups": [], "user_permissions": [], "password": "", "email": "u469", "date_joined": "2010-07-06 23:36:35"}}, {"pk": 467, "model": "auth.user", "fields": {"username": "u470", "first_name": "JeremiahLoh", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-24 03:56:20", "groups": [], "user_permissions": [], "password": "", "email": "jemimaloh@gmail.com", "date_joined": "2010-07-07 02:20:06"}}, {"pk": 468, "model": "auth.user", "fields": {"username": "u471", "first_name": "User 471", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-08 04:06:20", "groups": [], "user_permissions": [], "password": "", "email": "u471", "date_joined": "2010-07-07 03:51:55"}}, {"pk": 469, "model": "auth.user", "fields": {"username": "u472", "first_name": "User 472", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-09-12 15:49:27", "groups": [], "user_permissions": [], "password": "", "email": "u472", "date_joined": "2010-07-07 07:31:35"}}, {"pk": 470, "model": "auth.user", "fields": {"username": "u473", "first_name": "Jason", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-08 06:56:33", "groups": [], "user_permissions": [], "password": "", "email": "ng_chang_yao@hotmail.com", "date_joined": "2010-07-08 03:00:02"}}, {"pk": 471, "model": "auth.user", "fields": {"username": "u474", "first_name": "User 474", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-08 20:46:23", "groups": [], "user_permissions": [], "password": "", "email": "u474", "date_joined": "2010-07-08 20:46:23"}}, {"pk": 472, "model": "auth.user", "fields": {"username": "u475", "first_name": "User 475", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-02-27 10:39:53", "groups": [], "user_permissions": [], "password": "", "email": "u475", "date_joined": "2010-07-08 22:44:53"}}, {"pk": 473, "model": "auth.user", "fields": {"username": "u476", "first_name": "doctoroots", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 06:32:32", "groups": [], "user_permissions": [], "password": "", "email": "u476", "date_joined": "2010-07-09 08:11:34"}}, {"pk": 474, "model": "auth.user", "fields": {"username": "u477", "first_name": "bioinfosm", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-18 15:39:09", "groups": [], "user_permissions": [], "password": "", "email": "smisbakc@gmail.com", "date_joined": "2010-07-09 14:50:09"}}, {"pk": 475, "model": "auth.user", "fields": {"username": "u478", "first_name": "Darren J. Fitzpatrick", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 15:35:28", "groups": [], "user_permissions": [], "password": "", "email": "u478", "date_joined": "2010-07-09 16:48:26"}}, {"pk": 476, "model": "auth.user", "fields": {"username": "u479", "first_name": "academicRobot", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-10 16:47:54", "groups": [], "user_permissions": [], "password": "", "email": "academicrobot@gmail.com", "date_joined": "2010-07-10 16:47:54"}}, {"pk": 477, "model": "auth.user", "fields": {"username": "u480", "first_name": "Greg Grant", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-11 12:09:52", "groups": [], "user_permissions": [], "password": "", "email": "greg@grant.org", "date_joined": "2010-07-11 12:09:52"}}, {"pk": 478, "model": "auth.user", "fields": {"username": "u481", "first_name": "User 481", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-26 08:43:25", "groups": [], "user_permissions": [], "password": "", "email": "roy-ahxiong@hotmail.com", "date_joined": "2010-07-12 09:03:01"}}, {"pk": 479, "model": "auth.user", "fields": {"username": "u482", "first_name": "david", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-12 15:05:42", "groups": [], "user_permissions": [], "password": "", "email": "dmontaner@cipf.es", "date_joined": "2010-07-12 15:05:42"}}, {"pk": 480, "model": "auth.user", "fields": {"username": "u483", "first_name": "User 483", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-12 17:22:04", "groups": [], "user_permissions": [], "password": "", "email": "christophercatto@hotmail.com", "date_joined": "2010-07-12 17:22:04"}}, {"pk": 481, "model": "auth.user", "fields": {"username": "u484", "first_name": "Jin", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-05-12 21:35:38", "groups": [], "user_permissions": [], "password": "", "email": "u484", "date_joined": "2010-07-12 19:39:36"}}, {"pk": 482, "model": "auth.user", "fields": {"username": "u485", "first_name": "Kenichi Shimada", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-12 21:39:31", "groups": [], "user_permissions": [], "password": "", "email": "kenichi.shimada@gmail.com", "date_joined": "2010-07-12 21:39:31"}}, {"pk": 483, "model": "auth.user", "fields": {"username": "u486", "first_name": "s4553711", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-07-26 03:40:37", "groups": [], "user_permissions": [], "password": "", "email": "s4553711@gmail.com", "date_joined": "2010-07-13 01:26:17"}}, {"pk": 484, "model": "auth.user", "fields": {"username": "u487", "first_name": "Helios", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-30 11:02:41", "groups": [], "user_permissions": [], "password": "", "email": "ilpuccio.febo@gmail.com", "date_joined": "2010-07-13 14:13:43"}}, {"pk": 485, "model": "auth.user", "fields": {"username": "u488", "first_name": "D. Puthier", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-01-19 09:45:53", "groups": [], "user_permissions": [], "password": "", "email": "u488", "date_joined": "2010-07-13 15:48:37"}}, {"pk": 486, "model": "auth.user", "fields": {"username": "u489", "first_name": "Hamid Ashrafi", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-13 18:25:36", "groups": [], "user_permissions": [], "password": "", "email": "ashrafi@ucdavis.edu", "date_joined": "2010-07-13 18:25:36"}}, {"pk": 487, "model": "auth.user", "fields": {"username": "u490", "first_name": "User 490", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-08-11 22:03:51", "groups": [], "user_permissions": [], "password": "", "email": "dshivak@gmail.com", "date_joined": "2010-07-13 18:47:04"}}, {"pk": 488, "model": "auth.user", "fields": {"username": "u491", "first_name": "ads-osu", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-30 17:38:27", "groups": [], "user_permissions": [], "password": "", "email": "motandrew@gmail.com", "date_joined": "2010-07-13 21:50:14"}}, {"pk": 489, "model": "auth.user", "fields": {"username": "u492", "first_name": "User 492", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-14 15:19:23", "groups": [], "user_permissions": [], "password": "", "email": "u492", "date_joined": "2010-07-14 15:19:23"}}, {"pk": 490, "model": "auth.user", "fields": {"username": "u493", "first_name": "Kyle", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-15 14:55:06", "groups": [], "user_permissions": [], "password": "", "email": "kyle.j.bibby@gmail.com", "date_joined": "2010-07-15 13:47:28"}}, {"pk": 491, "model": "auth.user", "fields": {"username": "u494", "first_name": "Gabriel Mitchell", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-07 18:57:55", "groups": [], "user_permissions": [], "password": "", "email": "gabriel.mitchell@gatech.edu", "date_joined": "2010-07-15 17:10:48"}}, {"pk": 492, "model": "auth.user", "fields": {"username": "u495", "first_name": "Lee Katz", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-21 19:21:18", "groups": [], "user_permissions": [], "password": "", "email": "lskatz@gmail.com", "date_joined": "2010-07-15 17:43:25"}}, {"pk": 493, "model": "auth.user", "fields": {"username": "u496", "first_name": "Herv\u00e9 Pag\u00e8s", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-11-22 19:17:01", "groups": [], "user_permissions": [], "password": "", "email": "hpages@fhcrc.org", "date_joined": "2010-07-15 22:15:14"}}, {"pk": 494, "model": "auth.user", "fields": {"username": "u497", "first_name": "nurjahan mehzabeen", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-22 03:57:40", "groups": [], "user_permissions": [], "password": "", "email": "nurjahanm@hotmail.com", "date_joined": "2010-07-16 03:38:14"}}, {"pk": 495, "model": "auth.user", "fields": {"username": "u498", "first_name": "User 498", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-16 08:11:46", "groups": [], "user_permissions": [], "password": "", "email": "u498", "date_joined": "2010-07-16 08:11:46"}}, {"pk": 496, "model": "auth.user", "fields": {"username": "u499", "first_name": "Jaydon", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-08-17 16:46:15", "groups": [], "user_permissions": [], "password": "", "email": "tinlaplee@gmail.com", "date_joined": "2010-07-16 14:04:35"}}, {"pk": 497, "model": "auth.user", "fields": {"username": "u500", "first_name": "Israel Barrantes", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2011-11-22 17:24:16", "groups": [], "user_permissions": [], "password": "", "email": "isradelacon@gmail.com", "date_joined": "2010-07-16 22:51:11"}}, {"pk": 498, "model": "auth.user", "fields": {"username": "u501", "first_name": "Yaser Sulaiman", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-18 00:01:06", "groups": [], "user_permissions": [], "password": "", "email": "yaserbuntu@gmail.com", "date_joined": "2010-07-18 00:01:06"}}, {"pk": 499, "model": "auth.user", "fields": {"username": "u502", "first_name": "bookhling", "last_name": "", "is_active": true, "is_superuser": false, "is_staff": false, "last_login": "2010-07-20 04:41:05", "groups": [], "user_permissions": [], "password": "", "email": "bookhling@gmail.com", "date_joined": "2010-07-18 01:09:10"}}, {"pk": 1, "model": "server.userprofile", "fields": {"website": "http://www.personal.psu.edu/iua1/", "openid": "https://www.google.com/accounts/o8/id?id=AItOawmMLamQ6fJhEqJZNocO46CUvOFM9cwc_A8", "openid_merge": true, "display_name": "Istvan Albert", "location": "University Park", "bronze_badges": 28, "views": 0, "last_visited": "2011-11-24 14:54:00", "json": "", "silver_badges": 9, "gold_badges": 1, "score": 2110, "about_me": "Current position: Research Associate Professor of Bioinformatics at Penn State", "user": 1, "suspended": false, "last_login_ip": "98.235.35.186", "type": 2, "reputation": 0}}, {"pk": 2, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Fabio", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 70, "about_me": "", "user": 2, "suspended": false, "last_login_ip": "128.118.200.167", "type": 0, "reputation": 0}}, {"pk": 3, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jason", "location": null, "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 3, "gold_badges": 0, "score": 107, "about_me": "Grad student at PSU", "user": 3, "suspended": false, "last_login_ip": "75.102.114.5", "type": 0, "reputation": 0}}, {"pk": 4, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Zhenhai Zhang", "location": "502 Wartik Lab, Penn State Univ", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 88, "about_me": null, "user": 4, "suspended": false, "last_login_ip": "156.145.28.117", "type": 0, "reputation": 0}}, {"pk": 5, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tom Koerber", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 40, "about_me": "", "user": 5, "suspended": false, "last_login_ip": "128.118.231.44", "type": 0, "reputation": 0}}, {"pk": 6, "model": "server.userprofile", "fields": {"website": "http://twitter.com/suk211", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Suk211", "location": "state college", "bronze_badges": 10, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 378, "about_me": "interested systems biology,protein folding ,genomics", "user": 6, "suspended": false, "last_login_ip": "146.186.25.15", "type": 0, "reputation": 0}}, {"pk": 7, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Lemon", "location": "China,WH", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 7, "suspended": false, "last_login_ip": "220.249.99.166", "type": 0, "reputation": 0}}, {"pk": 8, "model": "server.userprofile", "fields": {"website": "http://quwubin.sinaapp.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Wubin Qu", "location": "China", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Bioinformatics researcher, author of MFEprimer, MPprimer and CelRNAi.", "user": 8, "suspended": false, "last_login_ip": "202.38.153.190", "type": 0, "reputation": 0}}, {"pk": 9, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Question Bot", "location": null, "bronze_badges": 13, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 4, "gold_badges": 0, "score": 443, "about_me": null, "user": 9, "suspended": false, "last_login_ip": "98.235.35.186", "type": 0, "reputation": 0}}, {"pk": 10, "model": "server.userprofile", "fields": {"website": "http://www.phys.psu.edu/~ralbert/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Reka Albert", "location": "University Park", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 10, "suspended": false, "last_login_ip": "128.118.200.167", "type": 0, "reputation": 0}}, {"pk": 11, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Yang Yang", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 30, "about_me": "", "user": 11, "suspended": false, "last_login_ip": "128.118.159.180", "type": 0, "reputation": 0}}, {"pk": 12, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gue Su Chang", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 30, "about_me": "", "user": 12, "suspended": false, "last_login_ip": "128.118.200.154", "type": 0, "reputation": 0}}, {"pk": 13, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Zhaorong", "location": "State College, PA", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 3, "gold_badges": 0, "score": 97, "about_me": "A grad student in bioinformatics studying plant small RNAs.", "user": 13, "suspended": false, "last_login_ip": "128.118.123.176", "type": 0, "reputation": 0}}, {"pk": 14, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nickey", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 14, "suspended": false, "last_login_ip": "219.89.7.131", "type": 0, "reputation": 0}}, {"pk": 15, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Renee", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 1, "gold_badges": 1, "score": 120, "about_me": null, "user": 15, "suspended": false, "last_login_ip": "130.245.201.236", "type": 0, "reputation": 0}}, {"pk": 16, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Yu", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 16, "suspended": false, "last_login_ip": "132.239.171.202", "type": 0, "reputation": 0}}, {"pk": 17, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gue Su", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 30, "about_me": "", "user": 17, "suspended": false, "last_login_ip": "128.118.200.154", "type": 0, "reputation": 0}}, {"pk": 18, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Mohammed Islaih", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 30, "about_me": "", "user": 18, "suspended": false, "last_login_ip": "69.174.113.20", "type": 0, "reputation": 0}}, {"pk": 19, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Alex Reynolds", "location": null, "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 72, "about_me": null, "user": 19, "suspended": false, "last_login_ip": "69.91.218.119", "type": 0, "reputation": 0}}, {"pk": 20, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 21", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 20, "suspended": false, "last_login_ip": "202.127.20.29", "type": 0, "reputation": 0}}, {"pk": 21, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 22", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 21, "suspended": false, "last_login_ip": "222.20.43.2", "type": 0, "reputation": 0}}, {"pk": 22, "model": "server.userprofile", "fields": {"website": "http://bioinfoblog.it", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Giovanni M Dall'Olio", "location": "Barcelona, Spain", "bronze_badges": 31, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 10, "gold_badges": 1, "score": 1701, "about_me": "PhD student at the Pompeu Fabra University in Barcelona. Interested in bioinformatics, R, python programming and agile techniques.", "user": 22, "suspended": false, "last_login_ip": "85.50.12.18", "type": 1, "reputation": 0}}, {"pk": 23, "model": "server.userprofile", "fields": {"website": "http://etalog.blogspot.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Etal", "location": "Athens, GA", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 155, "about_me": null, "user": 23, "suspended": false, "last_login_ip": "128.192.15.218", "type": 0, "reputation": 0}}, {"pk": 24, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Fabio", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 54, "about_me": "", "user": 24, "suspended": false, "last_login_ip": "71.58.72.201", "type": 0, "reputation": 0}}, {"pk": 25, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nicojo", "location": null, "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 483, "about_me": null, "user": 25, "suspended": false, "last_login_ip": "133.103.101.175", "type": 0, "reputation": 0}}, {"pk": 26, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Allen Yu", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 120, "about_me": null, "user": 26, "suspended": false, "last_login_ip": "137.189.51.99", "type": 0, "reputation": 0}}, {"pk": 27, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Curious George", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 30, "about_me": "", "user": 27, "suspended": false, "last_login_ip": "128.118.200.167", "type": 0, "reputation": 0}}, {"pk": 28, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 29", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 28, "suspended": false, "last_login_ip": "219.137.149.55", "type": 0, "reputation": 0}}, {"pk": 29, "model": "server.userprofile", "fields": {"website": "http://plindenbaum.blogspot.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Pierre Lindenbaum", "location": "France", "bronze_badges": 48, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 19, "gold_badges": 1, "score": 1779, "about_me": "Virology, Bioinformatics , Genetics\n\nhttp://twitter.com/yokofakun\n\nNeil Saunders is an impostor because he doesn't exist.\n\nPlease, don't vote for him :-)\n", "user": 29, "suspended": false, "last_login_ip": "193.52.103.21", "type": 2, "reputation": 0}}, {"pk": 30, "model": "server.userprofile", "fields": {"website": "http://www.marcosdecarvalho.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Marcos De Carvalho", "location": "Porto Alegre, RS, Brasil", "bronze_badges": 7, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 168, "about_me": "Doctoral student.", "user": 30, "suspended": false, "last_login_ip": "187.113.213.114", "type": 0, "reputation": 0}}, {"pk": 31, "model": "server.userprofile", "fields": {"website": "http://www.lge.ibi.unicamp.br", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gustavo Costa", "location": "Campinas, Brazil", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Phd candidate at State University of Campinas (UNICAMP)\nBs in Computer Science (UFS)\n\nBioinformatician with experience in genomics, transcriptomics, gene finding and next-generation sequencing.", "user": 31, "suspended": false, "last_login_ip": "143.106.161.133", "type": 0, "reputation": 0}}, {"pk": 32, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 33", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 50, "about_me": "", "user": 32, "suspended": false, "last_login_ip": "71.58.72.201", "type": 0, "reputation": 0}}, {"pk": 33, "model": "server.userprofile", "fields": {"website": "http://www.davispj.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Paul J. Davis", "location": "Ipswich, MA", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 33, "suspended": false, "last_login_ip": "65.120.124.222", "type": 0, "reputation": 0}}, {"pk": 34, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "David Nusinow", "location": "Boston, MA", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 155, "about_me": null, "user": 34, "suspended": false, "last_login_ip": "170.223.185.61", "type": 0, "reputation": 0}}, {"pk": 35, "model": "server.userprofile", "fields": {"website": "https://github.com/brentp", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Brentp", "location": "Denver, Colorado", "bronze_badges": 32, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 8, "gold_badges": 0, "score": 675, "about_me": "I do bioinformatics at a hospital in denver.\n<p>\n<a href=\"http://github.com/brentp/\" rel=\"nofollow\">some of my code</a>\n</p>\n<p>\n<a href=\"http://hackmap.blogspot.com/\" rel=\"nofollow\">and my blog</a>\n</p>\nand \n<a href=\"http://twitter.com/#!/brent_p\" rel=\"nofollow\">twitter</a>", "user": 35, "suspended": false, "last_login_ip": "140.226.87.80", "type": 1, "reputation": 0}}, {"pk": 36, "model": "server.userprofile", "fields": {"website": "http://biopunk.hu", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Razor", "location": "Budapest", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 36, "suspended": false, "last_login_ip": "188.157.166.162", "type": 0, "reputation": 0}}, {"pk": 37, "model": "server.userprofile", "fields": {"website": "http://fuzzierlogic.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Simon Cockell", "location": "Newcastle", "bronze_badges": 24, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 7, "gold_badges": 1, "score": 629, "about_me": "<p>Bioinformatician, support scientist, Python programmer. Full bio on <a href=\"http://blog.fuzzierlogic.com/about\" rel=\"nofollow\">my blog</a>. You can also follow me <a href=\"http://twitter.com/sjcockell\" rel=\"nofollow\">on Twitter</a>.\n\n<p>I work with <a href=\"http://biostar.stackexchange.com/users/59/daniel-swan\" rel=\"nofollow\">Daniel</a> in the <a href=\"http://bsu.ncl.ac.uk/\" rel=\"nofollow\">Bioinformatics Support Unit</a> of Newcastle University.", "user": 37, "suspended": false, "last_login_ip": "128.240.225.120", "type": 1, "reputation": 0}}, {"pk": 38, "model": "server.userprofile", "fields": {"website": "http://konrad.foerstner.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Konrad", "location": null, "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 45, "about_me": null, "user": 38, "suspended": false, "last_login_ip": "82.113.98.162", "type": 0, "reputation": 0}}, {"pk": 39, "model": "server.userprofile", "fields": {"website": "http://www.biorelated.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Biorelated", "location": null, "bronze_badges": 7, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 60, "about_me": null, "user": 39, "suspended": false, "last_login_ip": "217.21.116.14", "type": 0, "reputation": 0}}, {"pk": 40, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Yann Abraham", "location": "Basel, Switzerland", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "computational biology for the pharmaceutical industry, father, geek, climber, biker", "user": 40, "suspended": false, "last_login_ip": "160.62.4.10", "type": 0, "reputation": 0}}, {"pk": 41, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Fernando Mu\u00f1iz", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 85, "about_me": "", "user": 41, "suspended": false, "last_login_ip": "193.145.46.52", "type": 0, "reputation": 0}}, {"pk": 42, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 43", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 42, "suspended": false, "last_login_ip": "193.145.46.52", "type": 0, "reputation": 0}}, {"pk": 43, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Andrew", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 22, "about_me": "", "user": 43, "suspended": false, "last_login_ip": "134.174.140.200", "type": 0, "reputation": 0}}, {"pk": 44, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Alex", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 90, "about_me": null, "user": 44, "suspended": false, "last_login_ip": "152.14.14.75", "type": 0, "reputation": 0}}, {"pk": 45, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Owen", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 45, "suspended": false, "last_login_ip": "99.147.169.197", "type": 0, "reputation": 0}}, {"pk": 46, "model": "server.userprofile", "fields": {"website": "http://www.rostlab.org/~schaefer/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Chris", "location": "Munich", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 70, "about_me": "Researcher in structural bioinformatics", "user": 46, "suspended": false, "last_login_ip": "131.159.28.123", "type": 0, "reputation": 0}}, {"pk": 47, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kelly O.", "location": "Salt Lake City Utah", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 47, "suspended": false, "last_login_ip": "155.101.105.116", "type": 0, "reputation": 0}}, {"pk": 48, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 49", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 48, "suspended": false, "last_login_ip": "128.118.200.220", "type": 0, "reputation": 0}}, {"pk": 49, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Greg", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 49, "suspended": false, "last_login_ip": "130.91.13.69", "type": 0, "reputation": 0}}, {"pk": 50, "model": "server.userprofile", "fields": {"website": "http://pbeltrao.blogspot.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Pedrobeltrao", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 60, "about_me": null, "user": 50, "suspended": false, "last_login_ip": "169.230.84.116", "type": 0, "reputation": 0}}, {"pk": 51, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Liam Thompson", "location": "Johannesburg, South Africa", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 51, "suspended": false, "last_login_ip": "146.141.1.96", "type": 0, "reputation": 0}}, {"pk": 52, "model": "server.userprofile", "fields": {"website": "http://www.michaelbarton.me.uk", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Michael Barton", "location": "Akron, Ohio, United States", "bronze_badges": 14, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 311, "about_me": "Doing post doc in genomics.", "user": 52, "suspended": false, "last_login_ip": "130.101.99.185", "type": 0, "reputation": 0}}, {"pk": 53, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Schrodinger'S Cat", "location": null, "bronze_badges": 7, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 53, "suspended": false, "last_login_ip": "193.52.39.1", "type": 0, "reputation": 0}}, {"pk": 54, "model": "server.userprofile", "fields": {"website": "http://esysbio.bccs.uib.no/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Michael Dondrup", "location": "Bergen", "bronze_badges": 19, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 6, "gold_badges": 1, "score": 830, "about_me": "Just wanted to get the autobiographer badge ;)", "user": 54, "suspended": false, "last_login_ip": "84.202.171.221", "type": 1, "reputation": 0}}, {"pk": 55, "model": "server.userprofile", "fields": {"website": "http://bcbio.wordpress.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Brad Chapman", "location": "Boston, MA", "bronze_badges": 12, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 6, "gold_badges": 1, "score": 0, "about_me": null, "user": 55, "suspended": false, "last_login_ip": "209.6.87.200", "type": 1, "reputation": 0}}, {"pk": 56, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Paulati", "location": "Buenos Aires, Argentina", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 56, "suspended": false, "last_login_ip": "190.244.39.172", "type": 0, "reputation": 0}}, {"pk": 57, "model": "server.userprofile", "fields": {"website": "http://davebridges.github.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dave Bridges", "location": "Ann Arbor, MI", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 80, "about_me": null, "user": 57, "suspended": false, "last_login_ip": "141.211.183.90", "type": 0, "reputation": 0}}, {"pk": 58, "model": "server.userprofile", "fields": {"website": "http://eridanus.net", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Daniel Swan", "location": "Oxford, UK", "bronze_badges": 21, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 6, "gold_badges": 1, "score": 650, "about_me": "Senior NGS Computational Biologist at Oxford Gene Technology.<P>\n\nYou can find out more about OGT's products and services at <a href=\"http://www.ogt.co.uk\" rel=\"nofollow\">www.ogt.co.uk</a>\n<P>\nOGT offers a broad range of microarray and targeted sequencing services enabling high-quality, high-throughput genomic studies. The company also specialises in cytogenetic microarays and biomarker discovery and validation.\n<P>\nBlog: <a href=\"http://eridanus.net\" rel=\"nofollow\">eridanus.net</a><p>\nTwitter: <a href=\"http://twitter.com/d_swan\" rel=\"nofollow\">twitter.com/d_swan</a>\n<P>\nI contribute to BioStar on my own time and therefore comments and opinions are my own and not that of my employer.", "user": 58, "suspended": false, "last_login_ip": "213.1.212.91", "type": 1, "reputation": 0}}, {"pk": 59, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Lukfor", "location": "Austria", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 59, "suspended": false, "last_login_ip": "79.31.34.238", "type": 0, "reputation": 0}}, {"pk": 60, "model": "server.userprofile", "fields": {"website": "http://bioperl.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Chris Fields", "location": "University of Illinois Urbana-Champaign", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 30, "about_me": "I'm very sleepy.", "user": 60, "suspended": false, "last_login_ip": "141.142.240.232", "type": 0, "reputation": 0}}, {"pk": 61, "model": "server.userprofile", "fields": {"website": "http://openwetware.org/wiki/User:Darek_Kedra", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Darked89", "location": "Barcelona, Spain", "bronze_badges": 11, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 534, "about_me": null, "user": 61, "suspended": false, "last_login_ip": "84.88.66.226", "type": 1, "reputation": 0}}, {"pk": 62, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Lmartinho", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 62, "suspended": false, "last_login_ip": "188.82.146.217", "type": 0, "reputation": 0}}, {"pk": 63, "model": "server.userprofile", "fields": {"website": "http://manuelcorpas.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Manuel Corpas", "location": "Cambridge", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 441, "about_me": "I am a lead developer of the DECIPHER database, a \u201cDatabasE of Chromosomal Imbalance and Phenotype in Humans using Ensembl Resources\u201d. The DECIPHER database is hosted at the Wellcome Trust Sanger Institute. Its main aim is to collect genotype and phenotype patient information from hospitals and research institutions around the world to help diagnose and catalogue developmental diseases. I was awarded a PhD in Computer Science by the University of Manchester for an algorithm I developed to enhance the classification of protein families using sequence and structural signatures.", "user": 63, "suspended": false, "last_login_ip": "193.62.202.242", "type": 0, "reputation": 0}}, {"pk": 64, "model": "server.userprofile", "fields": {"website": "http://www.abhishek-tiwari.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Abhishek Tiwari", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 50, "about_me": "", "user": 64, "suspended": false, "last_login_ip": "203.211.87.160", "type": 0, "reputation": 0}}, {"pk": 65, "model": "server.userprofile", "fields": {"website": "http://nsaunders.wordpress.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Neilfws", "location": "Sydney, Australia", "bronze_badges": 44, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 16, "gold_badges": 1, "score": 848, "about_me": "I'm a statistical bioinformatician with CSIRO Mathematics, Information and Statistics (CMIS), based in Sydney, Australia.", "user": 65, "suspended": false, "last_login_ip": "130.155.26.9", "type": 2, "reputation": 0}}, {"pk": 66, "model": "server.userprofile", "fields": {"website": "http://friendfeed.com/byzia", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Piotr Byzia", "location": "Wroclaw, Poland", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 66, "suspended": false, "last_login_ip": "85.128.107.226", "type": 0, "reputation": 0}}, {"pk": 67, "model": "server.userprofile", "fields": {"website": "http://jeroen.vangoey.be", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jeroen Van Goey", "location": "Antwerp, Belgium", "bronze_badges": 11, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 597, "about_me": "Just Another Genome Hacker, \n<br />\n<br />\nBioinformatics software developer at <a href=\"http://www.applied-maths.com/\" rel=\"nofollow\">Applied Maths</a>\n<br />\n<br />\nAlso known as BioGeek on the web. (Twitter: <a href=\"http://twitter.com/BioGeek\" rel=\"nofollow\">@BioGeek</a>)\n", "user": 67, "suspended": false, "last_login_ip": "84.198.186.98", "type": 0, "reputation": 0}}, {"pk": 68, "model": "server.userprofile", "fields": {"website": "http://bioinformatics.ucdavis.edu", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Vince", "location": "Davis, CA", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 68, "suspended": false, "last_login_ip": "108.213.76.241", "type": 0, "reputation": 0}}, {"pk": 69, "model": "server.userprofile", "fields": {"website": "http://friendfeed.com/walshtp", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tom Walsh", "location": null, "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": "<p>Bioinformatics programmer and sysadmin. Increasingly grizzled old Perl hacker. Machine for turning tea into grumpiness.\n</p>\n<p>\nAny views expressed here are mine alone and not necessarily representative of my employer.\n</p>", "user": 69, "suspended": false, "last_login_ip": "134.36.64.135", "type": 0, "reputation": 0}}, {"pk": 70, "model": "server.userprofile", "fields": {"website": "http://egonw.github.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Egon Willighagen", "location": "Uppsala", "bronze_badges": 17, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 4, "gold_badges": 1, "score": 407, "about_me": "Post-doc working on Open Data, Open Source, and Open Standards in cheminformatics, chemometrics and bioinformatics. Projects I work on include the CDK, Bioclipse, the Blue Obelisk Data Repository, and much more\u2026", "user": 70, "suspended": false, "last_login_ip": "109.58.70.118", "type": 1, "reputation": 0}}, {"pk": 71, "model": "server.userprofile", "fields": {"website": "http://mndoci.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Mndoci", "location": null, "bronze_badges": 7, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 130, "about_me": "Principal Product Manager for Amazon EC2.  Blogger, podcaster, scientist, technologist, musician and all round geek.  Find me at\n\n<p>\n\n<a href=\"http://mndoci.com\" rel=\"nofollow\">bbgm</a> - the blog<br>\n<a href=\"http://mndoci.github.com\" rel=\"nofollow\">mndoci.github.com</a> - the portal<br>\n<a href=\"http://c2cbio.com\" rel=\"nofollow\">Coast to Coast Bio</a> - the podcast\n</p>", "user": 71, "suspended": false, "last_login_ip": "216.9.28.110", "type": 0, "reputation": 0}}, {"pk": 72, "model": "server.userprofile", "fields": {"website": "http://jermdemo.blogspot.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jeremy Leipzig", "location": "Philadelphia, PA", "bronze_badges": 22, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 5, "gold_badges": 0, "score": 332, "about_me": "Bioinformatics software developer working at a pediatric hospital.", "user": 72, "suspended": false, "last_login_ip": "71.175.116.106", "type": 1, "reputation": 0}}, {"pk": 73, "model": "server.userprofile", "fields": {"website": "http://research.stowers-institute.org/mcm", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Mmarchin", "location": "Kansas City", "bronze_badges": 12, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 239, "about_me": "I'm a Programmer in a bioinformatics core facility at a research institute. I use R and Perl to munge and analyze data from \"next-generation\" sequencing experiments and microarrays.", "user": 73, "suspended": false, "last_login_ip": "12.201.176.150", "type": 0, "reputation": 0}}, {"pk": 74, "model": "server.userprofile", "fields": {"website": "http://onertipaday.blogspot.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Paolo", "location": "Trieste", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 74, "suspended": false, "last_login_ip": "88.54.56.36", "type": 0, "reputation": 0}}, {"pk": 75, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Andrew", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 75, "suspended": false, "last_login_ip": "132.183.93.94", "type": 0, "reputation": 0}}, {"pk": 76, "model": "server.userprofile", "fields": {"website": "http://eleanorhowe.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Eleanor Howe", "location": "Boston", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 76, "suspended": false, "last_login_ip": "155.52.120.23", "type": 0, "reputation": 0}}, {"pk": 77, "model": "server.userprofile", "fields": {"website": "http://bioinformatics.ucdavis.edu", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jboveda", "location": "Davis, CA", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 77, "suspended": false, "last_login_ip": "128.120.143.78", "type": 0, "reputation": 0}}, {"pk": 78, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tim", "location": "Nijmegen, the Netherlands", "bronze_badges": 7, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 105, "about_me": null, "user": 78, "suspended": false, "last_login_ip": "131.174.146.128", "type": 0, "reputation": 0}}, {"pk": 79, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Daniel Jurczak", "location": "Vienna", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 79, "suspended": false, "last_login_ip": "193.170.94.24", "type": 0, "reputation": 0}}, {"pk": 80, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 81", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 80, "suspended": false, "last_login_ip": "66.66.5.254", "type": 0, "reputation": 0}}, {"pk": 81, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Geoffjentry", "location": "MA", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 120, "about_me": null, "user": 81, "suspended": false, "last_login_ip": "132.183.93.59", "type": 0, "reputation": 0}}, {"pk": 82, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 83", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 82, "suspended": false, "last_login_ip": "157.142.202.213", "type": 0, "reputation": 0}}, {"pk": 83, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Anshu", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 50, "about_me": null, "user": 83, "suspended": false, "last_login_ip": "68.201.11.102", "type": 0, "reputation": 0}}, {"pk": 84, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bryan Maloney", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 30, "about_me": "", "user": 84, "suspended": false, "last_login_ip": "134.68.153.195", "type": 0, "reputation": 0}}, {"pk": 85, "model": "server.userprofile", "fields": {"website": "http://sulab.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Andrew Su", "location": "San Diego, CA", "bronze_badges": 15, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 132, "about_me": "I am an Associate Professor at the Scripps Research Institute.  My lab is equally focused on biomedical discovery and bioinformatics tool development.", "user": 85, "suspended": false, "last_login_ip": "137.131.120.185", "type": 1, "reputation": 0}}, {"pk": 86, "model": "server.userprofile", "fields": {"website": "http://scholar.google.com/citations?sortby=pubdate&hl=en&user=XSh3WiAAAAAJ&view_op=list_works", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Khader Shameer", "location": "Bangalore", "bronze_badges": 26, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 7, "gold_badges": 1, "score": 629, "about_me": "Post-doc (Translational Bioinformatics) at Mayo Clinic, working on projects in computational genomics, network analysis and biomedical informatics. \n\nPhD in Computational Biology (National Centre for Biological Sciences (NCBS - TIFR), Bangalore - India) ", "user": 86, "suspended": false, "last_login_ip": "129.176.151.11", "type": 1, "reputation": 0}}, {"pk": 87, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Pierre", "location": "", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 70, "about_me": "", "user": 87, "suspended": false, "last_login_ip": "193.145.56.241", "type": 0, "reputation": 0}}, {"pk": 88, "model": "server.userprofile", "fields": {"website": "http://stackoverflow.com/users/163080", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Yuri", "location": "Bethesda, MD", "bronze_badges": 13, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 265, "about_me": "Bioinformatics research of brain tumor, mostly with MATLAB. ", "user": 88, "suspended": false, "last_login_ip": "137.187.177.83", "type": 0, "reputation": 0}}, {"pk": 89, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Allpowerde", "location": null, "bronze_badges": 9, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 278, "about_me": null, "user": 89, "suspended": false, "last_login_ip": "130.102.158.12", "type": 0, "reputation": 0}}, {"pk": 90, "model": "server.userprofile", "fields": {"website": "http://followthedata.wordpress.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Mikael Huss", "location": "Stockholm", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 1, "score": 185, "about_me": "twitter.com/mikaelhuss", "user": 90, "suspended": false, "last_login_ip": "84.55.102.83", "type": 0, "reputation": 0}}, {"pk": 91, "model": "server.userprofile", "fields": {"website": "http://hostpathogen.blogspot.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Perry", "location": "philadelphia", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 92, "about_me": "genomics & computational biology student @ Upenn", "user": 91, "suspended": false, "last_login_ip": "128.36.40.91", "type": 0, "reputation": 0}}, {"pk": 92, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 93", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 92, "suspended": false, "last_login_ip": "68.81.94.44", "type": 0, "reputation": 0}}, {"pk": 93, "model": "server.userprofile", "fields": {"website": "http://rosettadesigngroup.com/blog/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nir London", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 40, "about_me": "", "user": 93, "suspended": false, "last_login_ip": "132.65.36.15", "type": 0, "reputation": 0}}, {"pk": 94, "model": "server.userprofile", "fields": {"website": "http://in.tegr.in", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bioinfo", "location": "DC Metro Area", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 70, "about_me": "Proven and highly competent engineer, biotechnology manager, and entrepreneur with over 8 years experience in providing intuitive project management, professional leadership, and deep technical understanding on a wide variety of biotechnology and web based projects.", "user": 94, "suspended": false, "last_login_ip": "38.127.157.162", "type": 0, "reputation": 0}}, {"pk": 95, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jc", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 95, "suspended": false, "last_login_ip": "128.91.204.81", "type": 0, "reputation": 0}}, {"pk": 96, "model": "server.userprofile", "fields": {"website": "http://noble.gs.washington.edu/~mmh1/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Michael Hoffman", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 20, "about_me": "", "user": 96, "suspended": false, "last_login_ip": "128.208.25.23", "type": 0, "reputation": 0}}, {"pk": 97, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nancy Parmalee", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 20, "about_me": "", "user": 97, "suspended": false, "last_login_ip": "156.111.228.98", "type": 0, "reputation": 0}}, {"pk": 98, "model": "server.userprofile", "fields": {"website": "http://sites.google.com/site/avilella", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Avilella", "location": "Cambridge, UK", "bronze_badges": 12, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 5, "gold_badges": 0, "score": 40, "about_me": "I am at the Vertebrate Genomics team at EMBL-EBI in Cambridge, UK.", "user": 98, "suspended": false, "last_login_ip": "193.62.194.244", "type": 0, "reputation": 0}}, {"pk": 99, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ryan", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 30, "about_me": "", "user": 99, "suspended": false, "last_login_ip": "169.230.105.12", "type": 0, "reputation": 0}}, {"pk": 100, "model": "server.userprofile", "fields": {"website": "http://www.socal-diybio.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ruphos", "location": "Los Angeles, CA", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Autism genebank manager, organizer / co-founder of SoCal DIYbio.", "user": 100, "suspended": false, "last_login_ip": "38.98.62.2", "type": 0, "reputation": 0}}, {"pk": 101, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "John Davey", "location": "Edinburgh", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 101, "suspended": false, "last_login_ip": "188.223.2.72", "type": 0, "reputation": 0}}, {"pk": 102, "model": "server.userprofile", "fields": {"website": "http://hongiiv.tistory.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Hongiiv", "location": "Seoul, Korea", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Genetic Hobbyist\nMy genome info: http://www.snpedia.com/index.php/User:Hongiiv", "user": 102, "suspended": false, "last_login_ip": "152.99.73.10", "type": 0, "reputation": 0}}, {"pk": 103, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Mfenner", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 103, "suspended": false, "last_login_ip": "193.174.111.250", "type": 0, "reputation": 0}}, {"pk": 104, "model": "server.userprofile", "fields": {"website": "http://metaDatabase.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dan", "location": "Dundee", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 40, "about_me": "Hello", "user": 104, "suspended": false, "last_login_ip": "92.233.142.235", "type": 0, "reputation": 0}}, {"pk": 105, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Sujai Kumar", "location": "United Kingdom", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 105, "suspended": false, "last_login_ip": "129.215.4.131", "type": 0, "reputation": 0}}, {"pk": 106, "model": "server.userprofile", "fields": {"website": "http://ericsuh.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Eric", "location": "Princeton, NJ", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 106, "suspended": false, "last_login_ip": "128.112.114.58", "type": 0, "reputation": 0}}, {"pk": 107, "model": "server.userprofile", "fields": {"website": "http://greengoo.de", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Konrad", "location": "Berlin", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:34", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "MSc student and tutor at the Freie Universit\u00e4t Berlin.", "user": 107, "suspended": false, "last_login_ip": "87.77.158.189", "type": 0, "reputation": 0}}, {"pk": 108, "model": "server.userprofile", "fields": {"website": "http://www.helixsoft.nl/blog", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Martijn Van Iersel", "location": "Netherlands", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "Developer for WikiPathways (http://www.wikipatwhays.org), PathVisio (http://www.pathvisio.org), BridgeDb (http://www.bridgedb.org) and LibSBGN (http://libsbgn.sourceforge.net)", "user": 108, "suspended": false, "last_login_ip": "193.62.194.248", "type": 0, "reputation": 0}}, {"pk": 109, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Sashi Kiran Challa", "location": "Portland, Oregon", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 30, "about_me": "Statistical Programmer, Oregon Clinical and Translational Research Institute.", "user": 109, "suspended": false, "last_login_ip": "137.53.241.9", "type": 0, "reputation": 0}}, {"pk": 110, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 111", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 110, "suspended": false, "last_login_ip": "80.98.236.22", "type": 0, "reputation": 0}}, {"pk": 111, "model": "server.userprofile", "fields": {"website": "http://www.walterjessen.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Walter Jessen", "location": "Indianapolis, Indiana", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Computational biologist, founder and CEO of <a href=\"http://www.highlighthealth.com\" rel=\"nofollow\">Highlight HEALTH</a>, curator of <a href=\"http://biomarkercommons.org\" rel=\"nofollow\">Biomarker Commons</a>, husband & father, easily distracted & interested in everything.", "user": 111, "suspended": false, "last_login_ip": "166.137.140.88", "type": 0, "reputation": 0}}, {"pk": 112, "model": "server.userprofile", "fields": {"website": "http://alisa-jon.net/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jmanning2K", "location": "Near Boston, MA", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 10, "about_me": "Bioinformatics Programmer / Analyst", "user": 112, "suspended": false, "last_login_ip": "12.9.88.66", "type": 0, "reputation": 0}}, {"pk": 113, "model": "server.userprofile", "fields": {"website": "http://gotgenes.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gotgenes", "location": "Blacksburg, VA, USA", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 10, "about_me": "My name is Chris Lasher. I study biological networks as a graduate student in the Genetics, Bioinformatics, and Computational Biology (GBCB) program at Virginia Tech. I enjoy revision control, unit testing, and long coding sessions in Python.\n\nI am on twitter at http://twitter.com/gotgenes", "user": 113, "suspended": false, "last_login_ip": "128.173.54.30", "type": 0, "reputation": 0}}, {"pk": 114, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jan Van Haarst", "location": "Wageningen, NL", "bronze_badges": 7, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 114, "suspended": false, "last_login_ip": "137.224.252.10", "type": 0, "reputation": 0}}, {"pk": 115, "model": "server.userprofile", "fields": {"website": "http://www.32geeks.com/biodb/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Melanie", "location": "San Diego", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 185, "about_me": null, "user": 115, "suspended": false, "last_login_ip": "209.234.190.105", "type": 0, "reputation": 0}}, {"pk": 116, "model": "server.userprofile", "fields": {"website": "http://www.chrisamiller.com/science/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Chris Miller", "location": "St. Louis, MO", "bronze_badges": 23, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 3, "gold_badges": 0, "score": 731, "about_me": "Staff Scientist at the Washington University Genome Institute.", "user": 116, "suspended": false, "last_login_ip": "128.252.233.244", "type": 1, "reputation": 0}}, {"pk": 117, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Enlavin", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 117, "suspended": false, "last_login_ip": "212.163.145.220", "type": 0, "reputation": 0}}, {"pk": 118, "model": "server.userprofile", "fields": {"website": "http://stackoverflow.com/users/69588/phis", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Phis", "location": "CH", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 348, "about_me": "Biology:\n*Evolutionary Biology/Phylogenetics\n*Molecular Biology/Biochemistry\n*Ecological Genetics/Population Genetics/Evolutionary Genomics\n*Computational Biology\n\n\nProgramming:\n*Delphi/Pascal\n*x86 Assembly\n*C (basic C++)\n*R\n*Perl (basic)", "user": 118, "suspended": false, "last_login_ip": "87.144.75.2", "type": 0, "reputation": 0}}, {"pk": 119, "model": "server.userprofile", "fields": {"website": "http://mng.iop.kcl.ac.uk", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Cassj", "location": "London", "bronze_badges": 11, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 208, "about_me": "Bioinformatician in Noel Buckley's <a href=\"http://mng.iop.kcl.ac.uk\" rel=\"nofollow\">Molecular Neurobiology Group</a> at the Institute of Psychiatry, King's College London. Mostly working with high throughput datasets relating to transcriptional regulation during neural cell differentiation.\n\nI also run <a href=\"http://biogeeks.wordpress.com/\" rel=\"nofollow\">London BioGeeks</a>", "user": 119, "suspended": false, "last_login_ip": "194.83.142.204", "type": 0, "reputation": 0}}, {"pk": 120, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "John", "location": null, "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 74, "about_me": null, "user": 120, "suspended": false, "last_login_ip": "67.188.178.172", "type": 0, "reputation": 0}}, {"pk": 121, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Will", "location": null, "bronze_badges": 14, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 181, "about_me": null, "user": 121, "suspended": false, "last_login_ip": "68.82.35.3", "type": 1, "reputation": 0}}, {"pk": 122, "model": "server.userprofile", "fields": {"website": "http://noble.gs.washington.edu", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Charles E. Grant", "location": "Seattle", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "I'm a computer programmer in the laboratory of William Noble in the Genome Science Department of the University of Washington. My primary responsibility if the maintenance of <a href=\"http://meme.nbcr.net\" rel=\"nofollow\">MEME Suite</a>. ", "user": 122, "suspended": false, "last_login_ip": "173.250.141.16", "type": 0, "reputation": 0}}, {"pk": 123, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Alex", "location": "Institute of Cytology, St.Petersburg, Russia", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": null, "user": 123, "suspended": false, "last_login_ip": "93.100.10.198", "type": 0, "reputation": 0}}, {"pk": 124, "model": "server.userprofile", "fields": {"website": "http://www.r-statistics.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tal Galili", "location": "Israel", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 42, "about_me": "I am doing my second degree in BioStatistics in TAU.", "user": 124, "suspended": false, "last_login_ip": "79.181.129.219", "type": 0, "reputation": 0}}, {"pk": 125, "model": "server.userprofile", "fields": {"website": "http://denverhealth.org/portal/Services/PublicHealth/TuberculosisTBClinic/Research.aspx", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Matt Parker", "location": "Denver, CO", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "I'm a statistician working with Denver's tuberculosis clinic.", "user": 125, "suspended": false, "last_login_ip": "205.170.235.246", "type": 0, "reputation": 0}}, {"pk": 126, "model": "server.userprofile", "fields": {"website": "http://genedrift.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Paulo Nuin", "location": "Kingston, ON Canada", "bronze_badges": 14, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 5, "gold_badges": 1, "score": -3, "about_me": "Bioinformatician", "user": 126, "suspended": false, "last_login_ip": "130.15.144.220", "type": 0, "reputation": 0}}, {"pk": 127, "model": "server.userprofile", "fields": {"website": "http://my.biotechlife.net", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Rvidal", "location": "Kingston, Canada", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 52, "about_me": "Biological Engineer, DNA Network co-founder, Science 2.0 enthusiast, PhD Candidate, Budding bioinformatician.", "user": 127, "suspended": false, "last_login_ip": "130.15.117.190", "type": 0, "reputation": 0}}, {"pk": 128, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Andriyev", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 128, "suspended": false, "last_login_ip": "66.244.80.2", "type": 0, "reputation": 0}}, {"pk": 129, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 130", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 129, "suspended": false, "last_login_ip": "98.201.105.10", "type": 0, "reputation": 0}}, {"pk": 130, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Rajarshi Guha", "location": null, "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 72, "about_me": null, "user": 130, "suspended": false, "last_login_ip": "165.112.44.100", "type": 0, "reputation": 0}}, {"pk": 131, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Pogonomyrmex", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 131, "suspended": false, "last_login_ip": "88.207.35.15", "type": 0, "reputation": 0}}, {"pk": 132, "model": "server.userprofile", "fields": {"website": "http://keithsheppard.name", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Keith", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 132, "suspended": false, "last_login_ip": "209.222.206.50", "type": 0, "reputation": 0}}, {"pk": 133, "model": "server.userprofile", "fields": {"website": "http://logspace.co.uk", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ben Blackburne", "location": "Manchester, UK", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 133, "suspended": false, "last_login_ip": "130.88.90.187", "type": 0, "reputation": 0}}, {"pk": 134, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Markf", "location": "New Zealand", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 40, "about_me": null, "user": 134, "suspended": false, "last_login_ip": "161.65.16.253", "type": 0, "reputation": 0}}, {"pk": 135, "model": "server.userprofile", "fields": {"website": "http://der.bioinformatiker.at", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Brandstaetter", "location": "Austria", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 164, "about_me": "Austrian bioinformatics researcher", "user": 135, "suspended": false, "last_login_ip": "193.170.124.186", "type": 0, "reputation": 0}}, {"pk": 136, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Othercriteria", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 136, "suspended": false, "last_login_ip": "72.221.64.155", "type": 0, "reputation": 0}}, {"pk": 137, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Marcin Cieslik", "location": null, "bronze_badges": 7, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 100, "about_me": null, "user": 137, "suspended": false, "last_login_ip": "128.143.44.119", "type": 0, "reputation": 0}}, {"pk": 138, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 139", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 138, "suspended": false, "last_login_ip": "95.146.161.244", "type": 0, "reputation": 0}}, {"pk": 139, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Fergycool", "location": "Cambridge, UK", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 139, "suspended": false, "last_login_ip": "87.194.211.43", "type": 0, "reputation": 0}}, {"pk": 140, "model": "server.userprofile", "fields": {"website": "http://yannick.poulet.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Yannick Wurm", "location": "Jakarta", "bronze_badges": 9, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": -1, "about_me": "Bioinformaticist studying the evolution of ant societies. \nSome recent stuff: \n<ul>\n <li><a href=\"http://www.pnas.org/cgi/doi/10.1073/pnas.1009690108\" rel=\"nofollow\">fire ant genome sequence</a></li>\n <li><a href=\"http://www.antgenomes.com\" rel=\"nofollow\">ant genomes database</a></li>\n <li><a href=\"http://www.sequenceserver.com\" rel=\"nofollow\">sequence blasting</a></li>\n</ul>\nenjoy NGS, ruby & bioconductor", "user": 140, "suspended": false, "last_login_ip": "110.139.184.254", "type": 0, "reputation": 0}}, {"pk": 141, "model": "server.userprofile", "fields": {"website": "http://www.bioinformatics.fr", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Fred Fleche", "location": "Paris, France", "bronze_badges": 13, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 3, "gold_badges": 0, "score": 247, "about_me": "<p>Bioinformatician @ Sanofi-Aventis.</p>\n\n<p>Main interest is data integration of cancer related information.</p>\n\n<p>Favorites Informatics tools:</p>\n<ul>\n<li>PHP</li>\n<li>Javascript - JQuery</li>\n<li>MySQL- PostgreSQL</li>\n<li>HTML - CSS</li>\n<li>XML - SVG</li>\n<li>VBA</li>\n</ul>", "user": 141, "suspended": false, "last_login_ip": "193.202.91.11", "type": 1, "reputation": 0}}, {"pk": 142, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 143", "location": "", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 42, "about_me": "", "user": 142, "suspended": false, "last_login_ip": "137.43.208.67", "type": 0, "reputation": 0}}, {"pk": 143, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 144", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 143, "suspended": false, "last_login_ip": "85.218.23.17", "type": 0, "reputation": 0}}, {"pk": 144, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Oli", "location": null, "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 60, "about_me": null, "user": 144, "suspended": false, "last_login_ip": "70.81.170.125", "type": 0, "reputation": 0}}, {"pk": 145, "model": "server.userprofile", "fields": {"website": "http://biopython.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Peter", "location": null, "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 9, "about_me": null, "user": 145, "suspended": false, "last_login_ip": "95.145.184.94", "type": 0, "reputation": 0}}, {"pk": 146, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 147", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:49:24", "json": "", "silver_badges": 0, "gold_badges": 0, "score": -18, "about_me": "", "user": 146, "suspended": false, "last_login_ip": "82.58.153.17", "type": 0, "reputation": 0}}, {"pk": 147, "model": "server.userprofile", "fields": {"website": "http://dim.fm.usp.br", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jarretinha", "location": "S\u00e3o Paulo, Brazil", "bronze_badges": 11, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 498, "about_me": "Researcher at HCFMUSP (a very large hospitalar complex), biologist and computer geek. Bionformatics appeared as a daily necessity. An excellent excuse to put my favorite abilities (programming & hacking) into action.\n<p>\nYou can find me on twitter and google things.\n<p>\nI'm on a VERY busy state these and miss the fuzz in BioStar.", "user": 147, "suspended": false, "last_login_ip": "143.107.178.54", "type": 1, "reputation": 0}}, {"pk": 148, "model": "server.userprofile", "fields": {"website": "http://www.ebi.ac.uk/~birney/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ewan Birney", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 95, "about_me": "", "user": 148, "suspended": false, "last_login_ip": "94.173.32.155", "type": 0, "reputation": 0}}, {"pk": 149, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 150", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 149, "suspended": false, "last_login_ip": "212.143.99.102", "type": 0, "reputation": 0}}, {"pk": 150, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jelle", "location": "Netherlands", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 150, "suspended": false, "last_login_ip": "87.209.26.175", "type": 0, "reputation": 0}}, {"pk": 151, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Rob Syme", "location": "Perth, Western Australia", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "Working on my PhD, looking at fungal genomics. Am easily excited by fast/cheap sequencing and horizontal gene transfer.", "user": 151, "suspended": false, "last_login_ip": "134.7.248.132", "type": 0, "reputation": 0}}, {"pk": 152, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Xtof", "location": "Paris", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 152, "suspended": false, "last_login_ip": "157.99.64.13", "type": 0, "reputation": 0}}, {"pk": 153, "model": "server.userprofile", "fields": {"website": "http://fr.linkedin.com/in/kirsleychennen", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kirsley", "location": "Paris", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 50, "about_me": "Trainee in Bioinformatics in the Unit of PF4 Integration and Genome Analysis at Institut Pasteur ", "user": 153, "suspended": false, "last_login_ip": "87.91.205.66", "type": 0, "reputation": 0}}, {"pk": 154, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 155", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 154, "suspended": false, "last_login_ip": "59.72.84.29", "type": 0, "reputation": 0}}, {"pk": 155, "model": "server.userprofile", "fields": {"website": "http://joachimbaran.wordpress.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Joachim", "location": "Toronto, Canada", "bronze_badges": 12, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 3, "gold_badges": 1, "score": 0, "about_me": "I am a Database Programmer and Technical Analyst at the Ontario Institute for Cancer Research in Toronto, Canada.\n\nMy previous affiliation was with the University of Manchester, Manchester, UK.", "user": 155, "suspended": false, "last_login_ip": "206.108.127.2", "type": 0, "reputation": 0}}, {"pk": 156, "model": "server.userprofile", "fields": {"website": "http://people.rez-gif.supelec.fr/mmichaut/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Magali Michaut", "location": "Toronto", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 1, "gold_badges": 1, "score": 0, "about_me": null, "user": 156, "suspended": false, "last_login_ip": "99.230.242.11", "type": 0, "reputation": 0}}, {"pk": 157, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 158", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": -10, "about_me": "", "user": 157, "suspended": false, "last_login_ip": "147.100.115.243", "type": 0, "reputation": 0}}, {"pk": 158, "model": "server.userprofile", "fields": {"website": "http://twitter.com/fredebibs", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Fred", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 158, "suspended": false, "last_login_ip": "193.48.42.2", "type": 0, "reputation": 0}}, {"pk": 159, "model": "server.userprofile", "fields": {"website": "http://personalpages.manchester.ac.uk/staff/David.Gerrard/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dave Gerrard", "location": "Manchester", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 70, "about_me": "You will be: \"Jack of all trades, master of none.\"", "user": 159, "suspended": false, "last_login_ip": "130.88.91.103", "type": 0, "reputation": 0}}, {"pk": 160, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Antony", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 10, "about_me": "", "user": 160, "suspended": false, "last_login_ip": "83.99.51.185", "type": 0, "reputation": 0}}, {"pk": 161, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dooguy", "location": "Rennes - France", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "I'm a french PHD student and i'm currently working in genome annotation and subcellular localization prediction.", "user": 161, "suspended": false, "last_login_ip": "129.20.85.216", "type": 0, "reputation": 0}}, {"pk": 162, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Handstad", "location": "Norway", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 162, "suspended": false, "last_login_ip": "129.241.180.241", "type": 0, "reputation": 0}}, {"pk": 163, "model": "server.userprofile", "fields": {"website": "http://iphylo.blogspot.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Roderic Page", "location": "Glasgow", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 144, "about_me": null, "user": 163, "suspended": false, "last_login_ip": "130.209.6.40", "type": 0, "reputation": 0}}, {"pk": 164, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 165", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 164, "suspended": false, "last_login_ip": "160.36.155.197", "type": 0, "reputation": 0}}, {"pk": 165, "model": "server.userprofile", "fields": {"website": "http://linnaeus.zoology.gla.ac.uk/~jhughes/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Joseph Hughes", "location": "Glasgow", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 62, "about_me": "<p>I was born in London but brought up in France. I moved back to London for university and spent a year in Marburg, Germany. I went on to do a PhD at Imperial College on the Silwood Park campus. My first postdoc was at the Natural History Museum, London. I then moved to Glasgow for a second postdoc at the University of Glasgow. I later got a grant to continue research at the university. I am married and have a kids (a girl and a boy).</p>\n<p>My interests are in the evolution of host-parasite interactions. Phylogenetics and bioinformatics form an important aspect of my research. You can see my most recent publications <a href=\"http://www.mendeley.com/profiles/joseph-hughes/\" rel=\"nofollow\">here</a>.</p>\nhttp://twitter.com/blJOg", "user": 165, "suspended": false, "last_login_ip": "130.209.6.41", "type": 0, "reputation": 0}}, {"pk": 166, "model": "server.userprofile", "fields": {"website": "http://www.davidosomething.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Davidosomething", "location": "Boston", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "enthusiast", "user": 166, "suspended": false, "last_login_ip": "24.34.124.207", "type": 0, "reputation": 0}}, {"pk": 167, "model": "server.userprofile", "fields": {"website": "http://www.bleedingedgebiotech.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kraut", "location": "Pittsburgh, PA", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "2nd hardest working man at <a href=\"http://bioteam.net\" rel=\"nofollow\">BioTeam</a>", "user": 167, "suspended": false, "last_login_ip": "67.172.16.188", "type": 0, "reputation": 0}}, {"pk": 168, "model": "server.userprofile", "fields": {"website": "http://twitter.com/tisimpson", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ian Simpson", "location": "Edinburgh", "bronze_badges": 11, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 340, "about_me": "Developmental Biologist, Geneticist, Bioinformatician and Neuroscientist.", "user": 168, "suspended": false, "last_login_ip": "129.215.91.213", "type": 0, "reputation": 0}}, {"pk": 169, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Roman Valls Guimer\u00e0", "location": null, "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 169, "suspended": false, "last_login_ip": "130.229.48.203", "type": 0, "reputation": 0}}, {"pk": 170, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jan Oosting", "location": "Leiden, NL", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 85, "about_me": null, "user": 170, "suspended": false, "last_login_ip": "83.82.49.230", "type": 0, "reputation": 0}}, {"pk": 171, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Simon Penel", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 20, "about_me": "", "user": 171, "suspended": false, "last_login_ip": "134.214.32.80", "type": 0, "reputation": 0}}, {"pk": 172, "model": "server.userprofile", "fields": {"website": "http://wwwfgu.anat.ox.ac.uk/~lg/oss/ruffus/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Leo Goodstadt", "location": "oxford", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 20, "about_me": null, "user": 172, "suspended": false, "last_login_ip": "163.1.29.123", "type": 0, "reputation": 0}}, {"pk": 173, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tom", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 173, "suspended": false, "last_login_ip": "86.16.25.115", "type": 0, "reputation": 0}}, {"pk": 174, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 175", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 174, "suspended": false, "last_login_ip": "195.138.194.1", "type": 0, "reputation": 0}}, {"pk": 175, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Noyk", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 20, "about_me": "", "user": 175, "suspended": false, "last_login_ip": "121.121.62.203", "type": 0, "reputation": 0}}, {"pk": 176, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bertrand", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 30, "about_me": "", "user": 176, "suspended": false, "last_login_ip": "147.99.111.194", "type": 0, "reputation": 0}}, {"pk": 177, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Charles", "location": "South Africa", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 177, "suspended": false, "last_login_ip": "137.215.6.53", "type": 0, "reputation": 0}}, {"pk": 178, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Scott", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 48, "about_me": "", "user": 178, "suspended": false, "last_login_ip": "67.237.56.153", "type": 0, "reputation": 0}}, {"pk": 179, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Rutger Vos", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 40, "about_me": "", "user": 179, "suspended": false, "last_login_ip": "90.218.5.12", "type": 0, "reputation": 0}}, {"pk": 180, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jukka Matilainen", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "<a href=\"http://www.euformatics.com/\" rel=\"nofollow\">http://www.euformatics.com/</a>", "user": 180, "suspended": false, "last_login_ip": "194.136.27.110", "type": 0, "reputation": 0}}, {"pk": 181, "model": "server.userprofile", "fields": {"website": "http://github.com/sopo", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Agrimaldi", "location": "Paris", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Master 2 student | Pure biology background | Learned bioinformatics and programming as a hobby | Interested in genomics, developmental biology, gene regulation mechanisms and epigenetics in general |", "user": 181, "suspended": false, "last_login_ip": "192.134.152.176", "type": 0, "reputation": 0}}, {"pk": 182, "model": "server.userprofile", "fields": {"website": "http://hyperphor.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Mt", "location": "Bay Area", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 182, "suspended": false, "last_login_ip": "69.107.73.184", "type": 0, "reputation": 0}}, {"pk": 183, "model": "server.userprofile", "fields": {"website": "http://boscoh.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bosco Ho", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 20, "about_me": null, "user": 183, "suspended": false, "last_login_ip": "123.243.137.13", "type": 0, "reputation": 0}}, {"pk": 184, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Noyk", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 60, "about_me": "", "user": 184, "suspended": false, "last_login_ip": "202.185.55.241", "type": 0, "reputation": 0}}, {"pk": 185, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Emmanuelle Morin", "location": "France", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 85, "about_me": "bioinformatician for 8 years now !\nactually working on NGS data and comparative genomics", "user": 185, "suspended": false, "last_login_ip": "147.99.215.194", "type": 0, "reputation": 0}}, {"pk": 186, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Panos", "location": "France", "bronze_badges": 12, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 186, "suspended": false, "last_login_ip": "24.126.66.113", "type": 0, "reputation": 0}}, {"pk": 187, "model": "server.userprofile", "fields": {"website": "http://www.rubor.de", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kristian Rother", "location": "Poznan, Poland", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Bioinformatics. SoftDev. Training.", "user": 187, "suspended": false, "last_login_ip": "150.254.122.5", "type": 0, "reputation": 0}}, {"pk": 188, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Colin", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 188, "suspended": false, "last_login_ip": "86.20.111.107", "type": 0, "reputation": 0}}, {"pk": 189, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 190", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 189, "suspended": false, "last_login_ip": "67.169.211.218", "type": 0, "reputation": 0}}, {"pk": 190, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Seidel", "location": null, "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": "I work as a scientist at a non-profit research institute.", "user": 190, "suspended": false, "last_login_ip": "75.87.178.14", "type": 0, "reputation": 0}}, {"pk": 191, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Selflessgene", "location": "Boston", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 191, "suspended": false, "last_login_ip": "75.74.96.251", "type": 0, "reputation": 0}}, {"pk": 192, "model": "server.userprofile", "fields": {"website": "http://www.fludb.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Burke Squires", "location": "Dallas", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "I am a computational biologist / bioinformaticist specialisting in influenza virus at the Influenza Research Database (www.fludb.org), formerly the BioHealthBase, one of five NIAID sponsoed Bioinformatics Resource Centers (BRC). I also contribute the to Virus Pathogen Resource (ViPR), the new virus Bioinformatics Resource Center (BRC).\n\nFurthermore, I am a Doctoral student at the University of Texas at Arlington in Computer Sciecne and Engineering, whiere my research involves molecular infection models and stochastic, discrete event simulations of influnza virus life cycle.", "user": 192, "suspended": false, "last_login_ip": "129.112.109.243", "type": 0, "reputation": 0}}, {"pk": 193, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jeff Kiefer", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 193, "suspended": false, "last_login_ip": "70.176.12.226", "type": 0, "reputation": 0}}, {"pk": 194, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gregor Rot", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 194, "suspended": false, "last_login_ip": "193.2.72.50", "type": 0, "reputation": 0}}, {"pk": 195, "model": "server.userprofile", "fields": {"website": "http://www.swamukh1985in.blogspot.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Swapnil", "location": "nagpur,india", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 195, "suspended": false, "last_login_ip": "216.104.15.134", "type": 0, "reputation": 0}}, {"pk": 196, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jess", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 196, "suspended": false, "last_login_ip": "144.32.213.51", "type": 0, "reputation": 0}}, {"pk": 197, "model": "server.userprofile", "fields": {"website": "http://-", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Sb3", "location": "-", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "-", "user": 197, "suspended": false, "last_login_ip": "212.250.189.37", "type": 0, "reputation": 0}}, {"pk": 198, "model": "server.userprofile", "fields": {"website": "http://none", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tony", "location": "Lyon", "bronze_badges": 12, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "Bioinformatician.\nInterested in genomics, trancriptomics, NGS.", "user": 198, "suspended": false, "last_login_ip": "194.167.143.4", "type": 0, "reputation": 0}}, {"pk": 199, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Biomed", "location": "Bethesda, MD, USA", "bronze_badges": 18, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 8, "gold_badges": 0, "score": 0, "about_me": "Research Fellow, National Human Genome Research Institute", "user": 199, "suspended": false, "last_login_ip": "165.112.151.49", "type": 0, "reputation": 0}}, {"pk": 200, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Susan", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 200, "suspended": false, "last_login_ip": "76.66.199.183", "type": 0, "reputation": 0}}, {"pk": 201, "model": "server.userprofile", "fields": {"website": "http://www.staff.ncl.ac.uk/d.j.wilkinson/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Darrenjw", "location": "Newcastle, UK", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Professor of Stochastic Modelling and Computational Systems Biologist at Newcastle University, UK", "user": 201, "suspended": false, "last_login_ip": "109.153.130.180", "type": 0, "reputation": 0}}, {"pk": 202, "model": "server.userprofile", "fields": {"website": "http://www.empiricist.ca", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Adrian", "location": "Center for Human Genetic Research, MGH, Boston MA", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 202, "suspended": false, "last_login_ip": "108.27.115.181", "type": 0, "reputation": 0}}, {"pk": 203, "model": "server.userprofile", "fields": {"website": "http://www.activeeon.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Cedric Dalmasso", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 203, "suspended": false, "last_login_ip": "83.136.166.178", "type": 0, "reputation": 0}}, {"pk": 204, "model": "server.userprofile", "fields": {"website": "http://gcollet.ouvaton.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bilouweb", "location": "Saclay, France", "bronze_badges": 10, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 3, "gold_badges": 1, "score": -1, "about_me": "I am on post-doc at CEA-Saclay.\n<p>\nI work at the IBITEC-S/SIMOPRO Lab.\n<p>\nMy research interests are in solving difficult issues from bioinformatics with efficient algorithms and math programming. I like graph theory and combinatorial optimization.\n<p>\nI currently work on protein multiple alignments and how to derive statistical information from them.", "user": 204, "suspended": false, "last_login_ip": "86.77.53.230", "type": 0, "reputation": 0}}, {"pk": 205, "model": "server.userprofile", "fields": {"website": "http://twitter.com/ma_ko", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ma_Ko", "location": "Saitama, Japan", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Molecular biologist // Genetics // Bioinformatics", "user": 205, "suspended": false, "last_login_ip": "220.96.44.232", "type": 0, "reputation": 0}}, {"pk": 206, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 207", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 206, "suspended": false, "last_login_ip": "84.88.20.10", "type": 0, "reputation": 0}}, {"pk": 207, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Anthony Kong", "location": "Sydney, Australia", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 207, "suspended": false, "last_login_ip": "203.210.68.145", "type": 0, "reputation": 0}}, {"pk": 208, "model": "server.userprofile", "fields": {"website": "http://vincentdavis.net", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Vincent", "location": "Colorado", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "<p>Interested in everything</p>\n<p>Don't know anything</p>\n<p>What to try everything</p>\n<p>Don't finish anything</p>", "user": 208, "suspended": false, "last_login_ip": "71.218.115.48", "type": 0, "reputation": 0}}, {"pk": 209, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tomasz", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 209, "suspended": false, "last_login_ip": "130.14.254.25", "type": 0, "reputation": 0}}, {"pk": 210, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Blackbox", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 210, "suspended": false, "last_login_ip": "131.174.146.243", "type": 0, "reputation": 0}}, {"pk": 211, "model": "server.userprofile", "fields": {"website": "http://www.linkedin.com/in/dkatsubo", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dma_K", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 211, "suspended": false, "last_login_ip": "85.145.153.25", "type": 0, "reputation": 0}}, {"pk": 212, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Pansapiens", "location": "AU", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 212, "suspended": false, "last_login_ip": "130.194.194.192", "type": 0, "reputation": 0}}, {"pk": 213, "model": "server.userprofile", "fields": {"website": "http://fearthecow.net/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Rob", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "", "user": 213, "suspended": false, "last_login_ip": "130.102.117.54", "type": 0, "reputation": 0}}, {"pk": 214, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Noyk", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 214, "suspended": false, "last_login_ip": "121.121.71.199", "type": 0, "reputation": 0}}, {"pk": 215, "model": "server.userprofile", "fields": {"website": "http://www.bio.ulaval.ca/louisbernatchez/pers_page/enormandeau_rp.htm", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Eric Normandeau", "location": "Quebec, Canada", "bronze_badges": 29, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 5, "gold_badges": 0, "score": -2, "about_me": "Biologist, fluent in R, aiming at Python guru-ness<br/>\n(give me a few more years :)<br/><br/>\nNow learning:<br/>\nPerl<br/>\nLinux system administration<br/><br/>\nI have worked with microarrays, qRT-PCR and am currently working with Next Generation Sequencing as well as RAD sequencing and Genotyping by Sequencing data.", "user": 215, "suspended": false, "last_login_ip": "74.15.200.28", "type": 1, "reputation": 0}}, {"pk": 216, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Louis Letourneau", "location": "Montreal", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 216, "suspended": false, "last_login_ip": "132.216.77.22", "type": 0, "reputation": 0}}, {"pk": 217, "model": "server.userprofile", "fields": {"website": "http://www.compbiome.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Stew", "location": "Cambridge", "bronze_badges": 10, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 4, "gold_badges": 0, "score": 0, "about_me": "I am a computational biologist in Cambridge. I work mainly in R, perl and shell scripts. I work on chIP chip/Seq, motif finding, microarrays and functional analysis. ", "user": 217, "suspended": false, "last_login_ip": "130.117.125.51", "type": 0, "reputation": 0}}, {"pk": 218, "model": "server.userprofile", "fields": {"website": "http://tfrayner.sdf-eu.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tim Rayner", "location": "Cambridge", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Bioinformatician attached to the Smith Lab, CIMR, University of Cambridge.", "user": 218, "suspended": false, "last_login_ip": "86.177.39.113", "type": 0, "reputation": 0}}, {"pk": 219, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ljxue", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 219, "suspended": false, "last_login_ip": "202.127.18.254", "type": 0, "reputation": 0}}, {"pk": 220, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Mehraj", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 220, "suspended": false, "last_login_ip": "139.124.153.193", "type": 0, "reputation": 0}}, {"pk": 221, "model": "server.userprofile", "fields": {"website": "http://standage.public.iastate.edu", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Daniel Standage", "location": "Ames, Iowa, USA", "bronze_badges": 12, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 221, "suspended": false, "last_login_ip": "129.186.10.108", "type": 0, "reputation": 0}}, {"pk": 222, "model": "server.userprofile", "fields": {"website": "http://msb.yark.fr", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nico", "location": "France", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "PhD student in bioinformatics :)", "user": 222, "suspended": false, "last_login_ip": "131.254.16.72", "type": 0, "reputation": 0}}, {"pk": 223, "model": "server.userprofile", "fields": {"website": "http://mahefrederic.org/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Fr\u00e9d\u00e9ric Mah\u00e9", "location": "Roscoff, France", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Post-doc at the station biologique de Roscoff, France. Interested in bioinformatics, R, python programming and marine biology. ", "user": 223, "suspended": false, "last_login_ip": "193.52.39.1", "type": 0, "reputation": 0}}, {"pk": 224, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bioch'Ti", "location": "Qu\u00e9bec City (Canada)", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": null, "user": 224, "suspended": false, "last_login_ip": "147.100.71.242", "type": 0, "reputation": 0}}, {"pk": 225, "model": "server.userprofile", "fields": {"website": "http://davelunt.net", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dave Lunt", "location": "Hull, UK", "bronze_badges": 10, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 3, "gold_badges": 0, "score": 0, "about_me": null, "user": 225, "suspended": false, "last_login_ip": "77.86.121.37", "type": 0, "reputation": 0}}, {"pk": 226, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 228", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 226, "suspended": false, "last_login_ip": "77.213.73.2", "type": 0, "reputation": 0}}, {"pk": 227, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 229", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:25", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 227, "suspended": false, "last_login_ip": "12.91.98.214", "type": 0, "reputation": 0}}, {"pk": 228, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Abhi", "location": null, "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 228, "suspended": false, "last_login_ip": "198.128.41.31", "type": 0, "reputation": 0}}, {"pk": 229, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ratonfilo", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 229, "suspended": false, "last_login_ip": "129.85.20.36", "type": 0, "reputation": 0}}, {"pk": 230, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "D W", "location": null, "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 230, "suspended": false, "last_login_ip": "134.87.4.251", "type": 0, "reputation": 0}}, {"pk": 231, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jason Winget", "location": "Vancouver, B.C.", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:35", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 231, "suspended": false, "last_login_ip": "174.6.48.209", "type": 0, "reputation": 0}}, {"pk": 232, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Yvan", "location": "CBU, Bergen, Norway", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Service scientist at The Computational Biology Unit <a href=\"http://www.bccs.uni.no/units/cbu\" rel=\"nofollow\">(CBU)</a>", "user": 232, "suspended": false, "last_login_ip": "80.203.66.75", "type": 0, "reputation": 0}}, {"pk": 233, "model": "server.userprofile", "fields": {"website": "http://www.mckuhn.de", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Michael Kuhn", "location": "Dresden, Germany", "bronze_badges": 13, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 3, "gold_badges": 0, "score": -1, "about_me": null, "user": 233, "suspended": false, "last_login_ip": "141.30.193.8", "type": 0, "reputation": 0}}, {"pk": 234, "model": "server.userprofile", "fields": {"website": "http://www3.imperial.ac.uk/theoreticalsystemsbiology/people/nathanharmston", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nathan Harmston", "location": "London", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 4, "gold_badges": 0, "score": 0, "about_me": "I am a phd student investigating applications of text mining tools to biological problems specifically from the field of Systems Biology.", "user": 234, "suspended": false, "last_login_ip": "86.168.102.253", "type": 0, "reputation": 0}}, {"pk": 235, "model": "server.userprofile", "fields": {"website": "http://www.greon.eu", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Asen Nenov", "location": "Sofia, Bulgaria", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 235, "suspended": false, "last_login_ip": "93.152.185.59", "type": 0, "reputation": 0}}, {"pk": 236, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Alexa", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 236, "suspended": false, "last_login_ip": "193.144.12.130", "type": 0, "reputation": 0}}, {"pk": 237, "model": "server.userprofile", "fields": {"website": "http://example.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Zach Stednick", "location": "Seattle, WA", "bronze_badges": 9, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 3, "gold_badges": 0, "score": 0, "about_me": "Data analyst grappling with issues of Big Data (like almost everyone else!)", "user": 237, "suspended": false, "last_login_ip": "98.237.143.104", "type": 0, "reputation": 0}}, {"pk": 238, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 240", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 238, "suspended": false, "last_login_ip": "164.15.228.44", "type": 0, "reputation": 0}}, {"pk": 239, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Xiechao", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 239, "suspended": false, "last_login_ip": "220.255.0.41", "type": 0, "reputation": 0}}, {"pk": 240, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Suhail", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 240, "suspended": false, "last_login_ip": "174.65.16.25", "type": 0, "reputation": 0}}, {"pk": 241, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bow", "location": null, "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 241, "suspended": false, "last_login_ip": "87.212.192.87", "type": 0, "reputation": 0}}, {"pk": 242, "model": "server.userprofile", "fields": {"website": "http://pedrolopes.net", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Pedro Lopes", "location": "PT", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 242, "suspended": false, "last_login_ip": "188.81.215.88", "type": 0, "reputation": 0}}, {"pk": 243, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Alex", "location": "East Lansing", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 243, "suspended": false, "last_login_ip": "12.231.163.254", "type": 0, "reputation": 0}}, {"pk": 244, "model": "server.userprofile", "fields": {"website": "http://www.andreas-wilm.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Andreas", "location": "Singapore", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 244, "suspended": false, "last_login_ip": "203.126.201.235", "type": 0, "reputation": 0}}, {"pk": 245, "model": "server.userprofile", "fields": {"website": "http://www.leomartins.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Leo Martins", "location": "Vigo, Spain", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Postdoctoral researcher working on Bayesian phylogenomics", "user": 245, "suspended": false, "last_login_ip": "213.60.152.19", "type": 0, "reputation": 0}}, {"pk": 246, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 248", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 246, "suspended": false, "last_login_ip": "173.61.103.132", "type": 0, "reputation": 0}}, {"pk": 247, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ning-Yi Shao", "location": null, "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "I just got my PhD in July, 2011. I work on the NGS datasets analysis in the group of Dr. Philipp Khaitovich in CAS-MPG Partner Institute for Computational Biology, Shanghai.", "user": 247, "suspended": false, "last_login_ip": "202.127.20.33", "type": 0, "reputation": 0}}, {"pk": 248, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ria", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 248, "suspended": false, "last_login_ip": "210.212.48.4", "type": 0, "reputation": 0}}, {"pk": 249, "model": "server.userprofile", "fields": {"website": "http://blog.physionconsulting.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Barry Wark", "location": "Seattle, WA", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Founder of Physion Consulting LLC.\nPhD in Neurobiology and Behavior, University of Washington.  ", "user": 249, "suspended": false, "last_login_ip": "216.207.146.54", "type": 0, "reputation": 0}}, {"pk": 250, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Christiank", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 250, "suspended": false, "last_login_ip": "91.64.182.242", "type": 0, "reputation": 0}}, {"pk": 251, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Anar", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 251, "suspended": false, "last_login_ip": "202.20.103.137", "type": 0, "reputation": 0}}, {"pk": 252, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gurado", "location": null, "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 252, "suspended": false, "last_login_ip": "130.102.118.152", "type": 0, "reputation": 0}}, {"pk": 253, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Samat", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 253, "suspended": false, "last_login_ip": "75.160.49.65", "type": 0, "reputation": 0}}, {"pk": 254, "model": "server.userprofile", "fields": {"website": "http://yangzt.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gentle Yang", "location": "Shenzhen,China", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Just another developer in Internet,Bioinformatics,Genomics and Mathematics.", "user": 254, "suspended": false, "last_login_ip": "183.62.200.129", "type": 0, "reputation": 0}}, {"pk": 255, "model": "server.userprofile", "fields": {"website": "http://www.medicalgenomics.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Markus Krupp", "location": "Germany", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 255, "suspended": false, "last_login_ip": "134.93.123.250", "type": 0, "reputation": 0}}, {"pk": 256, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jvb", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 256, "suspended": false, "last_login_ip": "128.243.21.224", "type": 0, "reputation": 0}}, {"pk": 257, "model": "server.userprofile", "fields": {"website": "http://rfam.sanger.ac.uk", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Paul Gardner", "location": "Christchurch, New Zealand. ", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "I'm a Senior Lecturer and Rutherford Discovery Fellow at the School of Biological Sciences at the University of Canterbury in New Zealand. \n\nI used to run the Rfam database (2007-2011). Hence many of my answers here deal with RNA-related queries. ", "user": 257, "suspended": false, "last_login_ip": "132.181.220.147", "type": 0, "reputation": 0}}, {"pk": 258, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 260", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 258, "suspended": false, "last_login_ip": "70.177.62.50", "type": 0, "reputation": 0}}, {"pk": 259, "model": "server.userprofile", "fields": {"website": "http://www.sanger.ac.uk", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Conny", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 259, "suspended": false, "last_login_ip": "193.62.205.58", "type": 0, "reputation": 0}}, {"pk": 260, "model": "server.userprofile", "fields": {"website": "http://jp.linkedin.com/in/nakaomitsuteru", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nakao", "location": "Tokyo, Japan", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "BioRuby Developer", "user": 260, "suspended": false, "last_login_ip": "220.100.14.143", "type": 0, "reputation": 0}}, {"pk": 261, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nate", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 261, "suspended": false, "last_login_ip": "130.239.72.131", "type": 0, "reputation": 0}}, {"pk": 262, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tim", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 262, "suspended": false, "last_login_ip": "203.188.235.10", "type": 0, "reputation": 0}}, {"pk": 263, "model": "server.userprofile", "fields": {"website": "https://twitter.com/#!/naga_rna", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nagarajan Paramasivam", "location": "Germany", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": "Phd student @ MPI for developmental biology", "user": 263, "suspended": false, "last_login_ip": "192.124.26.250", "type": 0, "reputation": 0}}, {"pk": 264, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Paul Tang", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 264, "suspended": false, "last_login_ip": "71.132.223.174", "type": 0, "reputation": 0}}, {"pk": 265, "model": "server.userprofile", "fields": {"website": "http://www.google.com/profiles/malcolm.cook", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Malcolm.Cook", "location": "kansas, usa", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 265, "suspended": false, "last_login_ip": "76.92.123.18", "type": 0, "reputation": 0}}, {"pk": 266, "model": "server.userprofile", "fields": {"website": "http://people.pcbi.upenn.edu/~ewingad/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Adam Ewing", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 266, "suspended": false, "last_login_ip": "69.141.183.180", "type": 0, "reputation": 0}}, {"pk": 267, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Wishva", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 267, "suspended": false, "last_login_ip": "203.126.201.246", "type": 0, "reputation": 0}}, {"pk": 268, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nico", "location": "NYC", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 268, "suspended": false, "last_login_ip": "140.163.254.157", "type": 0, "reputation": 0}}, {"pk": 269, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 271", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 269, "suspended": false, "last_login_ip": "86.9.119.53", "type": 0, "reputation": 0}}, {"pk": 270, "model": "server.userprofile", "fields": {"website": "http://www.researchremix.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Heather Piwowar", "location": "Vancouver, Canada", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 270, "suspended": false, "last_login_ip": "12.6.60.20", "type": 0, "reputation": 0}}, {"pk": 271, "model": "server.userprofile", "fields": {"website": "http://usefulchem.blogspot.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jean-Claude Bradley", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 271, "suspended": false, "last_login_ip": "144.118.49.64", "type": 0, "reputation": 0}}, {"pk": 272, "model": "server.userprofile", "fields": {"website": "http://stackoverflow.com/users/97160/amro", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Amro", "location": "United States", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Graduate Student", "user": 272, "suspended": false, "last_login_ip": "68.118.224.40", "type": 0, "reputation": 0}}, {"pk": 273, "model": "server.userprofile", "fields": {"website": "http://tanghaibao.blogspot.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Haibao Tang", "location": "Rockville, MD", "bronze_badges": 10, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": "Ph. D. in Plant Biology. I am currently a Senior bioinformatics engineer in J. Craig Venter Institute working on plant genomics, with a focus on genome assembly and annotations. I am interested in large scale data analysis and comparison of genome structures. I am also interested in the regulatory changes associated with the morphological transitions that have occurred during the domestication process of cereal crops. <hr />\n<strong>\nSee my <a href=\"http://github.com/tanghaibao\" rel=\"nofollow\">github</a>. Also check out my <a href=\"http://tanghaibao.blogspot.com\" rel=\"nofollow\">blog</a>. \n</strong>", "user": 273, "suspended": false, "last_login_ip": "192.207.234.194", "type": 1, "reputation": 0}}, {"pk": 274, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Casbon", "location": null, "bronze_badges": 11, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": null, "user": 274, "suspended": false, "last_login_ip": "95.172.233.192", "type": 0, "reputation": 0}}, {"pk": 275, "model": "server.userprofile", "fields": {"website": "http://www.carlboettiger.info", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Cboettig", "location": "Davis", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 275, "suspended": false, "last_login_ip": "128.120.122.242", "type": 0, "reputation": 0}}, {"pk": 276, "model": "server.userprofile", "fields": {"website": "http://vidar.scs.uiuc.edu/~jeargle/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "John Eargle", "location": "Champaign, IL", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "computational biophysicist working on RNA:protein complexes in translation", "user": 276, "suspended": false, "last_login_ip": "130.126.230.64", "type": 0, "reputation": 0}}, {"pk": 277, "model": "server.userprofile", "fields": {"website": "http://sites.google.com/site/abhimaans/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Abhiman", "location": "Bethesda, MD, USA", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 277, "suspended": false, "last_login_ip": "130.14.254.25", "type": 0, "reputation": 0}}, {"pk": 278, "model": "server.userprofile", "fields": {"website": "http://Virology.ca", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Cupton", "location": "Victoria, BC, Canada", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 278, "suspended": false, "last_login_ip": "142.104.33.102", "type": 0, "reputation": 0}}, {"pk": 279, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kaiw", "location": "AU", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 279, "suspended": false, "last_login_ip": "130.102.158.16", "type": 0, "reputation": 0}}, {"pk": 280, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Echo", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 280, "suspended": false, "last_login_ip": "222.178.186.37", "type": 0, "reputation": 0}}, {"pk": 281, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Wilka", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 281, "suspended": false, "last_login_ip": "82.108.99.210", "type": 0, "reputation": 0}}, {"pk": 282, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kurtb", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 282, "suspended": false, "last_login_ip": "192.174.37.50", "type": 0, "reputation": 0}}, {"pk": 283, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Omathew", "location": "Kochi", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Senior Python Software Analyst.\nNow Exploring BioPython.", "user": 283, "suspended": false, "last_login_ip": "122.181.3.138", "type": 0, "reputation": 0}}, {"pk": 284, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ryan Thompson", "location": "UCSD, San Diego, CA", "bronze_badges": 9, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 284, "suspended": false, "last_login_ip": "209.134.82.37", "type": 0, "reputation": 0}}, {"pk": 285, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Hob", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 285, "suspended": false, "last_login_ip": "122.181.137.50", "type": 0, "reputation": 0}}, {"pk": 286, "model": "server.userprofile", "fields": {"website": "http://watson.nci.nih.gov/~sdavis/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Sean Davis", "location": "Bethesda, MD", "bronze_badges": 10, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": null, "user": 286, "suspended": false, "last_login_ip": "71.166.51.23", "type": 0, "reputation": 0}}, {"pk": 287, "model": "server.userprofile", "fields": {"website": "http://dzlab.pmb.berkeley.edu", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Psilva", "location": "Berkeley", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 287, "suspended": false, "last_login_ip": "128.32.218.143", "type": 0, "reputation": 0}}, {"pk": 288, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 290", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 288, "suspended": false, "last_login_ip": "211.155.251.157", "type": 0, "reputation": 0}}, {"pk": 289, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 291", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 289, "suspended": false, "last_login_ip": "82.108.99.210", "type": 0, "reputation": 0}}, {"pk": 290, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Heuermh", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 290, "suspended": false, "last_login_ip": "198.174.110.147", "type": 0, "reputation": 0}}, {"pk": 291, "model": "server.userprofile", "fields": {"website": "http://www.cs.rhul.ac.uk/home/tamas", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tam\u00e1s", "location": "Staines, UK", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Postdoctoral research fellow at Royal Holloway, University of London", "user": 291, "suspended": false, "last_login_ip": "84.3.71.220", "type": 0, "reputation": 0}}, {"pk": 292, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 294", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 292, "suspended": false, "last_login_ip": "164.100.170.6", "type": 0, "reputation": 0}}, {"pk": 293, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Zacharyvoase", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 293, "suspended": false, "last_login_ip": "86.137.206.140", "type": 0, "reputation": 0}}, {"pk": 294, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Cotsapas", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 294, "suspended": false, "last_login_ip": "76.24.27.115", "type": 0, "reputation": 0}}, {"pk": 295, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jschnable", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 295, "suspended": false, "last_login_ip": "128.32.8.147", "type": 0, "reputation": 0}}, {"pk": 296, "model": "server.userprofile", "fields": {"website": "http://behindtherabbit.tumblr.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Behindtherabbit", "location": "Blacksburg, VA USA", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 296, "suspended": false, "last_login_ip": "128.173.102.23", "type": 0, "reputation": 0}}, {"pk": 297, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kmejia", "location": "Columbus, OH", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 297, "suspended": false, "last_login_ip": "128.146.132.95", "type": 0, "reputation": 0}}, {"pk": 298, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Joshm", "location": "Tucson, AZ", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 298, "suspended": false, "last_login_ip": "206.169.183.232", "type": 0, "reputation": 0}}, {"pk": 299, "model": "server.userprofile", "fields": {"website": "http://www.columbia.edu/~md2954/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Mike Dewar", "location": "Columbia University, NYC, USA", "bronze_badges": 9, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "I am a post-doc, looking at gene expression in CD8 T-Cell phenotypes. I'm interested in machine learning, specifically the application of latent variable modelling to the study of changing phenotypes. ", "user": 299, "suspended": false, "last_login_ip": "216.49.145.168", "type": 0, "reputation": 0}}, {"pk": 300, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Girma", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 300, "suspended": false, "last_login_ip": "130.238.108.175", "type": 0, "reputation": 0}}, {"pk": 301, "model": "server.userprofile", "fields": {"website": "http://www.ncbi.nlm.nih.gov/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Vlinxify", "location": "Rotterdam, Netherlands", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "I am trying to understand the world of bioinformatics. The best way to do this, I reckon, is to get into the very numbers and hard data itself through scripting and programming. \n\nSometimes I wonder whether I can actually find something out in the vast data resources publicly available. For example: I would love to find a translation for a particular protein in two separate organisms which are evolutionary linked. After finding this out I could go and check if the gene encoding for the proteins in those related organisms is also present in other evolutionary linked organisms. For me this would be very cool because I would be seeing evolution move before my eyes. These are the linkages and relations I will be looking for. So I am very education-oriented.\n\nI will start studying Plant Sciences soon at Wageningen University in the Netherlands.", "user": 301, "suspended": false, "last_login_ip": "87.211.34.115", "type": 0, "reputation": 0}}, {"pk": 302, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Harley", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 302, "suspended": false, "last_login_ip": "0.0.0.0", "type": 0, "reputation": 0}}, {"pk": 303, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Aaron Statham", "location": null, "bronze_badges": 9, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 303, "suspended": false, "last_login_ip": "114.198.48.111", "type": 0, "reputation": 0}}, {"pk": 304, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Barjaron", "location": "Seattle", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "A systems biologist interested in novel technologies to study complex diseases and to develop biomarkers", "user": 304, "suspended": false, "last_login_ip": "209.124.189.39", "type": 0, "reputation": 0}}, {"pk": 305, "model": "server.userprofile", "fields": {"website": "http://www.perkinslab.ca/people/gpalidwor", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gawp", "location": "Ottawa", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "I'm a Research Assistant at the Ottawa Hospital Research Institute", "user": 305, "suspended": false, "last_login_ip": "204.187.34.100", "type": 0, "reputation": 0}}, {"pk": 306, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Biosidd", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 306, "suspended": false, "last_login_ip": "98.206.137.176", "type": 0, "reputation": 0}}, {"pk": 307, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Shilda", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 307, "suspended": false, "last_login_ip": "210.212.238.248", "type": 0, "reputation": 0}}, {"pk": 308, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Michiel De Hoon", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 308, "suspended": false, "last_login_ip": "134.160.83.73", "type": 0, "reputation": 0}}, {"pk": 309, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Harsh", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 309, "suspended": false, "last_login_ip": "122.181.137.50", "type": 0, "reputation": 0}}, {"pk": 310, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 313", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 310, "suspended": false, "last_login_ip": "218.19.163.105", "type": 0, "reputation": 0}}, {"pk": 311, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Divya", "location": "", "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "", "user": 311, "suspended": false, "last_login_ip": "58.68.108.109", "type": 0, "reputation": 0}}, {"pk": 312, "model": "server.userprofile", "fields": {"website": "http://biodigger.wordpress.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Thaman", "location": "Finland", "bronze_badges": 15, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 3, "gold_badges": 1, "score": 0, "about_me": "A Bioinformatician in a digging process!", "user": 312, "suspended": false, "last_login_ip": "86.50.92.99", "type": 0, "reputation": 0}}, {"pk": 313, "model": "server.userprofile", "fields": {"website": "http://bergmanlab.smith.man.ac.uk/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Casey Bergman", "location": "Manchester, UK", "bronze_badges": 26, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 7, "gold_badges": 1, "score": 0, "about_me": "Molecular Evolutionist turned Genome Bioinformatician, working on various aspects of Genome Annotation, Genome Evolution, Functional Genomics and Text Mining.\n\n<br/>\n<br/>\n\nWork Blog: http://bergmanlab.smith.man.ac.uk/?page_id=45\n<br/>\nWork Twitter: http://twitter.com/#!/bergmanlab\n<br/>\nPersonal Twitter: http://twitter.com/#!/caseybergman\n\n<br/>\n<br/>\n\nNote: all questions, comments and responses I have provided prior to 1 Dec 2010 are licensed under a Creative Commons Attribution-Share Alike 3.0 Unported License. ", "user": 313, "suspended": false, "last_login_ip": "82.69.34.243", "type": 1, "reputation": 0}}, {"pk": 314, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ryan", "location": "US", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 314, "suspended": false, "last_login_ip": "148.84.61.142", "type": 0, "reputation": 0}}, {"pk": 315, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dhivya", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 315, "suspended": false, "last_login_ip": "58.68.108.109", "type": 0, "reputation": 0}}, {"pk": 316, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Mylex", "location": "Helsinki", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 316, "suspended": false, "last_login_ip": "128.214.20.122", "type": 0, "reputation": 0}}, {"pk": 317, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Cymon", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 317, "suspended": false, "last_login_ip": "193.136.225.26", "type": 0, "reputation": 0}}, {"pk": 318, "model": "server.userprofile", "fields": {"website": "http://revcaptcha.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Vamin", "location": "Gainesville, FL", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Working in bioinformatics at the University of Florida.", "user": 318, "suspended": false, "last_login_ip": "159.178.253.185", "type": 0, "reputation": 0}}, {"pk": 319, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Reece", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 319, "suspended": false, "last_login_ip": "107.3.148.240", "type": 0, "reputation": 0}}, {"pk": 320, "model": "server.userprofile", "fields": {"website": "http://heyaudy.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Audyyy", "location": "Gainesville, FL", "bronze_badges": 10, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 320, "suspended": false, "last_login_ip": "128.227.117.189", "type": 0, "reputation": 0}}, {"pk": 321, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Hazel", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 321, "suspended": false, "last_login_ip": "152.226.7.201", "type": 0, "reputation": 0}}, {"pk": 322, "model": "server.userprofile", "fields": {"website": "http://brandonbodnar.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Brandon Bodn\u00e1r", "location": "Ames, Iowa", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Computer Scientist turned Law Student who helps his Geneticist wife with various computational biology problems.", "user": 322, "suspended": false, "last_login_ip": "173.20.50.124", "type": 0, "reputation": 0}}, {"pk": 323, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dhivi", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 323, "suspended": false, "last_login_ip": "58.68.108.109", "type": 0, "reputation": 0}}, {"pk": 324, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Hanif Khalak", "location": "Riyadh, KSA", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 3, "gold_badges": 0, "score": 0, "about_me": "bioinformatician, computational geneticist", "user": 324, "suspended": false, "last_login_ip": "207.162.245.232", "type": 0, "reputation": 0}}, {"pk": 325, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Rks", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 325, "suspended": false, "last_login_ip": "149.155.96.6", "type": 0, "reputation": 0}}, {"pk": 326, "model": "server.userprofile", "fields": {"website": "http://www.kellyrob99.com/blog", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Thekaptain", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 326, "suspended": false, "last_login_ip": "69.196.72.202", "type": 0, "reputation": 0}}, {"pk": 327, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Young", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 327, "suspended": false, "last_login_ip": "220.181.61.31", "type": 0, "reputation": 0}}, {"pk": 328, "model": "server.userprofile", "fields": {"website": "http://www.ibab.ac.in", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Sanchari", "location": "Bangalore", "bronze_badges": 9, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": "Research Associate in Institute of Bioinformatics And Applied Biotechnology (IBAB,Bangalore) India.", "user": 328, "suspended": false, "last_login_ip": "115.111.15.210", "type": 0, "reputation": 0}}, {"pk": 329, "model": "server.userprofile", "fields": {"website": "http://www.uta.fi/gt81371", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gabs", "location": "tampere, finland", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "MSc. Bioinformatics\nUnemployed\nNeeds a PhD research position or job in a company\n", "user": 329, "suspended": false, "last_login_ip": "81.197.78.160", "type": 0, "reputation": 0}}, {"pk": 330, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Meng", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "I am interested in data mining, machine learning, bioinformatics. I mainly focus on genome sequence analysis.", "user": 330, "suspended": false, "last_login_ip": "152.19.47.143", "type": 0, "reputation": 0}}, {"pk": 331, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 334", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 331, "suspended": false, "last_login_ip": "86.51.114.108", "type": 0, "reputation": 0}}, {"pk": 332, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Typing-Faster-Than-Before", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 332, "suspended": false, "last_login_ip": "70.36.128.71", "type": 0, "reputation": 0}}, {"pk": 333, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Cheng Zhongshan", "location": "", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "", "user": 333, "suspended": false, "last_login_ip": "147.8.39.44", "type": 0, "reputation": 0}}, {"pk": 334, "model": "server.userprofile", "fields": {"website": "http://bioinformatics.ru", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Mikhail Pyatnitskiy", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 334, "suspended": false, "last_login_ip": "195.96.83.101", "type": 0, "reputation": 0}}, {"pk": 335, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Pauln", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 335, "suspended": false, "last_login_ip": "124.169.114.21", "type": 0, "reputation": 0}}, {"pk": 336, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "B\u00e9reng\u00e8re", "location": "France", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 336, "suspended": false, "last_login_ip": "193.202.78.126", "type": 0, "reputation": 0}}, {"pk": 337, "model": "server.userprofile", "fields": {"website": "http://arclite.byu.edu/dan", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dstan", "location": "Provo, Utah, USA", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 337, "suspended": false, "last_login_ip": "76.27.88.157", "type": 0, "reputation": 0}}, {"pk": 338, "model": "server.userprofile", "fields": {"website": "http://onconomicon.blogspot.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Wjeck", "location": "Chapel Hill, NC", "bronze_badges": 9, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "MD/PhD student at University of North Carolina at Chapel Hill", "user": 338, "suspended": false, "last_login_ip": "152.19.39.233", "type": 0, "reputation": 0}}, {"pk": 339, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 342", "location": "", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 339, "suspended": false, "last_login_ip": "196.211.173.89", "type": 0, "reputation": 0}}, {"pk": 340, "model": "server.userprofile", "fields": {"website": "http://www.nicolaromano.net", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nico80", "location": "Montpellier", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": ":)", "user": 340, "suspended": false, "last_login_ip": "79.87.9.211", "type": 0, "reputation": 0}}, {"pk": 341, "model": "server.userprofile", "fields": {"website": "http://andrewjgrimm.wordpress.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Andrewjgrimm", "location": "Sydney, Australia", "bronze_badges": 7, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "I am a bioinformatician at the University of New South Wales, where I use plain old ruby objects. In part of my spare time, I work on fun projects.\n\nFun projects I have worked on are:\n<ul>\n<li>The Weather in London: recognising the names of Wikipedia titles in a body of text)</li>\n<li>Get to Philosophy: if you click on the first link of an article in Wikipedia, until recently you would end up at the one on Philosophy. I was trying to analyse why)</li>\n<li>Chaser: a mutation tester (as in unit testing, not as in biology) for ruby</li>\n<li>Zombie-chaser: mutation testing ... with zombies!</li>\n</ul>\n", "user": 341, "suspended": false, "last_login_ip": "149.171.107.52", "type": 0, "reputation": 0}}, {"pk": 342, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gregory Miles", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 342, "suspended": false, "last_login_ip": "71.232.75.188", "type": 0, "reputation": 0}}, {"pk": 343, "model": "server.userprofile", "fields": {"website": "http://www.precancer.leeds.ac.uk/group-members/stefano-berri-postdoctoral-scientist/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Stefano Berri", "location": "LIMM, Leeds", "bronze_badges": 10, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "Trained in molecular biology I slowly moved to the computational side and data anlysis of genomic data.\nI am now a postdoctoral scientist working in the bioinformatic unit of the Prencancer group. My main interests is in copy number analysis by very low coverage (approx 0.05X) NGS. We work on clinical samples. ", "user": 343, "suspended": false, "last_login_ip": "94.195.88.26", "type": 0, "reputation": 0}}, {"pk": 344, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 347", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 344, "suspended": false, "last_login_ip": "128.178.183.32", "type": 0, "reputation": 0}}, {"pk": 345, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Crocodile", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 345, "suspended": false, "last_login_ip": "152.226.6.203", "type": 0, "reputation": 0}}, {"pk": 346, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Hazelin", "location": "Singapore", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "I am a student, please help me! :D", "user": 346, "suspended": false, "last_login_ip": "152.226.7.202", "type": 0, "reputation": 0}}, {"pk": 347, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Hazel", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 347, "suspended": false, "last_login_ip": "152.226.7.202", "type": 0, "reputation": 0}}, {"pk": 348, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Pauln", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 348, "suspended": false, "last_login_ip": "124.169.114.21", "type": 0, "reputation": 0}}, {"pk": 349, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Hiberbear", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 349, "suspended": false, "last_login_ip": "129.206.245.160", "type": 0, "reputation": 0}}, {"pk": 350, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Alex Twyford", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 350, "suspended": false, "last_login_ip": "193.62.154.252", "type": 0, "reputation": 0}}, {"pk": 351, "model": "server.userprofile", "fields": {"website": "http://www.theatavism.blogspot.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "David W", "location": "New Zealand", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": null, "user": 351, "suspended": false, "last_login_ip": "139.80.123.42", "type": 0, "reputation": 0}}, {"pk": 352, "model": "server.userprofile", "fields": {"website": "http://Spain", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jorge De La Barrera", "location": "Santander", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 352, "suspended": false, "last_login_ip": "193.144.211.9", "type": 0, "reputation": 0}}, {"pk": 353, "model": "server.userprofile", "fields": {"website": "http://www.genevestigator.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Philip Zimmermann", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 353, "suspended": false, "last_login_ip": "129.132.162.7", "type": 0, "reputation": 0}}, {"pk": 354, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Andeyatz", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 354, "suspended": false, "last_login_ip": "193.62.194.248", "type": 0, "reputation": 0}}, {"pk": 355, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "You", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 355, "suspended": false, "last_login_ip": "220.181.61.31", "type": 0, "reputation": 0}}, {"pk": 356, "model": "server.userprofile", "fields": {"website": "http://www.tipunk.fr", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Arnaud Tierant", "location": "Montpellier, France", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "/me is on line.... acgatcgatcgatcactgactgactacatc", "user": 356, "suspended": false, "last_login_ip": "86.74.6.243", "type": 0, "reputation": 0}}, {"pk": 357, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Brandon Walts", "location": "US", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 357, "suspended": false, "last_login_ip": "159.178.230.130", "type": 0, "reputation": 0}}, {"pk": 358, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Krab", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 358, "suspended": false, "last_login_ip": "147.231.145.12", "type": 0, "reputation": 0}}, {"pk": 359, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Melissa", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 359, "suspended": false, "last_login_ip": "75.102.69.175", "type": 0, "reputation": 0}}, {"pk": 360, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Alexandre Kuhn", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 360, "suspended": false, "last_login_ip": "137.187.227.2", "type": 0, "reputation": 0}}, {"pk": 361, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dario Corrada", "location": "Monza - ITALY", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 361, "suspended": false, "last_login_ip": "155.253.6.254", "type": 0, "reputation": 0}}, {"pk": 362, "model": "server.userprofile", "fields": {"website": "http://www.google.com/profiles/daniel.mietchen", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Daniel Mietchen", "location": "Jena", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:36", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "A biophysicist working on cognitive evolution, with current focus on brain morphometry.", "user": 362, "suspended": false, "last_login_ip": "141.35.120.2", "type": 0, "reputation": 0}}, {"pk": 363, "model": "server.userprofile", "fields": {"website": "http://www.ggvaidya.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gaurav", "location": "Singapore", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 363, "suspended": false, "last_login_ip": "137.132.250.10", "type": 0, "reputation": 0}}, {"pk": 364, "model": "server.userprofile", "fields": {"website": "http://saaientist.blogspot.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jandot", "location": "GB", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 364, "suspended": false, "last_login_ip": "134.58.253.57", "type": 0, "reputation": 0}}, {"pk": 365, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Timothy Bailey", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 365, "suspended": false, "last_login_ip": "130.102.117.134", "type": 0, "reputation": 0}}, {"pk": 366, "model": "server.userprofile", "fields": {"website": "http://doeidoei.wordpress.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jo\u00e3o Rodrigues", "location": "Utrecht, The Netherlands", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Computational Structural Biologist, focused on protein docking methodologies and in silico methods for structural studies.", "user": 366, "suspended": false, "last_login_ip": "87.212.171.154", "type": 0, "reputation": 0}}, {"pk": 367, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 370", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 367, "suspended": false, "last_login_ip": "70.90.174.173", "type": 0, "reputation": 0}}, {"pk": 368, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 371", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 368, "suspended": false, "last_login_ip": "120.50.70.189", "type": 0, "reputation": 0}}, {"pk": 369, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ep", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 369, "suspended": false, "last_login_ip": "87.194.47.24", "type": 0, "reputation": 0}}, {"pk": 370, "model": "server.userprofile", "fields": {"website": "http://kevin-gattaca.blogspot.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kevin", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 370, "suspended": false, "last_login_ip": "202.156.13.235", "type": 0, "reputation": 0}}, {"pk": 371, "model": "server.userprofile", "fields": {"website": "http://walkytalky.net/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Walkytalky", "location": "London", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Erstwhile programmer turned experimental scientist. Now spend more time fiddling with cells and microscopes than coding, but still do the latter occasionally too.", "user": 371, "suspended": false, "last_login_ip": "62.49.27.114", "type": 0, "reputation": 0}}, {"pk": 372, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Christelle", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 372, "suspended": false, "last_login_ip": "60.50.84.131", "type": 0, "reputation": 0}}, {"pk": 373, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dhivya", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 373, "suspended": false, "last_login_ip": "58.68.108.109", "type": 0, "reputation": 0}}, {"pk": 374, "model": "server.userprofile", "fields": {"website": "http://www.xente.mundo-r.com/lechu/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jorge Amigo", "location": "Santiago de Compostela", "bronze_badges": 10, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": "scrutinizing genomic human variation by dealing with high throughput genotyping and next generation sequencing results, among many other things.\n<br/>\n<br/>\n<b>Bioinformatician</b>\n<br/>\n<a href=\"http://medicina.xenomica.org/\" rel=\"nofollow\">Genomic Medicine Group</a>\n<br/>\n<a href=\"http://maps.google.es/maps?f=q&source=s_q&hl=es&geocode=&q=hospital+clinico+santiago+de+compostela&sll=42.870389,-8.565838&sspn=0.004191,0.007113&g=42.870109,-8.566387&ie=UTF8&hq=hospital+clinico&hnear=Santiago+de+Compostela,+La+Coru%C3%B1a,+Galicia&ll=42.876027,-8.549423&spn=0.033525,0.056906&t=h&z=14\" rel=\"nofollow\">Santiago de Compostela, Spain</a>", "user": 374, "suspended": false, "last_login_ip": "91.117.54.226", "type": 1, "reputation": 0}}, {"pk": 375, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tam", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 375, "suspended": false, "last_login_ip": "85.64.92.163", "type": 0, "reputation": 0}}, {"pk": 376, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Sergej Andrejev", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 376, "suspended": false, "last_login_ip": "194.94.44.220", "type": 0, "reputation": 0}}, {"pk": 377, "model": "server.userprofile", "fields": {"website": "http://gene3d.biochem.ucl.ac.uk", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Coriny", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 377, "suspended": false, "last_login_ip": "128.40.46.160", "type": 0, "reputation": 0}}, {"pk": 378, "model": "server.userprofile", "fields": {"website": "http://biotext.org.uk/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Andrew Clegg", "location": "London", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": "<p>I'm a bioinformatics researcher at <a href=\"http://cathdb.info/\" rel=\"nofollow\">CATH</a> , and in my spare time, a social media analytics hacker at <a href=\"http://smeshup.com/\" rel=\"nofollow\">Smesh</a>.</p>\n\n<p>I have a <a href=\"http://biotext.org.uk/\" rel=\"nofollow\">blog</a>, a <a href=\"http://www.cathdb.info/wiki/cathteam:clegg\" rel=\"nofollow\">bio and publications list</a>, and you can also find me on <a href=\"http://twitter.com/andrew_clegg\" rel=\"nofollow\">Twitter</a>.</p>", "user": 378, "suspended": false, "last_login_ip": "87.194.63.126", "type": 0, "reputation": 0}}, {"pk": 379, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Eugene", "location": "Gainesville, Florida", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Plant scientist", "user": 379, "suspended": false, "last_login_ip": "128.227.142.219", "type": 0, "reputation": 0}}, {"pk": 380, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Tanya Cashorali", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 380, "suspended": false, "last_login_ip": "68.162.253.61", "type": 0, "reputation": 0}}, {"pk": 381, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 384", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 381, "suspended": false, "last_login_ip": "79.18.166.25", "type": 0, "reputation": 0}}, {"pk": 382, "model": "server.userprofile", "fields": {"website": "http://sites.google.com/site/cbouyio/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Cbouyio", "location": "Norwich, UK", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 382, "suspended": false, "last_login_ip": "149.155.96.6", "type": 0, "reputation": 0}}, {"pk": 383, "model": "server.userprofile", "fields": {"website": "http://www.SNPedia.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Cariaso", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "I'm the founding Sysop at SNPedia. <a href=\"http://www.cariaso.com\" rel=\"nofollow\">http://www.cariaso.com</a> has more about me, including my <a href=\"https://docs.google.com/document/preview?id=1G9FieEGlqfZXUUKAkTpI7LFG621moyaJB2IwXiR7rX8&pli=1\" rel=\"nofollow\">resume</a>. I've been a bioinformatician since the Human Genome Project.", "user": 383, "suspended": false, "last_login_ip": "118.172.213.66", "type": 0, "reputation": 0}}, {"pk": 384, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 387", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 384, "suspended": false, "last_login_ip": "202.189.122.124", "type": 0, "reputation": 0}}, {"pk": 385, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gilesc", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 385, "suspended": false, "last_login_ip": "72.198.65.238", "type": 0, "reputation": 0}}, {"pk": 386, "model": "server.userprofile", "fields": {"website": "http://www.ingenuity.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bkmacy", "location": "San Mateo, CA", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 386, "suspended": false, "last_login_ip": "65.120.181.2", "type": 0, "reputation": 0}}, {"pk": 387, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Zhongshan", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 387, "suspended": false, "last_login_ip": "147.8.206.61", "type": 0, "reputation": 0}}, {"pk": 388, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ranjita", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 388, "suspended": false, "last_login_ip": "115.118.129.179", "type": 0, "reputation": 0}}, {"pk": 389, "model": "server.userprofile", "fields": {"website": "http://cphg.virginia.edu/quinlan", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Aaronquinlan", "location": null, "bronze_badges": 15, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": null, "user": 389, "suspended": false, "last_login_ip": "128.143.108.181", "type": 1, "reputation": 0}}, {"pk": 390, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Keeney", "location": "Denver, CO", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 390, "suspended": false, "last_login_ip": "140.226.190.83", "type": 0, "reputation": 0}}, {"pk": 391, "model": "server.userprofile", "fields": {"website": "http://www.imagenix.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jerry", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 391, "suspended": false, "last_login_ip": "71.139.10.45", "type": 0, "reputation": 0}}, {"pk": 392, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Chia-Lang Hsu", "location": "Taiwan", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 392, "suspended": false, "last_login_ip": "120.126.47.1", "type": 0, "reputation": 0}}, {"pk": 393, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ranjita", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 393, "suspended": false, "last_login_ip": "115.118.129.179", "type": 0, "reputation": 0}}, {"pk": 394, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gabor", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 394, "suspended": false, "last_login_ip": "130.223.205.248", "type": 0, "reputation": 0}}, {"pk": 395, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ametire", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 395, "suspended": false, "last_login_ip": "194.94.115.122", "type": 0, "reputation": 0}}, {"pk": 396, "model": "server.userprofile", "fields": {"website": "http://www.nodalpoint.org/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Greg Tyrelle", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 396, "suspended": false, "last_login_ip": "83.84.219.16", "type": 0, "reputation": 0}}, {"pk": 397, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Anna Nikulina", "location": "Moscow", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": "researcher", "user": 397, "suspended": false, "last_login_ip": "95.27.86.91", "type": 0, "reputation": 0}}, {"pk": 398, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Seq_Ga", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 398, "suspended": false, "last_login_ip": "203.126.201.235", "type": 0, "reputation": 0}}, {"pk": 399, "model": "server.userprofile", "fields": {"website": "https://www.latrobe.edu.au/biochemistry/staff/fellows/ira_cooke.htm", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ira", "location": "Melbourne", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Working on Mass Spectrometry and Proteomics", "user": 399, "suspended": false, "last_login_ip": "131.172.4.45", "type": 0, "reputation": 0}}, {"pk": 400, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dole", "location": null, "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 400, "suspended": false, "last_login_ip": "86.104.236.54", "type": 0, "reputation": 0}}, {"pk": 401, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Flxlex", "location": "Slependen, Norway", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": null, "user": 401, "suspended": false, "last_login_ip": "129.240.88.176", "type": 0, "reputation": 0}}, {"pk": 402, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 405", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 402, "suspended": false, "last_login_ip": "58.45.248.8", "type": 0, "reputation": 0}}, {"pk": 403, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Wouter", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 403, "suspended": false, "last_login_ip": "131.174.146.134", "type": 0, "reputation": 0}}, {"pk": 404, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Emma", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 404, "suspended": false, "last_login_ip": "129.215.5.231", "type": 0, "reputation": 0}}, {"pk": 405, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 408", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 405, "suspended": false, "last_login_ip": "24.17.221.40", "type": 0, "reputation": 0}}, {"pk": 406, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Satish Gupta", "location": "Warsaw, Poland", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "I am doing Phd from Warsaw Medical University...", "user": 406, "suspended": false, "last_login_ip": "212.14.7.227", "type": 0, "reputation": 0}}, {"pk": 407, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 410", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 407, "suspended": false, "last_login_ip": "130.91.10.54", "type": 0, "reputation": 0}}, {"pk": 408, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jordan Willis", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 408, "suspended": false, "last_login_ip": "129.59.8.10", "type": 0, "reputation": 0}}, {"pk": 409, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jayant Maini", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 409, "suspended": false, "last_login_ip": "202.141.141.18", "type": 0, "reputation": 0}}, {"pk": 410, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ranjita", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 410, "suspended": false, "last_login_ip": "115.118.129.179", "type": 0, "reputation": 0}}, {"pk": 411, "model": "server.userprofile", "fields": {"website": "http://www.mpi.nl/people/dunn-michael", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Michael Dunn", "location": "Nijmegen", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 411, "suspended": false, "last_login_ip": "83.161.2.208", "type": 0, "reputation": 0}}, {"pk": 412, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Rlong", "location": "US", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:42", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 412, "suspended": false, "last_login_ip": "128.252.233.244", "type": 0, "reputation": 0}}, {"pk": 413, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Joel Hoff", "location": "Massachusetts, USA", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 413, "suspended": false, "last_login_ip": "68.162.217.67", "type": 0, "reputation": 0}}, {"pk": 414, "model": "server.userprofile", "fields": {"website": "http://www.euformatics.com/blogs/jussi-volanen", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jussi", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 414, "suspended": false, "last_login_ip": "213.243.133.234", "type": 0, "reputation": 0}}, {"pk": 415, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dror", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 415, "suspended": false, "last_login_ip": "132.64.64.80", "type": 0, "reputation": 0}}, {"pk": 416, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Leojlee", "location": "Toronto", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 416, "suspended": false, "last_login_ip": "128.100.221.103", "type": 0, "reputation": 0}}, {"pk": 417, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Huggie", "location": null, "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 417, "suspended": false, "last_login_ip": "120.126.38.177", "type": 0, "reputation": 0}}, {"pk": 418, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Michael Schubert", "location": "Austria", "bronze_badges": 13, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 4, "gold_badges": 1, "score": 0, "about_me": "Currently MSc student in Biotechnology/Bioinformatics.\n<br/><br/>\nBe patient with me, I'm still learning ;-)", "user": 418, "suspended": false, "last_login_ip": "84.119.28.41", "type": 0, "reputation": 0}}, {"pk": 419, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Shigeta", "location": "berkeley", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 419, "suspended": false, "last_login_ip": "76.126.161.148", "type": 0, "reputation": 0}}, {"pk": 420, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kyra", "location": "Canada", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 420, "suspended": false, "last_login_ip": "129.128.253.53", "type": 0, "reputation": 0}}, {"pk": 421, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Scott", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 421, "suspended": false, "last_login_ip": "128.146.59.242", "type": 0, "reputation": 0}}, {"pk": 422, "model": "server.userprofile", "fields": {"website": "http://www.lucasbrouwers.nl", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Lucas", "location": "Heidelberg", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 422, "suspended": false, "last_login_ip": "188.110.112.138", "type": 0, "reputation": 0}}, {"pk": 423, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Sean", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 423, "suspended": false, "last_login_ip": "140.112.121.97", "type": 0, "reputation": 0}}, {"pk": 424, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ranjita", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 424, "suspended": false, "last_login_ip": "115.118.129.179", "type": 0, "reputation": 0}}, {"pk": 425, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Sukhdeep Singh", "location": "England", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "I am a Bioinformatician with interests in scientific data analysis and web application development. I like to work on new projects and challenges.\n\nSukhdeep Singh\nMSc Bioinformatics", "user": 425, "suspended": false, "last_login_ip": "193.62.202.241", "type": 0, "reputation": 0}}, {"pk": 426, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gao Wang", "location": "Houston", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Student in Statistical Genetics, Baylor College of Medicine, Texas, USA", "user": 426, "suspended": false, "last_login_ip": "128.249.106.194", "type": 0, "reputation": 0}}, {"pk": 427, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Sushma Grellscheid", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 427, "suspended": false, "last_login_ip": "128.240.229.3", "type": 0, "reputation": 0}}, {"pk": 428, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Shefali", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 428, "suspended": false, "last_login_ip": "129.59.8.10", "type": 0, "reputation": 0}}, {"pk": 429, "model": "server.userprofile", "fields": {"website": "http://www.drive5.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Robert Edgar", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 429, "suspended": false, "last_login_ip": "76.126.109.60", "type": 0, "reputation": 0}}, {"pk": 430, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Dror", "location": "Israel", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 430, "suspended": false, "last_login_ip": "85.250.161.190", "type": 0, "reputation": 0}}, {"pk": 431, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Will", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 431, "suspended": false, "last_login_ip": "129.67.27.152", "type": 0, "reputation": 0}}, {"pk": 432, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Phwd", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 432, "suspended": false, "last_login_ip": "190.213.27.186", "type": 0, "reputation": 0}}, {"pk": 433, "model": "server.userprofile", "fields": {"website": "http://stevemoss.ath.cx/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Steve Moss", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 433, "suspended": false, "last_login_ip": "150.237.85.247", "type": 0, "reputation": 0}}, {"pk": 434, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 437", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 434, "suspended": false, "last_login_ip": "203.255.44.173", "type": 0, "reputation": 0}}, {"pk": 435, "model": "server.userprofile", "fields": {"website": "http://fiamh.info", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Fiamh", "location": "Boston, MA", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 435, "suspended": false, "last_login_ip": "71.232.43.209", "type": 0, "reputation": 0}}, {"pk": 436, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 439", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 436, "suspended": false, "last_login_ip": "159.140.254.10", "type": 0, "reputation": 0}}, {"pk": 437, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 440", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 437, "suspended": false, "last_login_ip": "68.230.152.7", "type": 0, "reputation": 0}}, {"pk": 438, "model": "server.userprofile", "fields": {"website": "http://genetics.bwh.harvard.edu/genetics/members/Ivan_Adzhubey.html", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bamyasi", "location": "Boston, MA", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 438, "suspended": false, "last_login_ip": "71.174.130.142", "type": 0, "reputation": 0}}, {"pk": 439, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Owen", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 439, "suspended": false, "last_login_ip": "128.218.127.46", "type": 0, "reputation": 0}}, {"pk": 440, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "David Grellscheid", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 440, "suspended": false, "last_login_ip": "129.234.186.27", "type": 0, "reputation": 0}}, {"pk": 441, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Phil Goetz", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 441, "suspended": false, "last_login_ip": "192.207.234.194", "type": 0, "reputation": 0}}, {"pk": 442, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kevin Crowell", "location": "Richland, WA", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Bioinformatics software developer working mainly in the Proteomics field.", "user": 442, "suspended": false, "last_login_ip": "130.20.230.45", "type": 0, "reputation": 0}}, {"pk": 443, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Maik", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 443, "suspended": false, "last_login_ip": "84.88.66.226", "type": 0, "reputation": 0}}, {"pk": 444, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Atalon1", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 444, "suspended": false, "last_login_ip": "147.100.111.154", "type": 0, "reputation": 0}}, {"pk": 445, "model": "server.userprofile", "fields": {"website": "http://stevemoss.ath.cx", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gawbul", "location": "Planet Earth", "bronze_badges": 12, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "I'm a mature PhD student and Dad with a passion for science, medicine, computing, computational biology, bioinformatics, natural computation and all things geeky :D", "user": 445, "suspended": false, "last_login_ip": "150.237.85.247", "type": 0, "reputation": 0}}, {"pk": 446, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Radwen", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 446, "suspended": false, "last_login_ip": "80.119.167.243", "type": 0, "reputation": 0}}, {"pk": 447, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Craig", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 447, "suspended": false, "last_login_ip": "128.54.25.58", "type": 0, "reputation": 0}}, {"pk": 448, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 451", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 448, "suspended": false, "last_login_ip": "174.1.240.93", "type": 0, "reputation": 0}}, {"pk": 449, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Foreveremain", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Coordinator for www.jalview.org", "user": 449, "suspended": false, "last_login_ip": "81.156.234.187", "type": 0, "reputation": 0}}, {"pk": 450, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Wendy", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 450, "suspended": false, "last_login_ip": "202.185.55.241", "type": 0, "reputation": 0}}, {"pk": 451, "model": "server.userprofile", "fields": {"website": "http://personalpages.manchester.ac.uk/staff/ian.donaldson/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ian", "location": "University of Manchester, UK", "bronze_badges": 10, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "Member of bioinformatics core facility.\n\nBioinformatician who analyses ChIP-chip, ChIP-seq and is interested in other next generation analysis methods (generally uses data from the SOLiD platform).  \n\nAnalysis, organisation and displaying genomics data, in particular transcription factor binding site related data.", "user": 451, "suspended": false, "last_login_ip": "130.88.91.162", "type": 0, "reputation": 0}}, {"pk": 452, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Haji", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 452, "suspended": false, "last_login_ip": "132.68.108.64", "type": 0, "reputation": 0}}, {"pk": 453, "model": "server.userprofile", "fields": {"website": "http://phylogenomics.berkeley.edu/members/ruchira", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ruchira", "location": "Berkeley, California", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "Computational biologist and game theorist, now a research specialist with the Berkeley Phylogenomics Group.", "user": 453, "suspended": false, "last_login_ip": "24.7.70.157", "type": 0, "reputation": 0}}, {"pk": 454, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Harpal", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 454, "suspended": false, "last_login_ip": "132.239.240.183", "type": 0, "reputation": 0}}, {"pk": 455, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 458", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 455, "suspended": false, "last_login_ip": "24.250.248.111", "type": 0, "reputation": 0}}, {"pk": 456, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 459", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 456, "suspended": false, "last_login_ip": "24.2.56.255", "type": 0, "reputation": 0}}, {"pk": 457, "model": "server.userprofile", "fields": {"website": "http://davidquigley.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "David Quigley", "location": "San Francisco", "bronze_badges": 18, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 7, "gold_badges": 1, "score": 0, "about_me": "I am a cancer genetics researcher at UCSF. My work in Allan Balmain's lab centers on using analytical methods to identify genetic networks associated with susceptibility to cancer or which are selectively modified after a tumor develops. We primarily use mouse models of skin and lung cancer. My training is in Computer Science and Biomedical Informatics; I also have worked as a professional software developer.", "user": 457, "suspended": false, "last_login_ip": "174.253.242.89", "type": 1, "reputation": 0}}, {"pk": 458, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 461", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 458, "suspended": false, "last_login_ip": "96.242.201.201", "type": 0, "reputation": 0}}, {"pk": 459, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 462", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:39", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 459, "suspended": false, "last_login_ip": "69.140.60.53", "type": 0, "reputation": 0}}, {"pk": 460, "model": "server.userprofile", "fields": {"website": "http://www.genomic.ch", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Katrine", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 460, "suspended": false, "last_login_ip": "169.234.2.174", "type": 0, "reputation": 0}}, {"pk": 461, "model": "server.userprofile", "fields": {"website": "http://www.google.com/profiles/kanaksvet", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kanagarajadurai", "location": "Bangalore", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "My friends will say about me", "user": 461, "suspended": false, "last_login_ip": "117.199.134.188", "type": 0, "reputation": 0}}, {"pk": 462, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Protostome", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 462, "suspended": false, "last_login_ip": "84.228.144.81", "type": 0, "reputation": 0}}, {"pk": 463, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Fgibson", "location": null, "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 463, "suspended": false, "last_login_ip": "82.211.65.136", "type": 0, "reputation": 0}}, {"pk": 464, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Olebebo", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 464, "suspended": false, "last_login_ip": "79.180.1.3", "type": 0, "reputation": 0}}, {"pk": 465, "model": "server.userprofile", "fields": {"website": "http://lanceparsons.net", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Lance", "location": null, "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Scientific Programmer", "user": 465, "suspended": false, "last_login_ip": "128.112.117.216", "type": 0, "reputation": 0}}, {"pk": 466, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Joshm", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 466, "suspended": false, "last_login_ip": "206.169.183.232", "type": 0, "reputation": 0}}, {"pk": 467, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jeremiahloh", "location": "Singapore", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 467, "suspended": false, "last_login_ip": "220.255.0.58", "type": 0, "reputation": 0}}, {"pk": 468, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 471", "location": "", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": "", "user": 468, "suspended": false, "last_login_ip": "18.139.5.210", "type": 0, "reputation": 0}}, {"pk": 469, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 472", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 469, "suspended": false, "last_login_ip": "192.17.145.210", "type": 0, "reputation": 0}}, {"pk": 470, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jason", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 470, "suspended": false, "last_login_ip": "152.226.7.201", "type": 0, "reputation": 0}}, {"pk": 471, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 474", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 471, "suspended": false, "last_login_ip": "85.65.170.25", "type": 0, "reputation": 0}}, {"pk": 472, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 475", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:38", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 472, "suspended": false, "last_login_ip": "121.98.141.207", "type": 0, "reputation": 0}}, {"pk": 473, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Doctoroots", "location": null, "bronze_badges": 9, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 3, "gold_badges": 0, "score": 0, "about_me": null, "user": 473, "suspended": false, "last_login_ip": "192.114.23.209", "type": 0, "reputation": 0}}, {"pk": 474, "model": "server.userprofile", "fields": {"website": "http://twitter.com/bioinfosm", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bioinfosm", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "Nextgen Sequencing and all the informatics surrounding it", "user": 474, "suspended": false, "last_login_ip": "129.176.151.11", "type": 0, "reputation": 0}}, {"pk": 475, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Darren J. Fitzpatrick", "location": "Ireland/ United Kingdom", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 475, "suspended": false, "last_login_ip": "193.1.132.48", "type": 0, "reputation": 0}}, {"pk": 476, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Academicrobot", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 476, "suspended": false, "last_login_ip": "69.219.224.226", "type": 0, "reputation": 0}}, {"pk": 477, "model": "server.userprofile", "fields": {"website": "http://greg.grant.org", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Greg Grant", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 477, "suspended": false, "last_login_ip": "76.124.61.162", "type": 0, "reputation": 0}}, {"pk": 478, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 481", "location": "", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:40", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 478, "suspended": false, "last_login_ip": "152.226.7.201", "type": 0, "reputation": 0}}, {"pk": 479, "model": "server.userprofile", "fields": {"website": "http://bioinfo.cipf.es/dmontaner/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "David", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 479, "suspended": false, "last_login_ip": "193.144.127.12", "type": 0, "reputation": 0}}, {"pk": 480, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 483", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 480, "suspended": false, "last_login_ip": "216.52.167.244", "type": 0, "reputation": 0}}, {"pk": 481, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jin", "location": null, "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 481, "suspended": false, "last_login_ip": "128.249.1.194", "type": 0, "reputation": 0}}, {"pk": 482, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kenichi Shimada", "location": "New York", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 482, "suspended": false, "last_login_ip": "209.2.211.102", "type": 0, "reputation": 0}}, {"pk": 483, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "S4553711", "location": "Taiwan", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 483, "suspended": false, "last_login_ip": "113.196.133.194", "type": 0, "reputation": 0}}, {"pk": 484, "model": "server.userprofile", "fields": {"website": "http://blog.raoulbonnal.net", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Helios", "location": "Italy", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 484, "suspended": false, "last_login_ip": "212.31.227.18", "type": 0, "reputation": 0}}, {"pk": 485, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "D. Puthier", "location": null, "bronze_badges": 4, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 485, "suspended": false, "last_login_ip": "86.69.28.52", "type": 0, "reputation": 0}}, {"pk": 486, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Hamid Ashrafi", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 486, "suspended": false, "last_login_ip": "169.237.27.116", "type": 0, "reputation": 0}}, {"pk": 487, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 490", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "", "user": 487, "suspended": false, "last_login_ip": "207.47.61.4", "type": 0, "reputation": 0}}, {"pk": 488, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Ads-Osu", "location": null, "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 488, "suspended": false, "last_login_ip": "128.193.143.130", "type": 0, "reputation": 0}}, {"pk": 489, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 492", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 489, "suspended": false, "last_login_ip": "152.19.39.233", "type": 0, "reputation": 0}}, {"pk": 490, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Kyle", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 490, "suspended": false, "last_login_ip": "128.36.14.230", "type": 0, "reputation": 0}}, {"pk": 491, "model": "server.userprofile", "fields": {"website": "http://ecotheory.biology.gatech.edu/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Gabriel Mitchell", "location": "Atlanta", "bronze_badges": 5, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 2, "gold_badges": 0, "score": 0, "about_me": "Mostly theoretical ecology.", "user": 491, "suspended": false, "last_login_ip": "130.207.66.72", "type": 0, "reputation": 0}}, {"pk": 492, "model": "server.userprofile", "fields": {"website": "http://leeskatz.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Lee Katz", "location": "Atlanta, GA", "bronze_badges": 8, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": null, "user": 492, "suspended": false, "last_login_ip": "158.111.4.55", "type": 0, "reputation": 0}}, {"pk": 493, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Herv\u00e9 Pag\u00e8s", "location": "", "bronze_badges": 1, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 1, "gold_badges": 0, "score": 0, "about_me": "", "user": 493, "suspended": false, "last_login_ip": "140.107.151.119", "type": 0, "reputation": 0}}, {"pk": 494, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Nurjahan Mehzabeen", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 494, "suspended": false, "last_login_ip": "65.28.80.196", "type": 0, "reputation": 0}}, {"pk": 495, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "User 498", "location": "", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 495, "suspended": false, "last_login_ip": "212.87.14.5", "type": 0, "reputation": 0}}, {"pk": 496, "model": "server.userprofile", "fields": {"website": "", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Jaydon", "location": "", "bronze_badges": 3, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "", "user": 496, "suspended": false, "last_login_ip": "128.231.222.197", "type": 0, "reputation": 0}}, {"pk": 497, "model": "server.userprofile", "fields": {"website": null, "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Israel Barrantes", "location": "Magdeburg, Germany", "bronze_badges": 6, "views": 0, "last_visited": "2011-11-24 14:49:41", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 497, "suspended": false, "last_login_ip": "141.44.139.8", "type": 0, "reputation": 0}}, {"pk": 498, "model": "server.userprofile", "fields": {"website": "http://yaserxp.wordpress.com/", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Yaser Sulaiman", "location": "Dammam, Saudi Arabia", "bronze_badges": 2, "views": 0, "last_visited": "2011-11-24 14:49:37", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": "A computer scientist, a cognitive science hobbyist, and a Rubyist. A software developer, a juggler, and a wannabe mathematician/philosopher.", "user": 498, "suspended": false, "last_login_ip": "78.93.163.165", "type": 0, "reputation": 0}}, {"pk": 499, "model": "server.userprofile", "fields": {"website": "http://bookhling.wordpress.com", "openid": "http://www.biostars.org", "openid_merge": false, "display_name": "Bookhling", "location": "nyc", "bronze_badges": 0, "views": 0, "last_visited": "2011-11-24 14:48:26", "json": "", "silver_badges": 0, "gold_badges": 0, "score": 0, "about_me": null, "user": 499, "suspended": false, "last_login_ip": "24.42.127.171", "type": 0, "reputation": 0}}, {"pk": 1, "model": "server.tag", "fields": {"count": 1, "name": "guidelines"}}, {"pk": 2, "model": "server.tag", "fields": {"count": 2, "name": "bed"}}, {"pk": 3, "model": "server.tag", "fields": {"count": 3, "name": "gff"}}, {"pk": 4, "model": "server.tag", "fields": {"count": 2, "name": "galaxy"}}, {"pk": 5, "model": "server.tag", "fields": {"count": 1, "name": "yeast"}}, {"pk": 6, "model": "server.tag", "fields": {"count": 2, "name": "motif"}}, {"pk": 7, "model": "server.tag", "fields": {"count": 4, "name": "microarray"}}, {"pk": 8, "model": "server.tag", "fields": {"count": 2, "name": "clustering"}}, {"pk": 9, "model": "server.tag", "fields": {"count": 1, "name": "test"}}, {"pk": 10, "model": "server.tag", "fields": {"count": 1, "name": "nucleotides"}}, {"pk": 11, "model": "server.tag", "fields": {"count": 6, "name": "python"}}, {"pk": 12, "model": "server.tag", "fields": {"count": 1, "name": "frequency"}}, {"pk": 13, "model": "server.tag", "fields": {"count": 1, "name": "density"}}, {"pk": 14, "model": "server.tag", "fields": {"count": 3, "name": "solid"}}, {"pk": 15, "model": "server.tag", "fields": {"count": 1, "name": "chip"}}, {"pk": 16, "model": "server.tag", "fields": {"count": 2, "name": "boy"}}, {"pk": 17, "model": "server.tag", "fields": {"count": 2, "name": "george"}}, {"pk": 18, "model": "server.tag", "fields": {"count": 2, "name": "geneid"}}, {"pk": 19, "model": "server.tag", "fields": {"count": 2, "name": "accession"}}, {"pk": 20, "model": "server.tag", "fields": {"count": 1, "name": "mapping"}}, {"pk": 21, "model": "server.tag", "fields": {"count": 3, "name": "conversion"}}, {"pk": 22, "model": "server.tag", "fields": {"count": 1, "name": "shrimp"}}, {"pk": 23, "model": "server.tag", "fields": {"count": 5, "name": "sequencing"}}, {"pk": 24, "model": "server.tag", "fields": {"count": 2, "name": "short"}}, {"pk": 25, "model": "server.tag", "fields": {"count": 2, "name": "aligner"}}, {"pk": 26, "model": "server.tag", "fields": {"count": 1, "name": "meme"}}, {"pk": 27, "model": "server.tag", "fields": {"count": 1, "name": "sge"}}, {"pk": 28, "model": "server.tag", "fields": {"count": 2, "name": "compilation"}}, {"pk": 29, "model": "server.tag", "fields": {"count": 2, "name": "parallel"}}, {"pk": 30, "model": "server.tag", "fields": {"count": 1, "name": "rna"}}, {"pk": 31, "model": "server.tag", "fields": {"count": 8, "name": "general"}}, {"pk": 32, "model": "server.tag", "fields": {"count": 15, "name": "subjective"}}, {"pk": 33, "model": "server.tag", "fields": {"count": 0, "name": "operating"}}, {"pk": 34, "model": "server.tag", "fields": {"count": 1, "name": "programming"}}, {"pk": 35, "model": "server.tag", "fields": {"count": 1, "name": "languages"}}, {"pk": 36, "model": "server.tag", "fields": {"count": 6, "name": "gene"}}, {"pk": 37, "model": "server.tag", "fields": {"count": 1, "name": "function"}}, {"pk": 38, "model": "server.tag", "fields": {"count": 1, "name": "string"}}, {"pk": 39, "model": "server.tag", "fields": {"count": 1, "name": "ppi"}}, {"pk": 40, "model": "server.tag", "fields": {"count": 17, "name": "sequence"}}, {"pk": 41, "model": "server.tag", "fields": {"count": 8, "name": "protein"}}, {"pk": 42, "model": "server.tag", "fields": {"count": 2, "name": "structure"}}, {"pk": 43, "model": "server.tag", "fields": {"count": 6, "name": "blast"}}, {"pk": 44, "model": "server.tag", "fields": {"count": 1, "name": "ucsc"}}, {"pk": 45, "model": "server.tag", "fields": {"count": 1, "name": "fasta"}}, {"pk": 46, "model": "server.tag", "fields": {"count": 1, "name": "hdf"}}, {"pk": 47, "model": "server.tag", "fields": {"count": 1, "name": "biohdf"}}, {"pk": 48, "model": "server.tag", "fields": {"count": 4, "name": "data"}}, {"pk": 49, "model": "server.tag", "fields": {"count": 2, "name": "taverna"}}, {"pk": 50, "model": "server.tag", "fields": {"count": 1, "name": "plugin"}}, {"pk": 51, "model": "server.tag", "fields": {"count": 1, "name": "maven"}}, {"pk": 52, "model": "server.tag", "fields": {"count": 2, "name": "workflow"}}, {"pk": 53, "model": "server.tag", "fields": {"count": 2, "name": "format"}}, {"pk": 54, "model": "server.tag", "fields": {"count": 1, "name": "make"}}, {"pk": 55, "model": "server.tag", "fields": {"count": 1, "name": "pipeline"}}, {"pk": 56, "model": "server.tag", "fields": {"count": 1, "name": "organization"}}, {"pk": 57, "model": "server.tag", "fields": {"count": 2, "name": "agile"}}, {"pk": 58, "model": "server.tag", "fields": {"count": 1, "name": "best"}}, {"pk": 59, "model": "server.tag", "fields": {"count": 2, "name": "team"}}, {"pk": 60, "model": "server.tag", "fields": {"count": 2, "name": "biopython"}}, {"pk": 61, "model": "server.tag", "fields": {"count": 1, "name": "pygr"}}, {"pk": 62, "model": "server.tag", "fields": {"count": 1, "name": "interval"}}, {"pk": 63, "model": "server.tag", "fields": {"count": 1, "name": "query"}}, {"pk": 64, "model": "server.tag", "fields": {"count": 2, "name": "genomics"}}, {"pk": 65, "model": "server.tag", "fields": {"count": 4, "name": "dna"}}, {"pk": 66, "model": "server.tag", "fields": {"count": 1, "name": "competition"}}, {"pk": 67, "model": "server.tag", "fields": {"count": 6, "name": "genome"}}, {"pk": 68, "model": "server.tag", "fields": {"count": 6, "name": "annotation"}}, {"pk": 69, "model": "server.tag", "fields": {"count": 2, "name": "database"}}, {"pk": 70, "model": "server.tag", "fields": {"count": 1, "name": "taxonomy"}}, {"pk": 71, "model": "server.tag", "fields": {"count": 2, "name": "blog"}}, {"pk": 72, "model": "server.tag", "fields": {"count": 1, "name": "off"}}, {"pk": 73, "model": "server.tag", "fields": {"count": 3, "name": "resources"}}, {"pk": 74, "model": "server.tag", "fields": {"count": 1, "name": "pfam"}}, {"pk": 75, "model": "server.tag", "fields": {"count": 1, "name": "k"}}, {"pk": 76, "model": "server.tag", "fields": {"count": 1, "name": "cloud"}}, {"pk": 77, "model": "server.tag", "fields": {"count": 1, "name": "education"}}, {"pk": 78, "model": "server.tag", "fields": {"count": 2, "name": "snp"}}, {"pk": 79, "model": "server.tag", "fields": {"count": 1, "name": "genotyping"}}, {"pk": 80, "model": "server.tag", "fields": {"count": 0, "name": "pathway"}}, {"pk": 81, "model": "server.tag", "fields": {"count": 1, "name": "enrichment"}}, {"pk": 82, "model": "server.tag", "fields": {"count": 1, "name": "meta"}}, {"pk": 83, "model": "server.tag", "fields": {"count": 3, "name": "alignment"}}, {"pk": 84, "model": "server.tag", "fields": {"count": 2, "name": "scoring"}}, {"pk": 85, "model": "server.tag", "fields": {"count": 2, "name": "multiple"}}, {"pk": 86, "model": "server.tag", "fields": {"count": 1, "name": "hardware"}}, {"pk": 87, "model": "server.tag", "fields": {"count": 1, "name": "linux"}}, {"pk": 88, "model": "server.tag", "fields": {"count": 2, "name": "server"}}, {"pk": 89, "model": "server.tag", "fields": {"count": 1, "name": "ensembl"}}, {"pk": 90, "model": "server.tag", "fields": {"count": 3, "name": "books"}}, {"pk": 91, "model": "server.tag", "fields": {"count": 0, "name": "teaching"}}, {"pk": 92, "model": "server.tag", "fields": {"count": 1, "name": "bacteria"}}, {"pk": 93, "model": "server.tag", "fields": {"count": 1, "name": "genetic"}}, {"pk": 94, "model": "server.tag", "fields": {"count": 2, "name": "map"}}, {"pk": 95, "model": "server.tag", "fields": {"count": 1, "name": "distance"}}, {"pk": 96, "model": "server.tag", "fields": {"count": 1, "name": "dnase"}}, {"pk": 97, "model": "server.tag", "fields": {"count": 1, "name": "transcription"}}, {"pk": 98, "model": "server.tag", "fields": {"count": 0, "name": "binding"}}, {"pk": 99, "model": "server.tag", "fields": {"count": 1, "name": "contact"}}, {"pk": 100, "model": "server.tag", "fields": {"count": 1, "name": "faq"}}, {"pk": 101, "model": "server.tag", "fields": {"count": 1, "name": "assembly"}}, {"pk": 102, "model": "server.tag", "fields": {"count": 1, "name": "unambiguous"}}, {"pk": 103, "model": "server.tag", "fields": {"count": 3, "name": "fastq"}}, {"pk": 104, "model": "server.tag", "fields": {"count": 0, "name": "next"}}, {"pk": 105, "model": "server.tag", "fields": {"count": 1, "name": "search"}}, {"pk": 106, "model": "server.tag", "fields": {"count": 2, "name": "tool"}}, {"pk": 107, "model": "server.tag", "fields": {"count": 1, "name": "primer"}}, {"pk": 108, "model": "server.tag", "fields": {"count": 0, "name": "heatmap"}}, {"pk": 109, "model": "server.tag", "fields": {"count": 1, "name": "professional"}}, {"pk": 110, "model": "server.tag", "fields": {"count": 4, "name": "career"}}, {"pk": 111, "model": "server.tag", "fields": {"count": 1, "name": "assessment"}}, {"pk": 112, "model": "server.tag", "fields": {"count": 1, "name": "metabolomics"}}, {"pk": 113, "model": "server.tag", "fields": {"count": 1, "name": "chemoinformatics"}}, {"pk": 114, "model": "server.tag", "fields": {"count": 2, "name": "java"}}, {"pk": 115, "model": "server.tag", "fields": {"count": 1, "name": "open"}}, {"pk": 116, "model": "server.tag", "fields": {"count": 1, "name": "base"}}, {"pk": 117, "model": "server.tag", "fields": {"count": 1, "name": "phred"}}, {"pk": 118, "model": "server.tag", "fields": {"count": 1, "name": "bustard"}}, {"pk": 119, "model": "server.tag", "fields": {"count": 1, "name": "podcast"}}, {"pk": 120, "model": "server.tag", "fields": {"count": 2, "name": "recommendations"}}, {"pk": 121, "model": "server.tag", "fields": {"count": 1, "name": "vodcast"}}, {"pk": 122, "model": "server.tag", "fields": {"count": 1, "name": "trna"}}, {"pk": 123, "model": "server.tag", "fields": {"count": 1, "name": "redundancy"}}, {"pk": 124, "model": "server.tag", "fields": {"count": 2, "name": "c"}}, {"pk": 125, "model": "server.tag", "fields": {"count": 1, "name": "mpi"}}, {"pk": 126, "model": "server.tag", "fields": {"count": 2, "name": "job"}}, {"pk": 127, "model": "server.tag", "fields": {"count": 1, "name": "sturdy"}}, {"pk": 128, "model": "server.tag", "fields": {"count": 1, "name": "development"}}, {"pk": 129, "model": "server.tag", "fields": {"count": 1, "name": "image"}}, {"pk": 130, "model": "server.tag", "fields": {"count": 1, "name": "fpga"}}, {"pk": 131, "model": "server.tag", "fields": {"count": 2, "name": "hpc"}}, {"pk": 132, "model": "server.tag", "fields": {"count": 1, "name": "affymetrix"}}, {"pk": 133, "model": "server.tag", "fields": {"count": 1, "name": "probeset"}}, {"pk": 134, "model": "server.tag", "fields": {"count": 1, "name": "profiles"}}, {"pk": 135, "model": "server.tag", "fields": {"count": 1, "name": "licensing"}}, {"pk": 136, "model": "server.tag", "fields": {"count": 2, "name": "software"}}, {"pk": 137, "model": "server.tag", "fields": {"count": 3, "name": "r"}}, {"pk": 138, "model": "server.tag", "fields": {"count": 1, "name": "symbol"}}, {"pk": 139, "model": "server.tag", "fields": {"count": 1, "name": "biomart"}}, {"pk": 140, "model": "server.tag", "fields": {"count": 1, "name": "wsdl"}}, {"pk": 141, "model": "server.tag", "fields": {"count": 2, "name": "soap"}}, {"pk": 142, "model": "server.tag", "fields": {"count": 2, "name": "webservice"}}, {"pk": 143, "model": "server.tag", "fields": {"count": 3, "name": "visualization"}}, {"pk": 144, "model": "server.tag", "fields": {"count": 0, "name": "uniprot"}}, {"pk": 145, "model": "server.tag", "fields": {"count": 1, "name": "embl"}}, {"pk": 146, "model": "server.tag", "fields": {"count": 1, "name": "genbank"}}, {"pk": 147, "model": "server.tag", "fields": {"count": 1, "name": "chromosome"}}, {"pk": 148, "model": "server.tag", "fields": {"count": 1, "name": "ideogram"}}, {"pk": 149, "model": "server.tag", "fields": {"count": 1, "name": "methods"}}, {"pk": 150, "model": "server.tag", "fields": {"count": 0, "name": "model"}}, {"pk": 151, "model": "server.tag", "fields": {"count": 1, "name": "what"}}, {"pk": 152, "model": "server.tag", "fields": {"count": 9, "name": "bioinformatics"}}, {"pk": 153, "model": "server.tag", "fields": {"count": 1, "name": "torrent"}}, {"pk": 154, "model": "server.tag", "fields": {"count": 0, "name": "phylogenetics"}}, {"pk": 155, "model": "server.tag", "fields": {"count": 1, "name": "feedback"}}, {"pk": 156, "model": "server.tag", "fields": {"count": 1, "name": "literature"}}, {"pk": 157, "model": "server.tag", "fields": {"count": 1, "name": "text"}}, {"pk": 158, "model": "server.tag", "fields": {"count": 1, "name": "human"}}, {"pk": 159, "model": "server.tag", "fields": {"count": 1, "name": "rest"}}, {"pk": 160, "model": "server.tag", "fields": {"count": 1, "name": "submission"}}, {"pk": 161, "model": "server.tag", "fields": {"count": 1, "name": "ncbi"}}, {"pk": 162, "model": "server.tag", "fields": {"count": 1, "name": "gwas"}}, {"pk": 163, "model": "server.tag", "fields": {"count": 1, "name": "plone"}}, {"pk": 164, "model": "server.tag", "fields": {"count": 1, "name": "online"}}, {"pk": 165, "model": "server.tag", "fields": {"count": 1, "name": "call"}}, {"pk": 166, "model": "server.tag", "fields": {"count": 1, "name": "papers"}}, {"pk": 167, "model": "server.tag", "fields": {"count": 1, "name": "conferences"}}, {"pk": 168, "model": "server.tag", "fields": {"count": 1, "name": "cran"}}, {"pk": 169, "model": "server.tag", "fields": {"count": 1, "name": "college"}}, {"pk": 170, "model": "server.tag", "fields": {"count": 1, "name": "project"}}, {"pk": 171, "model": "server.tag", "fields": {"count": 1, "name": "peer"}}, {"pk": 172, "model": "server.tag", "fields": {"count": 1, "name": "articles"}}, {"pk": 173, "model": "server.tag", "fields": {"count": 1, "name": "journals"}}, {"pk": 174, "model": "server.tag", "fields": {"count": 1, "name": "tips"}}, {"pk": 175, "model": "server.tag", "fields": {"count": 1, "name": "practical"}}, {"pk": 176, "model": "server.tag", "fields": {"count": 0, "name": "big"}}, {"pk": 177, "model": "server.tag", "fields": {"count": 1, "name": "markov"}}, {"pk": 178, "model": "server.tag", "fields": {"count": 1, "name": "random"}}, {"pk": 179, "model": "server.tag", "fields": {"count": 1, "name": "generation"}}, {"pk": 180, "model": "server.tag", "fields": {"count": 1, "name": "sql"}}, {"pk": 181, "model": "server.tag", "fields": {"count": 2, "name": "statistics"}}, {"pk": 182, "model": "server.tag", "fields": {"count": 0, "name": "amino"}}, {"pk": 183, "model": "server.tag", "fields": {"count": 0, "name": "composition"}}, {"pk": 184, "model": "server.tag", "fields": {"count": 1, "name": "testing"}}, {"pk": 185, "model": "server.tag", "fields": {"count": 1, "name": "standard"}}, {"pk": 186, "model": "server.tag", "fields": {"count": 0, "name": "start"}}, {"pk": 187, "model": "server.tag", "fields": {"count": 0, "name": "dinucleotide"}}, {"pk": 188, "model": "server.tag", "fields": {"count": 1, "name": "deep"}}, {"pk": 189, "model": "server.tag", "fields": {"count": 0, "name": "geneontology"}}, {"pk": 190, "model": "server.tag", "fields": {"count": 2, "name": "go"}}, {"pk": 191, "model": "server.tag", "fields": {"count": 1, "name": "interacti"}}, {"pk": 192, "model": "server.tag", "fields": {"count": 2, "name": "use"}}, {"pk": 193, "model": "server.tag", "fields": {"count": 1, "name": "good"}}, {"pk": 194, "model": "server.tag", "fields": {"count": 1, "name": "os"}}, {"pk": 195, "model": "server.tag", "fields": {"count": 1, "name": "storage"}}, {"pk": 196, "model": "server.tag", "fields": {"count": 0, "name": "places"}}, {"pk": 197, "model": "server.tag", "fields": {"count": 1, "name": "pathways"}}, {"pk": 198, "model": "server.tag", "fields": {"count": 2, "name": "genes"}}, {"pk": 199, "model": "server.tag", "fields": {"count": 1, "name": "mining"}}, {"pk": 200, "model": "server.tag", "fields": {"count": 0, "name": "biostar"}}, {"pk": 201, "model": "server.tag", "fields": {"count": 0, "name": "multiplealignment"}}, {"pk": 202, "model": "server.tag", "fields": {"count": 0, "name": "scoringmatix"}}, {"pk": 203, "model": "server.tag", "fields": {"count": 0, "name": "book"}}, {"pk": 204, "model": "server.tag", "fields": {"count": 1, "name": "cm"}}, {"pk": 205, "model": "server.tag", "fields": {"count": 1, "name": "pin"}}, {"pk": 206, "model": "server.tag", "fields": {"count": 1, "name": "cis"}}, {"pk": 207, "model": "server.tag", "fields": {"count": 1, "name": "module"}}, {"pk": 208, "model": "server.tag", "fields": {"count": 0, "name": "prediction"}}, {"pk": 209, "model": "server.tag", "fields": {"count": 0, "name": "high"}}, {"pk": 210, "model": "server.tag", "fields": {"count": 0, "name": "metabolite"}}, {"pk": 211, "model": "server.tag", "fields": {"count": 0, "name": "cheminformatics"}}, {"pk": 212, "model": "server.tag", "fields": {"count": 0, "name": "opensource"}}, {"pk": 213, "model": "server.tag", "fields": {"count": 1, "name": "analysis"}}, {"pk": 214, "model": "server.tag", "fields": {"count": 1, "name": "integrated"}}, {"pk": 215, "model": "server.tag", "fields": {"count": 3, "name": "ngs"}}, {"pk": 216, "model": "server.tag", "fields": {"count": 0, "name": "recommandation"}}, {"pk": 217, "model": "server.tag", "fields": {"count": 1, "name": "reconfigurable"}}, {"pk": 218, "model": "server.tag", "fields": {"count": 2, "name": "plotting"}}, {"pk": 219, "model": "server.tag", "fields": {"count": 1, "name": "swissprot"}}, {"pk": 220, "model": "server.tag", "fields": {"count": 0, "name": "scoringmatrix"}}, {"pk": 221, "model": "server.tag", "fields": {"count": 3, "name": "not"}}, {"pk": 222, "model": "server.tag", "fields": {"count": 3, "name": "related"}}, {"pk": 223, "model": "server.tag", "fields": {"count": 1, "name": "phylogeny"}}, {"pk": 224, "model": "server.tag", "fields": {"count": 1, "name": "models"}}, {"pk": 225, "model": "server.tag", "fields": {"count": 2, "name": "public"}}, {"pk": 226, "model": "server.tag", "fields": {"count": 0, "name": "virtual"}}, {"pk": 227, "model": "server.tag", "fields": {"count": 1, "name": "research"}}, {"pk": 228, "model": "server.tag", "fields": {"count": 0, "name": "chain"}}, {"pk": 229, "model": "server.tag", "fields": {"count": 0, "name": "statistic"}}, {"pk": 230, "model": "server.tag", "fields": {"count": 0, "name": "parser"}}, {"pk": 231, "model": "server.tag", "fields": {"count": 1, "name": "relief"}}, {"pk": 232, "model": "server.tag", "fields": {"count": 1, "name": "fun"}}, {"pk": 233, "model": "server.tag", "fields": {"count": 0, "name": "science"}}, {"pk": 1, "model": "server.post", "fields": {"rght": 24, "author": 1, "answer_accepted": true, "tag_string": "guidelines", "creation_date": "2009-09-30 14:12:07", "lft": 1, "post_type": 164033, "score": 3, "title": "Site use guidelines", "unanswered": false, "content": "Here are a few guidelines:\n\n 1. The site's goal is to answer bioinformatics and systems biology related questions\n 2. Answer questions to gain *reputation*. \n 3. Don't forget to vote for answers that you like! Registered users may vote on answers.\n 4. If you are the one asking the original question you may also select the best answer\n 5. Subscribe to the RSS feeds for all questions or a single question to keep up to date with the developments", "comment_count": 0, "html": "<p>Here are a few guidelines:</p>\n<ol>\n<li>The site's goal is to answer bioinformatics and systems biology related questions</li>\n<li>Answer questions to gain <em>reputation</em>. </li>\n<li>Don't forget to vote for answers that you like! Registered users may vote on answers.</li>\n<li>If you are the one asking the original question you may also select the best answer</li>\n<li>Subscribe to the RSS feeds for all questions or a single question to keep up to date with the developments</li>\n</ol>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 4, "parent": null, "views": 129, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:28", "slug": "site-use-guidelines", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [1], "lastedit_user": 1}}, {"pk": 2, "model": "server.post", "fields": {"rght": 12, "author": 1, "answer_accepted": false, "tag_string": "bed gff galaxy", "creation_date": "2009-09-30 14:55:00", "lft": 1, "post_type": 164033, "score": 4, "title": "How do I convert from BED format to GFF format?", "unanswered": false, "content": "I have a file in GFF format and I need to convert it to BED format. What do I do?", "comment_count": 0, "html": "<p>I have a file in GFF format and I need to convert it to BED format. What do I do?</p>", "child_count": 0, "closed": false, "tree_id": 2, "revision_count": 2, "parent": null, "views": 2458, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:29", "slug": "how-do-i-convert-from-bed-format-to-gff-format", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [2, 3, 4], "lastedit_user": 1}}, {"pk": 3, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2009-09-30 14:56:18", "lft": 2, "post_type": 109787, "score": 1, "title": "A: How do I convert from BED format to GFF format?", "unanswered": false, "content": "Both formats are tab delimited text files used to represent DNA features in genomes. The order of columns between the two are different, there are also columns that correspond to attributes missing from one or the other format. Nonetheless **the most important** difference between the two is the coordinate systems that they assume. \n\nThe [BED](http://genome.ucsc.edu/FAQ/FAQformat#format1) format developed at `UCSC` uses a zero based indexing and an open end interval whereas the [GFF](http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml) format developed at `Sanger` assumes a 1 based coordinate system that includes both start and end coordinates. Therefore\n\nThe `[0,100]` interval in `BED` format corresponds to `[1,100]` in `GFF` format and both are `100` base long. That the first element in BED format will be have the index of `0` where the last `100th` element will have the index of `99`! Whereas in `GFF` the first element will have the index of `1` and the last element will have the index of `100`.\n\nTo convert between the two you may use [Galaxy](http://main.g2.bx.psu.edu/) and select the section called `Select Formats` that will list various transformation options.\n", "comment_count": 0, "html": "<p>Both formats are tab delimited text files used to represent DNA features in genomes. The order of columns between the two are different, there are also columns that correspond to attributes missing from one or the other format. Nonetheless <strong>the most important</strong> difference between the two is the coordinate systems that they assume. </p>\n<p>The <a href=\"http://genome.ucsc.edu/FAQ/FAQformat#format1\">BED</a> format developed at <code>UCSC</code> uses a zero based indexing and an open end interval whereas the <a href=\"http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml\">GFF</a> format developed at <code>Sanger</code> assumes a 1 based coordinate system that includes both start and end coordinates. Therefore</p>\n<p>The <code>[0,100]</code> interval in <code>BED</code> format corresponds to <code>[1,100]</code> in <code>GFF</code> format and both are <code>100</code> base long. That the first element in BED format will be have the index of <code>0</code> where the last <code>100th</code> element will have the index of <code>99</code>! Whereas in <code>GFF</code> the first element will have the index of <code>1</code> and the last element will have the index of <code>100</code>.</p>\n<p>To convert between the two you may use <a href=\"http://main.g2.bx.psu.edu/\">Galaxy</a> and select the section called <code>Select Formats</code> that will list various transformation options.</p>", "child_count": 0, "closed": false, "tree_id": 2, "revision_count": 2, "parent": 2, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:15", "slug": "a-how-do-i-convert-from-bed-format-to-gff-format", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 4, "model": "server.post", "fields": {"rght": 18, "author": 2, "answer_accepted": false, "tag_string": "yeast motif", "creation_date": "2009-09-30 16:09:06", "lft": 1, "post_type": 164033, "score": 7, "title": "Finding common motifs in sequences", "unanswered": false, "content": "I have a few hundred yeast sequences (20-80bp long) and I want to find common motifs (conserved bases at certain indices) in them. I am using a Mac", "comment_count": 0, "html": "<p>I have a few hundred yeast sequences (20-80bp long) and I want to find common motifs (conserved bases at certain indices) in them. I am using a Mac</p>", "child_count": 0, "closed": false, "tree_id": 3, "revision_count": 1, "parent": null, "views": 861, "deleted": false, "answer_count": 14, "touch_date": "2011-11-24 14:49:29", "slug": "finding-common-motifs-in-sequences", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [5, 6], "lastedit_user": 2}}, {"pk": 5, "model": "server.post", "fields": {"rght": 12, "author": 1, "answer_accepted": false, "tag_string": "microarray clustering", "creation_date": "2009-09-30 16:44:22", "lft": 1, "post_type": 164033, "score": 5, "title": "Recommend easy to use microarray clustering software", "unanswered": false, "content": "Feel free to post your favorite clustering tool.", "comment_count": 0, "html": "<p>Feel free to post your favorite clustering tool.</p>", "child_count": 0, "closed": false, "tree_id": 4, "revision_count": 4, "parent": null, "views": 989, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:31", "slug": "recommend-easy-to-use-microarray-clustering-software", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [7, 8], "lastedit_user": 1}}, {"pk": 6, "model": "server.post", "fields": {"rght": 2, "author": 4, "answer_accepted": false, "tag_string": "test", "creation_date": "2009-09-30 18:49:39", "lft": 1, "post_type": 164033, "score": 0, "title": "test by zhenhai", "unanswered": false, "content": "Hi, I just created my user id a few minutes ago. \n\nPost this question to see how it works.", "comment_count": 0, "html": "<p>Hi, I just created my user id a few minutes ago. </p>\n<p>Post this question to see how it works.</p>", "child_count": 0, "closed": false, "tree_id": 5, "revision_count": 2, "parent": null, "views": 3, "deleted": true, "answer_count": 0, "touch_date": "2011-11-24 14:48:57", "slug": "test-by-zhenhai", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [9], "lastedit_user": 4}}, {"pk": 7, "model": "server.post", "fields": {"rght": 3, "author": 4, "answer_accepted": false, "tag_string": "", "creation_date": "2009-09-30 18:55:02", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Finding common motifs in sequences", "unanswered": false, "content": "try this out?\n\nhttp://fraenkel.mit.edu/webmotifs/form.html", "comment_count": 0, "html": "<p>try this out?</p>\n<p>http://fraenkel.mit.edu/webmotifs/form.html</p>", "child_count": 0, "closed": false, "tree_id": 3, "revision_count": 1, "parent": 4, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-finding-common-motifs-in-sequences", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 4}}, {"pk": 8, "model": "server.post", "fields": {"rght": 5, "author": 5, "answer_accepted": false, "tag_string": "", "creation_date": "2009-09-30 19:32:29", "lft": 4, "post_type": 109787, "score": 4, "title": "A: Finding common motifs in sequences", "unanswered": false, "content": "You can also use MEME:  http://meme.sdsc.edu/.", "comment_count": 0, "html": "<p>You can also use MEME:  http://meme.sdsc.edu/.</p>", "child_count": 0, "closed": false, "tree_id": 3, "revision_count": 1, "parent": 4, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-finding-common-motifs-in-sequences", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 5}}, {"pk": 9, "model": "server.post", "fields": {"rght": 9, "author": 6, "answer_accepted": false, "tag_string": "", "creation_date": "2009-09-30 19:35:28", "lft": 6, "post_type": 109787, "score": 0, "title": "A: Finding common motifs in sequences", "unanswered": false, "content": "<pre>\nACGGGCCCGACGATGCGTCGTA\n\nACGTACGTCGAACCGTCGTCGT\n\nACGTGCGTCGAAACGTCAGTCG\n\nACGGGTTCGATCGTCGTCGTCG\n</pre>\n may be in Python I will break down the first sequence of required motif length into a sliding window and will search for those list of motifs in the rest of sequences using regular expression in python using `re.search()` method.", "comment_count": 1, "html": "<p>[HTML_REMOVED]</p>", "child_count": 0, "closed": false, "tree_id": 3, "revision_count": 2, "parent": 4, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:59", "slug": "a-finding-common-motifs-in-sequences", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 10, "model": "server.post", "fields": {"rght": 4, "author": 9, "answer_accepted": true, "tag_string": "nucleotides python frequency density", "creation_date": "2009-10-05 15:51:37", "lft": 1, "post_type": 164033, "score": 4, "title": "How to generate multi-nucleotide occupancy counts for each coordinate of my reads?", "unanswered": false, "content": "I need to generate nucleotide occupancy counts for each position of a given sequence then summed over each of the input sequences. An example desired output (for di-nucleotide AT):\n\n![dinucleotide occupancy][1]\n\n\n  [1]: http://github.com/ialbert/biostar-codesample/raw/master/python/images/dinuc.png", "comment_count": 0, "html": "<p>I need to generate nucleotide occupancy counts for each position of a given sequence then summed over each of the input sequences. An example desired output (for di-nucleotide AT):</p>\n<p><img alt=\"dinucleotide occupancy\" src=\"http://github.com/ialbert/biostar-codesample/raw/master/python/images/dinuc.png\" /></p>", "child_count": 0, "closed": false, "tree_id": 6, "revision_count": 4, "parent": null, "views": 91, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:28", "slug": "how-to-generate-multi-nucleotide-occupancy-counts-for-each-coordinate-of-my-reads", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [10, 11, 12, 13], "lastedit_user": 22}}, {"pk": 11, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-05 16:03:01", "lft": 2, "post_type": 109787, "score": 4, "title": "A: How to generate multi-nucleotide occupancy counts for each coordinate of my reads?", "unanswered": false, "content": "The code snippet below will populate the ``store`` dictionary keyed by the nucleotide patterns and values as lists that contain the occupancy for each index. (Updated answer now includes arbitrary lenght nucleotide counts)::\n\n\n\n    from itertools import count\n\n    def pattern_update(sequence, width=2, store={}):\n        \"\"\"\n        Accumulates nucleotide patterns of a certain width with \n        position counts at each index.\n        \"\"\"\n       \n        # open intervals need a padding at end for proper slicing\n        size  = len(sequence) + 1\n\n        def zeroes():\n            \"Generates an empty array that holds the positions\"\n            return [ 0 ] * (size - width)\n        \n        # these are the end indices\n        ends = range(width, size)\n\n        for lo, hi in zip(count(), ends):\n            # upon encoutering a missing key initialize \n            # that value for that key to the return value of the empty() function\n            key = sequence[lo:hi]\n            store.setdefault(key, zeroes())[lo] += 1\n\n        return store\n\n\n\nThe code at [multipatt.py][1] demonstrates its use in a full program. Set the ``size`` to the maximal possible sequence size. A typical use case::\n\n\n    store = {}\n    seq1 = 'ATGCT'\n    pattern_update(seq1, width=2, store=store)    \n\n    seq2 = 'ATCGC'\n    pattern_update(seq2, width=2, store=store)    \n\n    print store\n\nwill print::\n\n\n    {'CG': [0, 0, 1, 0], 'GC': [0, 0, 1, 1], 'AT': [2, 0, 0, 0], \n    'TG': [0, 1, 0, 0], 'TC': [0, 1, 0, 0], 'CT': [0, 0, 0, 1]}\n\n\n[1]: http://github.com/ialbert/biostar-codesample/blob/master/python/multipatt.py\n    ", "comment_count": 0, "html": "<p>The code snippet below will populate the <code>store</code> dictionary keyed by the nucleotide patterns and values as lists that contain the occupancy for each index. (Updated answer now includes arbitrary lenght nucleotide counts)::</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">from</span> <span class=\"n\">itertools</span> <span class=\"nb\">import</span> <span class=\"n\">count</span>\n\n    <span class=\"n\">def</span> <span class=\"n\">pattern_update</span><span class=\"p\">(</span><span class=\"n\">sequence</span><span class=\"p\">,</span> <span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">store</span><span class=\"o\">=</span><span class=\"p\">{}):</span>\n        <span class=\"s\">&quot;&quot;&quot;</span>\n<span class=\"s\">        Accumulates nucleotide patterns of a certain width with </span>\n<span class=\"s\">        position counts at each index.</span>\n<span class=\"s\">        &quot;&quot;&quot;</span>\n       \n        <span class=\"c1\"># open intervals need a padding at end for proper slicing</span>\n        <span class=\"n\">size</span>  <span class=\"o\">=</span> <span class=\"n\">len</span><span class=\"p\">(</span><span class=\"n\">sequence</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span>\n\n        <span class=\"n\">def</span> <span class=\"n\">zeroes</span><span class=\"p\">():</span>\n            <span class=\"s\">&quot;Generates an empty array that holds the positions&quot;</span>\n            <span class=\"k\">return</span> <span class=\"p\">[</span> <span class=\"mi\">0</span> <span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">size</span> <span class=\"o\">-</span> <span class=\"n\">width</span><span class=\"p\">)</span>\n        \n        <span class=\"c1\"># these are the end indices</span>\n        <span class=\"n\">ends</span> <span class=\"o\">=</span> <span class=\"n\">range</span><span class=\"p\">(</span><span class=\"n\">width</span><span class=\"p\">,</span> <span class=\"n\">size</span><span class=\"p\">)</span>\n\n        <span class=\"k\">for</span> <span class=\"n\">lo</span><span class=\"p\">,</span> <span class=\"n\">hi</span> <span class=\"n\">in</span> <span class=\"n\">zip</span><span class=\"p\">(</span><span class=\"n\">count</span><span class=\"p\">(),</span> <span class=\"n\">ends</span><span class=\"p\">):</span>\n            <span class=\"c1\"># upon encoutering a missing key initialize </span>\n            <span class=\"c1\"># that value for that key to the return value of the empty() function</span>\n            <span class=\"n\">key</span> <span class=\"o\">=</span> <span class=\"n\">sequence</span><span class=\"p\">[</span><span class=\"n\">lo:hi</span><span class=\"p\">]</span>\n            <span class=\"n\">store</span><span class=\"o\">.</span><span class=\"n\">setdefault</span><span class=\"p\">(</span><span class=\"n\">key</span><span class=\"p\">,</span> <span class=\"n\">zeroes</span><span class=\"p\">())[</span><span class=\"n\">lo</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n\n        <span class=\"k\">return</span> <span class=\"n\">store</span>\n</pre></div>\n</p>\n<p>The code at <a href=\"http://github.com/ialbert/biostar-codesample/blob/master/python/multipatt.py\">multipatt.py</a> demonstrates its use in a full program. Set the <code>size</code> to the maximal possible sequence size. A typical use case::</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">store</span> <span class=\"o\">=</span> <span class=\"p\">{}</span>\n    <span class=\"n\">seq1</span> <span class=\"o\">=</span> <span class=\"s\">&#39;ATGCT&#39;</span>\n    <span class=\"n\">pattern_update</span><span class=\"p\">(</span><span class=\"n\">seq1</span><span class=\"p\">,</span> <span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">store</span><span class=\"o\">=</span><span class=\"n\">store</span><span class=\"p\">)</span>    \n\n    <span class=\"n\">seq2</span> <span class=\"o\">=</span> <span class=\"s\">&#39;ATCGC&#39;</span>\n    <span class=\"n\">pattern_update</span><span class=\"p\">(</span><span class=\"n\">seq2</span><span class=\"p\">,</span> <span class=\"n\">width</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">store</span><span class=\"o\">=</span><span class=\"n\">store</span><span class=\"p\">)</span>    \n\n    <span class=\"k\">print</span> <span class=\"n\">store</span>\n</pre></div>\n</p>\n<p>will print::</p>\n<p><div class=\"highlight\"><pre>    <span class=\"p\">{</span><span class=\"s\">&#39;CG&#39;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"s\">&#39;GC&#39;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"s\">&#39;AT&#39;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> \n    <span class=\"s\">&#39;TG&#39;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"s\">&#39;TC&#39;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"s\">&#39;CT&#39;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">]}</span>\n</pre></div>\n</p>\n<p><div class=\"highlight\"><pre>    \n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 6, "revision_count": 4, "parent": 10, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-generate-multi-nucleotide-occupancy-counts-for-each-coordinate-of-my-reads", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 1}}, {"pk": 12, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-05 16:09:57", "lft": 2, "post_type": 109787, "score": 6, "title": "A: Recommend easy to use microarray clustering software", "unanswered": false, "content": "One of my favorites is the [MEV](http://www.tm4.org/mev.html) micro-array data analysis tool.\nIt is simple to use and it has a very large number of features. \n\nWorks well for any type of data. You can also load into it data from a file that is in a simple text format:\n\n<pre>\nGENE1, value1, value2\nGENE2, value1, value2\n</pre>\n\nFeel free to post your favorite clustering tool.", "comment_count": 0, "html": "<p>One of my favorites is the <a href=\"http://www.tm4.org/mev.html\">MEV</a> micro-array data analysis tool.\nIt is simple to use and it has a very large number of features. </p>\n<p>Works well for any type of data. You can also load into it data from a file that is in a simple text format:</p>\n<p>[HTML_REMOVED]</p>\n<p>Feel free to post your favorite clustering tool.</p>", "child_count": 0, "closed": false, "tree_id": 4, "revision_count": 1, "parent": 5, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-recommend-easy-to-use-microarray-clustering-software", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 13, "model": "server.post", "fields": {"rght": 8, "author": 11, "answer_accepted": false, "tag_string": "solid deep sequence", "creation_date": "2009-10-06 18:58:10", "lft": 1, "post_type": 164033, "score": 3, "title": "CHIP DNA deep sequence", "unanswered": false, "content": "Hi, everyone,\nI am posting this question for my friend.\nHe is analyzing his CHIP DNA solid deep sequence data, and find out that near 80% reads can not be mapped to the human genome. We are wondering if this high percentage unmapped reads is normal in CHIP DNA deep sequence or there may be something wrong with his result.", "comment_count": 0, "html": "<p>Hi, everyone,\nI am posting this question for my friend.\nHe is analyzing his CHIP DNA solid deep sequence data, and find out that near 80% reads can not be mapped to the human genome. We are wondering if this high percentage unmapped reads is normal in CHIP DNA deep sequence or there may be something wrong with his result.</p>", "child_count": 0, "closed": false, "tree_id": 7, "revision_count": 1, "parent": null, "views": 492, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:28", "slug": "chip-dna-deep-sequence", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [14, 40, 188], "lastedit_user": 11}}, {"pk": 14, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-06 20:10:32", "lft": 2, "post_type": 109787, "score": 1, "title": "A: CHIP DNA deep sequence", "unanswered": false, "content": "I recall that our first samples that we ran on the Solid sequencer have had bad performance. Not quite an 80% loss but around 40%-60% reads were unmappable (yeast). Some other lab members will hopefully chime in with more details. ", "comment_count": 0, "html": "<p>I recall that our first samples that we ran on the Solid sequencer have had bad performance. Not quite an 80% loss but around 40%-60% reads were unmappable (yeast). Some other lab members will hopefully chime in with more details. </p>", "child_count": 0, "closed": false, "tree_id": 7, "revision_count": 1, "parent": 13, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-chip-dna-deep-sequence", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 15, "model": "server.post", "fields": {"rght": 5, "author": 4, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-06 20:41:24", "lft": 4, "post_type": 109787, "score": 2, "title": "A: CHIP DNA deep sequence", "unanswered": false, "content": "Hi there,\n\nWe have done numbers of SOLiD sequencing run on yeast samples. Normally there are only 30-40 percent of total tags can be uniquely mapped back to yeast genome. \n\nWhat I would recommend is do it on solexa. You get much higher quality tags.\n\ncheers,", "comment_count": 0, "html": "<p>Hi there,</p>\n<p>We have done numbers of SOLiD sequencing run on yeast samples. Normally there are only 30-40 percent of total tags can be uniquely mapped back to yeast genome. </p>\n<p>What I would recommend is do it on solexa. You get much higher quality tags.</p>\n<p>cheers,</p>", "child_count": 0, "closed": false, "tree_id": 7, "revision_count": 1, "parent": 13, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-chip-dna-deep-sequence", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 4}}, {"pk": 16, "model": "server.post", "fields": {"rght": 7, "author": 12, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-06 22:04:41", "lft": 6, "post_type": 109787, "score": 3, "title": "A: CHIP DNA deep sequence", "unanswered": false, "content": "Your 20% mapping yield looks like low for normal ChIP experiment, even for human. Several factors can reduce this mapping yield. I am wondering which kind of ChIP was used in your case. That is, which kind of proteins was ChIPed?", "comment_count": 0, "html": "<p>Your 20% mapping yield looks like low for normal ChIP experiment, even for human. Several factors can reduce this mapping yield. I am wondering which kind of ChIP was used in your case. That is, which kind of proteins was ChIPed?</p>", "child_count": 0, "closed": false, "tree_id": 7, "revision_count": 1, "parent": 13, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-chip-dna-deep-sequence", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 12}}, {"pk": 17, "model": "server.post", "fields": {"rght": 3, "author": 9, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-07 16:41:44", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Site use guidelines", "unanswered": false, "content": "If you are shy about asking the question on your own behalf submit it to to the **Question Bot** and it will be posted anonymously. Send email to the `Question Bot` link at the bottom.", "comment_count": 0, "html": "<p>If you are shy about asking the question on your own behalf submit it to to the <strong>Question Bot</strong> and it will be posted anonymously. Send email to the <code>Question Bot</code> link at the bottom.</p>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 2, "parent": 1, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-site-use-guidelines", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 18, "model": "server.post", "fields": {"rght": 7, "author": 13, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-09 03:28:20", "lft": 4, "post_type": 109787, "score": 2, "title": "A: Site use guidelines", "unanswered": false, "content": "Hi,\n\nI don't think a new user can vote on a question or an answer.\nThe site says I need 15 reputation...", "comment_count": 1, "html": "<p>Hi,</p>\n<p>I don't think a new user can vote on a question or an answer.\nThe site says I need 15 reputation...</p>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 1, "parent": 1, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-site-use-guidelines", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 13}}, {"pk": 19, "model": "server.post", "fields": {"rght": 5, "author": 4, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-16 12:25:38", "lft": 4, "post_type": 109787, "score": 4, "title": "A: Recommend easy to use microarray clustering software", "unanswered": false, "content": "I would recommend a combination of cluster and treeview.\n\npretty powerful!", "comment_count": 0, "html": "<p>I would recommend a combination of cluster and treeview.</p>\n<p>pretty powerful!</p>", "child_count": 0, "closed": false, "tree_id": 4, "revision_count": 1, "parent": 5, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-recommend-easy-to-use-microarray-clustering-software", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 4}}, {"pk": 20, "model": "server.post", "fields": {"rght": 2, "author": 14, "answer_accepted": false, "tag_string": "boy george", "creation_date": "2009-10-18 03:22:53", "lft": 1, "post_type": 164033, "score": 0, "title": "do you have to be a guy to dress up as boy george", "unanswered": false, "content": "any ideas im a girl", "comment_count": 0, "html": "<p>any ideas im a girl</p>", "child_count": 0, "closed": false, "tree_id": 8, "revision_count": 2, "parent": null, "views": 1, "deleted": true, "answer_count": 0, "touch_date": "2011-11-24 14:48:57", "slug": "do-you-have-to-be-a-guy-to-dress-up-as-boy-george", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [16, 17], "lastedit_user": 14}}, {"pk": 21, "model": "server.post", "fields": {"rght": 2, "author": 14, "answer_accepted": false, "tag_string": "boy george", "creation_date": "2009-10-18 03:23:34", "lft": 1, "post_type": 164033, "score": 0, "title": "do you have to be a guy to dress up as boy george", "unanswered": false, "content": "any ideas im a girl", "comment_count": 0, "html": "<p>any ideas im a girl</p>", "child_count": 0, "closed": false, "tree_id": 9, "revision_count": 2, "parent": null, "views": 0, "deleted": true, "answer_count": 0, "touch_date": "2011-11-24 14:48:57", "slug": "do-you-have-to-be-a-guy-to-dress-up-as-boy-george", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [16, 17], "lastedit_user": 14}}, {"pk": 22, "model": "server.post", "fields": {"rght": 22, "author": 15, "answer_accepted": false, "tag_string": "geneid accession mapping conversion", "creation_date": "2009-10-23 17:42:24", "lft": 1, "post_type": 164033, "score": 12, "title": "Gene ID conversion tool", "unanswered": false, "content": "Hey,\n\nI was using DAVID (http://david.abcc.ncifcrf.gov/conversion.jsp) to do the gene ID conversion, e.g.conversion between Agilent ID, Genebank accession id and Entrez gene ID, but I found the DAVID database is not updated. Does anyone know a better updataed conversion tool to do this job? Thanks! ", "comment_count": 0, "html": "<p>Hey,</p>\n<p>I was using DAVID (http://david.abcc.ncifcrf.gov/conversion.jsp) to do the gene ID conversion, e.g.conversion between Agilent ID, Genebank accession id and Entrez gene ID, but I found the DAVID database is not updated. Does anyone know a better updataed conversion tool to do this job? Thanks! </p>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 2, "parent": null, "views": 10082, "deleted": false, "answer_count": 14, "touch_date": "2011-11-24 14:49:31", "slug": "gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [18, 19, 20, 21], "lastedit_user": 58}}, {"pk": 23, "model": "server.post", "fields": {"rght": 7, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-23 19:46:45", "lft": 2, "post_type": 109787, "score": 0, "title": "A: Gene ID conversion tool", "unanswered": false, "content": "I don't know of a direct solution myself, but this is a topic that may be of interest for the biological data analysis class that I am teaching. \n\nIf you specify the organism/genomic builds that you are interested in we may be able to generate a full translation list as an in class example or a homework. I was planning on covering an `Affymetrix ID` to `Genebank example` anyhow.\n", "comment_count": 2, "html": "<p>I don't know of a direct solution myself, but this is a topic that may be of interest for the biological data analysis class that I am teaching. </p>\n<p>If you specify the organism/genomic builds that you are interested in we may be able to generate a full translation list as an in class example or a homework. I was planning on covering an <code>Affymetrix ID</code> to <code>Genebank example</code> anyhow.</p>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 1, "parent": 22, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "a-gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 24, "model": "server.post", "fields": {"rght": 6, "author": 13, "answer_accepted": false, "tag_string": "shrimp sequencing short aligner", "creation_date": "2009-12-01 07:13:53", "lft": 1, "post_type": 164033, "score": 3, "title": "How to set SHRiMP parameters for best sensitivity with 35bp colorspace data?", "unanswered": false, "content": "Hi,\n\nI have 35bp Solid colorspace sequencing data, and the actual sequences to be mapped are 20-25bp after removing the linker sequence.\n\nI hope to find all the hits allowing no more than n mismatches (say n=3), not only the best hit.\n\nI know there is a -M option to specify -M sensitivity,35bp. I wonder whether this setting will guarantee the best sensitivity in this case. Since my reads are only 20-25bp long, should I changed the default 4 spaced seeds to 3?\n\nI'm new to SHRiMP, so I'd like to hear some suggestions on setting the parameters of SHRiMP to achieve the best sensitivity.\n\nThank you!", "comment_count": 0, "html": "<p>Hi,</p>\n<p>I have 35bp Solid colorspace sequencing data, and the actual sequences to be mapped are 20-25bp after removing the linker sequence.</p>\n<p>I hope to find all the hits allowing no more than n mismatches (say n=3), not only the best hit.</p>\n<p>I know there is a -M option to specify -M sensitivity,35bp. I wonder whether this setting will guarantee the best sensitivity in this case. Since my reads are only 20-25bp long, should I changed the default 4 spaced seeds to 3?</p>\n<p>I'm new to SHRiMP, so I'd like to hear some suggestions on setting the parameters of SHRiMP to achieve the best sensitivity.</p>\n<p>Thank you!</p>", "child_count": 0, "closed": false, "tree_id": 11, "revision_count": 1, "parent": null, "views": 180, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:28", "slug": "how-to-set-shrimp-parameters-for-best-sensitivity-with-35bp-colorspace-data", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [22, 23, 24, 25], "lastedit_user": 13}}, {"pk": 25, "model": "server.post", "fields": {"rght": 3, "author": 17, "answer_accepted": false, "tag_string": "", "creation_date": "2009-12-01 14:57:35", "lft": 2, "post_type": 109787, "score": 3, "title": "A: How to set SHRiMP parameters for best sensitivity with 35bp colorspace data?", "unanswered": false, "content": "I just read the SHRiMP manual again, but I think that their explanation about -M option may not be enough to answer your question. I usually use the \"seed\" mode by using -s, -n, and -w and the option -M is a new feature of the version 1.3.1, which I have never tried before.\n\nI recommend for you to use the \"seed\" mode--the default would be good, but please adjust the -s option if you want more sensitivity. Always fast speed compensates sensitivity and the -M option seems to exist for this purpose.\n\nHope my message to be helpful for your project.", "comment_count": 0, "html": "<p>I just read the SHRiMP manual again, but I think that their explanation about -M option may not be enough to answer your question. I usually use the \"seed\" mode by using -s, -n, and -w and the option -M is a new feature of the version 1.3.1, which I have never tried before.</p>\n<p>I recommend for you to use the \"seed\" mode--the default would be good, but please adjust the -s option if you want more sensitivity. Always fast speed compensates sensitivity and the -M option seems to exist for this purpose.</p>\n<p>Hope my message to be helpful for your project.</p>", "child_count": 0, "closed": false, "tree_id": 11, "revision_count": 1, "parent": 24, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-set-shrimp-parameters-for-best-sensitivity-with-35bp-colorspace-data", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 17}}, {"pk": 26, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2009-12-01 18:00:53", "lft": 4, "post_type": 109787, "score": 2, "title": "A: How to set SHRiMP parameters for best sensitivity with 35bp colorspace data?", "unanswered": false, "content": "> Since my reads are only 20-25bp long,\n> should I changed the default 4 spaced\n> seeds to 3?\n\nwhile the shrimp manual says:\n\n- We recommend using the default 4 seeds of weight 12 in most cases.\n\nyou could try running on a smaller sample and see what happens. ", "comment_count": 0, "html": "<blockquote>\n<p>Since my reads are only 20-25bp long,\nshould I changed the default 4 spaced\nseeds to 3?</p>\n</blockquote>\n<p>while the shrimp manual says:</p>\n<ul>\n<li>We recommend using the default 4 seeds of weight 12 in most cases.</li>\n</ul>\n<p>you could try running on a smaller sample and see what happens. </p>", "child_count": 0, "closed": false, "tree_id": 11, "revision_count": 1, "parent": 24, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-set-shrimp-parameters-for-best-sensitivity-with-35bp-colorspace-data", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 27, "model": "server.post", "fields": {"rght": 5, "author": 18, "answer_accepted": false, "tag_string": "", "creation_date": "2009-12-08 21:45:54", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Gene ID conversion tool", "unanswered": false, "content": "The following link has a list of ID conversion tools:\n\nhttp://hum-molgen.org/NewsGen/08-2009/000020.html", "comment_count": 0, "html": "<p>The following link has a list of ID conversion tools:</p>\n<p>http://hum-molgen.org/NewsGen/08-2009/000020.html</p>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 1, "parent": 22, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 18}}, {"pk": 28, "model": "server.post", "fields": {"rght": 4, "author": 19, "answer_accepted": true, "tag_string": "meme sge motif compilation parallel", "creation_date": "2010-01-13 12:59:22", "lft": 1, "post_type": 164033, "score": 4, "title": "Tips on compiling and using MEME 4.3 with a Sun Grid Engine computation cluster", "unanswered": false, "content": "Has anyone compiled and used MEME 4.x for use in a parallel computation environment, based upon operation with a Sun Grid Engine (SGE) cluster?\n\nI can compile the suite and its tests pass. However, when I attempt to use the `-p n` option, to specify `n` computation nodes, I get several error messages:\n\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    1: Command not found.\n\nWe do not have `/gridware/codine/util/arch`, but we do have `/gridengine/sgi/util/arch`.\n\nI tried looking around MEME's source code, particularly at `meme.c` and `mp.h`, but there are no references to these paths.\n\nI'm wondering if I am missing makefile directives. Here is my `./configure` statement:\n\n    ./configure --prefix=/home/areynolds/proj/meme/meme_4.3.0_build --with-url=\"http://meme.nbcr.net/meme\" --enable-openmp --enable-debug\n\nIs MPI a requirement; are there directives I am missing for MPI?\n\nThank you for any advice.\n\n**EDIT**\n\nI was able to successfully build a version of MEME 4.3 that supports OpenMPI.\n\nFirst, I worked with our sys admin to install [OpenMPI 1.4][1] on each of the SGE nodes ([compilation options][2]) and set up an [SGE parallel environment][3] called `mpi_test`:\n\n    $ qconf -sp mpi_test\n    pe_name           mpi_test\n    slots             120 \n    user_lists        NONE\n    xuser_lists       NONE\n    start_proc_args   /bin/true\n    stop_proc_args    /bin/true     \n    allocation_rule   $fill_up\n    control_slaves    TRUE\n    job_is_first_task FALSE \n    urgency_slots     min\n\nSecondly, I used the following build options for MEME:\n\n    $ ./configure --prefix=/home/areynolds/proj/meme/meme_4.3.0_build \\ \n    --with-url=\"http://meme.nbcr.net/meme\" \\\n    --enable-openmp \\\n    --enable-debug \\\n    --with-mpicc=/opt/openmpi-1.4/bin/mpicc \\\n    --enable-opt\n\nThirdly, the `mpirun` and `meme_p` binaries depend upon shared libraries in the OpenMPI installation. It is necessary to add `/opt/openmpi-1.4/lib` to your local `LD_LIBRARY_PATH` environment variable before running `qsub`.\n\nFinally, I set up a script (called `runall.cluster`) along the following lines. Runtime options can be adjusted to taste:\n\n    #!/bin/bash\n\n    #\n    # runall.cluster\n    #\n\n    #$ -N memeCluster64\n    #$ -S /bin/bash\n    #$ -pe mpi_test 64\n    #$ -v -np=64\n    #$ -cwd\n    #$ -o \"memeCluster64.out\"\n    #$ -e \"memeCluster64.err\"\n    #$ -notify\n    #$ -V\n\n    time /opt/openmpi-1.4/bin/mpirun -np 64 \\\n       /home/areynolds/proj/meme/meme/bin/meme_p \\\n       /home/areynolds/proj/meme/data/K562.DS9767.fps.not.in.promoters.fa.top10k.fa \\\n       -oc /home/areynolds/proj/meme/output/K562.DS9767.fps.not.in.promoters.10k.cluster.64 \\\n       -maxsize 230000 \\\n       -dna \\\n       -minw 8 -maxw 12 -allw \\\n       -p 64\n\nThis script is executed directly with `qsub` and runs the parallelized MEME binary `meme_p` with the specified options. In this case, it will run on 64 nodes of our computation cluster:\n\n    qsub ./runall.cluster\n\nHopefully this information will help out others.\n\n\n  [1]: http://www.open-mpi.org/\n  [2]: http://www.open-mpi.org/faq/?category=running#run-n1ge-or-sge\n  [3]: http://wikis.sun.com/display/GridEngine/Managing+Parallel+Environments#ManagingParallelEnvironments-AboutParallelEnvironments", "comment_count": 0, "html": "<p>Has anyone compiled and used MEME 4.x for use in a parallel computation environment, based upon operation with a Sun Grid Engine (SGE) cluster?</p>\n<p>I can compile the suite and its tests pass. However, when I attempt to use the <code>-p n</code> option, to specify <code>n</code> computation nodes, I get several error messages:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"sr\">/gridware/co</span><span class=\"n\">dine</span><span class=\"sr\">/util/</span><span class=\"n\">arch:</span> <span class=\"n\">Command</span> <span class=\"ow\">not</span> <span class=\"n\">found</span><span class=\"o\">.</span>\n    <span class=\"sr\">/gridware/co</span><span class=\"n\">dine</span><span class=\"sr\">/util/</span><span class=\"n\">arch:</span> <span class=\"n\">Command</span> <span class=\"ow\">not</span> <span class=\"n\">found</span><span class=\"o\">.</span>\n    <span class=\"sr\">/gridware/co</span><span class=\"n\">dine</span><span class=\"sr\">/util/</span><span class=\"n\">arch:</span> <span class=\"n\">Command</span> <span class=\"ow\">not</span> <span class=\"n\">found</span><span class=\"o\">.</span>\n    <span class=\"sr\">/gridware/co</span><span class=\"n\">dine</span><span class=\"sr\">/util/</span><span class=\"n\">arch:</span> <span class=\"n\">Command</span> <span class=\"ow\">not</span> <span class=\"n\">found</span><span class=\"o\">.</span>\n    <span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"n\">Command</span> <span class=\"ow\">not</span> <span class=\"n\">found</span><span class=\"o\">.</span>\n</pre></div>\n</p>\n<p>We do not have <code>/gridware/codine/util/arch</code>, but we do have <code>/gridengine/sgi/util/arch</code>.</p>\n<p>I tried looking around MEME's source code, particularly at <code>meme.c</code> and <code>mp.h</code>, but there are no references to these paths.</p>\n<p>I'm wondering if I am missing makefile directives. Here is my <code>./configure</code> statement:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"o\">.</span><span class=\"sr\">/configure --prefix=/</span><span class=\"n\">home</span><span class=\"sr\">/areynolds/</span><span class=\"n\">proj</span><span class=\"sr\">/meme/m</span><span class=\"n\">eme_4</span><span class=\"mf\">.3.0_</span><span class=\"n\">build</span> <span class=\"o\">--</span><span class=\"n\">with</span><span class=\"o\">-</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s\">&quot;http://meme.nbcr.net/meme&quot;</span> <span class=\"o\">--</span><span class=\"n\">enable</span><span class=\"o\">-</span><span class=\"n\">openmp</span> <span class=\"o\">--</span><span class=\"n\">enable</span><span class=\"o\">-</span><span class=\"n\">debug</span>\n</pre></div>\n</p>\n<p>Is MPI a requirement; are there directives I am missing for MPI?</p>\n<p>Thank you for any advice.</p>\n<p><strong>EDIT</strong></p>\n<p>I was able to successfully build a version of MEME 4.3 that supports OpenMPI.</p>\n<p>First, I worked with our sys admin to install <a href=\"http://www.open-mpi.org/\">OpenMPI 1.4</a> on each of the SGE nodes (<a href=\"http://www.open-mpi.org/faq/?category=running#run-n1ge-or-sge\">compilation options</a>) and set up an <a href=\"http://wikis.sun.com/display/GridEngine/Managing+Parallel+Environments#ManagingParallelEnvironments-AboutParallelEnvironments\">SGE parallel environment</a> called <code>mpi_test</code>:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"nv\">$</span> <span class=\"nv\">qconf</span> <span class=\"o\">-</span><span class=\"n\">sp</span> <span class=\"n\">mpi_test</span>\n    <span class=\"n\">pe_name</span>           <span class=\"n\">mpi_test</span>\n    <span class=\"n\">slots</span>             <span class=\"mi\">120</span> \n    <span class=\"n\">user_lists</span>        <span class=\"n\">NONE</span>\n    <span class=\"n\">xuser_lists</span>       <span class=\"n\">NONE</span>\n    <span class=\"n\">start_proc_args</span>   <span class=\"sr\">/bin/</span><span class=\"n\">true</span>\n    <span class=\"n\">stop_proc_args</span>    <span class=\"sr\">/bin/</span><span class=\"n\">true</span>     \n    <span class=\"n\">allocation_rule</span>   <span class=\"nv\">$fill_up</span>\n    <span class=\"n\">control_slaves</span>    <span class=\"n\">TRUE</span>\n    <span class=\"n\">job_is_first_task</span> <span class=\"n\">FALSE</span> \n    <span class=\"n\">urgency_slots</span>     <span class=\"n\">min</span>\n</pre></div>\n</p>\n<p>Secondly, I used the following build options for MEME:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"nv\">$</span> <span class=\"err\">./</span><span class=\"nv\">configure</span> <span class=\"o\">--</span><span class=\"n\">prefix</span><span class=\"o\">=</span><span class=\"sr\">/home/</span><span class=\"n\">areynolds</span><span class=\"sr\">/proj/m</span><span class=\"n\">eme</span><span class=\"o\">/</span><span class=\"n\">meme_4</span><span class=\"mf\">.3.0_</span><span class=\"n\">build</span> <span class=\"o\">\\</span> \n    <span class=\"o\">--</span><span class=\"n\">with</span><span class=\"o\">-</span><span class=\"n\">url</span><span class=\"o\">=</span><span class=\"s\">&quot;http://meme.nbcr.net/meme&quot;</span> <span class=\"o\">\\</span>\n    <span class=\"o\">--</span><span class=\"n\">enable</span><span class=\"o\">-</span><span class=\"n\">openmp</span> <span class=\"o\">\\</span>\n    <span class=\"o\">--</span><span class=\"n\">enable</span><span class=\"o\">-</span><span class=\"n\">debug</span> <span class=\"o\">\\</span>\n    <span class=\"o\">--</span><span class=\"n\">with</span><span class=\"o\">-</span><span class=\"n\">mpicc</span><span class=\"o\">=</span><span class=\"sr\">/opt/o</span><span class=\"n\">penmpi</span><span class=\"o\">-</span><span class=\"mf\">1.4</span><span class=\"sr\">/bin/m</span><span class=\"n\">picc</span> <span class=\"o\">\\</span>\n    <span class=\"o\">--</span><span class=\"n\">enable</span><span class=\"o\">-</span><span class=\"n\">opt</span>\n</pre></div>\n</p>\n<p>Thirdly, the <code>mpirun</code> and <code>meme_p</code> binaries depend upon shared libraries in the OpenMPI installation. It is necessary to add <code>/opt/openmpi-1.4/lib</code> to your local <code>LD_LIBRARY_PATH</code> environment variable before running <code>qsub</code>.</p>\n<p>Finally, I set up a script (called <code>runall.cluster</code>) along the following lines. Runtime options can be adjusted to taste:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"c1\">#!/bin/bash</span>\n\n    <span class=\"c1\">#</span>\n    <span class=\"c1\"># runall.cluster</span>\n    <span class=\"c1\">#</span>\n\n    <span class=\"c1\">#$ -N memeCluster64</span>\n    <span class=\"c1\">#$ -S /bin/bash</span>\n    <span class=\"c1\">#$ -pe mpi_test 64</span>\n    <span class=\"c1\">#$ -v -np=64</span>\n    <span class=\"c1\">#$ -cwd</span>\n    <span class=\"c1\">#$ -o &quot;memeCluster64.out&quot;</span>\n    <span class=\"c1\">#$ -e &quot;memeCluster64.err&quot;</span>\n    <span class=\"c1\">#$ -notify</span>\n    <span class=\"c1\">#$ -V</span>\n\n    <span class=\"nb\">time</span> <span class=\"sr\">/opt/o</span><span class=\"n\">penmpi</span><span class=\"o\">-</span><span class=\"mf\">1.4</span><span class=\"sr\">/bin/m</span><span class=\"n\">pirun</span> <span class=\"o\">-</span><span class=\"n\">np</span> <span class=\"mi\">64</span> <span class=\"o\">\\</span>\n       <span class=\"sr\">/home/</span><span class=\"n\">areynolds</span><span class=\"sr\">/proj/m</span><span class=\"n\">eme</span><span class=\"sr\">/meme/</span><span class=\"n\">bin</span><span class=\"o\">/</span><span class=\"n\">meme_p</span> <span class=\"o\">\\</span>\n       <span class=\"sr\">/home/</span><span class=\"n\">areynolds</span><span class=\"sr\">/proj/m</span><span class=\"n\">eme</span><span class=\"sr\">/data/</span><span class=\"n\">K562</span><span class=\"o\">.</span><span class=\"n\">DS9767</span><span class=\"o\">.</span><span class=\"n\">fps</span><span class=\"o\">.</span><span class=\"ow\">not</span><span class=\"o\">.</span><span class=\"n\">in</span><span class=\"o\">.</span><span class=\"n\">promoters</span><span class=\"o\">.</span><span class=\"n\">fa</span><span class=\"o\">.</span><span class=\"n\">top10k</span><span class=\"o\">.</span><span class=\"n\">fa</span> <span class=\"o\">\\</span>\n       <span class=\"o\">-</span><span class=\"n\">oc</span> <span class=\"sr\">/home/</span><span class=\"n\">areynolds</span><span class=\"sr\">/proj/m</span><span class=\"n\">eme</span><span class=\"sr\">/output/</span><span class=\"n\">K562</span><span class=\"o\">.</span><span class=\"n\">DS9767</span><span class=\"o\">.</span><span class=\"n\">fps</span><span class=\"o\">.</span><span class=\"ow\">not</span><span class=\"o\">.</span><span class=\"n\">in</span><span class=\"o\">.</span><span class=\"n\">promoters</span><span class=\"mf\">.10</span><span class=\"n\">k</span><span class=\"o\">.</span><span class=\"n\">cluster</span><span class=\"mf\">.64</span> <span class=\"o\">\\</span>\n       <span class=\"o\">-</span><span class=\"n\">maxsize</span> <span class=\"mi\">230000</span> <span class=\"o\">\\</span>\n       <span class=\"o\">-</span><span class=\"n\">dna</span> <span class=\"o\">\\</span>\n       <span class=\"o\">-</span><span class=\"n\">minw</span> <span class=\"mi\">8</span> <span class=\"o\">-</span><span class=\"n\">maxw</span> <span class=\"mi\">12</span> <span class=\"o\">-</span><span class=\"n\">allw</span> <span class=\"o\">\\</span>\n       <span class=\"o\">-</span><span class=\"n\">p</span> <span class=\"mi\">64</span>\n</pre></div>\n</p>\n<p>This script is executed directly with <code>qsub</code> and runs the parallelized MEME binary <code>meme_p</code> with the specified options. In this case, it will run on 64 nodes of our computation cluster:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">qsub</span> <span class=\"o\">./</span><span class=\"n\">runall</span><span class=\"o\">.</span><span class=\"n\">cluster</span>\n</pre></div>\n</p>\n<p>Hopefully this information will help out others.</p>", "child_count": 0, "closed": false, "tree_id": 12, "revision_count": 3, "parent": null, "views": 568, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:31", "slug": "tips-on-compiling-and-using-meme-43-with-a-sun-grid-engine-computation-cluster", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [6, 26, 27, 28, 29], "lastedit_user": 263}}, {"pk": 29, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-13 21:17:50", "lft": 2, "post_type": 109787, "score": 1, "title": "A: Tips on compiling and using MEME 4.3 with a Sun Grid Engine computation cluster", "unanswered": false, "content": "This may not be overly useful but it very much sounds like a configuration problem.\n\nUsually there is  configure flag that needs to be set to point to the libraries, something like:\n\n    --with-mpidir=MPIDIR\n    --with-mpicc=MPICC\n\nIt also appears that the MEME suite does not support Open MPI (as per [install notes][1]).\n\nI would also recommend posting on the MEME user forum:\n\n[https://www.nbcr.net/forum/viewforum.php?f=5][2]\n\n\n  [1]: http://meme.sdsc.edu/meme4/meme-install.html\n  [2]: https://www.nbcr.net/forum/viewforum.php?f=5", "comment_count": 0, "html": "<p>This may not be overly useful but it very much sounds like a configuration problem.</p>\n<p>Usually there is  configure flag that needs to be set to point to the libraries, something like:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"o\">--</span><span class=\"n\">with</span><span class=\"o\">-</span><span class=\"n\">mpidir</span><span class=\"o\">=</span><span class=\"n\">MPIDIR</span>\n    <span class=\"o\">--</span><span class=\"n\">with</span><span class=\"o\">-</span><span class=\"n\">mpicc</span><span class=\"o\">=</span><span class=\"n\">MPICC</span>\n</pre></div>\n</p>\n<p>It also appears that the MEME suite does not support Open MPI (as per <a href=\"http://meme.sdsc.edu/meme4/meme-install.html\">install notes</a>).</p>\n<p>I would also recommend posting on the MEME user forum:</p>\n<p><a href=\"https://www.nbcr.net/forum/viewforum.php?f=5\">https://www.nbcr.net/forum/viewforum.php?f=5</a></p>", "child_count": 0, "closed": false, "tree_id": 12, "revision_count": 1, "parent": 28, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-tips-on-compiling-and-using-meme-43-with-a-sun-grid-engine-computation-cluster", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 1}}, {"pk": 30, "model": "server.post", "fields": {"rght": 9, "author": 19, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-15 08:48:14", "lft": 4, "post_type": 109787, "score": 3, "title": "A: How do I convert from BED format to GFF format?", "unanswered": false, "content": "Here's a Perl script I wrote if you wanted to do something local. \n\nThere's some code in there for translating yeast chromosome names that can be removed, if not needed. I also used a `Site` feature in the GFF file as the region ID, which might also need tweaking, depending on what features you're interested in.\n\n    #!/usr/bin/perl -w\n\n    use strict;\n    use Bio::Tools::GFF;\n    use feature qw(say switch);\n\n    my $gffio = Bio::Tools::GFF->new(-fh => \\*STDIN, -gff_version => 2);\n    my $feature;\n\n    while ($feature = $gffio->next_feature()) {\n        # print $gffio->gff_string($feature).\"\\n\";\n\n        # cf. http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml\n        my $seq_id = $feature->seq_id();   \n        my $start = $feature->start() - 1;\n        my $end = $feature->end();\n        my $strand = $feature->strand();\n        my @sites = $feature->get_tag_values('Site');\n\n        # translate strand\n        given ( $strand ) {\n            when ($_ == 1)  { $strand = \"+\"; }\n            when ($_ == -1) { $strand = \"-\"; }\n        }\n    \n        # translate yeast chromosome to UCSC browser-readable chromosome\n        # cf. http://www.yeastgenome.org/sgdpub/Saccharomyces_cerevisiae.pdf\n        given ( $seq_id ) {\n            when ( $_ eq \"I\" )    { $seq_id = \"chr1\"; }\n            when ( $_ eq \"II\" )   { $seq_id = \"chr2\"; }\n            when ( $_ eq \"III\" )  { $seq_id = \"chr3\"; }\n            when ( $_ eq \"IV\" )   { $seq_id = \"chr4\"; }\n            when ( $_ eq \"V\" )    { $seq_id = \"chr5\"; }\n            when ( $_ eq \"VI\" )   { $seq_id = \"chr6\"; }\n            when ( $_ eq \"VII\" )  { $seq_id = \"chr7\"; }\n            when ( $_ eq \"VIII\" ) { $seq_id = \"chr8\"; }\n            when ( $_ eq \"IX\" )   { $seq_id = \"chr9\"; }\n            when ( $_ eq \"X\" )    { $seq_id = \"chr10\"; }\n            when ( $_ eq \"XI\" )   { $seq_id = \"chr11\"; }\n            when ( $_ eq \"XII\" )  { $seq_id = \"chr12\"; }\n            when ( $_ eq \"XIII\" ) { $seq_id = \"chr13\"; }\n            when ( $_ eq \"XIV\" )  { $seq_id = \"chr14\"; }\n            when ( $_ eq \"XV\" )   { $seq_id = \"chr15\"; }\n            when ( $_ eq \"XVI\" )  { $seq_id = \"chr16\"; }\n            default { }\n        }\n\n        # output\n        print \"$seq_id\\t$start\\t$end\\t$sites[0]\\t0.0\\t$strand\\n\";\n    }\n    $gffio->close();\n\nTo use it:\n\n    gff2bed.pl < data.gff > data.bed", "comment_count": 2, "html": "<p>Here's a Perl script I wrote if you wanted to do something local. </p>\n<p>There's some code in there for translating yeast chromosome names that can be removed, if not needed. I also used a <code>Site</code> feature in the GFF file as the region ID, which might also need tweaking, depending on what features you're interested in.</p>\n<p><div class=\"highlight\"><pre>    <span class=\"c1\">#!/usr/bin/perl -w</span>\n\n    <span class=\"k\">use</span> <span class=\"n\">strict</span><span class=\"p\">;</span>\n    <span class=\"k\">use</span> <span class=\"nn\">Bio::Tools::</span><span class=\"n\">GFF</span><span class=\"p\">;</span>\n    <span class=\"k\">use</span> <span class=\"n\">feature</span> <span class=\"sx\">qw(say switch)</span><span class=\"p\">;</span>\n\n    <span class=\"k\">my</span> <span class=\"nv\">$gffio</span> <span class=\"o\">=</span> <span class=\"nn\">Bio::Tools::</span><span class=\"n\">GFF</span><span class=\"o\">-&gt;</span><span class=\"k\">new</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"n\">fh</span> <span class=\"o\">=&gt;</span> <span class=\"o\">\\*</span><span class=\"bp\">STDIN</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"n\">gff_version</span> <span class=\"o\">=&gt;</span> <span class=\"mi\">2</span><span class=\"p\">);</span>\n    <span class=\"k\">my</span> <span class=\"nv\">$feature</span><span class=\"p\">;</span>\n\n    <span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"nv\">$feature</span> <span class=\"o\">=</span> <span class=\"nv\">$gffio</span><span class=\"o\">-&gt;</span><span class=\"n\">next_feature</span><span class=\"p\">())</span> <span class=\"p\">{</span>\n        <span class=\"c1\"># print $gffio-&gt;gff_string($feature).&quot;\\n&quot;;</span>\n\n        <span class=\"c1\"># cf. http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml</span>\n        <span class=\"k\">my</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"nv\">$feature</span><span class=\"o\">-&gt;</span><span class=\"n\">seq_id</span><span class=\"p\">();</span>   \n        <span class=\"k\">my</span> <span class=\"nv\">$start</span> <span class=\"o\">=</span> <span class=\"nv\">$feature</span><span class=\"o\">-&gt;</span><span class=\"n\">start</span><span class=\"p\">()</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">;</span>\n        <span class=\"k\">my</span> <span class=\"nv\">$end</span> <span class=\"o\">=</span> <span class=\"nv\">$feature</span><span class=\"o\">-&gt;</span><span class=\"n\">end</span><span class=\"p\">();</span>\n        <span class=\"k\">my</span> <span class=\"nv\">$strand</span> <span class=\"o\">=</span> <span class=\"nv\">$feature</span><span class=\"o\">-&gt;</span><span class=\"n\">strand</span><span class=\"p\">();</span>\n        <span class=\"k\">my</span> <span class=\"nv\">@sites</span> <span class=\"o\">=</span> <span class=\"nv\">$feature</span><span class=\"o\">-&gt;</span><span class=\"n\">get_tag_values</span><span class=\"p\">(</span><span class=\"s\">&#39;Site&#39;</span><span class=\"p\">);</span>\n\n        <span class=\"c1\"># translate strand</span>\n        <span class=\"n\">given</span> <span class=\"p\">(</span> <span class=\"nv\">$strand</span> <span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span><span class=\"nv\">$_</span> <span class=\"o\">==</span> <span class=\"mi\">1</span><span class=\"p\">)</span>  <span class=\"p\">{</span> <span class=\"nv\">$strand</span> <span class=\"o\">=</span> <span class=\"s\">&quot;+&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span><span class=\"nv\">$_</span> <span class=\"o\">==</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"nv\">$strand</span> <span class=\"o\">=</span> <span class=\"s\">&quot;-&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n    \n        <span class=\"c1\"># translate yeast chromosome to UCSC browser-readable chromosome</span>\n        <span class=\"c1\"># cf. http://www.yeastgenome.org/sgdpub/Saccharomyces_cerevisiae.pdf</span>\n        <span class=\"n\">given</span> <span class=\"p\">(</span> <span class=\"nv\">$seq_id</span> <span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;I&quot;</span> <span class=\"p\">)</span>    <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr1&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;II&quot;</span> <span class=\"p\">)</span>   <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr2&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;III&quot;</span> <span class=\"p\">)</span>  <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr3&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;IV&quot;</span> <span class=\"p\">)</span>   <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr4&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;V&quot;</span> <span class=\"p\">)</span>    <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr5&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;VI&quot;</span> <span class=\"p\">)</span>   <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr6&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;VII&quot;</span> <span class=\"p\">)</span>  <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr7&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;VIII&quot;</span> <span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr8&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;IX&quot;</span> <span class=\"p\">)</span>   <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr9&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;X&quot;</span> <span class=\"p\">)</span>    <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr10&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;XI&quot;</span> <span class=\"p\">)</span>   <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr11&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;XII&quot;</span> <span class=\"p\">)</span>  <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr12&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;XIII&quot;</span> <span class=\"p\">)</span> <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr13&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;XIV&quot;</span> <span class=\"p\">)</span>  <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr14&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;XV&quot;</span> <span class=\"p\">)</span>   <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr15&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">when</span> <span class=\"p\">(</span> <span class=\"nv\">$_</span> <span class=\"ow\">eq</span> <span class=\"s\">&quot;XVI&quot;</span> <span class=\"p\">)</span>  <span class=\"p\">{</span> <span class=\"nv\">$seq_id</span> <span class=\"o\">=</span> <span class=\"s\">&quot;chr16&quot;</span><span class=\"p\">;</span> <span class=\"p\">}</span>\n            <span class=\"n\">default</span> <span class=\"p\">{</span> <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"c1\"># output</span>\n        <span class=\"k\">print</span> <span class=\"s\">&quot;$seq_id\\t$start\\t$end\\t$sites[0]\\t0.0\\t$strand\\n&quot;</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n    <span class=\"nv\">$gffio</span><span class=\"o\">-&gt;</span><span class=\"nb\">close</span><span class=\"p\">();</span>\n</pre></div>\n</p>\n<p>To use it:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">gff2bed</span><span class=\"o\">.</span><span class=\"n\">pl</span> <span class=\"o\">&lt;</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">gff</span> <span class=\"o\">&gt;</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">bed</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 2, "revision_count": 1, "parent": 2, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-do-i-convert-from-bed-format-to-gff-format", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 19}}, {"pk": 31, "model": "server.post", "fields": {"rght": 16, "author": 3, "answer_accepted": true, "tag_string": "solid rna galaxy", "creation_date": "2010-01-22 03:14:17", "lft": 1, "post_type": 164033, "score": 4, "title": "How do I map, align, and plot my SOLiD results?", "unanswered": false, "content": "Hi, I recently performed an RNA immunoprecipitation followed by SOLiD sequencing (50 bp fragmented reads). I haven't received my first SOLiD sequencing results yet, but I was told I should have them soon. I've tried doing my own research on how to map, align, and plot my results but I don't have a concrete workflow as to how I will analyze my results yet. I have very little experience doing any programming and would prefer to use galaxy. There are labs on my campus I can go to to get my color space data mapped, but I would like to do things myself. Is there a way on galaxy (or another program) to convert my color space data to sequence, then map those reads to the yeast transcriptome and analyze it? Even if you can't answer my question directly I'd appreciate any tips from anyone who has worked with RNA-seq data already.    \n\nThanks in advance ", "comment_count": 0, "html": "<p>Hi, I recently performed an RNA immunoprecipitation followed by SOLiD sequencing (50 bp fragmented reads). I haven't received my first SOLiD sequencing results yet, but I was told I should have them soon. I've tried doing my own research on how to map, align, and plot my results but I don't have a concrete workflow as to how I will analyze my results yet. I have very little experience doing any programming and would prefer to use galaxy. There are labs on my campus I can go to to get my color space data mapped, but I would like to do things myself. Is there a way on galaxy (or another program) to convert my color space data to sequence, then map those reads to the yeast transcriptome and analyze it? Even if you can't answer my question directly I'd appreciate any tips from anyone who has worked with RNA-seq data already.  <br />\n</p>\n<p>Thanks in advance </p>", "child_count": 0, "closed": false, "tree_id": 13, "revision_count": 1, "parent": null, "views": 1118, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:54:27", "slug": "how-do-i-map-align-and-plot-my-solid-results", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [4, 14, 30], "lastedit_user": 3}}, {"pk": 32, "model": "server.post", "fields": {"rght": 7, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-22 15:13:42", "lft": 2, "post_type": 109787, "score": 2, "title": "A: How do I map, align, and plot my SOLiD results?", "unanswered": false, "content": "Personally I would advise that if you know someone who can partially perform the task you should have them do it, and ask them to explain and show it to you how they've done it.\n\nThe task at hand is complex. The solution always depends immensely on the particulars of the problem, moreover you will be facing myriads of frustrating limitations, errors and problems.\n\nLearning directly from someone who has done it, establishing a personal rapport with them will allow you to ease into this problem domain. In fact when you are finished mapping your RNA - your are still likely to be far from being done - yet you might have expanded a lot of energy and excitement. \n\n\n", "comment_count": 2, "html": "<p>Personally I would advise that if you know someone who can partially perform the task you should have them do it, and ask them to explain and show it to you how they've done it.</p>\n<p>The task at hand is complex. The solution always depends immensely on the particulars of the problem, moreover you will be facing myriads of frustrating limitations, errors and problems.</p>\n<p>Learning directly from someone who has done it, establishing a personal rapport with them will allow you to ease into this problem domain. In fact when you are finished mapping your RNA - your are still likely to be far from being done - yet you might have expanded a lot of energy and excitement. </p>", "child_count": 0, "closed": false, "tree_id": 13, "revision_count": 1, "parent": 31, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-do-i-map-align-and-plot-my-solid-results", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 1}}, {"pk": 33, "model": "server.post", "fields": {"rght": 32, "author": 22, "answer_accepted": false, "tag_string": "general subjective os", "creation_date": "2010-01-26 15:14:38", "lft": 1, "post_type": 164033, "score": 2, "title": "Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "So, you will probably hate me for asking this question here, as there are lot of forum and blog posts on internet about it and it is also a very subjective question.\n\nHowever, it may be a starting point for a good discussion, if we don't flame... Which operating system do you usually use for your work? Did you install it by yourself, and do you have administrative rights on it, or is there any IT administrator in your lab? ", "comment_count": 0, "html": "<p>So, you will probably hate me for asking this question here, as there are lot of forum and blog posts on internet about it and it is also a very subjective question.</p>\n<p>However, it may be a starting point for a good discussion, if we don't flame... Which operating system do you usually use for your work? Did you install it by yourself, and do you have administrative rights on it, or is there any IT administrator in your lab? </p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 2, "parent": null, "views": 1248, "deleted": false, "answer_count": 18, "touch_date": "2011-11-24 14:49:18", "slug": "which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [31, 32, 194], "lastedit_user": 22}}, {"pk": 34, "model": "server.post", "fields": {"rght": 30, "author": 22, "answer_accepted": true, "tag_string": "subjective programming languages", "creation_date": "2010-01-26 15:45:06", "lft": 1, "post_type": 164033, "score": 4, "title": "Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "This is a very classic question: Which is your favorite programming language in bioinformatics? Which languages would you recommend to a student wishing to enter the world of bioinformatics?\n\nThis topic has already been discussed on the Internet, but I think it would be nice to discuss it here. Here there are some links to previous polls and discussions:\n\n - [Bioinformatics.org poll][1]\n - [Bioinformatics Career survey 2008 by Michael Barton][2]\n\n\n  [1]: http://www.bioinformatics.org/poll/index.php?dispid=17\n  [2]: http://openwetware.org/wiki/Biogang:Projects/Bioinformatics_Career_Survey_2008", "comment_count": 0, "html": "<p>This is a very classic question: Which is your favorite programming language in bioinformatics? Which languages would you recommend to a student wishing to enter the world of bioinformatics?</p>\n<p>This topic has already been discussed on the Internet, but I think it would be nice to discuss it here. Here there are some links to previous polls and discussions:</p>\n<ul>\n<li><a href=\"http://www.bioinformatics.org/poll/index.php?dispid=17\">Bioinformatics.org poll</a></li>\n<li><a href=\"\">Bioinformatics Career survey 2008 by Michael Barton</a></li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 5, "parent": null, "views": 3240, "deleted": false, "answer_count": 26, "touch_date": "2011-11-24 14:49:31", "slug": "which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [32, 34, 35], "lastedit_user": 22}}, {"pk": 35, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-26 20:23:45", "lft": 2, "post_type": 109787, "score": 1, "title": "A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "Often people are limited to their choices by factors outside of their control. One lab that I work with requires the use of Mac computers another is using Windows mostly. Large scale computations seem to be best suited for Linux systems.\n\nLuckily there is a migration towards unified capabilities across all platforms. Installing Cygwin on Windows allows us to tap into the power of Unix, while Linux distros have advanced graphical user interfaces like Windows and Macs.\n\nFrom my own observations of non technical people, the installation of new and interdependent software packages seems to be the most difficult on Mac computers and easiest on Windows due to the computational architecture that makes all Windows computers identical. \n", "comment_count": 1, "html": "<p>Often people are limited to their choices by factors outside of their control. One lab that I work with requires the use of Mac computers another is using Windows mostly. Large scale computations seem to be best suited for Linux systems.</p>\n<p>Luckily there is a migration towards unified capabilities across all platforms. Installing Cygwin on Windows allows us to tap into the power of Unix, while Linux distros have advanced graphical user interfaces like Windows and Macs.</p>\n<p>From my own observations of non technical people, the installation of new and interdependent software packages seems to be the most difficult on Mac computers and easiest on Windows due to the computational architecture that makes all Windows computers identical. </p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 1, "parent": 33, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:15", "slug": "a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 36, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-26 20:32:29", "lft": 2, "post_type": 109787, "score": 4, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "It is important to be considerate and not characterize one particular approach negatively. My favorite quote is:\n\n**Programming is pure thought.**\n\nHopefully everyone is able to pick an approach that matches their individual way of thinking. While I myself do not program in Perl, I consider it to be one of the most popular and powerful platforms for doing bioinformatics analysis. ", "comment_count": 0, "html": "<p>It is important to be considerate and not characterize one particular approach negatively. My favorite quote is:</p>\n<p><strong>Programming is pure thought.</strong></p>\n<p>Hopefully everyone is able to pick an approach that matches their individual way of thinking. While I myself do not program in Perl, I consider it to be one of the most popular and powerful platforms for doing bioinformatics analysis. </p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 37, "model": "server.post", "fields": {"rght": 11, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-26 20:38:24", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "Tips for installing software om Max OS X:\n\n - install the Apple developer tools called **Xcode** [http://developer.apple.com/tools/xcode/][1]\n - install **MacPorts** from [http://www.macports.org/][2]\n\nYou can now easily install everything from command line using the `port` command. List all available software\n\n    port list\n\nInstall libraries and software. etc:\n\n    port install <some-library>\n\n  [1]: http://developer.apple.com/tools/xcode/\n  [2]: http://www.macports.org/", "comment_count": 3, "html": "<p>Tips for installing software om Max OS X:</p>\n<ul>\n<li>install the Apple developer tools called <strong>Xcode</strong> <a href=\"http://developer.apple.com/tools/xcode/\">http://developer.apple.com/tools/xcode/</a></li>\n<li>install <strong>MacPorts</strong> from <a href=\"http://www.macports.org/\">http://www.macports.org/</a></li>\n</ul>\n<p>You can now easily install everything from command line using the <code>port</code> command. List all available software</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">port</span> <span class=\"n\">list</span>\n</pre></div>\n</p>\n<p>Install libraries and software. etc:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">port</span> <span class=\"n\">install</span> <span class=\"sr\">&lt;some-library&gt;</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 1, "parent": 33, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 38, "model": "server.post", "fields": {"rght": 5, "author": 24, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-26 23:42:14", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "Any programming language is good as long you know what you're doing.", "comment_count": 0, "html": "<p>Any programming language is good as long you know what you're doing.</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 24}}, {"pk": 39, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-27 10:08:52", "lft": 6, "post_type": 109787, "score": 2, "title": "A: Gene ID conversion tool", "unanswered": false, "content": "You can also do it with the following services:\n\n - [uniprot][1] - Click on 'Id Mapping' from the home page.\n - [biomart][2] - choose a database and a version, then put the ids you want to convert under Filters->Id List limit (select the proper input id in the menu), and then the output ids under 'Attributes'. Biomart is a general tool that enables you to extract a lot of different informations from databases - sequences, ontologies, transcripts, homologues - but maybe for converting gene ids is a bit too complex.\n - [galaxy][3] - I can't help too much about this here but I am sure it has a function for doing that - and many other things.\n\n\n  [1]: http://www.uniprot.org/?tab=mapping\n  [2]: http://www.biomart.org/biomart/martview/\n  [3]: http://main.g2.bx.psu.edu/", "comment_count": 0, "html": "<p>You can also do it with the following services:</p>\n<ul>\n<li><a href=\"http://www.uniprot.org/?tab=mapping\">uniprot</a> - Click on 'Id Mapping' from the home page.</li>\n<li><a href=\"http://www.biomart.org/biomart/martview/\">biomart</a> - choose a database and a version, then put the ids you want to convert under Filters-&gt;Id List limit (select the proper input id in the menu), and then the output ids under 'Attributes'. Biomart is a general tool that enables you to extract a lot of different informations from databases - sequences, ontologies, transcripts, homologues - but maybe for converting gene ids is a bit too complex.</li>\n<li><a href=\"http://main.g2.bx.psu.edu/\">galaxy</a> - I can't help too much about this here but I am sure it has a function for doing that - and many other things.</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 1, "parent": 22, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 40, "model": "server.post", "fields": {"rght": 9, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-28 15:31:50", "lft": 8, "post_type": 109787, "score": 2, "title": "A: Finding common motifs in sequences", "unanswered": false, "content": "Meme has been the first program to be published for doing that.\nAs an alternative you can find one of the [EMBOSS tools][1]; if you are scared by a terminal and want to do it from a web-based interface, you can use the EMBOSS tools from [galaxy][2]\n\n\n  [1]: http://www.be.embnet.org/embosshelp/\n  [2]: http://main.g2.bx.psu.edu/", "comment_count": 0, "html": "<p>Meme has been the first program to be published for doing that.\nAs an alternative you can find one of the <a href=\"http://www.be.embnet.org/embosshelp/\">EMBOSS tools</a>; if you are scared by a terminal and want to do it from a web-based interface, you can use the EMBOSS tools from <a href=\"http://main.g2.bx.psu.edu/\">galaxy</a></p>", "child_count": 0, "closed": false, "tree_id": 3, "revision_count": 1, "parent": 4, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-finding-common-motifs-in-sequences", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 41, "model": "server.post", "fields": {"rght": 6, "author": 22, "answer_accepted": true, "tag_string": "subjective gene go", "creation_date": "2010-01-28 16:17:37", "lft": 1, "post_type": 164033, "score": 6, "title": "How much do you trust GeneOntology annotations?", "unanswered": false, "content": "[GeneOntology][1] is a nice project to provide a standard terminology for genes and gene functions, to help avoid the use of synonyms and wrong spelling when describing a gene.\n\nI have been using the GeneOntology for a while, but honestly I think that it contains many errors and that many terms have not enough terms associated. Moreover, the terminology they use is not always clear and there are some duplications.\n\nIt is frequent to read in article or in slideshows charts were the GO classification is used to infer the properties of a set of genes... But I wonder if the authors check the GO annotations they use.\n\nWhat is your experience about [GO][2]?\n\n\n  [1]: http://www.geneontology.org/\n  [2]: http://www.geneontology.org/", "comment_count": 0, "html": "<p><a href=\"http://www.geneontology.org/\">GeneOntology</a> is a nice project to provide a standard terminology for genes and gene functions, to help avoid the use of synonyms and wrong spelling when describing a gene.</p>\n<p>I have been using the GeneOntology for a while, but honestly I think that it contains many errors and that many terms have not enough terms associated. Moreover, the terminology they use is not always clear and there are some duplications.</p>\n<p>It is frequent to read in article or in slideshows charts were the GO classification is used to infer the properties of a set of genes... But I wonder if the authors check the GO annotations they use.</p>\n<p>What is your experience about <a href=\"http://www.geneontology.org/\">GO</a>?</p>", "child_count": 0, "closed": false, "tree_id": 16, "revision_count": 4, "parent": null, "views": 495, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:30", "slug": "how-much-do-you-trust-geneontology-annotations", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [32, 36, 190], "lastedit_user": 22}}, {"pk": 42, "model": "server.post", "fields": {"rght": 9, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-28 16:22:04", "lft": 6, "post_type": 109787, "score": 1, "title": "A: Site use guidelines", "unanswered": false, "content": "The StackExchange websites have been designed for making questions related to programming and technical issues.\n\nFor example, for this reason, if you try to write a question which starts with 'What is your favorite experience...' you get a disclaimer saying that 'your question seems to be probably subjective and it is likely to be closed'.\n\nHowever, I think that it is very useful to make subjective and opinion-based questions on bioinformatics, as there are few places to do so... So, what is your policy? Will you accept subjective questions?", "comment_count": 1, "html": "<p>The StackExchange websites have been designed for making questions related to programming and technical issues.</p>\n<p>For example, for this reason, if you try to write a question which starts with 'What is your favorite experience...' you get a disclaimer saying that 'your question seems to be probably subjective and it is likely to be closed'.</p>\n<p>However, I think that it is very useful to make subjective and opinion-based questions on bioinformatics, as there are few places to do so... So, what is your policy? Will you accept subjective questions?</p>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 1, "parent": 1, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-site-use-guidelines", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 43, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-28 17:58:20", "lft": 6, "post_type": 109787, "score": 12, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "The choice of a programming language is purely subjective, but when a student asks you which programming language he should start with, you have to make an answer, or at least provide some informations.\n\nI think that a bioinformatician who studies **R** and at least two or three libraries (lattice/ggplot2, plyr) early can have an advantage, because he will be able to represent his data properly and obtain good results without too much effort. If your supervisor is not a computer scientist, he will be a lot more impressed by plots and charts than by programs, even if they are well written, with unittests etc.\n\n**Python** is a good programming language to learn as a general purpose tool. Its bigger advantages are its easy to read syntax, and its paradigm 'there is only one way to do it', so the number of language keywords is reduced to the minimum, and two programs with the same function written by different people will be very similar (which is what doesn't happen with perl). \nThe negative points of python are that its CSV files reading/plotting interface is not ready yet (the best is pylab), so you must rely on R to produce nice plots.\n\nHonestly I don't like **perl**, because I think it can induce to many bad-behaviours in novel programmers. For example, in perl there are many similar constructs to accomplish the same objective: so, it is very difficult to understand a program written by someone else, because you have to known all the possible constructs and hope there are enough comments. It is already very difficult to reproduce a bioinformatician experiment, if you write your code in a difficult language it is a lot worst. \nMoreover, I know of many people who have been using perl for years, but that don't even use functions, because it looks too complicated. How can it be? It looks very inefficient. \nThe only good point of perl is its repositories, bioperl and CPAN; however, I know of people using perl that don't even know of the existence of these, so I don't understand why they keep going with perl.\n\n\nApart from programming language, is it very useful to learn the basic usage of **gnu-make**, or of a derivate. This program is very useful when you have lot of different scripts, as it allows you to define a pipeline in order to run them. \nSome basic **bash commands** may also be very useful if you work with a lot of flat files (head, sed, gawk, grep, ...)", "comment_count": 0, "html": "<p>The choice of a programming language is purely subjective, but when a student asks you which programming language he should start with, you have to make an answer, or at least provide some informations.</p>\n<p>I think that a bioinformatician who studies <strong>R</strong> and at least two or three libraries (lattice/ggplot2, plyr) early can have an advantage, because he will be able to represent his data properly and obtain good results without too much effort. If your supervisor is not a computer scientist, he will be a lot more impressed by plots and charts than by programs, even if they are well written, with unittests etc.</p>\n<p><strong>Python</strong> is a good programming language to learn as a general purpose tool. Its bigger advantages are its easy to read syntax, and its paradigm 'there is only one way to do it', so the number of language keywords is reduced to the minimum, and two programs with the same function written by different people will be very similar (which is what doesn't happen with perl). \nThe negative points of python are that its CSV files reading/plotting interface is not ready yet (the best is pylab), so you must rely on R to produce nice plots.</p>\n<p>Honestly I don't like <strong>perl</strong>, because I think it can induce to many bad-behaviours in novel programmers. For example, in perl there are many similar constructs to accomplish the same objective: so, it is very difficult to understand a program written by someone else, because you have to known all the possible constructs and hope there are enough comments. It is already very difficult to reproduce a bioinformatician experiment, if you write your code in a difficult language it is a lot worst. \nMoreover, I know of many people who have been using perl for years, but that don't even use functions, because it looks too complicated. How can it be? It looks very inefficient. \nThe only good point of perl is its repositories, bioperl and CPAN; however, I know of people using perl that don't even know of the existence of these, so I don't understand why they keep going with perl.</p>\n<p>Apart from programming language, is it very useful to learn the basic usage of <strong>gnu-make</strong>, or of a derivate. This program is very useful when you have lot of different scripts, as it allows you to define a pipeline in order to run them. \nSome basic <strong>bash commands</strong> may also be very useful if you work with a lot of flat files (head, sed, gawk, grep, ...)</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 44, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-28 22:41:29", "lft": 2, "post_type": 109787, "score": 1, "title": "A: How much do you trust GeneOntology annotations?", "unanswered": false, "content": "The GO terms and classifications are primarily an based on opinions and a human interpretation of a small group of people of what the current state of the knowledge is.Thus  are more subjective than say experimental measurements would be. \n\nIn fact it is surprising that it works at all; and it does indeed.  We just need to becareful not too read to much into it.", "comment_count": 0, "html": "<p>The GO terms and classifications are primarily an based on opinions and a human interpretation of a small group of people of what the current state of the knowledge is.Thus  are more subjective than say experimental measurements would be. </p>\n<p>In fact it is surprising that it works at all; and it does indeed.  We just need to becareful not too read to much into it.</p>", "child_count": 0, "closed": false, "tree_id": 16, "revision_count": 1, "parent": 41, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:15", "slug": "a-how-much-do-you-trust-geneontology-annotations", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 45, "model": "server.post", "fields": {"rght": 5, "author": 3, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-29 05:50:26", "lft": 4, "post_type": 109787, "score": 5, "title": "A: How much do you trust GeneOntology annotations?", "unanswered": false, "content": "In my experience it's case by case. In other words just because you are getting significant p-values, does not mean the results are biologically significant. I once submitted clusters of microarray data and received a bunch of hits that were significant by p-value, but really didn't have a theme. The GO terms I saw were from many different processes without an overall term (besides biological process) which linked them together. When I've looked at published GO terms searches I generally see a strong theme among many of the terms (however that doesn't necessarily mean it has biological significance until tested empirically). So seeing themes among your terms may suggest higher significance, but it should make biological sense too. \n\n", "comment_count": 0, "html": "<p>In my experience it's case by case. In other words just because you are getting significant p-values, does not mean the results are biologically significant. I once submitted clusters of microarray data and received a bunch of hits that were significant by p-value, but really didn't have a theme. The GO terms I saw were from many different processes without an overall term (besides biological process) which linked them together. When I've looked at published GO terms searches I generally see a strong theme among many of the terms (however that doesn't necessarily mean it has biological significance until tested empirically). So seeing themes among your terms may suggest higher significance, but it should make biological sense too. </p>", "child_count": 0, "closed": false, "tree_id": 16, "revision_count": 1, "parent": 41, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-how-much-do-you-trust-geneontology-annotations", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 3}}, {"pk": 46, "model": "server.post", "fields": {"rght": 12, "author": 22, "answer_accepted": true, "tag_string": "subjective string protein interacti ppi pin", "creation_date": "2010-01-29 11:42:23", "lft": 1, "post_type": 164033, "score": 3, "title": "What is your experience with the STRING (interactions) database?", "unanswered": false, "content": "STRING is a database of predicted protein-protein interactions at EMBL. It cluster the results from many sources of protein-protein interactions databases, like Mint, etc.., and it also use the informations from KEGG-pathways and reactome, to provide the best annotations for the interactions of a protein.\n\nI am a bit confused from the results that I see there, because when I look at the genes in the pathway I am studying, I see many errors and annotations that I don't understand.\n\nWhat is your experience with STRING? If you want to do me a favor, go there and try to see the interactions annotated for a gene that you know already. Do you see anything weird?", "comment_count": 0, "html": "<p>STRING is a database of predicted protein-protein interactions at EMBL. It cluster the results from many sources of protein-protein interactions databases, like Mint, etc.., and it also use the informations from KEGG-pathways and reactome, to provide the best annotations for the interactions of a protein.</p>\n<p>I am a bit confused from the results that I see there, because when I look at the genes in the pathway I am studying, I see many errors and annotations that I don't understand.</p>\n<p>What is your experience with STRING? If you want to do me a favor, go there and try to see the interactions annotated for a gene that you know already. Do you see anything weird?</p>", "child_count": 0, "closed": false, "tree_id": 17, "revision_count": 2, "parent": null, "views": 535, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:16", "slug": "what-is-your-experience-with-the-string-interactions-database", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [32, 38, 39, 41, 191, 205], "lastedit_user": 86}}, {"pk": 47, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-29 14:06:06", "lft": 2, "post_type": 109787, "score": 1, "title": "A: What is your experience with the STRING (interactions) database?", "unanswered": false, "content": "I have not used STRING in particular but I have worked with protein interactions before (DIP dataset). I recall that even experimentally produced protein-protein interactions may have very large false positive ratios  (as for false negatives, who knows?) Some papers claim that up to 50% of the interactions were spurious; and repeated experiments showed very small overlaps. Predictions may be even less reliable.\n\n\nAt the same time the DIP dataset performed substantially better if we only considered the interactions for which there were multiple sources of evidence, so that may be a strategy to consider in your case as well.\n", "comment_count": 0, "html": "<p>I have not used STRING in particular but I have worked with protein interactions before (DIP dataset). I recall that even experimentally produced protein-protein interactions may have very large false positive ratios  (as for false negatives, who knows?) Some papers claim that up to 50% of the interactions were spurious; and repeated experiments showed very small overlaps. Predictions may be even less reliable.</p>\n<p>At the same time the DIP dataset performed substantially better if we only considered the interactions for which there were multiple sources of evidence, so that may be a strategy to consider in your case as well.</p>", "child_count": 0, "closed": false, "tree_id": 17, "revision_count": 1, "parent": 46, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:15", "slug": "a-what-is-your-experience-with-the-string-interactions-database", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 1}}, {"pk": 48, "model": "server.post", "fields": {"rght": 16, "author": 22, "answer_accepted": true, "tag_string": "sequence protein structure", "creation_date": "2010-02-12 17:33:06", "lft": 1, "post_type": 164033, "score": 3, "title": "Where can I get the secondary structure of a protein?", "unanswered": false, "content": "As in the title... I have a protein and I would like to know its secundary structure.\nI couldn't find it in uniprot, althought I tought they had annotations for it there.\nIn the end I have used a predictor ([jpred][1]) but there it should be a database somewhere.\n\n\n  [1]: http://www.compbio.dundee.ac.uk/www-jpred", "comment_count": 0, "html": "<p>As in the title... I have a protein and I would like to know its secundary structure.\nI couldn't find it in uniprot, althought I tought they had annotations for it there.\nIn the end I have used a predictor (<a href=\"http://www.compbio.dundee.ac.uk/www-jpred\">jpred</a>) but there it should be a database somewhere.</p>", "child_count": 0, "closed": false, "tree_id": 18, "revision_count": 3, "parent": null, "views": 431, "deleted": false, "answer_count": 14, "touch_date": "2011-11-24 14:49:30", "slug": "where-can-i-get-the-secondary-structure-of-a-protein", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [40, 41, 42], "lastedit_user": 22}}, {"pk": 49, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-12 20:01:49", "lft": 2, "post_type": 109787, "score": 1, "title": "A: Where can I get the secondary structure of a protein?", "unanswered": false, "content": "Protein structure prediction is a complex issue that is likely to require multiple approaches. There are many methods/tools listed at the \n\n - [Expert Protein Analysis System website][1]\n\n\n  [1]: http://www.expasy.ch/", "comment_count": 0, "html": "<p>Protein structure prediction is a complex issue that is likely to require multiple approaches. There are many methods/tools listed at the </p>\n<ul>\n<li><a href=\"http://www.expasy.ch/\">Expert Protein Analysis System website</a></li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 18, "revision_count": 1, "parent": 48, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:15", "slug": "a-where-can-i-get-the-secondary-structure-of-a-protein", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 50, "model": "server.post", "fields": {"rght": 5, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-12 21:57:06", "lft": 4, "post_type": 109787, "score": 4, "title": "A: Where can I get the secondary structure of a protein?", "unanswered": false, "content": "I think you found the best answer yourself: use a predictor! There are several out there...\n\nYou suggest that there should be a Secondary Structure Database. I'm not sure that makes much sense, let me explain my point of view (which may not be that of everyone): most often, the data that is found in databases is the \"state of knowledge\" of the described object, based on experimentation.\n\nThat may be the case for secondary structures of proteins, but only in the case where the said proteins have been crystalized. In those cases, it is not only the secondary structures but also the tertiary structures (with the caveat that the crystal structure of a protein does not prove \"all\" states that a protein may take in real \"dynamic\" physiological conditions).\n\nFor all those proteins that have not been crystalized, then we can only rely on predictions. And I use them quite frequently: they are extremely useful! But as far as I know, no prediction is accepted as fact. They're \"educated guesses\" that are often correct, but sometimes wrong. The results may differ from one prediction method to another. Also they change each time the algorithms are improved...\n\nIf there was a database of predicted secondary structures, people would likely take them for granted (make the equation prediction = fact) which would be quite \"unscientific\".\n\nI think such a resource would be more of a hindrance than an asset to the scientific community...", "comment_count": 0, "html": "<p>I think you found the best answer yourself: use a predictor! There are several out there...</p>\n<p>You suggest that there should be a Secondary Structure Database. I'm not sure that makes much sense, let me explain my point of view (which may not be that of everyone): most often, the data that is found in databases is the \"state of knowledge\" of the described object, based on experimentation.</p>\n<p>That may be the case for secondary structures of proteins, but only in the case where the said proteins have been crystalized. In those cases, it is not only the secondary structures but also the tertiary structures (with the caveat that the crystal structure of a protein does not prove \"all\" states that a protein may take in real \"dynamic\" physiological conditions).</p>\n<p>For all those proteins that have not been crystalized, then we can only rely on predictions. And I use them quite frequently: they are extremely useful! But as far as I know, no prediction is accepted as fact. They're \"educated guesses\" that are often correct, but sometimes wrong. The results may differ from one prediction method to another. Also they change each time the algorithms are improved...</p>\n<p>If there was a database of predicted secondary structures, people would likely take them for granted (make the equation prediction = fact) which would be quite \"unscientific\".</p>\n<p>I think such a resource would be more of a hindrance than an asset to the scientific community...</p>", "child_count": 0, "closed": false, "tree_id": 18, "revision_count": 1, "parent": 48, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-where-can-i-get-the-secondary-structure-of-a-protein", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 25}}, {"pk": 51, "model": "server.post", "fields": {"rght": 4, "author": 13, "answer_accepted": true, "tag_string": "sequence blast", "creation_date": "2010-02-16 01:13:06", "lft": 1, "post_type": 164033, "score": 2, "title": "Turn off BLAST search on reverse complement strand in blastn", "unanswered": false, "content": "I have a quick question:\nHow can I turn off search on reverse complement strand of my query nucleotide sequence in blastn?\n\nFor example, I don't want 'GUAAAGCCAAAUCUUCGGUUA' to be a hit when I use 'UAACCGAAGAUUUGGCUUUAC' as the query.\n\nMaybe I missed it when I read the man page, but I really appreciate it if someone can point out the parameter I should use.\n\nThanks!", "comment_count": 0, "html": "<p>I have a quick question:\nHow can I turn off search on reverse complement strand of my query nucleotide sequence in blastn?</p>\n<p>For example, I don't want 'GUAAAGCCAAAUCUUCGGUUA' to be a hit when I use 'UAACCGAAGAUUUGGCUUUAC' as the query.</p>\n<p>Maybe I missed it when I read the man page, but I really appreciate it if someone can point out the parameter I should use.</p>\n<p>Thanks!</p>", "child_count": 0, "closed": false, "tree_id": 19, "revision_count": 2, "parent": null, "views": 506, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:27", "slug": "turn-off-blast-search-on-reverse-complement-strand-in-blastn", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [40, 43], "lastedit_user": 1}}, {"pk": 52, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-16 02:31:37", "lft": 2, "post_type": 109787, "score": 1, "title": "A: Turn off BLAST search on reverse complement strand in blastn", "unanswered": false, "content": "The -S flag can select the strands:\n\n    -S  Query strands to search against database \n        (for blast[nx], and tblastx) 3 is both, 1 is top, 2 is bottom [Integer]", "comment_count": 0, "html": "<p>The -S flag can select the strands:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"o\">-</span><span class=\"n\">S</span>  <span class=\"n\">Query</span> <span class=\"n\">strands</span> <span class=\"n\">to</span> <span class=\"n\">search</span> <span class=\"n\">against</span> <span class=\"n\">database</span> \n        <span class=\"p\">(</span><span class=\"k\">for</span> <span class=\"n\">blast</span><span class=\"p\">[</span><span class=\"n\">nx</span><span class=\"p\">],</span> <span class=\"ow\">and</span> <span class=\"n\">tblastx</span><span class=\"p\">)</span> <span class=\"mi\">3</span> <span class=\"n\">is</span> <span class=\"n\">both</span><span class=\"p\">,</span> <span class=\"mi\">1</span> <span class=\"n\">is</span> <span class=\"n\">top</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"n\">is</span> <span class=\"n\">bottom</span> <span class=\"p\">[</span><span class=\"n\">Integer</span><span class=\"p\">]</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 19, "revision_count": 1, "parent": 51, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:16", "slug": "a-turn-off-blast-search-on-reverse-complement-strand-in-blastn", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 1}}, {"pk": 53, "model": "server.post", "fields": {"rght": 8, "author": 26, "answer_accepted": false, "tag_string": "solid", "creation_date": "2010-02-19 07:29:18", "lft": 1, "post_type": 164033, "score": 3, "title": "How to do quality trimming of SoLid Reads in colour space?", "unanswered": false, "content": "The reads returned from the Solid sequencing provider are littered with dots and some bases have a negative quality value. Does anyone know if there is a good method to extract high quality regions from the reads without distorting the reading of bases in colour space?", "comment_count": 0, "html": "<p>The reads returned from the Solid sequencing provider are littered with dots and some bases have a negative quality value. Does anyone know if there is a good method to extract high quality regions from the reads without distorting the reading of bases in colour space?</p>", "child_count": 0, "closed": false, "tree_id": 20, "revision_count": 1, "parent": null, "views": 532, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:28", "slug": "how-to-do-quality-trimming-of-solid-reads-in-colour-space", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [14], "lastedit_user": 26}}, {"pk": 54, "model": "server.post", "fields": {"rght": 7, "author": 26, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-19 07:31:24", "lft": 4, "post_type": 109787, "score": 1, "title": "A: How do I map, align, and plot my SOLiD results?", "unanswered": false, "content": "You can try BWA as well:\nhttp://maq.sourceforge.net/bwa-man.shtml", "comment_count": 1, "html": "<p>You can try BWA as well:\nhttp://maq.sourceforge.net/bwa-man.shtml</p>", "child_count": 0, "closed": false, "tree_id": 13, "revision_count": 1, "parent": 31, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:16", "slug": "a-how-do-i-map-align-and-plot-my-solid-results", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 26}}, {"pk": 55, "model": "server.post", "fields": {"rght": 5, "author": 27, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-19 13:33:45", "lft": 2, "post_type": 109787, "score": 3, "title": "A: How to do quality trimming of SoLid Reads in colour space?", "unanswered": false, "content": "The [Solid Accuracy Enhancer Tool][1] might be useful for this.\n\n\n  [1]: http://solidsoftwaretools.com/gf/project/saet/", "comment_count": 1, "html": "<p>The <a href=\"http://solidsoftwaretools.com/gf/project/saet/\">Solid Accuracy Enhancer Tool</a> might be useful for this.</p>", "child_count": 0, "closed": false, "tree_id": 20, "revision_count": 1, "parent": 53, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-do-quality-trimming-of-solid-reads-in-colour-space", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 27}}, {"pk": 56, "model": "server.post", "fields": {"rght": 22, "author": 22, "answer_accepted": true, "tag_string": "sequence ucsc fasta", "creation_date": "2010-02-21 16:13:39", "lft": 1, "post_type": 164033, "score": 4, "title": "How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "Let's say I want to download the fasta sequence of the region chr1:100000..200000 from the UCSC browser.\nHow do you do that? I can't find a button to 'export to fasta' in the UCSC genome browser. I think that the solution is to click on one of the tracks displayed, but I am not sure of which.\nIf I go to the Tables section, I can't find a table with the fasta sequences among the many.", "comment_count": 0, "html": "<p>Let's say I want to download the fasta sequence of the region chr1:100000..200000 from the UCSC browser.\nHow do you do that? I can't find a button to 'export to fasta' in the UCSC genome browser. I think that the solution is to click on one of the tracks displayed, but I am not sure of which.\nIf I go to the Tables section, I can't find a table with the fasta sequences among the many.</p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 2, "parent": null, "views": 865, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:17", "slug": "how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [40, 44, 45], "lastedit_user": 1}}, {"pk": 57, "model": "server.post", "fields": {"rght": 9, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-21 19:11:20", "lft": 2, "post_type": 109787, "score": 2, "title": "A: How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "The Genome Browser is for visualization.\n\nTo get data in many formats use the [UCSC Table Browser][1] then select the output format of your choice.\n\nYou may also need to select the right **group** and **track** to get the data you want.\n\n  [1]: http://genome.ucsc.edu/cgi-bin/hgTables?org=human", "comment_count": 3, "html": "<p>The Genome Browser is for visualization.</p>\n<p>To get data in many formats use the <a href=\"http://genome.ucsc.edu/cgi-bin/hgTables?org=human\">UCSC Table Browser</a> then select the output format of your choice.</p>\n<p>You may also need to select the right <strong>group</strong> and <strong>track</strong> to get the data you want.</p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 1, "parent": 56, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:17", "slug": "a-how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 58, "model": "server.post", "fields": {"rght": 22, "author": 22, "answer_accepted": true, "tag_string": "general subjective", "creation_date": "2010-02-25 15:39:15", "lft": 1, "post_type": 164033, "score": 2, "title": "What is the best way to share scripts between members of a lab?", "unanswered": false, "content": " One of the most awful problems in my group is avoiding to rewrite scripts that have been already written by others. Since we have different projects and we work with different data, everybody ends up writing its own scripts in his favorite programming language, and it is very frequent to waste an afternoon on writing a new program and then discover that your workmate already had a script to do that.\n\nApart from the most logical answer (\"talk with your workmates\"), we are thinking about having a common place to store our best scripts, and if possible work together on them.\nIt would be similar to an image library like this: http://matplotlib.sourceforge.net/gallery.html , where to put the script and an example of its output (most of our scripts produce graphs), and if possible integrated with Git. \n\nDo you have any idea? How to you cope with the problem in your lab?", "comment_count": 0, "html": "<p>One of the most awful problems in my group is avoiding to rewrite scripts that have been already written by others. Since we have different projects and we work with different data, everybody ends up writing its own scripts in his favorite programming language, and it is very frequent to waste an afternoon on writing a new program and then discover that your workmate already had a script to do that.</p>\n<p>Apart from the most logical answer (\"talk with your workmates\"), we are thinking about having a common place to store our best scripts, and if possible work together on them.\nIt would be similar to an image library like this: http://matplotlib.sourceforge.net/gallery.html , where to put the script and an example of its output (most of our scripts produce graphs), and if possible integrated with Git. </p>\n<p>Do you have any idea? How to you cope with the problem in your lab?</p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 1, "parent": null, "views": 523, "deleted": false, "answer_count": 16, "touch_date": "2011-11-24 14:49:30", "slug": "what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [31, 32], "lastedit_user": 22}}, {"pk": 59, "model": "server.post", "fields": {"rght": 13, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-25 17:32:53", "lft": 4, "post_type": 109787, "score": 6, "title": "A: How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "Use the **DAS** server:\n\n[http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=chr1:100000,200000][1]\n\n\n  [1]: http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=chr1:100000,200000", "comment_count": 4, "html": "<p>Use the <strong>DAS</strong> server:</p>\n<p><a href=\"\">http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=chr1:100000,200000</a></p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 1, "parent": 56, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 29}}, {"pk": 60, "model": "server.post", "fields": {"rght": 11, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-25 17:51:28", "lft": 10, "post_type": 109787, "score": 4, "title": "A: Finding common motifs in sequences", "unanswered": false, "content": "Some time ago I used SOMBRERO ([http://bioinf.nuigalway.ie/sombrero/download.html][1]) with a good degree of success on finding motifs in a very diverse set of sequences. They have a Mac version for download as well as parallel versions for Irix and Linux.\n\n\n  [1]: http://bioinf.nuigalway.ie/sombrero/download.html", "comment_count": 0, "html": "<p>Some time ago I used SOMBRERO (<a href=\"http://bioinf.nuigalway.ie/sombrero/download.html\">http://bioinf.nuigalway.ie/sombrero/download.html</a>) with a good degree of success on finding motifs in a very diverse set of sequences. They have a Mac version for download as well as parallel versions for Irix and Linux.</p>", "child_count": 0, "closed": false, "tree_id": 3, "revision_count": 1, "parent": 4, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-finding-common-motifs-in-sequences", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 61, "model": "server.post", "fields": {"rght": 5, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-25 17:54:49", "lft": 2, "post_type": 109787, "score": 2, "title": "A: What is the best way to share scripts between members of a lab?", "unanswered": false, "content": "I would recommend you to setup a wiki for your group. If you do not have a server readily you can always use one of the many wiki services available for free like Wikispaces (www.wikispaces.com).", "comment_count": 1, "html": "<p>I would recommend you to setup a wiki for your group. If you do not have a server readily you can always use one of the many wiki services available for free like Wikispaces (www.wikispaces.com).</p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 1, "parent": 58, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 62, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-25 18:24:46", "lft": 4, "post_type": 109787, "score": 3, "title": "A: What is the best way to share scripts between members of a lab?", "unanswered": false, "content": "Integrating with the source code management tool is essential, that way when code gets changed everyone can easily get the updated version. Wikis are also a good idea.", "comment_count": 0, "html": "<p>Integrating with the source code management tool is essential, that way when code gets changed everyone can easily get the updated version. Wikis are also a good idea.</p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 1, "parent": 58, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 63, "model": "server.post", "fields": {"rght": 5, "author": 34, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-25 21:33:37", "lft": 4, "post_type": 109787, "score": 3, "title": "A: What is your experience with the STRING (interactions) database?", "unanswered": false, "content": "I've been using STRING extensively, but not for protein-protein interactions work. STRING, as you note, is a bit of a mutt in terms of the different data sources it mines. Some that you're missing include a broad literature-based search, as well as gene expression data sets. So if you're interested primarily in physical interactions or any other single type of data source, STRING is a poor choice for your work. On the other hand, STRING does provide confidence scores for each association, as well as annotation for their data source types (with the license). So you can use those to filter out the interactions derived from data types you don't want to see.", "comment_count": 0, "html": "<p>I've been using STRING extensively, but not for protein-protein interactions work. STRING, as you note, is a bit of a mutt in terms of the different data sources it mines. Some that you're missing include a broad literature-based search, as well as gene expression data sets. So if you're interested primarily in physical interactions or any other single type of data source, STRING is a poor choice for your work. On the other hand, STRING does provide confidence scores for each association, as well as annotation for their data source types (with the license). So you can use those to filter out the interactions derived from data types you don't want to see.</p>", "child_count": 0, "closed": false, "tree_id": 17, "revision_count": 1, "parent": 46, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:16", "slug": "a-what-is-your-experience-with-the-string-interactions-database", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 34}}, {"pk": 64, "model": "server.post", "fields": {"rght": 9, "author": 34, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-25 21:41:22", "lft": 8, "post_type": 109787, "score": 3, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "Perl can be quite lovely if you choose to write it well. If you find yourself in need of writing some perl, I'd highly recommend getting the Perl Best Practices book and going through it to learn how to make your perl code not suck. Essential tools for helping with that are perlcritic and perltidy, both of which I have bound to quick keystrokes in my emacs cperl-mode so as to make sure my code is in reasonably good shape. There's lots of blog articles out there about writing \"Modern Perl\" or \"Enlightened Perl\" that help make the language not just bearable but actually quite nice for a certain type of brain.\n\nOne thing that Perl does very well that no other language does is quick text processing on the command line. If you want to do some simple processing of a text file (which is pretty standard in this business), perl is a fantastic package to do so. Stringing together a set of UNIX utilities on a Linux system will usually have you running for a half dozen manpages looking for conflicting and unique switches, where with perl I find that there's far less I have to remember to get the same effect. The book Minimal Perl goes in to this sort of thing in detail (perl as a better awk/sed/grep/etc) and I highly recommend having a look. At the very least, I've found that using perl in this fashion filled a hole in my toolkit that I didn't even realize was there. R and Python can, of course, do this sort of thing too, but not nearly so well as Perl.", "comment_count": 0, "html": "<p>Perl can be quite lovely if you choose to write it well. If you find yourself in need of writing some perl, I'd highly recommend getting the Perl Best Practices book and going through it to learn how to make your perl code not suck. Essential tools for helping with that are perlcritic and perltidy, both of which I have bound to quick keystrokes in my emacs cperl-mode so as to make sure my code is in reasonably good shape. There's lots of blog articles out there about writing \"Modern Perl\" or \"Enlightened Perl\" that help make the language not just bearable but actually quite nice for a certain type of brain.</p>\n<p>One thing that Perl does very well that no other language does is quick text processing on the command line. If you want to do some simple processing of a text file (which is pretty standard in this business), perl is a fantastic package to do so. Stringing together a set of UNIX utilities on a Linux system will usually have you running for a half dozen manpages looking for conflicting and unique switches, where with perl I find that there's far less I have to remember to get the same effect. The book Minimal Perl goes in to this sort of thing in detail (perl as a better awk/sed/grep/etc) and I highly recommend having a look. At the very least, I've found that using perl in this fashion filled a hole in my toolkit that I didn't even realize was there. R and Python can, of course, do this sort of thing too, but not nearly so well as Perl.</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 34}}, {"pk": 65, "model": "server.post", "fields": {"rght": 9, "author": 32, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-25 21:50:25", "lft": 6, "post_type": 109787, "score": 2, "title": "A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "My tip: install Cygwin if you are using Windows ", "comment_count": 1, "html": "<p>My tip: install Cygwin if you are using Windows </p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 1, "parent": 33, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:16", "slug": "a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 32}}, {"pk": 66, "model": "server.post", "fields": {"rght": 11, "author": 32, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-25 21:52:10", "lft": 8, "post_type": 109787, "score": 3, "title": "A: Site use guidelines", "unanswered": false, "content": "Who is running this site?", "comment_count": 1, "html": "<p>Who is running this site?</p>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 1, "parent": 1, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-site-use-guidelines", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 32}}, {"pk": 67, "model": "server.post", "fields": {"rght": 9, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 09:51:33", "lft": 8, "post_type": 109787, "score": 4, "title": "A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "All of the 3 major platforms have their advantages, and I use all 3 practically every day. Mac OS X is my primary desktop OS, for a number of reasons, but mostly because I just seem more productive using it than any of the alternatives. All of my coding work is done over SSH on Linux (almost exclusively Ubuntu) servers. The power of Aptitude package management, and the robustness of this platform means that there really is no other choice for this kind of work. Finally I run Windows 7 on my netbook, because it is an excellent OS for that platform, and enables me to do everything I want that machine to be capable of, note-taking, blog writing, as a display machine for Powerpoint etc. It is also useful to have Internet Explorer kicking around somewhere for compatability testing.\n\nI wouldn't consider using any machine that I didn't have admin rights on for work purposes, if I have to jump through hoops to get stuff installed, it just slows me down too much. This is another reason for using OS X for my primary desktop, it allows me to escape the University's \"Common Desktop\" policy for Windows PCs, which would take control of my computer out of my hands.", "comment_count": 0, "html": "<p>All of the 3 major platforms have their advantages, and I use all 3 practically every day. Mac OS X is my primary desktop OS, for a number of reasons, but mostly because I just seem more productive using it than any of the alternatives. All of my coding work is done over SSH on Linux (almost exclusively Ubuntu) servers. The power of Aptitude package management, and the robustness of this platform means that there really is no other choice for this kind of work. Finally I run Windows 7 on my netbook, because it is an excellent OS for that platform, and enables me to do everything I want that machine to be capable of, note-taking, blog writing, as a display machine for Powerpoint etc. It is also useful to have Internet Explorer kicking around somewhere for compatability testing.</p>\n<p>I wouldn't consider using any machine that I didn't have admin rights on for work purposes, if I have to jump through hoops to get stuff installed, it just slows me down too much. This is another reason for using OS X for my primary desktop, it allows me to escape the University's \"Common Desktop\" policy for Windows PCs, which would take control of my computer out of my hands.</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 2, "parent": 33, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 68, "model": "server.post", "fields": {"rght": 7, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 10:07:14", "lft": 6, "post_type": 109787, "score": 5, "title": "A: What is the best way to share scripts between members of a lab?", "unanswered": false, "content": "If you want to see the code, but also store associated information, such as expected outputs etc, then a wiki probably is the best choice (we prefer [DokuWiki][1] here), although this would involve a lot of manual effort to document each script. \n\nUse of a site such as GitHub would give you version control + a handy place to read code, although it is not free to host private repositories there, which I guess is what the majority of labs would require. \n\nIf privacy is not a concern, then I would consider GitHub [gists][2] for code, which can then be embedded in a [Posterous][3] blog for comments. Posterous automatically unfolds Gist URLs into code samples in blog posts, so then you can annotate them easily. This would be a lot less manual effort than a wiki.\n\n\n  [1]: http://www.dokuwiki.org/dokuwiki\n  [2]: http://gist.github.com/\n  [3]: http://posterous.com/", "comment_count": 0, "html": "<p>If you want to see the code, but also store associated information, such as expected outputs etc, then a wiki probably is the best choice (we prefer <a href=\"http://www.dokuwiki.org/dokuwiki\">DokuWiki</a> here), although this would involve a lot of manual effort to document each script. </p>\n<p>Use of a site such as GitHub would give you version control + a handy place to read code, although it is not free to host private repositories there, which I guess is what the majority of labs would require. </p>\n<p>If privacy is not a concern, then I would consider GitHub <a href=\"http://gist.github.com/\">gists</a> for code, which can then be embedded in a <a href=\"http://posterous.com/\">Posterous</a> blog for comments. Posterous automatically unfolds Gist URLs into code samples in blog posts, so then you can annotate them easily. This would be a lot less manual effort than a wiki.</p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 1, "parent": 58, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 37}}, {"pk": 69, "model": "server.post", "fields": {"rght": 38, "author": 29, "answer_accepted": true, "tag_string": "hdf biohdf hdf storage", "creation_date": "2010-02-26 12:50:17", "lft": 1, "post_type": 164033, "score": 11, "title": "Using HDF5 to store  bio-data", "unanswered": false, "content": "Hi all,\nhas anobody ever used the [HDF5 API][1] to store some biological data (genotypes...). I know about this [kind of reference][2] (BioHDF...)  but I'm looking for some **source code** I could browse to understand how I can access data faster.\n\nPierre\n\n\nPS: hum, I'm a new user. I'm not allowed to add the following tags: storage database hdf5 source code \n\n  [1]: http://www.hdfgroup.org/HDF5/\n  [2]: http://www.geospiza.com/finchtalk/2008/03/genotyping-with-hdf.html", "comment_count": 0, "html": "<p>Hi all,\nhas anobody ever used the <a href=\"http://www.hdfgroup.org/HDF5/\">HDF5 API</a> to store some biological data (genotypes...). I know about this <a href=\"http://www.geospiza.com/finchtalk/2008/03/genotyping-with-hdf.html\">kind of reference</a> (BioHDF...)  but I'm looking for some <strong>source code</strong> I could browse to understand how I can access data faster.</p>\n<p>Pierre</p>\n<p>PS: hum, I'm a new user. I'm not allowed to add the following tags: storage database hdf5 source code </p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 3, "parent": null, "views": 1507, "deleted": false, "answer_count": 18, "touch_date": "2011-11-24 14:49:30", "slug": "using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [46, 47, 195], "lastedit_user": 29}}, {"pk": 70, "model": "server.post", "fields": {"rght": 9, "author": 39, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 13:15:16", "lft": 8, "post_type": 109787, "score": 2, "title": "A: What is the best way to share scripts between members of a lab?", "unanswered": false, "content": "You might also want to setup a simple snippets database. Navysnip application by Jason Strutz is easy to install and run if you have ruby and rubyonrails installed.\n\ngit clone git://github.com/navyrain/navysnip.git\n  cd navysnip\n  sudo rake gems:install\n  rake db:migrate\n  ruby script/server\nThen visit your app at http://localhost:3000\n\ncheck out http://github.com/navyrain/navysnip  for complete details", "comment_count": 0, "html": "<p>You might also want to setup a simple snippets database. Navysnip application by Jason Strutz is easy to install and run if you have ruby and rubyonrails installed.</p>\n<p>git clone git://github.com/navyrain/navysnip.git\n  cd navysnip\n  sudo rake gems:install\n  rake db:migrate\n  ruby script/server\nThen visit your app at http://localhost:3000</p>\n<p>check out http://github.com/navyrain/navysnip  for complete details</p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 1, "parent": 58, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:16", "slug": "a-what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 39}}, {"pk": 71, "model": "server.post", "fields": {"rght": 9, "author": 41, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 13:47:41", "lft": 2, "post_type": 109787, "score": 3, "title": "A: Using HDF5 to store  bio-data", "unanswered": false, "content": "Hello Pierre!\n\nI have been talking with the BioHDF guys and from what they tell me, their work will be centered around a number of command-line APIs, written in C, that will address some areas of usage which for now do not seem to overlap. \n\nI have seen this example on their site:\nhttp://www.hdfgroup.org/projects/biohdf/biohdf_tools.html\nDon't know if that helps.\n\nI have been talking with them to see if we can achieve an API for saving genotype data. Don't know yet where that will lead me.\n\nIf you are looking for something more versatile, you will probably have to delve in the official HDF5 C code ( http://www.hdfgroup.org/HDF5/Tutor/ ), which seems to be the only one that offers all the functionality and goodies of that impressive storage system. ", "comment_count": 3, "html": "<p>Hello Pierre!</p>\n<p>I have been talking with the BioHDF guys and from what they tell me, their work will be centered around a number of command-line APIs, written in C, that will address some areas of usage which for now do not seem to overlap. </p>\n<p>I have seen this example on their site:\nhttp://www.hdfgroup.org/projects/biohdf/biohdf_tools.html\nDon't know if that helps.</p>\n<p>I have been talking with them to see if we can achieve an API for saving genotype data. Don't know yet where that will lead me.</p>\n<p>If you are looking for something more versatile, you will probably have to delve in the official HDF5 C code ( http://www.hdfgroup.org/HDF5/Tutor/ ), which seems to be the only one that offers all the functionality and goodies of that impressive storage system. </p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 1, "parent": 69, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 41}}, {"pk": 72, "model": "server.post", "fields": {"rght": 5, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 13:54:03", "lft": 4, "post_type": 109787, "score": 1, "title": "A: Using HDF5 to store  bio-data", "unanswered": false, "content": "Unfortunately I don't have any example to shows you yet.\nI don't know how to program in C/C++ so I have been looking at two hdf5 wrappers in python, [PyTables][1] and [H5PY][2].\n\nPyTables has a database-like approach in which HDF5 is used as a sort of hierarchical database, in which a column can be a table itself, allowing to store nested data. For example, you have a table called 'SNPs' with two columns, 'id' and 'genotypes'; the column 'genotypes' contains a nested table, with the columns 'individual' and 'genotype'; and so on.\n\nH5Py is basically a re-implementation of numpy's arrays, so you can store and access arrays/matrixes as you would do with numpy (it is similar to arrays and matrixes in matlab, R, and any other language with this data type) and they are stored in an HDF5 file so the access is faster.\n\n\n  [1]: http://www.pytables.org/moin\n  [2]: http://h5py.alfven.org/", "comment_count": 0, "html": "<p>Unfortunately I don't have any example to shows you yet.\nI don't know how to program in C/C++ so I have been looking at two hdf5 wrappers in python, <a href=\"http://www.pytables.org/moin\">PyTables</a> and <a href=\"http://h5py.alfven.org/\">H5PY</a>.</p>\n<p>PyTables has a database-like approach in which HDF5 is used as a sort of hierarchical database, in which a column can be a table itself, allowing to store nested data. For example, you have a table called 'SNPs' with two columns, 'id' and 'genotypes'; the column 'genotypes' contains a nested table, with the columns 'individual' and 'genotype'; and so on.</p>\n<p>H5Py is basically a re-implementation of numpy's arrays, so you can store and access arrays/matrixes as you would do with numpy (it is similar to arrays and matrixes in matlab, R, and any other language with this data type) and they are stored in an HDF5 file so the access is faster.</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 1, "parent": 69, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:16", "slug": "a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 73, "model": "server.post", "fields": {"rght": 11, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 13:56:22", "lft": 6, "post_type": 109787, "score": 5, "title": "A: Using HDF5 to store  bio-data", "unanswered": false, "content": "In the [GeneTrack][1] software we have used HDF to store values for each genomic base. Its main advantage over other storage systems was that it was able to return consecutive values with minimal overhead. \n\nFor example it is *extremely fast* (ms) in retrieving say 100,000 consecutive values starting with a certain index.We used the [Python bindings][2] to HDF. An added advantage of these bindings is that they will return the data back as numpy arrays (very fast numerical operations). \n\nHere is the relevant code that deals with HDF only: [hdf.py][3]\n\nThe HDF schema is set up in a different module, but in the end it simply something like:\n\n    class MySchema( IsDescription ):\n        \"\"\"\n        Stores a triplet of float values for each index.\n        \"\"\"\n        ix = IntCol  ( pos=1 )  # index\n        wx = FloatCol( pos=2 )  # values on the W (forward) strand\n        cx = FloatCol( pos=3 )  # value on the C (reverse) strand\n        ax = FloatCol( pos=4 )  # weighted value on the combined W + C strands\n\n\n  [1]: http://code.google.com/p/genetrack/\n  [2]: http://www.pytables.org/moin\n  [3]: http://code.google.com/p/genetrack/source/browse/trunk/atlas/hdf.py", "comment_count": 2, "html": "<p>In the <a href=\"http://code.google.com/p/genetrack/\">GeneTrack</a> software we have used HDF to store values for each genomic base. Its main advantage over other storage systems was that it was able to return consecutive values with minimal overhead. </p>\n<p>For example it is <em>extremely fast</em> (ms) in retrieving say 100,000 consecutive values starting with a certain index.We used the <a href=\"http://www.pytables.org/moin\">Python bindings</a> to HDF. An added advantage of these bindings is that they will return the data back as numpy arrays (very fast numerical operations). </p>\n<p>Here is the relevant code that deals with HDF only: <a href=\"http://code.google.com/p/genetrack/source/browse/trunk/atlas/hdf.py\">hdf.py</a></p>\n<p>The HDF schema is set up in a different module, but in the end it simply something like:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">class</span> <span class=\"n\">MySchema</span><span class=\"p\">(</span> <span class=\"n\">IsDescription</span> <span class=\"p\">):</span>\n        <span class=\"s\">&quot;&quot;&quot;</span>\n<span class=\"s\">        Stores a triplet of float values for each index.</span>\n<span class=\"s\">        &quot;&quot;&quot;</span>\n        <span class=\"n\">ix</span> <span class=\"o\">=</span> <span class=\"n\">IntCol</span>  <span class=\"p\">(</span> <span class=\"nb\">pos</span><span class=\"o\">=</span><span class=\"mi\">1</span> <span class=\"p\">)</span>  <span class=\"c1\"># index</span>\n        <span class=\"n\">wx</span> <span class=\"o\">=</span> <span class=\"n\">FloatCol</span><span class=\"p\">(</span> <span class=\"nb\">pos</span><span class=\"o\">=</span><span class=\"mi\">2</span> <span class=\"p\">)</span>  <span class=\"c1\"># values on the W (forward) strand</span>\n        <span class=\"n\">cx</span> <span class=\"o\">=</span> <span class=\"n\">FloatCol</span><span class=\"p\">(</span> <span class=\"nb\">pos</span><span class=\"o\">=</span><span class=\"mi\">3</span> <span class=\"p\">)</span>  <span class=\"c1\"># value on the C (reverse) strand</span>\n        <span class=\"n\">ax</span> <span class=\"o\">=</span> <span class=\"n\">FloatCol</span><span class=\"p\">(</span> <span class=\"nb\">pos</span><span class=\"o\">=</span><span class=\"mi\">4</span> <span class=\"p\">)</span>  <span class=\"c1\"># weighted value on the combined W + C strands</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 2, "parent": 69, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 74, "model": "server.post", "fields": {"rght": 11, "author": 41, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 14:26:41", "lft": 8, "post_type": 109787, "score": 4, "title": "A: Using HDF5 to store  bio-data", "unanswered": false, "content": "What I do have is a netCDF-3 based Java application that I could show you.\nNetCDF-3 is basically the same idea as HDF, but quite more limited as it cannot do compound datatypes among other limitations.\n\nBut here's a small test code example to toy with:\n\npackage netCDF;\n\n\nimport java.io.File;\nimport ucar.ma2.*;\nimport ucar.nc2.*;\nimport java.io.IOException;\nimport java.util.ArrayList;\n\n/**\n *\n * @author Fernando Mu\u00f1iz Fernandez\n * IBE, Institute of Evolutionary Biology (UPF-CSIC)\n * CEXS-UPF-PRBB\n * \n * THIS TO CREATE THE netCDF-3 GENOTYPE FILE\n */\npublic class CreateNetcdf {\n\n     public static NetcdfFileWriteable setDimsAndAttributes(Integer studyId, \n                                          String technology, \n                                          String description, \n                                          String strand, \n                                          int sampleSetSize,\n                                          int markerSetSize) throws InvalidRangeException, IOException {\n\n        ///////////// CREATE netCDF-3 FILE ////////////\n        String genotypesFolder = \"/media/data/genotypes\";\n        File pathToStudy = new File(genotypesFolder+\"/netCDF_test\");\n        int gtSpan = constants.cNetCDF.Strides.STRIDE_GT;\n        int markerSpan = constants.cNetCDF.Strides.STRIDE_MARKER_NAME;\n        int sampleSpan = constants.cNetCDF.Strides.STRIDE_SAMPLE_NAME;\n        \n        String matrixName = \"prototype\";\n        String writeFileName = pathToStudy+\"/\"+matrixName+\".nc\";\n        NetcdfFileWriteable ncfile = NetcdfFileWriteable.createNew(writeFileName, false);\n\n        // add dimensions\n        Dimension samplesDim = ncfile.addDimension(\"samples\", sampleSetSize);\n        Dimension markersDim = ncfile.addDimension(\"markers\", markerSetSize);\n        Dimension gtSpanDim = ncfile.addDimension(\"span\", gtSpan);\n        ArrayList dims = new ArrayList();\n        dims.add(samplesDim);\n        dims.add(markersDim);\n        dims.add(gtSpanDim);\n\n        ArrayList markerGenotypeDims = new ArrayList();\n        markerGenotypeDims.add(markersDim);\n        markerGenotypeDims.add(markerSpan);\n\n        ArrayList markerPositionDim = new ArrayList();\n        markerPositionDim.add(markersDim);\n\n        ArrayList markerPropertyDim32 = new ArrayList();\n        markerPropertyDim32.add(markersDim);\n        markerPropertyDim32.add(32);\n\n        ArrayList markerPropertyDim16 = new ArrayList();\n        markerPropertyDim16.add(markersDim);\n        markerPropertyDim16.add(16);\n\n        ArrayList markerPropertyDim8 = new ArrayList();\n        markerPropertyDim8.add(markersDim);\n        markerPropertyDim8.add(8);\n\n        ArrayList markerPropertyDim2 = new ArrayList();\n        markerPropertyDim2.add(markersDim);\n        markerPropertyDim2.add(2);\n\n        ArrayList markerPropertyDim1 = new ArrayList();\n        markerPropertyDim1.add(markersDim);\n        markerPropertyDim1.add(1);\n\n        ArrayList sampleSetDims = new ArrayList();\n        sampleSetDims.add(samplesDim);\n        sampleSetDims.add(sampleSpan);\n\n        // Define Marker Variables\n        ncfile.addVariable(\"markerset\", DataType.CHAR, markerGenotypeDims);\n        ncfile.addVariableAttribute(\"markerset\", constants.cNetCDF.Attributes.LENGTH, markerSetSize);\n\n        ncfile.addVariable(\"marker_chromosome\", DataType.CHAR, markerPropertyDim8);\n        ncfile.addVariable(\"marker_position\", DataType.CHAR, markerPropertyDim32);\n        ncfile.addVariable(\"marker_position_int\", DataType.INT, markerPositionDim);\n        ncfile.addVariable(\"marker_strand\", DataType.CHAR, markerPropertyDim8);\n\n        ncfile.addVariable(\"marker_property_1\", DataType.CHAR, markerPropertyDim1);\n        ncfile.addVariable(\"marker_property_2\", DataType.CHAR, markerPropertyDim2);\n        ncfile.addVariable(\"marker_property_8\", DataType.CHAR, markerPropertyDim8);\n        ncfile.addVariable(\"marker_property_16\", DataType.CHAR, markerPropertyDim16);\n        ncfile.addVariable(\"marker_property_32\", DataType.CHAR, markerPropertyDim32);\n\n        // Define Sample Variables\n        ncfile.addVariable(\"sampleset\", DataType.CHAR, sampleSetDims);\n        ncfile.addVariableAttribute(\"sampleset\", constants.cNetCDF.Attributes.LENGTH, sampleSetSize);\n\n        // Define Genotype Variables\n        ncfile.addVariable(\"genotypes\", DataType.CHAR, dims);\n        ncfile.addVariableAttribute(\"genotypes\", constants.cNetCDF.Attributes.GLOB_STRAND, \"+/-\");\n\n        // add global attributes\n        ncfile.addGlobalAttribute(constants.cNetCDF.Attributes.GLOB_STUDY, studyId);\n        ncfile.addGlobalAttribute(constants.cNetCDF.Attributes.GLOB_TECHNOLOGY, \"INTERNAL\");\n        ncfile.addGlobalAttribute(constants.cNetCDF.Attributes.GLOB_DESCRIPTION, \"Matrix created by MOAPI through addition of 2 matrices\");\n        \n        return ncfile;\n\n    }\n}\n\nUse the above in the following way:\n\npackage netCDF;\n\nimport java.util.List;\nimport ucar.ma2.*;\nimport ucar.nc2.*;\nimport java.io.IOException;\n\n/**\n *\n * @author Fernando Mu\u00f1iz Fernandez\n * IBE, Institute of Evolutionary Biology (UPF-CSIC)\n * CEXS-UPF-PRBB\n * \n * THIS TO GENERATE A netCDF-3 GENOTYPE DB\n */\n\npublic class TestWriteNetcdf {\n    \n    public static void main(String[] arg) throws InvalidRangeException, IOException {\n        \n        NetcdfFileWriteable ncfile = netCDF.CreateNetcdf.setDimsAndAttributes(0, \n                                                                          \"INTERNAL\", \n                                                                          \"test in TestWriteNetcdf\", \n                                                                          \"+/-\", \n                                                                          5,\n                                                                          10);\n                \n        // create the file\n        try {\n            ncfile.create();\n        } catch (IOException e) {\n            System.err.println(\"ERROR creating file \"+ncfile.getLocation()+\"\\n\"+e);\n        }\n        \n        \n        ////////////// FILL'ER UP! ////////////////\n        List<Dimension> dims = ncfile.getDimensions();\n        Dimension samplesDim = dims.get(0);\n        Dimension markersDim = dims.get(1);\n        Dimension markerSpanDim = dims.get(2);\n        \n        ArrayChar charArray = new ArrayChar.D3(samplesDim.getLength(),markersDim.getLength(),markerSpanDim.getLength());\n        int i,j;\n        Index ima = charArray.getIndex();\n        \n        \n        int method = 1;\n        switch (method) {\n            case 1: \n                // METHOD 1: Feed the complete genotype in one go\n                for (i=0; i<samplesDim.getLength(); i++) {\n                    for (j=0; j<markersDim.getLength(); j++) {\n                        char c = (char) ((char) j + 65);\n                        String s = Character.toString(c) + Character.toString(c);\n                        charArray.setString(ima.set(i,j,0),s);\n                        System.out.println(\"SNP: \"+i);\n                    }\n                }\n                break;\n            case 2: \n                //METHOD 2: One snp at a time -> feed in all samples\n                for (i=0; i<markersDim.getLength(); i++) {\n                    charArray.setString(ima.set(i,0), \"s\"+i+\"I0\");\n                    System.out.println(\"SNP: \"+i);\n                }\n                break;\n            case 3: \n                //METHOD 3: One sample at a time -> feed in all snps\n                break;\n        }\n        \n        \n        \n        int[] offsetOrigin = new int[3]; //0,0\n        try {\n            ncfile.write(\"genotypes\", offsetOrigin, charArray);\n            //ncfile.write(\"genotype\", origin, A);\n        } catch (IOException e) {\n            System.err.println(\"ERROR writing file\");\n        } catch (InvalidRangeException e) {\n            e.printStackTrace();\n        }\n        \n        // close the file\n        try {\n            ncfile.close();\n        } catch (IOException e) {\n            System.err.println(\"ERROR creating file \"+ncfile.getLocation()+\"\\n\"+e);\n        }\n\n    }\n}\n\n\n", "comment_count": 1, "html": "<p>What I do have is a netCDF-3 based Java application that I could show you.\nNetCDF-3 is basically the same idea as HDF, but quite more limited as it cannot do compound datatypes among other limitations.</p>\n<p>But here's a small test code example to toy with:</p>\n<p>package netCDF;</p>\n<p>import java.io.File;\nimport ucar.ma2.<em>;\nimport ucar.nc2.</em>;\nimport java.io.IOException;\nimport java.util.ArrayList;</p>\n<p>/<em><em>\n </em>\n * @author Fernando Mu\u00f1iz Fernandez\n * IBE, Institute of Evolutionary Biology (UPF-CSIC)\n * CEXS-UPF-PRBB\n * \n * THIS TO CREATE THE netCDF-3 GENOTYPE FILE\n </em>/\npublic class CreateNetcdf {</p>\n<p><div class=\"highlight\"><pre>     <span class=\"n\">public</span> <span class=\"n\">static</span> <span class=\"n\">NetcdfFileWriteable</span> <span class=\"n\">setDimsAndAttributes</span><span class=\"p\">(</span><span class=\"n\">Integer</span> <span class=\"n\">studyId</span><span class=\"p\">,</span> \n                                          <span class=\"n\">String</span> <span class=\"n\">technology</span><span class=\"p\">,</span> \n                                          <span class=\"n\">String</span> <span class=\"n\">description</span><span class=\"p\">,</span> \n                                          <span class=\"n\">String</span> <span class=\"n\">strand</span><span class=\"p\">,</span> \n                                          <span class=\"nb\">int</span> <span class=\"n\">sampleSetSize</span><span class=\"p\">,</span>\n                                          <span class=\"nb\">int</span> <span class=\"n\">markerSetSize</span><span class=\"p\">)</span> <span class=\"n\">throws</span> <span class=\"n\">InvalidRangeException</span><span class=\"p\">,</span> <span class=\"n\">IOException</span> <span class=\"p\">{</span>\n\n        <span class=\"sr\">///////////// CREATE netCDF-3 FILE ///////////</span><span class=\"o\">/</span>\n        <span class=\"n\">String</span> <span class=\"n\">genotypesFolder</span> <span class=\"o\">=</span> <span class=\"s\">&quot;/media/data/genotypes&quot;</span><span class=\"p\">;</span>\n        <span class=\"n\">File</span> <span class=\"n\">pathToStudy</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">File</span><span class=\"p\">(</span><span class=\"n\">genotypesFolder</span><span class=\"o\">+</span><span class=\"s\">&quot;/netCDF_test&quot;</span><span class=\"p\">);</span>\n        <span class=\"nb\">int</span> <span class=\"n\">gtSpan</span> <span class=\"o\">=</span> <span class=\"n\">constants</span><span class=\"o\">.</span><span class=\"n\">cNetCDF</span><span class=\"o\">.</span><span class=\"n\">Strides</span><span class=\"o\">.</span><span class=\"n\">STRIDE_GT</span><span class=\"p\">;</span>\n        <span class=\"nb\">int</span> <span class=\"n\">markerSpan</span> <span class=\"o\">=</span> <span class=\"n\">constants</span><span class=\"o\">.</span><span class=\"n\">cNetCDF</span><span class=\"o\">.</span><span class=\"n\">Strides</span><span class=\"o\">.</span><span class=\"n\">STRIDE_MARKER_NAME</span><span class=\"p\">;</span>\n        <span class=\"nb\">int</span> <span class=\"n\">sampleSpan</span> <span class=\"o\">=</span> <span class=\"n\">constants</span><span class=\"o\">.</span><span class=\"n\">cNetCDF</span><span class=\"o\">.</span><span class=\"n\">Strides</span><span class=\"o\">.</span><span class=\"n\">STRIDE_SAMPLE_NAME</span><span class=\"p\">;</span>\n        \n        <span class=\"n\">String</span> <span class=\"n\">matrixName</span> <span class=\"o\">=</span> <span class=\"s\">&quot;prototype&quot;</span><span class=\"p\">;</span>\n        <span class=\"n\">String</span> <span class=\"n\">writeFileName</span> <span class=\"o\">=</span> <span class=\"n\">pathToStudy</span><span class=\"o\">+</span><span class=\"s\">&quot;/&quot;</span><span class=\"o\">+</span><span class=\"n\">matrixName</span><span class=\"o\">+</span><span class=\"s\">&quot;.nc&quot;</span><span class=\"p\">;</span>\n        <span class=\"n\">NetcdfFileWriteable</span> <span class=\"n\">ncfile</span> <span class=\"o\">=</span> <span class=\"n\">NetcdfFileWriteable</span><span class=\"o\">.</span><span class=\"n\">createNew</span><span class=\"p\">(</span><span class=\"n\">writeFileName</span><span class=\"p\">,</span> <span class=\"n\">false</span><span class=\"p\">);</span>\n\n        <span class=\"sr\">//</span> <span class=\"n\">add</span> <span class=\"n\">dimensions</span>\n        <span class=\"n\">Dimension</span> <span class=\"n\">samplesDim</span> <span class=\"o\">=</span> <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addDimension</span><span class=\"p\">(</span><span class=\"s\">&quot;samples&quot;</span><span class=\"p\">,</span> <span class=\"n\">sampleSetSize</span><span class=\"p\">);</span>\n        <span class=\"n\">Dimension</span> <span class=\"n\">markersDim</span> <span class=\"o\">=</span> <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addDimension</span><span class=\"p\">(</span><span class=\"s\">&quot;markers&quot;</span><span class=\"p\">,</span> <span class=\"n\">markerSetSize</span><span class=\"p\">);</span>\n        <span class=\"n\">Dimension</span> <span class=\"n\">gtSpanDim</span> <span class=\"o\">=</span> <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addDimension</span><span class=\"p\">(</span><span class=\"s\">&quot;span&quot;</span><span class=\"p\">,</span> <span class=\"n\">gtSpan</span><span class=\"p\">);</span>\n        <span class=\"n\">ArrayList</span> <span class=\"n\">dims</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ArrayList</span><span class=\"p\">();</span>\n        <span class=\"n\">dims</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">samplesDim</span><span class=\"p\">);</span>\n        <span class=\"n\">dims</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">markersDim</span><span class=\"p\">);</span>\n        <span class=\"n\">dims</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">gtSpanDim</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ArrayList</span> <span class=\"n\">markerGenotypeDims</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ArrayList</span><span class=\"p\">();</span>\n        <span class=\"n\">markerGenotypeDims</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">markersDim</span><span class=\"p\">);</span>\n        <span class=\"n\">markerGenotypeDims</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">markerSpan</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ArrayList</span> <span class=\"n\">markerPositionDim</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ArrayList</span><span class=\"p\">();</span>\n        <span class=\"n\">markerPositionDim</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">markersDim</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ArrayList</span> <span class=\"n\">markerPropertyDim32</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ArrayList</span><span class=\"p\">();</span>\n        <span class=\"n\">markerPropertyDim32</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">markersDim</span><span class=\"p\">);</span>\n        <span class=\"n\">markerPropertyDim32</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ArrayList</span> <span class=\"n\">markerPropertyDim16</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ArrayList</span><span class=\"p\">();</span>\n        <span class=\"n\">markerPropertyDim16</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">markersDim</span><span class=\"p\">);</span>\n        <span class=\"n\">markerPropertyDim16</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ArrayList</span> <span class=\"n\">markerPropertyDim8</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ArrayList</span><span class=\"p\">();</span>\n        <span class=\"n\">markerPropertyDim8</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">markersDim</span><span class=\"p\">);</span>\n        <span class=\"n\">markerPropertyDim8</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ArrayList</span> <span class=\"n\">markerPropertyDim2</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ArrayList</span><span class=\"p\">();</span>\n        <span class=\"n\">markerPropertyDim2</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">markersDim</span><span class=\"p\">);</span>\n        <span class=\"n\">markerPropertyDim2</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ArrayList</span> <span class=\"n\">markerPropertyDim1</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ArrayList</span><span class=\"p\">();</span>\n        <span class=\"n\">markerPropertyDim1</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">markersDim</span><span class=\"p\">);</span>\n        <span class=\"n\">markerPropertyDim1</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ArrayList</span> <span class=\"n\">sampleSetDims</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ArrayList</span><span class=\"p\">();</span>\n        <span class=\"n\">sampleSetDims</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">samplesDim</span><span class=\"p\">);</span>\n        <span class=\"n\">sampleSetDims</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">sampleSpan</span><span class=\"p\">);</span>\n\n        <span class=\"sr\">//</span> <span class=\"n\">Define</span> <span class=\"n\">Marker</span> <span class=\"n\">Variables</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;markerset&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">markerGenotypeDims</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariableAttribute</span><span class=\"p\">(</span><span class=\"s\">&quot;markerset&quot;</span><span class=\"p\">,</span> <span class=\"n\">constants</span><span class=\"o\">.</span><span class=\"n\">cNetCDF</span><span class=\"o\">.</span><span class=\"n\">Attributes</span><span class=\"o\">.</span><span class=\"n\">LENGTH</span><span class=\"p\">,</span> <span class=\"n\">markerSetSize</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;marker_chromosome&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">markerPropertyDim8</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;marker_position&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">markerPropertyDim32</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;marker_position_int&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">INT</span><span class=\"p\">,</span> <span class=\"n\">markerPositionDim</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;marker_strand&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">markerPropertyDim8</span><span class=\"p\">);</span>\n\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;marker_property_1&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">markerPropertyDim1</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;marker_property_2&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">markerPropertyDim2</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;marker_property_8&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">markerPropertyDim8</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;marker_property_16&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">markerPropertyDim16</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;marker_property_32&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">markerPropertyDim32</span><span class=\"p\">);</span>\n\n        <span class=\"sr\">//</span> <span class=\"n\">Define</span> <span class=\"n\">Sample</span> <span class=\"n\">Variables</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;sampleset&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">sampleSetDims</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariableAttribute</span><span class=\"p\">(</span><span class=\"s\">&quot;sampleset&quot;</span><span class=\"p\">,</span> <span class=\"n\">constants</span><span class=\"o\">.</span><span class=\"n\">cNetCDF</span><span class=\"o\">.</span><span class=\"n\">Attributes</span><span class=\"o\">.</span><span class=\"n\">LENGTH</span><span class=\"p\">,</span> <span class=\"n\">sampleSetSize</span><span class=\"p\">);</span>\n\n        <span class=\"sr\">//</span> <span class=\"n\">Define</span> <span class=\"n\">Genotype</span> <span class=\"n\">Variables</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariable</span><span class=\"p\">(</span><span class=\"s\">&quot;genotypes&quot;</span><span class=\"p\">,</span> <span class=\"n\">DataType</span><span class=\"o\">.</span><span class=\"n\">CHAR</span><span class=\"p\">,</span> <span class=\"n\">dims</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addVariableAttribute</span><span class=\"p\">(</span><span class=\"s\">&quot;genotypes&quot;</span><span class=\"p\">,</span> <span class=\"n\">constants</span><span class=\"o\">.</span><span class=\"n\">cNetCDF</span><span class=\"o\">.</span><span class=\"n\">Attributes</span><span class=\"o\">.</span><span class=\"n\">GLOB_STRAND</span><span class=\"p\">,</span> <span class=\"s\">&quot;+/-&quot;</span><span class=\"p\">);</span>\n\n        <span class=\"sr\">//</span> <span class=\"n\">add</span> <span class=\"n\">global</span> <span class=\"n\">attributes</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addGlobalAttribute</span><span class=\"p\">(</span><span class=\"n\">constants</span><span class=\"o\">.</span><span class=\"n\">cNetCDF</span><span class=\"o\">.</span><span class=\"n\">Attributes</span><span class=\"o\">.</span><span class=\"n\">GLOB_STUDY</span><span class=\"p\">,</span> <span class=\"n\">studyId</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addGlobalAttribute</span><span class=\"p\">(</span><span class=\"n\">constants</span><span class=\"o\">.</span><span class=\"n\">cNetCDF</span><span class=\"o\">.</span><span class=\"n\">Attributes</span><span class=\"o\">.</span><span class=\"n\">GLOB_TECHNOLOGY</span><span class=\"p\">,</span> <span class=\"s\">&quot;INTERNAL&quot;</span><span class=\"p\">);</span>\n        <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">addGlobalAttribute</span><span class=\"p\">(</span><span class=\"n\">constants</span><span class=\"o\">.</span><span class=\"n\">cNetCDF</span><span class=\"o\">.</span><span class=\"n\">Attributes</span><span class=\"o\">.</span><span class=\"n\">GLOB_DESCRIPTION</span><span class=\"p\">,</span> <span class=\"s\">&quot;Matrix created by MOAPI through addition of 2 matrices&quot;</span><span class=\"p\">);</span>\n        \n        <span class=\"k\">return</span> <span class=\"n\">ncfile</span><span class=\"p\">;</span>\n\n    <span class=\"p\">}</span>\n</pre></div>\n\n}</p>\n<p>Use the above in the following way:</p>\n<p>package netCDF;</p>\n<p>import java.util.List;\nimport ucar.ma2.<em>;\nimport ucar.nc2.</em>;\nimport java.io.IOException;</p>\n<p>/<em><em>\n </em>\n * @author Fernando Mu\u00f1iz Fernandez\n * IBE, Institute of Evolutionary Biology (UPF-CSIC)\n * CEXS-UPF-PRBB\n * \n * THIS TO GENERATE A netCDF-3 GENOTYPE DB\n </em>/</p>\n<p>public class TestWriteNetcdf {\n<div class=\"highlight\"><pre>    \n    <span class=\"n\">public</span> <span class=\"n\">static</span> <span class=\"n\">void</span> <span class=\"n\">main</span><span class=\"p\">(</span><span class=\"n\">String</span><span class=\"o\">[]</span> <span class=\"n\">arg</span><span class=\"p\">)</span> <span class=\"n\">throws</span> <span class=\"n\">InvalidRangeException</span><span class=\"p\">,</span> <span class=\"n\">IOException</span> <span class=\"p\">{</span>\n        \n        <span class=\"n\">NetcdfFileWriteable</span> <span class=\"n\">ncfile</span> <span class=\"o\">=</span> <span class=\"n\">netCDF</span><span class=\"o\">.</span><span class=\"n\">CreateNetcdf</span><span class=\"o\">.</span><span class=\"n\">setDimsAndAttributes</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> \n                                                                          <span class=\"s\">&quot;INTERNAL&quot;</span><span class=\"p\">,</span> \n                                                                          <span class=\"s\">&quot;test in TestWriteNetcdf&quot;</span><span class=\"p\">,</span> \n                                                                          <span class=\"s\">&quot;+/-&quot;</span><span class=\"p\">,</span> \n                                                                          <span class=\"mi\">5</span><span class=\"p\">,</span>\n                                                                          <span class=\"mi\">10</span><span class=\"p\">);</span>\n                \n        <span class=\"sr\">//</span> <span class=\"n\">create</span> <span class=\"n\">the</span> <span class=\"n\">file</span>\n        <span class=\"n\">try</span> <span class=\"p\">{</span>\n            <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">create</span><span class=\"p\">();</span>\n        <span class=\"p\">}</span> <span class=\"n\">catch</span> <span class=\"p\">(</span><span class=\"n\">IOException</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">System</span><span class=\"o\">.</span><span class=\"n\">err</span><span class=\"o\">.</span><span class=\"n\">println</span><span class=\"p\">(</span><span class=\"s\">&quot;ERROR creating file &quot;</span><span class=\"o\">+</span><span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">getLocation</span><span class=\"p\">()</span><span class=\"o\">+</span><span class=\"s\">&quot;\\n&quot;</span><span class=\"o\">+</span><span class=\"n\">e</span><span class=\"p\">);</span>\n        <span class=\"p\">}</span>\n        \n        \n        <span class=\"sr\">//////////////</span> <span class=\"n\">FILL</span><span class=\"err\">&#39;</span><span class=\"n\">ER</span> <span class=\"n\">UP</span><span class=\"o\">!</span> <span class=\"sr\">////////////////</span>\n        <span class=\"n\">List</span><span class=\"sr\">&lt;Dimension&gt;</span> <span class=\"n\">dims</span> <span class=\"o\">=</span> <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">getDimensions</span><span class=\"p\">();</span>\n        <span class=\"n\">Dimension</span> <span class=\"n\">samplesDim</span> <span class=\"o\">=</span> <span class=\"n\">dims</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n        <span class=\"n\">Dimension</span> <span class=\"n\">markersDim</span> <span class=\"o\">=</span> <span class=\"n\">dims</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n        <span class=\"n\">Dimension</span> <span class=\"n\">markerSpanDim</span> <span class=\"o\">=</span> <span class=\"n\">dims</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">);</span>\n        \n        <span class=\"n\">ArrayChar</span> <span class=\"n\">charArray</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">ArrayChar</span><span class=\"o\">.</span><span class=\"n\">D3</span><span class=\"p\">(</span><span class=\"n\">samplesDim</span><span class=\"o\">.</span><span class=\"n\">getLength</span><span class=\"p\">(),</span><span class=\"n\">markersDim</span><span class=\"o\">.</span><span class=\"n\">getLength</span><span class=\"p\">(),</span><span class=\"n\">markerSpanDim</span><span class=\"o\">.</span><span class=\"n\">getLength</span><span class=\"p\">());</span>\n        <span class=\"nb\">int</span> <span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">j</span><span class=\"p\">;</span>\n        <span class=\"n\">Index</span> <span class=\"n\">ima</span> <span class=\"o\">=</span> <span class=\"n\">charArray</span><span class=\"o\">.</span><span class=\"n\">getIndex</span><span class=\"p\">();</span>\n        \n        \n        <span class=\"nb\">int</span> <span class=\"n\">method</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">;</span>\n        <span class=\"n\">switch</span> <span class=\"p\">(</span><span class=\"n\">method</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"k\">case</span> <span class=\"mi\">1</span><span class=\"p\">:</span> \n                <span class=\"sr\">//</span> <span class=\"n\">METHOD</span> <span class=\"mi\">1</span><span class=\"p\">:</span> <span class=\"n\">Feed</span> <span class=\"n\">the</span> <span class=\"n\">complete</span> <span class=\"n\">genotype</span> <span class=\"n\">in</span> <span class=\"n\">one</span> <span class=\"n\">go</span>\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">samplesDim</span><span class=\"o\">.</span><span class=\"n\">getLength</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n                    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">j</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">j</span><span class=\"o\">&lt;</span><span class=\"n\">markersDim</span><span class=\"o\">.</span><span class=\"n\">getLength</span><span class=\"p\">();</span> <span class=\"n\">j</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n                        <span class=\"n\">char</span> <span class=\"n\">c</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">char</span><span class=\"p\">)</span> <span class=\"p\">((</span><span class=\"n\">char</span><span class=\"p\">)</span> <span class=\"n\">j</span> <span class=\"o\">+</span> <span class=\"mi\">65</span><span class=\"p\">);</span>\n                        <span class=\"n\">String</span> <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"n\">Character</span><span class=\"o\">.</span><span class=\"n\">toString</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">Character</span><span class=\"o\">.</span><span class=\"n\">toString</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">);</span>\n                        <span class=\"n\">charArray</span><span class=\"o\">.</span><span class=\"n\">setString</span><span class=\"p\">(</span><span class=\"n\">ima</span><span class=\"o\">.</span><span class=\"n\">set</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">j</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">),</span><span class=\"n\">s</span><span class=\"p\">);</span>\n                        <span class=\"n\">System</span><span class=\"o\">.</span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">println</span><span class=\"p\">(</span><span class=\"s\">&quot;SNP: &quot;</span><span class=\"o\">+</span><span class=\"n\">i</span><span class=\"p\">);</span>\n                    <span class=\"p\">}</span>\n                <span class=\"p\">}</span>\n                <span class=\"n\">break</span><span class=\"p\">;</span>\n            <span class=\"k\">case</span> <span class=\"mi\">2</span><span class=\"p\">:</span> \n                <span class=\"sr\">//</span><span class=\"n\">METHOD</span> <span class=\"mi\">2</span><span class=\"p\">:</span> <span class=\"n\">One</span> <span class=\"n\">snp</span> <span class=\"n\">at</span> <span class=\"n\">a</span> <span class=\"nb\">time</span> <span class=\"o\">-&gt;</span> <span class=\"n\">feed</span> <span class=\"n\">in</span> <span class=\"n\">all</span> <span class=\"n\">samples</span>\n                <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">i</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"n\">i</span><span class=\"o\">&lt;</span><span class=\"n\">markersDim</span><span class=\"o\">.</span><span class=\"n\">getLength</span><span class=\"p\">();</span> <span class=\"n\">i</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n                    <span class=\"n\">charArray</span><span class=\"o\">.</span><span class=\"n\">setString</span><span class=\"p\">(</span><span class=\"n\">ima</span><span class=\"o\">.</span><span class=\"n\">set</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"s\">&quot;s&quot;</span><span class=\"o\">+</span><span class=\"n\">i</span><span class=\"o\">+</span><span class=\"s\">&quot;I0&quot;</span><span class=\"p\">);</span>\n                    <span class=\"n\">System</span><span class=\"o\">.</span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">println</span><span class=\"p\">(</span><span class=\"s\">&quot;SNP: &quot;</span><span class=\"o\">+</span><span class=\"n\">i</span><span class=\"p\">);</span>\n                <span class=\"p\">}</span>\n                <span class=\"n\">break</span><span class=\"p\">;</span>\n            <span class=\"k\">case</span> <span class=\"mi\">3</span><span class=\"p\">:</span> \n                <span class=\"sr\">//</span><span class=\"n\">METHOD</span> <span class=\"mi\">3</span><span class=\"p\">:</span> <span class=\"n\">One</span> <span class=\"n\">sample</span> <span class=\"n\">at</span> <span class=\"n\">a</span> <span class=\"nb\">time</span> <span class=\"o\">-&gt;</span> <span class=\"n\">feed</span> <span class=\"n\">in</span> <span class=\"n\">all</span> <span class=\"n\">snps</span>\n                <span class=\"n\">break</span><span class=\"p\">;</span>\n        <span class=\"p\">}</span>\n        \n        \n        \n        <span class=\"nb\">int</span><span class=\"o\">[]</span> <span class=\"n\">offsetOrigin</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nb\">int</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">];</span> <span class=\"sr\">//</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span>\n        <span class=\"n\">try</span> <span class=\"p\">{</span>\n            <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"nb\">write</span><span class=\"p\">(</span><span class=\"s\">&quot;genotypes&quot;</span><span class=\"p\">,</span> <span class=\"n\">offsetOrigin</span><span class=\"p\">,</span> <span class=\"n\">charArray</span><span class=\"p\">);</span>\n            <span class=\"sr\">//</span><span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"nb\">write</span><span class=\"p\">(</span><span class=\"s\">&quot;genotype&quot;</span><span class=\"p\">,</span> <span class=\"n\">origin</span><span class=\"p\">,</span> <span class=\"n\">A</span><span class=\"p\">);</span>\n        <span class=\"p\">}</span> <span class=\"n\">catch</span> <span class=\"p\">(</span><span class=\"n\">IOException</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">System</span><span class=\"o\">.</span><span class=\"n\">err</span><span class=\"o\">.</span><span class=\"n\">println</span><span class=\"p\">(</span><span class=\"s\">&quot;ERROR writing file&quot;</span><span class=\"p\">);</span>\n        <span class=\"p\">}</span> <span class=\"n\">catch</span> <span class=\"p\">(</span><span class=\"n\">InvalidRangeException</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">e</span><span class=\"o\">.</span><span class=\"n\">printStackTrace</span><span class=\"p\">();</span>\n        <span class=\"p\">}</span>\n        \n        <span class=\"sr\">//</span> <span class=\"nb\">close</span> <span class=\"n\">the</span> <span class=\"n\">file</span>\n        <span class=\"n\">try</span> <span class=\"p\">{</span>\n            <span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"nb\">close</span><span class=\"p\">();</span>\n        <span class=\"p\">}</span> <span class=\"n\">catch</span> <span class=\"p\">(</span><span class=\"n\">IOException</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">System</span><span class=\"o\">.</span><span class=\"n\">err</span><span class=\"o\">.</span><span class=\"n\">println</span><span class=\"p\">(</span><span class=\"s\">&quot;ERROR creating file &quot;</span><span class=\"o\">+</span><span class=\"n\">ncfile</span><span class=\"o\">.</span><span class=\"n\">getLocation</span><span class=\"p\">()</span><span class=\"o\">+</span><span class=\"s\">&quot;\\n&quot;</span><span class=\"o\">+</span><span class=\"n\">e</span><span class=\"p\">);</span>\n        <span class=\"p\">}</span>\n\n    <span class=\"p\">}</span>\n</pre></div>\n\n}</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 1, "parent": 69, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:16", "slug": "a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 41}}, {"pk": 75, "model": "server.post", "fields": {"rght": 17, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 14:44:01", "lft": 10, "post_type": 109787, "score": 3, "title": "A: Site use guidelines", "unanswered": false, "content": "This is an excellent initiative: congratulations and thank you for setting it up!\n\nI guess this site will be all the more useful as there are more contributers... So I guess that good questions for the administrator(s) of this site are: \n\n - Do you have a plan for advertising this site/attracting new Users?\n - How can the Users help?\n\n", "comment_count": 3, "html": "<p>This is an excellent initiative: congratulations and thank you for setting it up!</p>\n<p>I guess this site will be all the more useful as there are more contributers... So I guess that good questions for the administrator(s) of this site are: </p>\n<ul>\n<li>Do you have a plan for advertising this site/attracting new Users?</li>\n<li>How can the Users help?</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 1, "parent": 1, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-site-use-guidelines", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 76, "model": "server.post", "fields": {"rght": 8, "author": 29, "answer_accepted": true, "tag_string": "compilation taverna plugin maven workflow", "creation_date": "2010-02-26 15:37:25", "lft": 1, "post_type": 164033, "score": 4, "title": "Looking for a 'Hello world\" plugin for Taverna.", "unanswered": false, "content": "Hi all,\nI'd like to create a very simple plugin for [Taverna 2.0][1], something very simple like like implementing a 'convertDnaToRna'. There is already some source code that can be found on the net e.g. Egon Willighagen's code at [http://github.com/egonw/cdk-taverna][2] but it requires to know **Maven** and.... I'm too **lazy** :-)\n\nHow can I implement this kind of simple plugin without maven ? ( I *just* want to compile, package & create the right XML config files)\n\n\nThanks !\n\n  [1]: http://www.taverna.org.uk/\n  [2]: http://github.com/egonw/cdk-taverna", "comment_count": 0, "html": "<p>Hi all,\nI'd like to create a very simple plugin for <a href=\"http://www.taverna.org.uk/\">Taverna 2.0</a>, something very simple like like implementing a 'convertDnaToRna'. There is already some source code that can be found on the net e.g. Egon Willighagen's code at <a href=\"http://github.com/egonw/cdk-taverna\">http://github.com/egonw/cdk-taverna</a> but it requires to know <strong>Maven</strong> and.... I'm too <strong>lazy</strong> :-)</p>\n<p>How can I implement this kind of simple plugin without maven ? ( I <em>just</em> want to compile, package &amp; create the right XML config files)</p>\n<p>Thanks !</p>", "child_count": 0, "closed": false, "tree_id": 24, "revision_count": 3, "parent": null, "views": 164, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:30", "slug": "looking-for-a-hello-world-plugin-for-taverna", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [28, 49, 50, 51, 52], "lastedit_user": 29}}, {"pk": 77, "model": "server.post", "fields": {"rght": 6, "author": 43, "answer_accepted": true, "tag_string": "bed conversion format", "creation_date": "2010-02-26 15:49:18", "lft": 1, "post_type": 164033, "score": 2, "title": "How do I convert an Illumina export file to BED?", "unanswered": false, "content": "I have some illumina data generated from the latest version of the illumina pipeline (1.6.0) I need to convert my data into BED to view in ucsc genome browser.\n\nThis seems like it should be a fairly common task, however, I am unable to find any scripts to convert my data.", "comment_count": 0, "html": "<p>I have some illumina data generated from the latest version of the illumina pipeline (1.6.0) I need to convert my data into BED to view in ucsc genome browser.</p>\n<p>This seems like it should be a fairly common task, however, I am unable to find any scripts to convert my data.</p>", "child_count": 0, "closed": false, "tree_id": 25, "revision_count": 2, "parent": null, "views": 886, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:27", "slug": "how-do-i-convert-an-illumina-export-file-to-bed", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [2, 21, 53], "lastedit_user": 22}}, {"pk": 78, "model": "server.post", "fields": {"rght": 3, "author": 9, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 16:15:18", "lft": 2, "post_type": 109787, "score": 2, "title": "A: How do I convert an Illumina export file to BED?", "unanswered": false, "content": "I found a script [on another site][1], Uses perl but I have not checked for correctness:\n \n    #!/usr/bin/perl\n    \n    use strict;\n    use warnings;\n    use IO::File;\n    \n    my $filename = shift @ARGV;\n    die \"Usage\\n\\tperl sorted2bed.pl s_X_sorted.txt > s_X_sorted.bed\\n\" unless $filename;\n    chomp $filename;\n    \n    my $fh = new IO::File;\n    $fh->open(\"< $filename\") or die \"Can't open file $filename for reading: $!\";\n    \n    my $count = 1;\n    while(my $line = <$fh>){\n       warn \"Line $count\\n\" if $count%1000 == 0;\n       $count++;\n       my @line = split \"\\t\", $line;\n       my $chr = $line[10];\n       $chr =~ s/(.+)\\.fa/$1/;\n       #Illumina is 1-based, BED is 0-based\n       my $start = $line[12]-1;\n       my $read = $line[8];\n       my $end = $start + length $read;\n       my $strand = $line[13] eq 'F' ? '+': '-';\n       my $score = $line[15];\n       my $bedline = \"$chr\\t$start\\t$end\\t$read\\t$score\\t$strand\\n\";\n       print $bedline;\n    }\n    $fh->close;\n    \n    warn \"Done\";\n\n\n  [1]: http://mng.iop.kcl.ac.uk/site/node/378", "comment_count": 0, "html": "<p>I found a script <a href=\"http://mng.iop.kcl.ac.uk/site/node/378\">on another site</a>, Uses perl but I have not checked for correctness:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"c1\">#!/usr/bin/perl</span>\n    \n    <span class=\"k\">use</span> <span class=\"n\">strict</span><span class=\"p\">;</span>\n    <span class=\"k\">use</span> <span class=\"n\">warnings</span><span class=\"p\">;</span>\n    <span class=\"k\">use</span> <span class=\"nn\">IO::</span><span class=\"n\">File</span><span class=\"p\">;</span>\n    \n    <span class=\"k\">my</span> <span class=\"nv\">$filename</span> <span class=\"o\">=</span> <span class=\"nb\">shift</span> <span class=\"nv\">@ARGV</span><span class=\"p\">;</span>\n    <span class=\"nb\">die</span> <span class=\"s\">&quot;Usage\\n\\tperl sorted2bed.pl s_X_sorted.txt &gt; s_X_sorted.bed\\n&quot;</span> <span class=\"k\">unless</span> <span class=\"nv\">$filename</span><span class=\"p\">;</span>\n    <span class=\"nb\">chomp</span> <span class=\"nv\">$filename</span><span class=\"p\">;</span>\n    \n    <span class=\"k\">my</span> <span class=\"nv\">$fh</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nn\">IO::</span><span class=\"n\">File</span><span class=\"p\">;</span>\n    <span class=\"nv\">$fh</span><span class=\"o\">-&gt;</span><span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s\">&quot;&lt; $filename&quot;</span><span class=\"p\">)</span> <span class=\"ow\">or</span> <span class=\"nb\">die</span> <span class=\"s\">&quot;Can&#39;t open file $filename for reading: $!&quot;</span><span class=\"p\">;</span>\n    \n    <span class=\"k\">my</span> <span class=\"nv\">$count</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">;</span>\n    <span class=\"k\">while</span><span class=\"p\">(</span><span class=\"k\">my</span> <span class=\"nv\">$line</span> <span class=\"o\">=</span> <span class=\"sr\">&lt;$fh&gt;</span><span class=\"p\">){</span>\n       <span class=\"nb\">warn</span> <span class=\"s\">&quot;Line $count\\n&quot;</span> <span class=\"k\">if</span> <span class=\"nv\">$count%1000</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n       <span class=\"nv\">$count</span><span class=\"o\">++</span><span class=\"p\">;</span>\n       <span class=\"k\">my</span> <span class=\"nv\">@line</span> <span class=\"o\">=</span> <span class=\"nb\">split</span> <span class=\"s\">&quot;\\t&quot;</span><span class=\"p\">,</span> <span class=\"nv\">$line</span><span class=\"p\">;</span>\n       <span class=\"k\">my</span> <span class=\"nv\">$chr</span> <span class=\"o\">=</span> <span class=\"nv\">$line</span><span class=\"p\">[</span><span class=\"mi\">10</span><span class=\"p\">];</span>\n       <span class=\"nv\">$chr</span> <span class=\"o\">=~</span> <span class=\"sr\">s/(.+)\\.fa/$1/</span><span class=\"p\">;</span>\n       <span class=\"c1\">#Illumina is 1-based, BED is 0-based</span>\n       <span class=\"k\">my</span> <span class=\"nv\">$start</span> <span class=\"o\">=</span> <span class=\"nv\">$line</span><span class=\"p\">[</span><span class=\"mi\">12</span><span class=\"p\">]</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">;</span>\n       <span class=\"k\">my</span> <span class=\"nv\">$read</span> <span class=\"o\">=</span> <span class=\"nv\">$line</span><span class=\"p\">[</span><span class=\"mi\">8</span><span class=\"p\">];</span>\n       <span class=\"k\">my</span> <span class=\"nv\">$end</span> <span class=\"o\">=</span> <span class=\"nv\">$start</span> <span class=\"o\">+</span> <span class=\"nb\">length</span> <span class=\"nv\">$read</span><span class=\"p\">;</span>\n       <span class=\"k\">my</span> <span class=\"nv\">$strand</span> <span class=\"o\">=</span> <span class=\"nv\">$line</span><span class=\"p\">[</span><span class=\"mi\">13</span><span class=\"p\">]</span> <span class=\"ow\">eq</span> <span class=\"s\">&#39;F&#39;</span> <span class=\"p\">?</span> <span class=\"s\">&#39;+&#39;</span><span class=\"p\">:</span> <span class=\"s\">&#39;-&#39;</span><span class=\"p\">;</span>\n       <span class=\"k\">my</span> <span class=\"nv\">$score</span> <span class=\"o\">=</span> <span class=\"nv\">$line</span><span class=\"p\">[</span><span class=\"mi\">15</span><span class=\"p\">];</span>\n       <span class=\"k\">my</span> <span class=\"nv\">$bedline</span> <span class=\"o\">=</span> <span class=\"s\">&quot;$chr\\t$start\\t$end\\t$read\\t$score\\t$strand\\n&quot;</span><span class=\"p\">;</span>\n       <span class=\"k\">print</span> <span class=\"nv\">$bedline</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n    <span class=\"nv\">$fh</span><span class=\"o\">-&gt;</span><span class=\"nb\">close</span><span class=\"p\">;</span>\n    \n    <span class=\"nb\">warn</span> <span class=\"s\">&quot;Done&quot;</span><span class=\"p\">;</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 25, "revision_count": 1, "parent": 77, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:17", "slug": "a-how-do-i-convert-an-illumina-export-file-to-bed", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 9}}, {"pk": 79, "model": "server.post", "fields": {"rght": 56, "author": 22, "answer_accepted": true, "tag_string": "general make pipeline organization", "creation_date": "2010-02-26 16:49:35", "lft": 1, "post_type": 164033, "score": 10, "title": "How to organize a pipeline of small scripts together?", "unanswered": false, "content": "In bioinformatics it is very common to end up with a lot of small scripts, each one with a different scope - plotting a chart, converting a file into another format, execute small operations - so it is very important to have a good way to clue them together, to define which should be executed before the others and so on.\n\nHow do you deal with the problem? Do you use makefiles, taverna workflows, batch scripts, or any other solution?", "comment_count": 0, "html": "<p>In bioinformatics it is very common to end up with a lot of small scripts, each one with a different scope - plotting a chart, converting a file into another format, execute small operations - so it is very important to have a good way to clue them together, to define which should be executed before the others and so on.</p>\n<p>How do you deal with the problem? Do you use makefiles, taverna workflows, batch scripts, or any other solution?</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 2, "parent": null, "views": 1272, "deleted": false, "answer_count": 22, "touch_date": "2011-11-24 14:49:31", "slug": "how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [31, 54, 55, 56], "lastedit_user": 22}}, {"pk": 80, "model": "server.post", "fields": {"rght": 7, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 16:58:09", "lft": 2, "post_type": 109787, "score": 7, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "I don't have personal experience with this package but it is something that I plan to explore in the near future:\n\n**[Ruffus ][1]** a lightweight python module to run computational pipelines. \n\n\n  [1]: http://code.google.com/p/ruffus/", "comment_count": 2, "html": "<p>I don't have personal experience with this package but it is something that I plan to explore in the near future:</p>\n<p><strong><a href=\"http://code.google.com/p/ruffus/\">Ruffus </a></strong> a lightweight python module to run computational pipelines. </p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 1, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 81, "model": "server.post", "fields": {"rght": 9, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 17:03:52", "lft": 4, "post_type": 109787, "score": 8, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "My favorite way of defining pipelines is by writing Makefiles, about which you can find [a very good introduction][1] in Software Carpentry for Bioinformatics: http://swc.scipy.org/lec/build.html .\n\nAlthough they have been originally developed for compiling programs, Makefiles allow to define which operations are needed to create each file, with a declarative syntax that it is a bit old-style but still does its job. Each Makefile is composed of a set of rules, which define operations needed to calculate a file and that can be combined together to make a pipeline. Other advantages of makefiles are conditional execution of tasks, so you can stop the execution of a pipeline and get back to it later, without having to repeat calculations. However, one of the big disadvantages of Makefiles is its old syntax... in particular, rules are identified by the names of the files that they create, and there is no such thing as 'titles' for rules, which make more tricky.\n\nI think one of the best solutions would be to use [BioMake][2], that allow to define tasks with titles that are not the name of the output files. To understand it better, look at [this example][3]: you see that each rule has a title and a series of parameters like its output, inputs, comments, etc.\n\nUnfortunately, I can't make biomake to run on my computer, as it requires very old dependencies and it is written in a very difficult perl. I have tried many alternatives and I think that [rake][4] is the one that is more close to biomake, but unfortunately I don't understand ruby's syntax. \n\nSo, I am still looking for a good alternative... Maybe one day I will have to time to re-write BioMake in python :-)\n\n\n  [1]: http://software-carpentry.org/build.html\n  [2]: http://skam.sourceforge.net/skam-intro.html\n  [3]: http://skam.sourceforge.net/skam-intro.html\n  [4]: http://rake.rubyforge.org/files/doc/rational_rdoc.html", "comment_count": 2, "html": "<p>My favorite way of defining pipelines is by writing Makefiles, about which you can find <a href=\"http://software-carpentry.org/build.html\">a very good introduction</a> in Software Carpentry for Bioinformatics: http://swc.scipy.org/lec/build.html .</p>\n<p>Although they have been originally developed for compiling programs, Makefiles allow to define which operations are needed to create each file, with a declarative syntax that it is a bit old-style but still does its job. Each Makefile is composed of a set of rules, which define operations needed to calculate a file and that can be combined together to make a pipeline. Other advantages of makefiles are conditional execution of tasks, so you can stop the execution of a pipeline and get back to it later, without having to repeat calculations. However, one of the big disadvantages of Makefiles is its old syntax... in particular, rules are identified by the names of the files that they create, and there is no such thing as 'titles' for rules, which make more tricky.</p>\n<p>I think one of the best solutions would be to use <a href=\"http://skam.sourceforge.net/skam-intro.html\">BioMake</a>, that allow to define tasks with titles that are not the name of the output files. To understand it better, look at <a href=\"http://skam.sourceforge.net/skam-intro.html\">this example</a>: you see that each rule has a title and a series of parameters like its output, inputs, comments, etc.</p>\n<p>Unfortunately, I can't make biomake to run on my computer, as it requires very old dependencies and it is written in a very difficult perl. I have tried many alternatives and I think that <a href=\"http://rake.rubyforge.org/files/doc/rational_rdoc.html\">rake</a> is the one that is more close to biomake, but unfortunately I don't understand ruby's syntax. </p>\n<p>So, I am still looking for a good alternative... Maybe one day I will have to time to re-write BioMake in python :-)</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 1, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 82, "model": "server.post", "fields": {"rght": 9, "author": 46, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 17:04:53", "lft": 6, "post_type": 109787, "score": 5, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "Since I work a lot with Python, I usually write a wrapper method that embeds the external script/program, i.e. calls it, parses its output and returns the desired information. The 'glueing' of several such methods then takes place within my Python code that calls all these wrappers. I guess that's a very common thing to do.\n\nChris", "comment_count": 1, "html": "<p>Since I work a lot with Python, I usually write a wrapper method that embeds the external script/program, i.e. calls it, parses its output and returns the desired information. The 'glueing' of several such methods then takes place within my Python code that calls all these wrappers. I guess that's a very common thing to do.</p>\n<p>Chris</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 1, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 46}}, {"pk": 83, "model": "server.post", "fields": {"rght": 7, "author": 6, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 17:16:41", "lft": 6, "post_type": 109787, "score": 6, "title": "A: Where can I get the secondary structure of a protein?", "unanswered": false, "content": "If you have the PDB file then you can use the standard tool called DSSP , it is supposed to be the gold standard for obtaining secondary structure. In case you just have sequence then I personally prefer PSIPRED , it takes evolutionary information into account to predict the secondary structure . According to CASP evaluation it is one of the best secondary structure predictor available.", "comment_count": 0, "html": "<p>If you have the PDB file then you can use the standard tool called DSSP , it is supposed to be the gold standard for obtaining secondary structure. In case you just have sequence then I personally prefer PSIPRED , it takes evolutionary information into account to predict the secondary structure . According to CASP evaluation it is one of the best secondary structure predictor available.</p>", "child_count": 0, "closed": false, "tree_id": 18, "revision_count": 1, "parent": 48, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-where-can-i-get-the-secondary-structure-of-a-protein", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 6}}, {"pk": 84, "model": "server.post", "fields": {"rght": 11, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 20:16:31", "lft": 8, "post_type": 109787, "score": 7, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "My answer would be: don't bother. I've often found that much of the scripts I write are never used again after the initial use. Therefore spending time using a complex framework that considers dependency between scripts is a waste because the results might be negative and you never visit the analysis again. Even if you do end up using the script multiple times a simple hacky bash script might be more than enough to meet the requirements.\n\nThere will however be the 1-2% of initial analyses that return a interesting result and therefore need to be expanded with more deeper investigation. I think this is the point to invest more time time in organising the project. For me I use Rake because it's simple and allows me to write in the language I'm used to (Ruby).\n\nOverall I think pragmatism is the important factor in computational biology. Just do enough to get the results you need and only invest more time when it's necessary. There's so many blind alleys in computational analysis of biological data it's not worth investing too much of your time until it's necessary.\n", "comment_count": 1, "html": "<p>My answer would be: don't bother. I've often found that much of the scripts I write are never used again after the initial use. Therefore spending time using a complex framework that considers dependency between scripts is a waste because the results might be negative and you never visit the analysis again. Even if you do end up using the script multiple times a simple hacky bash script might be more than enough to meet the requirements.</p>\n<p>There will however be the 1-2% of initial analyses that return a interesting result and therefore need to be expanded with more deeper investigation. I think this is the point to invest more time time in organising the project. For me I use Rake because it's simple and allows me to write in the language I'm used to (Ruby).</p>\n<p>Overall I think pragmatism is the important factor in computational biology. Just do enough to get the results you need and only invest more time when it's necessary. There's so many blind alleys in computational analysis of biological data it's not worth investing too much of your time until it's necessary.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 1, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 85, "model": "server.post", "fields": {"rght": 13, "author": 23, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 20:27:32", "lft": 10, "post_type": 109787, "score": 2, "title": "A: What is the best way to share scripts between members of a lab?", "unanswered": false, "content": "My lab uses a network-attached storage unit which every Linux workstation mounts by NFS at startup. It was reasonably cheap -- a couple hundred dollars per TB. We also keep copies of public databases on there. We put data sets on there as we're working on them, and also put the more important scripts in a Mercurial repositiory.\n\nAs Marcos and Istvan mentioned, a wiki integrated with your VCS would be wise, and Trac (trac.edgewall.org) is the obvious choice for that.", "comment_count": 1, "html": "<p>My lab uses a network-attached storage unit which every Linux workstation mounts by NFS at startup. It was reasonably cheap -- a couple hundred dollars per TB. We also keep copies of public databases on there. We put data sets on there as we're working on them, and also put the more important scripts in a Mercurial repositiory.</p>\n<p>As Marcos and Istvan mentioned, a wiki integrated with your VCS would be wise, and Trac (trac.edgewall.org) is the obvious choice for that.</p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 1, "parent": 58, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 23}}, {"pk": 86, "model": "server.post", "fields": {"rght": 13, "author": 6, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 20:44:04", "lft": 12, "post_type": 109787, "score": 3, "title": "A: What is the best way to share scripts between members of a lab?", "unanswered": false, "content": "This might be useful .\n\n[A Quick Guide to Organizing Computational Biology Projects][1]\n\n\n  [1]: http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1000424", "comment_count": 0, "html": "<p>This might be useful .</p>\n<p><a href=\"http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1000424\">A Quick Guide to Organizing Computational Biology Projects</a></p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 1, "parent": 58, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 6}}, {"pk": 87, "model": "server.post", "fields": {"rght": 11, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-27 21:00:56", "lft": 10, "post_type": 109787, "score": 2, "title": "A: Using HDF5 to store  bio-data", "unanswered": false, "content": "There is also a Perl binding to HDF5: PDL::IO::HDF5\n\nhttp://search.cpan.org/~cerney/PDL-IO-HDF5-0.5/\nThis requires the Perl Data Language (PDL) package. The way, data-structures can be handled, sub-ranges of data can be defined  an data can be manipulated is actually very elegant in PDL such that computational code can profit from PDLs vectorized style of writing expressions.\n\nThe same is true for R and the hdf5 package: http://cran.r-project.org/web/packages/hdf5/index.html\n\nCode examples are in the package documentations of both, the R-hdf5 package documentation is quite little though.\n\nBoth of these language bindings might be a very efficient way to read and write HDF5 files.\n\nThere are also APIs in Fortran, Java, Python, Matlab, C, or C++. So it might make sense to select the language and define the type of data you wish to store first. ", "comment_count": 0, "html": "<p>There is also a Perl binding to HDF5: PDL::IO::HDF5</p>\n<p>http://search.cpan.org/~cerney/PDL-IO-HDF5-0.5/\nThis requires the Perl Data Language (PDL) package. The way, data-structures can be handled, sub-ranges of data can be defined  an data can be manipulated is actually very elegant in PDL such that computational code can profit from PDLs vectorized style of writing expressions.</p>\n<p>The same is true for R and the hdf5 package: http://cran.r-project.org/web/packages/hdf5/index.html</p>\n<p>Code examples are in the package documentations of both, the R-hdf5 package documentation is quite little though.</p>\n<p>Both of these language bindings might be a very efficient way to read and write HDF5 files.</p>\n<p>There are also APIs in Fortran, Java, Python, Matlab, C, or C++. So it might make sense to select the language and define the type of data you wish to store first. </p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 1, "parent": 69, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:17", "slug": "a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 88, "model": "server.post", "fields": {"rght": 8, "author": 22, "answer_accepted": true, "tag_string": "general agile good team", "creation_date": "2010-03-01 13:51:12", "lft": 1, "post_type": 164033, "score": 3, "title": "Agile programming for bioinformaticians - any suggestions?", "unanswered": false, "content": "I am planning to prepare a talk for my workmates, to introduce them the basics of some agile programming methodology, which I think could give us good ideas to improve our working as a team.\n\nMy idea was to take inspiration from [extreme programming][1] and explain the rules I like the most: use of [A7 cards to write tasks][2], [release planning][3] every 3 week, stand-up meeting every day, [Move people around][4], [unit tests first][5], [pair programming][6] (at least introduce the concept), [collective ownership][7].\n\nIt is difficult for me to explain these rules as I don't have much direct experience with, apart for few exceptions, and it is even more difficult because I will have to explain them to people who are not comfortable with programming and with software engineering in general.\nHowever, I also think that I have to prepare this talk early and it will be much more difficult if I wait too much.\n\nDo you have any experience with what I am talking about? Do you have any advice to give me, or can you recommend me a book or a practice that I could explain along with extreme programming?\n\n\n  [1]: http://www.extremeprogramming.org/rules/\n  [2]: http://www.extremeprogramming.org/example/crcsim.html\n  [3]: http://www.extremeprogramming.org/rules/planninggame.html\n  [4]: http://www.extremeprogramming.org/rules/movepeople.html\n  [5]: http://www.extremeprogramming.org/rules/testfirst.html\n  [6]: http://www.extremeprogramming.org/rules/pair.html\n  [7]: http://www.extremeprogramming.org/rules/collective.html", "comment_count": 0, "html": "<p>I am planning to prepare a talk for my workmates, to introduce them the basics of some agile programming methodology, which I think could give us good ideas to improve our working as a team.</p>\n<p>My idea was to take inspiration from <a href=\"http://www.extremeprogramming.org/rules/\">extreme programming</a> and explain the rules I like the most: use of <a href=\"http://www.extremeprogramming.org/example/crcsim.html\">A7 cards to write tasks</a>, <a href=\"http://www.extremeprogramming.org/rules/planninggame.html\">release planning</a> every 3 week, stand-up meeting every day, <a href=\"http://www.extremeprogramming.org/rules/movepeople.html\">Move people around</a>, <a href=\"http://www.extremeprogramming.org/rules/testfirst.html\">unit tests first</a>, <a href=\"http://www.extremeprogramming.org/rules/pair.html\">pair programming</a> (at least introduce the concept), <a href=\"http://www.extremeprogramming.org/rules/collective.html\">collective ownership</a>.</p>\n<p>It is difficult for me to explain these rules as I don't have much direct experience with, apart for few exceptions, and it is even more difficult because I will have to explain them to people who are not comfortable with programming and with software engineering in general.\nHowever, I also think that I have to prepare this talk early and it will be much more difficult if I wait too much.</p>\n<p>Do you have any experience with what I am talking about? Do you have any advice to give me, or can you recommend me a book or a practice that I could explain along with extreme programming?</p>", "child_count": 0, "closed": false, "tree_id": 27, "revision_count": 3, "parent": null, "views": 288, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:31", "slug": "agile-programming-for-bioinformaticians-any-suggestions", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [31, 57, 59, 193], "lastedit_user": 22}}, {"pk": 89, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 14:06:55", "lft": 2, "post_type": 109787, "score": 3, "title": "A: Agile programming for bioinformaticians - any suggestions?", "unanswered": false, "content": "\n\nI think the approach is unsuited for individuals who are not comfortable with programming in general. There is a long way to go until someone becomes confident in their abilities. Before that this approach is not only ineffective, it might be even be detrimental.\n\nInstead what helps most is transparency. Everyone needs to write code in a source code repository that can be viewed, commented and verified. People should become familiar with testing, code coverage, and continuous integration. \n\nSomething to read: [Mythical Man Month][1].\n\n  [1]: http://en.wikipedia.org/wiki/The_Mythical_Man-Month", "comment_count": 0, "html": "<p>I think the approach is unsuited for individuals who are not comfortable with programming in general. There is a long way to go until someone becomes confident in their abilities. Before that this approach is not only ineffective, it might be even be detrimental.</p>\n<p>Instead what helps most is transparency. Everyone needs to write code in a source code repository that can be viewed, commented and verified. People should become familiar with testing, code coverage, and continuous integration. </p>\n<p>Something to read: <a href=\"http://en.wikipedia.org/wiki/The_Mythical_Man-Month\">Mythical Man Month</a>.</p>", "child_count": 0, "closed": false, "tree_id": 27, "revision_count": 1, "parent": 88, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-agile-programming-for-bioinformaticians-any-suggestions", "lastedit_date": "2011-11-24 14:48:31", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 90, "model": "server.post", "fields": {"rght": 16, "author": 9, "answer_accepted": false, "tag_string": "sequence biopython python", "creation_date": "2010-03-01 14:26:09", "lft": 1, "post_type": 164033, "score": 0, "title": "Computing the reverse and complement of a sequence with Biopython", "unanswered": false, "content": "An example that computes the reverse complement of a sequence with [BioPython][1]\n\n    #\n    # Reverse complement example with BioPython\n    #\n    \n    from Bio.Seq import Seq\n    \n    # a separate function to reverse strings (or other iterables)\n    def rev(it):\n        \"Reverses an interable and returns it as a string\"\n        return ''.join(reversed(it))\n    \n    # create a Seq class instance\n    dna = Seq(\"ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\")\n    \n    # original DNA\n    print type(dna)\n    print dna\n    \n    # reverse complement DNA, returns a new sequence\n    print dna.reverse_complement()\n    \n    # currently there is no direct way to just reverse a sequence\n    # we need to do a little extra work\n    \n    rseq = rev(str(dna))\n    rdna = Seq(rseq)\n    \n    # reversed sequence\n    print rdna\n    \n    # to complement DNA, returns a new sequence\n    print dna.complement()\n\nProduces the following output:\n\n    <class 'Bio.Seq.Seq'>\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA\n    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC\n\n\n   [1]: http://biopython.org/wiki/Main_Page", "comment_count": 0, "html": "<p>An example that computes the reverse complement of a sequence with <a href=\"http://biopython.org/wiki/Main_Page\">BioPython</a></p>\n<p><div class=\"highlight\"><pre>    <span class=\"c1\">#</span>\n    <span class=\"c1\"># Reverse complement example with BioPython</span>\n    <span class=\"c1\">#</span>\n    \n    <span class=\"n\">from</span> <span class=\"n\">Bio</span><span class=\"o\">.</span><span class=\"n\">Seq</span> <span class=\"nb\">import</span> <span class=\"n\">Seq</span>\n    \n    <span class=\"c1\"># a separate function to reverse strings (or other iterables)</span>\n    <span class=\"n\">def</span> <span class=\"n\">rev</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">):</span>\n        <span class=\"s\">&quot;Reverses an interable and returns it as a string&quot;</span>\n        <span class=\"k\">return</span> <span class=\"s\">&#39;&#39;</span><span class=\"o\">.</span><span class=\"nb\">join</span><span class=\"p\">(</span><span class=\"n\">reversed</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">))</span>\n    \n    <span class=\"c1\"># create a Seq class instance</span>\n    <span class=\"n\">dna</span> <span class=\"o\">=</span> <span class=\"n\">Seq</span><span class=\"p\">(</span><span class=\"s\">&quot;ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG&quot;</span><span class=\"p\">)</span>\n    \n    <span class=\"c1\"># original DNA</span>\n    <span class=\"k\">print</span> <span class=\"n\">type</span><span class=\"p\">(</span><span class=\"n\">dna</span><span class=\"p\">)</span>\n    <span class=\"k\">print</span> <span class=\"n\">dna</span>\n    \n    <span class=\"c1\"># reverse complement DNA, returns a new sequence</span>\n    <span class=\"k\">print</span> <span class=\"n\">dna</span><span class=\"o\">.</span><span class=\"n\">reverse_complement</span><span class=\"p\">()</span>\n    \n    <span class=\"c1\"># currently there is no direct way to just reverse a sequence</span>\n    <span class=\"c1\"># we need to do a little extra work</span>\n    \n    <span class=\"n\">rseq</span> <span class=\"o\">=</span> <span class=\"n\">rev</span><span class=\"p\">(</span><span class=\"n\">str</span><span class=\"p\">(</span><span class=\"n\">dna</span><span class=\"p\">))</span>\n    <span class=\"n\">rdna</span> <span class=\"o\">=</span> <span class=\"n\">Seq</span><span class=\"p\">(</span><span class=\"n\">rseq</span><span class=\"p\">)</span>\n    \n    <span class=\"c1\"># reversed sequence</span>\n    <span class=\"k\">print</span> <span class=\"n\">rdna</span>\n    \n    <span class=\"c1\"># to complement DNA, returns a new sequence</span>\n    <span class=\"k\">print</span> <span class=\"n\">dna</span><span class=\"o\">.</span><span class=\"n\">complement</span><span class=\"p\">()</span>\n</pre></div>\n</p>\n<p>Produces the following output:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"o\">&lt;</span><span class=\"n\">class</span> <span class=\"s\">&#39;Bio.Seq.Seq&#39;</span><span class=\"o\">&gt;</span>\n    <span class=\"n\">ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG</span>\n    <span class=\"n\">CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT</span>\n    <span class=\"n\">GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA</span>\n    <span class=\"n\">TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 28, "revision_count": 3, "parent": null, "views": 933, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:31", "slug": "computing-the-reverse-and-complement-of-a-sequence-with-biopython", "lastedit_date": "2011-11-24 14:48:31", "level": 0, "post_accepted": false, "tag_set": [11, 40, 60], "lastedit_user": 9}}, {"pk": 91, "model": "server.post", "fields": {"rght": 7, "author": 38, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 14:41:28", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Agile programming for bioinformaticians - any suggestions?", "unanswered": false, "content": "I would suggest to have a look at [Scrum][1], too. Certain parts would help not only bioinformations. For example estimating the time expenditure of tasks and the resulting burn down charts can be really helpful to see if something is stuck especially when working together on bigger projects.The daily scrum reports helps to meditate why who is doing what and offers a platform to discuss problems.\n\n\n  [1]: http://en.wikipedia.org/wiki/Scrum_(development)", "comment_count": 1, "html": "<p>I would suggest to have a look at <a href=\"http://en.wikipedia.org/wiki/Scrum_(development)\">Scrum</a>, too. Certain parts would help not only bioinformations. For example estimating the time expenditure of tasks and the resulting burn down charts can be really helpful to see if something is stuck especially when working together on bigger projects.The daily scrum reports helps to meditate why who is doing what and offers a platform to discuss problems.</p>", "child_count": 0, "closed": false, "tree_id": 27, "revision_count": 1, "parent": 88, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-agile-programming-for-bioinformaticians-any-suggestions", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 38}}, {"pk": 92, "model": "server.post", "fields": {"rght": 12, "author": 9, "answer_accepted": false, "tag_string": "python pygr use sequence", "creation_date": "2010-03-01 14:48:25", "lft": 1, "post_type": 164033, "score": 0, "title": "Computing the reverse and complement of a sequence with Pygr", "unanswered": false, "content": "Computing the reverse complement with the [Pygr][1] bioinformatics framework:\n\n    #\n    # Reverse complement example with pygr\n    #\n    \n    from pygr.sequence import Sequence\n    \n    # needs a separate function to reverse strings\n    def rev(it):\n        \"Reverses an interable and returns it as a string\"\n        return ''.join(reversed(it))\n    \n    # original sequence as as string\n    seq = 'ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG'\n    \n    # create a Sequence class  instance named bobo\n    dna = Sequence(seq,'bobo')\n    \n    # sequence class' type and content\n    print type(dna)\n    print dna\n    \n    # the -operator reverse complements the DNA, returns a new sequence\n    print -dna\n    \n    # to reverse the DNA, reverse the input data\n    rdna = Sequence( rev(seq),'bobo')\n    print rdna\n    \n    # to complement the DNA reverse complement, then reverse again\n    cseq = rev(str(-dna))\n    cdna = Sequence(cseq,'bobo')\n\n    print cdna\n\nProduces the output:\n\n    <class 'pygr.sequence.Sequence'>\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA\n    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC\n\n  [1]: http://code.google.com/p/pygr/wiki/PygrDocumentation\n\n", "comment_count": 2, "html": "<p>Computing the reverse complement with the <a href=\"http://code.google.com/p/pygr/wiki/PygrDocumentation\">Pygr</a> bioinformatics framework:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"c1\">#</span>\n    <span class=\"c1\"># Reverse complement example with pygr</span>\n    <span class=\"c1\">#</span>\n    \n    <span class=\"n\">from</span> <span class=\"n\">pygr</span><span class=\"o\">.</span><span class=\"n\">sequence</span> <span class=\"nb\">import</span> <span class=\"n\">Sequence</span>\n    \n    <span class=\"c1\"># needs a separate function to reverse strings</span>\n    <span class=\"n\">def</span> <span class=\"n\">rev</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">):</span>\n        <span class=\"s\">&quot;Reverses an interable and returns it as a string&quot;</span>\n        <span class=\"k\">return</span> <span class=\"s\">&#39;&#39;</span><span class=\"o\">.</span><span class=\"nb\">join</span><span class=\"p\">(</span><span class=\"n\">reversed</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">))</span>\n    \n    <span class=\"c1\"># original sequence as as string</span>\n    <span class=\"n\">seq</span> <span class=\"o\">=</span> <span class=\"s\">&#39;ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG&#39;</span>\n    \n    <span class=\"c1\"># create a Sequence class  instance named bobo</span>\n    <span class=\"n\">dna</span> <span class=\"o\">=</span> <span class=\"n\">Sequence</span><span class=\"p\">(</span><span class=\"n\">seq</span><span class=\"p\">,</span><span class=\"s\">&#39;bobo&#39;</span><span class=\"p\">)</span>\n    \n    <span class=\"c1\"># sequence class&#39; type and content</span>\n    <span class=\"k\">print</span> <span class=\"n\">type</span><span class=\"p\">(</span><span class=\"n\">dna</span><span class=\"p\">)</span>\n    <span class=\"k\">print</span> <span class=\"n\">dna</span>\n    \n    <span class=\"c1\"># the -operator reverse complements the DNA, returns a new sequence</span>\n    <span class=\"k\">print</span> <span class=\"o\">-</span><span class=\"n\">dna</span>\n    \n    <span class=\"c1\"># to reverse the DNA, reverse the input data</span>\n    <span class=\"n\">rdna</span> <span class=\"o\">=</span> <span class=\"n\">Sequence</span><span class=\"p\">(</span> <span class=\"n\">rev</span><span class=\"p\">(</span><span class=\"n\">seq</span><span class=\"p\">),</span><span class=\"s\">&#39;bobo&#39;</span><span class=\"p\">)</span>\n    <span class=\"k\">print</span> <span class=\"n\">rdna</span>\n    \n    <span class=\"c1\"># to complement the DNA reverse complement, then reverse again</span>\n    <span class=\"n\">cseq</span> <span class=\"o\">=</span> <span class=\"n\">rev</span><span class=\"p\">(</span><span class=\"n\">str</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"n\">dna</span><span class=\"p\">))</span>\n    <span class=\"n\">cdna</span> <span class=\"o\">=</span> <span class=\"n\">Sequence</span><span class=\"p\">(</span><span class=\"n\">cseq</span><span class=\"p\">,</span><span class=\"s\">&#39;bobo&#39;</span><span class=\"p\">)</span>\n\n    <span class=\"k\">print</span> <span class=\"n\">cdna</span>\n</pre></div>\n</p>\n<p>Produces the output:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"o\">&lt;</span><span class=\"n\">class</span> <span class=\"s\">&#39;pygr.sequence.Sequence&#39;</span><span class=\"o\">&gt;</span>\n    <span class=\"n\">ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG</span>\n    <span class=\"n\">CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT</span>\n    <span class=\"n\">GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA</span>\n    <span class=\"n\">TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC</span>\n</pre></div>\n</p>", "child_count": 0, "closed": true, "tree_id": 29, "revision_count": 5, "parent": null, "views": 241, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:22", "slug": "computing-the-reverse-and-complement-of-a-sequence-with-pygr", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [11, 40, 61, 192], "lastedit_user": 9}}, {"pk": 93, "model": "server.post", "fields": {"rght": 7, "author": 44, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 14:51:52", "lft": 6, "post_type": 109787, "score": 4, "title": "A: Recommend easy to use microarray clustering software", "unanswered": false, "content": "Possibly related:\nhttp://mmc.gnets.ncsu.edu/", "comment_count": 0, "html": "<p>Possibly related:\nhttp://mmc.gnets.ncsu.edu/</p>", "child_count": 0, "closed": false, "tree_id": 4, "revision_count": 1, "parent": 5, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-recommend-easy-to-use-microarray-clustering-software", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 44}}, {"pk": 94, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 16:07:15", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Computing the reverse and complement of a sequence with Biopython", "unanswered": false, "content": "Wouldn't it better to have a single question titled 'How to compute the reverse complement with python' and put all the examples as different answers? Otherwise it seems a bit confusing..", "comment_count": 2, "html": "<p>Wouldn't it better to have a single question titled 'How to compute the reverse complement with python' and put all the examples as different answers? Otherwise it seems a bit confusing..</p>", "child_count": 0, "closed": false, "tree_id": 28, "revision_count": 1, "parent": 90, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:18", "slug": "a-computing-the-reverse-and-complement-of-a-sequence-with-biopython", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 95, "model": "server.post", "fields": {"rght": 15, "author": 23, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 16:32:26", "lft": 10, "post_type": 109787, "score": 8, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "The most important thing for me has been keeping a README file at the top of each project directory, where I write down not just *how* to run the scripts, but *why* I wrote them in the first place -- coming back to a project after a several-month lull, it's remarkable difficult to figure out what all the half-finished results mean without detailed notes.\n\nThat said:\n\n - `make` is pretty handy for simple pipelines that need to be re-run a lot\n - I'm also intrigued by [waf][1] and [scons][2], since I use Python a lot\n - If a pipeline only takes a couple of minutes to run, and you only re-run it every few days, coercing it into a build system doesn't really save time overall for that project\n - But once you're used to working with a build system, the threshold where it pays off to use it on a new project drops dramatically\n\n  [1]: http://code.google.com/p/waf/\n  [2]: http://www.scons.org/", "comment_count": 2, "html": "<p>The most important thing for me has been keeping a README file at the top of each project directory, where I write down not just <em>how</em> to run the scripts, but <em>why</em> I wrote them in the first place -- coming back to a project after a several-month lull, it's remarkable difficult to figure out what all the half-finished results mean without detailed notes.</p>\n<p>That said:</p>\n<ul>\n<li><code>make</code> is pretty handy for simple pipelines that need to be re-run a lot</li>\n<li>I'm also intrigued by <a href=\"http://code.google.com/p/waf/\">waf</a> and <a href=\"http://www.scons.org/\">scons</a>, since I use Python a lot</li>\n<li>If a pipeline only takes a couple of minutes to run, and you only re-run it every few days, coercing it into a build system doesn't really save time overall for that project</li>\n<li>But once you're used to working with a build system, the threshold where it pays off to use it on a new project drops dramatically</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 1, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 23}}, {"pk": 96, "model": "server.post", "fields": {"rght": 7, "author": 23, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 16:52:22", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Computing the reverse and complement of a sequence with Biopython", "unanswered": false, "content": "The Bio.Seq module provides two easy ways to get the complement and reverse complement from a sequence:\n\n - If you have a string, use the functions `complement(dna)` and `reverse_complement(dna)`\n - If you have a Seq object, use its methods with the same names: `dna.complement()` and `dna.reverse_complement`\n\nTo reverse a sequence, there is a function in the `Bio.SeqUtils` module called `reverse` which does what you would expect.\n\n---\n\n(Sorry for going meta, but I don't have commenting privileges yet. This can be deleted if the original post is edited.)\n\nAccording to [Meta Stack Overflow][1], if you want to share the answer to a difficult question that's poorly documented elsewhere online, you should post the question as a genuine one, and then submit your own answer separately. In theory, someone else may have an answer that's better than yours, and this allows it to be voted to the top properly.\n\n  [1]: http://meta.stackoverflow.com/questions/17845/etiquette-for-answering-your-own-question", "comment_count": 1, "html": "<p>The Bio.Seq module provides two easy ways to get the complement and reverse complement from a sequence:</p>\n<ul>\n<li>If you have a string, use the functions <code>complement(dna)</code> and <code>reverse_complement(dna)</code></li>\n<li>If you have a Seq object, use its methods with the same names: <code>dna.complement()</code> and <code>dna.reverse_complement</code></li>\n</ul>\n<p>To reverse a sequence, there is a function in the <code>Bio.SeqUtils</code> module called <code>reverse</code> which does what you would expect.</p>\n<hr />\n<p>(Sorry for going meta, but I don't have commenting privileges yet. This can be deleted if the original post is edited.)</p>\n<p>According to <a href=\"http://meta.stackoverflow.com/questions/17845/etiquette-for-answering-your-own-question\">Meta Stack Overflow</a>, if you want to share the answer to a difficult question that's poorly documented elsewhere online, you should post the question as a genuine one, and then submit your own answer separately. In theory, someone else may have an answer that's better than yours, and this allows it to be voted to the top properly.</p>", "child_count": 0, "closed": false, "tree_id": 28, "revision_count": 1, "parent": 90, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-computing-the-reverse-and-complement-of-a-sequence-with-biopython", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 23}}, {"pk": 97, "model": "server.post", "fields": {"rght": 9, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 17:05:13", "lft": 8, "post_type": 109787, "score": 2, "title": "A: Gene ID conversion tool", "unanswered": false, "content": "http://idconverter.bioinfo.cnio.es/\n\nIs another possible solution to this, although you might find this is not as up to date as you might like either.", "comment_count": 0, "html": "<p>http://idconverter.bioinfo.cnio.es/</p>\n<p>Is another possible solution to this, although you might find this is not as up to date as you might like either.</p>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 1, "parent": 22, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 98, "model": "server.post", "fields": {"rght": 11, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 19:51:25", "lft": 10, "post_type": 109787, "score": 4, "title": "A: Gene ID conversion tool", "unanswered": false, "content": "BioMart has already been mentioned. It can do much more than ID conversion but it is very useful for conversion purposes, it is regularly updated and you can select different genome builds and all kinds of genomic features. It seems to me that you wish to retrieve GeneIDs linked to Affymetrix IDs. To select these attributes in BioMart: go to the [Martview][1] page to start a new BioMart query.\n\nSelect attributes on the attribute page: The Ensembl GeneIDs and Transcript IDs are default. Ensembl GeneID and Affy IDs are under the \"External\" tab. Select your chip there.\nTo limit to those genes which are on the chip, use the Filters->Gene menue. You can limit the genes to those present on various platforms or your favourite set.\n\nThere is an URL button in biomart that allows to retrieve a URL for your query and to pass it on to others. Try this example:\n\n[BioMart URL][2] URL, that should be a good starting point.\n\nIf you are interested in KEGG identifiers (Pathways, Genes), EC-numbers, etc. the  \n\n[KEGG Identifier page][3] could be handy, because the KEGG ids are not in BioMart as far as I know.\n\n\n  [1]: http://www.biomart.org/biomart/martview\n  [2]: http://www.biomart.org/biomart/martview?VIRTUALSCHEMANAME=default&ATTRIBUTES=hsapiens_gene_ensembl.default.feature_page.ensembl_gene_id|hsapiens_gene_ensembl.default.feature_page.ensembl_transcript_id|hsapiens_gene_ensembl.default.feature_page.embl|hsapiens_gene_ensembl.default.feature_page.affy_hg_u133a&FILTERS=hsapiens_gene_ensembl.default.filters.with_affy_hg_u133a.only&VISIBLEPANEL=resultspanel\n  [3]: http://www.genome.jp/kegg/kegg3.html", "comment_count": 0, "html": "<p>BioMart has already been mentioned. It can do much more than ID conversion but it is very useful for conversion purposes, it is regularly updated and you can select different genome builds and all kinds of genomic features. It seems to me that you wish to retrieve GeneIDs linked to Affymetrix IDs. To select these attributes in BioMart: go to the <a href=\"http://www.biomart.org/biomart/martview\">Martview</a> page to start a new BioMart query.</p>\n<p>Select attributes on the attribute page: The Ensembl GeneIDs and Transcript IDs are default. Ensembl GeneID and Affy IDs are under the \"External\" tab. Select your chip there.\nTo limit to those genes which are on the chip, use the Filters-&gt;Gene menue. You can limit the genes to those present on various platforms or your favourite set.</p>\n<p>There is an URL button in biomart that allows to retrieve a URL for your query and to pass it on to others. Try this example:</p>\n<p><a href=\"http://www.biomart.org/biomart/martview?VIRTUALSCHEMANAME=default&amp;ATTRIBUTES=hsapiens_gene_ensembl.default.feature_page.ensembl_gene_id|hsapiens_gene_ensembl.default.feature_page.ensembl_transcript_id|hsapiens_gene_ensembl.default.feature_page.embl|hsapiens_gene_ensembl.default.feature_page.affy_hg_u133a&amp;FILTERS=hsapiens_gene_ensembl.default.filters.with_affy_hg_u133a.only&amp;VISIBLEPANEL=resultspanel\">BioMart URL</a> URL, that should be a good starting point.</p>\n<p>If you are interested in KEGG identifiers (Pathways, Genes), EC-numbers, etc. the<br />\n</p>\n<p><a href=\"http://www.genome.jp/kegg/kegg3.html\">KEGG Identifier page</a> could be handy, because the KEGG ids are not in BioMart as far as I know.</p>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 1, "parent": 22, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 99, "model": "server.post", "fields": {"rght": 8, "author": 9, "answer_accepted": false, "tag_string": "interval query use genomics", "creation_date": "2010-03-01 20:01:20", "lft": 1, "post_type": 164033, "score": 6, "title": "Fast interval intersection methodologies", "unanswered": false, "content": "Most genomic annotations are specified as intervals along the genome. \n\n - [Interval trees][1] have been known to provide an efficient datastructure that allows for very fast overlap querying. \n - [Nested Containment Lists][2] have been proposed as an even faster alternative \n\nProvide code examples in your programming language that demonstrate the use of fast interval querying.\n\n  [1]: http://books.google.com/books?id=NLngYyWFl_YC&lpg=PA311&ots=BwTtEE-jJ9&dq=cormen%20interval%20tree&pg=PA311#v=onepage&q=&f=false\n  [2]: http://bioinformatics.oxfordjournals.org/cgi/content/abstract/btl647v1", "comment_count": 0, "html": "<p>Most genomic annotations are specified as intervals along the genome. </p>\n<ul>\n<li><a href=\"http://books.google.com/books?id=NLngYyWFl_YC&amp;lpg=PA311&amp;ots=BwTtEE-jJ9&amp;dq=cormen%20interval%20tree&amp;pg=PA311#v=onepage&amp;q=&amp;f=false\">Interval trees</a> have been known to provide an efficient datastructure that allows for very fast overlap querying. </li>\n<li><a href=\"http://bioinformatics.oxfordjournals.org/cgi/content/abstract/btl647v1\">Nested Containment Lists</a> have been proposed as an even faster alternative </li>\n</ul>\n<p>Provide code examples in your programming language that demonstrate the use of fast interval querying.</p>", "child_count": 0, "closed": false, "tree_id": 30, "revision_count": 2, "parent": null, "views": 2118, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:31", "slug": "fast-interval-intersection-methodologies", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [62, 63, 64, 192], "lastedit_user": 22}}, {"pk": 100, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 20:06:18", "lft": 2, "post_type": 109787, "score": 4, "title": "A: Fast interval intersection methodologies", "unanswered": false, "content": "This code example generates 10,000 intervals then queries them for overlapping regions. **Requires only the presence of Python.**\n\nThe code below requires the either the installation of the [bx python][1] package or alternatively you may just download the [quicksect.py][2] module and place it next to the script itself:\n\n\n    from random import randint, seed\n    \n    # if you can install bx python then uncomment the line below\n    #\n    # from bx.intervals.operations.quicksect import IntervalNode\n    \n    # otherwise just download the quickset module as shown above \n    # and place it in next to your program\n    #\n    from quicksect import IntervalNode\n    \n    # the span of the generated intervals\n    SPAN = 10\n    \n    # the size of the genome\n    SIZE = 5*10**4\n    \n    # the number of intervals\n    N = 10**4\n    \n    def generate(x):\n        \"Generates random interval over a size and span\"\n        lo = randint(10000, SIZE)\n        hi = lo + randint(1, SPAN)\n        return (lo, hi)\n    \n    def find(start, end, tree):\n        \"Returns a list with the overlapping intervals\"\n        out = []\n        tree.intersect( start, end, lambda x: out.append(x) )\n        return [ (x.start, x.end) for x in out ]\n    \n    # use this to force both examples to generate the same data\n    seed(10)\n    \n    # generate 10 thousand random intervals\n    data = map(generate, xrange(N))\n    \n    # generate the intervals to query over\n    query = map(generate, xrange(10))\n    \n    # start the root at the first element\n    start, end = data[0]\n    tree = IntervalNode( start, end )\n    \n    # build an interval tree from the rest of the data\n    for start, end in data[1:]:\n        tree = tree.insert( start, end )\n    \n    for start, end in query:\n        overlap = find(start, end , tree)\n        print '(%s, %s) -> %s' % (start, end, overlap)\n        \n\nProduces the output:\n\n    (41901, 41903) -> [(41894, 41902)]\n    (36981, 36987) -> [(36981, 36984), (36973, 36982), (36978, 36987)]\n    (36338, 36339) -> [(36337, 36347)]\n    (32741, 32748) -> [(32738, 32742)]\n    (49864, 49872) -> [(49859, 49865)]\n    (21475, 21477) -> []\n    (29425, 29428) -> [(29418, 29426), (29419, 29426)]\n    (29590, 29599) -> [(29586, 29595), (29596, 29598)]\n    (12804, 12811) -> [(12806, 12811), (12799, 12806), (12809, 12819)]\n    (30339, 30343) -> [(30336, 30346), (30335, 30345), (30340, 30341)]\n\n  [1]: http://bitbucket.org/james_taylor/bx-python/wiki/Home\n  [2]: http://bitbucket.org/james_taylor/bx-python/raw/ebf9a4b352d3/lib/bx/intervals/operations/quicksect.py", "comment_count": 0, "html": "<p>This code example generates 10,000 intervals then queries them for overlapping regions. <strong>Requires only the presence of Python.</strong></p>\n<p>The code below requires the either the installation of the <a href=\"http://bitbucket.org/james_taylor/bx-python/wiki/Home\">bx python</a> package or alternatively you may just download the <a href=\"http://bitbucket.org/james_taylor/bx-python/raw/ebf9a4b352d3/lib/bx/intervals/operations/quicksect.py\">quicksect.py</a> module and place it next to the script itself:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">from</span> <span class=\"n\">random</span> <span class=\"nb\">import</span> <span class=\"n\">randint</span><span class=\"p\">,</span> <span class=\"n\">seed</span>\n    \n    <span class=\"c1\"># if you can install bx python then uncomment the line below</span>\n    <span class=\"c1\">#</span>\n    <span class=\"c1\"># from bx.intervals.operations.quicksect import IntervalNode</span>\n    \n    <span class=\"c1\"># otherwise just download the quickset module as shown above </span>\n    <span class=\"c1\"># and place it in next to your program</span>\n    <span class=\"c1\">#</span>\n    <span class=\"n\">from</span> <span class=\"n\">quicksect</span> <span class=\"nb\">import</span> <span class=\"n\">IntervalNode</span>\n    \n    <span class=\"c1\"># the span of the generated intervals</span>\n    <span class=\"n\">SPAN</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>\n    \n    <span class=\"c1\"># the size of the genome</span>\n    <span class=\"n\">SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"o\">*</span><span class=\"mi\">10</span><span class=\"o\">**</span><span class=\"mi\">4</span>\n    \n    <span class=\"c1\"># the number of intervals</span>\n    <span class=\"n\">N</span> <span class=\"o\">=</span> <span class=\"mi\">10</span><span class=\"o\">**</span><span class=\"mi\">4</span>\n    \n    <span class=\"n\">def</span> <span class=\"n\">generate</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"s\">&quot;Generates random interval over a size and span&quot;</span>\n        <span class=\"n\">lo</span> <span class=\"o\">=</span> <span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"n\">SIZE</span><span class=\"p\">)</span>\n        <span class=\"n\">hi</span> <span class=\"o\">=</span> <span class=\"n\">lo</span> <span class=\"o\">+</span> <span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">SPAN</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"n\">lo</span><span class=\"p\">,</span> <span class=\"n\">hi</span><span class=\"p\">)</span>\n    \n    <span class=\"n\">def</span> <span class=\"n\">find</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"p\">,</span> <span class=\"n\">tree</span><span class=\"p\">):</span>\n        <span class=\"s\">&quot;Returns a list with the overlapping intervals&quot;</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"o\">[]</span>\n        <span class=\"n\">tree</span><span class=\"o\">.</span><span class=\"n\">intersect</span><span class=\"p\">(</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"p\">,</span> <span class=\"n\">lambda</span> <span class=\"n\">x:</span> <span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"p\">[</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">end</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"n\">in</span> <span class=\"n\">out</span> <span class=\"p\">]</span>\n    \n    <span class=\"c1\"># use this to force both examples to generate the same data</span>\n    <span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n    \n    <span class=\"c1\"># generate 10 thousand random intervals</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">generate</span><span class=\"p\">,</span> <span class=\"n\">xrange</span><span class=\"p\">(</span><span class=\"n\">N</span><span class=\"p\">))</span>\n    \n    <span class=\"c1\"># generate the intervals to query over</span>\n    <span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">generate</span><span class=\"p\">,</span> <span class=\"n\">xrange</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">))</span>\n    \n    <span class=\"c1\"># start the root at the first element</span>\n    <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n    <span class=\"n\">tree</span> <span class=\"o\">=</span> <span class=\"n\">IntervalNode</span><span class=\"p\">(</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span> <span class=\"p\">)</span>\n    \n    <span class=\"c1\"># build an interval tree from the rest of the data</span>\n    <span class=\"k\">for</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span> <span class=\"n\">in</span> <span class=\"n\">data</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">:]:</span>\n        <span class=\"n\">tree</span> <span class=\"o\">=</span> <span class=\"n\">tree</span><span class=\"o\">.</span><span class=\"n\">insert</span><span class=\"p\">(</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span> <span class=\"p\">)</span>\n    \n    <span class=\"k\">for</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span> <span class=\"n\">in</span> <span class=\"n\">query:</span>\n        <span class=\"n\">overlap</span> <span class=\"o\">=</span> <span class=\"n\">find</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span> <span class=\"p\">,</span> <span class=\"n\">tree</span><span class=\"p\">)</span>\n        <span class=\"k\">print</span> <span class=\"s\">&#39;(%s, %s) -&gt; %s&#39;</span> <span class=\"nv\">%</span> <span class=\"err\">(</span><span class=\"nv\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"p\">,</span> <span class=\"n\">overlap</span><span class=\"p\">)</span>\n        \n</pre></div>\n</p>\n<p>Produces the output:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"p\">(</span><span class=\"mi\">41901</span><span class=\"p\">,</span> <span class=\"mi\">41903</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">41894</span><span class=\"p\">,</span> <span class=\"mi\">41902</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">36981</span><span class=\"p\">,</span> <span class=\"mi\">36987</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">36981</span><span class=\"p\">,</span> <span class=\"mi\">36984</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">36973</span><span class=\"p\">,</span> <span class=\"mi\">36982</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">36978</span><span class=\"p\">,</span> <span class=\"mi\">36987</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">36338</span><span class=\"p\">,</span> <span class=\"mi\">36339</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">36337</span><span class=\"p\">,</span> <span class=\"mi\">36347</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">32741</span><span class=\"p\">,</span> <span class=\"mi\">32748</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">32738</span><span class=\"p\">,</span> <span class=\"mi\">32742</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">49864</span><span class=\"p\">,</span> <span class=\"mi\">49872</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">49859</span><span class=\"p\">,</span> <span class=\"mi\">49865</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">21475</span><span class=\"p\">,</span> <span class=\"mi\">21477</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"o\">[]</span>\n    <span class=\"p\">(</span><span class=\"mi\">29425</span><span class=\"p\">,</span> <span class=\"mi\">29428</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">29418</span><span class=\"p\">,</span> <span class=\"mi\">29426</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">29419</span><span class=\"p\">,</span> <span class=\"mi\">29426</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">29590</span><span class=\"p\">,</span> <span class=\"mi\">29599</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">29586</span><span class=\"p\">,</span> <span class=\"mi\">29595</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">29596</span><span class=\"p\">,</span> <span class=\"mi\">29598</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">12804</span><span class=\"p\">,</span> <span class=\"mi\">12811</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">12806</span><span class=\"p\">,</span> <span class=\"mi\">12811</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">12799</span><span class=\"p\">,</span> <span class=\"mi\">12806</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">12809</span><span class=\"p\">,</span> <span class=\"mi\">12819</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">30339</span><span class=\"p\">,</span> <span class=\"mi\">30343</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">30336</span><span class=\"p\">,</span> <span class=\"mi\">30346</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">30335</span><span class=\"p\">,</span> <span class=\"mi\">30345</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">30340</span><span class=\"p\">,</span> <span class=\"mi\">30341</span><span class=\"p\">)]</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 30, "revision_count": 2, "parent": 99, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-fast-interval-intersection-methodologies", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 101, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 20:09:49", "lft": 4, "post_type": 109787, "score": 2, "title": "A: Fast interval intersection methodologies", "unanswered": false, "content": "This code example generates 10,000 intervals then queries them for overlapping regions. **The installation requires a C compiler and Python.**\n\nThis is a faster solution than the other example, one that now requires the full installation of the [bx-python][1] module. **The data structure is implemented in C** and is at least one order of magnitude faster than the **quicksect.py** module presented in another example.\n\n    from random import randint, seed\n    from bx.intervals.intersection import Intersecter, Interval\n    \n    # the span of the generated intervals\n    SPAN = 10\n    \n    # the size of the genome\n    SIZE = 5*10**4\n    \n    # the number of intervals\n    N = 10**4\n    \n    def generate(x):\n        \"Generates random interval over a size and span\"\n        lo = randint(10000, SIZE)\n        hi = lo + randint(1, SPAN)\n        return (lo, hi)\n    \n    # use this to force both examples to generate the same data\n    seed(10)\n    \n    # generate 10 thousand random intervals\n    data = map(generate, xrange(N))\n    \n    # generate the intervals to query over\n    query = map(generate, xrange(10))\n    \n    # create the interval tree\n    tree = Intersecter()\n    \n    # build an interval tree from the rest of the data\n    for start, end in data:\n        tree.add_interval( Interval(start, end) )\n    \n    # perform the query\n    for start, end in query:\n        overlap = tree.find(start, end)\n        out = [ (x.start, x.end) for x in overlap ]\n        print '(%s, %s) -> %s' % (start, end, out)\n        \nProduces the output:\n\n    (41901, 41903) -> [(41894, 41902)]\n    (36981, 36987) -> [(36973, 36982), (36978, 36987), (36981, 36984)]\n    (36338, 36339) -> [(36337, 36347)]\n    (32741, 32748) -> [(32738, 32742)]\n    (49864, 49872) -> [(49859, 49865)]\n    (21475, 21477) -> []\n    (29425, 29428) -> [(29418, 29426), (29419, 29426)]\n    (29590, 29599) -> [(29586, 29595), (29596, 29598)]\n    (12804, 12811) -> [(12799, 12806), (12806, 12811), (12809, 12819)]\n    (30339, 30343) -> [(30335, 30345), (30336, 30346), (30340, 30341)]\n\n  [1]: http://bitbucket.org/james_taylor/bx-python/overview/\n", "comment_count": 0, "html": "<p>This code example generates 10,000 intervals then queries them for overlapping regions. <strong>The installation requires a C compiler and Python.</strong></p>\n<p>This is a faster solution than the other example, one that now requires the full installation of the <a href=\"http://bitbucket.org/james_taylor/bx-python/overview/\">bx-python</a> module. <strong>The data structure is implemented in C</strong> and is at least one order of magnitude faster than the <strong>quicksect.py</strong> module presented in another example.</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">from</span> <span class=\"n\">random</span> <span class=\"nb\">import</span> <span class=\"n\">randint</span><span class=\"p\">,</span> <span class=\"n\">seed</span>\n    <span class=\"n\">from</span> <span class=\"n\">bx</span><span class=\"o\">.</span><span class=\"n\">intervals</span><span class=\"o\">.</span><span class=\"n\">intersection</span> <span class=\"nb\">import</span> <span class=\"n\">Intersecter</span><span class=\"p\">,</span> <span class=\"n\">Interval</span>\n    \n    <span class=\"c1\"># the span of the generated intervals</span>\n    <span class=\"n\">SPAN</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>\n    \n    <span class=\"c1\"># the size of the genome</span>\n    <span class=\"n\">SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">5</span><span class=\"o\">*</span><span class=\"mi\">10</span><span class=\"o\">**</span><span class=\"mi\">4</span>\n    \n    <span class=\"c1\"># the number of intervals</span>\n    <span class=\"n\">N</span> <span class=\"o\">=</span> <span class=\"mi\">10</span><span class=\"o\">**</span><span class=\"mi\">4</span>\n    \n    <span class=\"n\">def</span> <span class=\"n\">generate</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n        <span class=\"s\">&quot;Generates random interval over a size and span&quot;</span>\n        <span class=\"n\">lo</span> <span class=\"o\">=</span> <span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">10000</span><span class=\"p\">,</span> <span class=\"n\">SIZE</span><span class=\"p\">)</span>\n        <span class=\"n\">hi</span> <span class=\"o\">=</span> <span class=\"n\">lo</span> <span class=\"o\">+</span> <span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">SPAN</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"n\">lo</span><span class=\"p\">,</span> <span class=\"n\">hi</span><span class=\"p\">)</span>\n    \n    <span class=\"c1\"># use this to force both examples to generate the same data</span>\n    <span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n    \n    <span class=\"c1\"># generate 10 thousand random intervals</span>\n    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">generate</span><span class=\"p\">,</span> <span class=\"n\">xrange</span><span class=\"p\">(</span><span class=\"n\">N</span><span class=\"p\">))</span>\n    \n    <span class=\"c1\"># generate the intervals to query over</span>\n    <span class=\"n\">query</span> <span class=\"o\">=</span> <span class=\"nb\">map</span><span class=\"p\">(</span><span class=\"n\">generate</span><span class=\"p\">,</span> <span class=\"n\">xrange</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">))</span>\n    \n    <span class=\"c1\"># create the interval tree</span>\n    <span class=\"n\">tree</span> <span class=\"o\">=</span> <span class=\"n\">Intersecter</span><span class=\"p\">()</span>\n    \n    <span class=\"c1\"># build an interval tree from the rest of the data</span>\n    <span class=\"k\">for</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span> <span class=\"n\">in</span> <span class=\"n\">data:</span>\n        <span class=\"n\">tree</span><span class=\"o\">.</span><span class=\"n\">add_interval</span><span class=\"p\">(</span> <span class=\"n\">Interval</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"p\">)</span> <span class=\"p\">)</span>\n    \n    <span class=\"c1\"># perform the query</span>\n    <span class=\"k\">for</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span> <span class=\"n\">in</span> <span class=\"n\">query:</span>\n        <span class=\"n\">overlap</span> <span class=\"o\">=</span> <span class=\"n\">tree</span><span class=\"o\">.</span><span class=\"n\">find</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"p\">)</span>\n        <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"p\">[</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">end</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"n\">in</span> <span class=\"n\">overlap</span> <span class=\"p\">]</span>\n        <span class=\"k\">print</span> <span class=\"s\">&#39;(%s, %s) -&gt; %s&#39;</span> <span class=\"nv\">%</span> <span class=\"err\">(</span><span class=\"nv\">start</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"p\">,</span> <span class=\"n\">out</span><span class=\"p\">)</span>\n        \n</pre></div>\n\nProduces the output:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"p\">(</span><span class=\"mi\">41901</span><span class=\"p\">,</span> <span class=\"mi\">41903</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">41894</span><span class=\"p\">,</span> <span class=\"mi\">41902</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">36981</span><span class=\"p\">,</span> <span class=\"mi\">36987</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">36973</span><span class=\"p\">,</span> <span class=\"mi\">36982</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">36978</span><span class=\"p\">,</span> <span class=\"mi\">36987</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">36981</span><span class=\"p\">,</span> <span class=\"mi\">36984</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">36338</span><span class=\"p\">,</span> <span class=\"mi\">36339</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">36337</span><span class=\"p\">,</span> <span class=\"mi\">36347</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">32741</span><span class=\"p\">,</span> <span class=\"mi\">32748</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">32738</span><span class=\"p\">,</span> <span class=\"mi\">32742</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">49864</span><span class=\"p\">,</span> <span class=\"mi\">49872</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">49859</span><span class=\"p\">,</span> <span class=\"mi\">49865</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">21475</span><span class=\"p\">,</span> <span class=\"mi\">21477</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"o\">[]</span>\n    <span class=\"p\">(</span><span class=\"mi\">29425</span><span class=\"p\">,</span> <span class=\"mi\">29428</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">29418</span><span class=\"p\">,</span> <span class=\"mi\">29426</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">29419</span><span class=\"p\">,</span> <span class=\"mi\">29426</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">29590</span><span class=\"p\">,</span> <span class=\"mi\">29599</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">29586</span><span class=\"p\">,</span> <span class=\"mi\">29595</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">29596</span><span class=\"p\">,</span> <span class=\"mi\">29598</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">12804</span><span class=\"p\">,</span> <span class=\"mi\">12811</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">12799</span><span class=\"p\">,</span> <span class=\"mi\">12806</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">12806</span><span class=\"p\">,</span> <span class=\"mi\">12811</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">12809</span><span class=\"p\">,</span> <span class=\"mi\">12819</span><span class=\"p\">)]</span>\n    <span class=\"p\">(</span><span class=\"mi\">30339</span><span class=\"p\">,</span> <span class=\"mi\">30343</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"p\">[(</span><span class=\"mi\">30335</span><span class=\"p\">,</span> <span class=\"mi\">30345</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">30336</span><span class=\"p\">,</span> <span class=\"mi\">30346</span><span class=\"p\">),</span> <span class=\"p\">(</span><span class=\"mi\">30340</span><span class=\"p\">,</span> <span class=\"mi\">30341</span><span class=\"p\">)]</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 30, "revision_count": 2, "parent": 99, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:17", "slug": "a-fast-interval-intersection-methodologies", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 102, "model": "server.post", "fields": {"rght": 6, "author": 9, "answer_accepted": false, "tag_string": "dna sequence competition", "creation_date": "2010-03-01 23:47:17", "lft": 1, "post_type": 164033, "score": 4, "title": "List all the tools or write a script to validate that a sequence only contains letters from a given alphabet", "unanswered": false, "content": "How do I verify that a sequence only contains letters from a given alphabet: DNA, RNA, protein?", "comment_count": 0, "html": "<p>How do I verify that a sequence only contains letters from a given alphabet: DNA, RNA, protein?</p>", "child_count": 0, "closed": false, "tree_id": 31, "revision_count": 3, "parent": null, "views": 243, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:30", "slug": "list-all-the-tools-or-write-a-script-to-validate-that-a-sequence-only-contains-letters-from-a-given-alphabet", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [40, 65, 66], "lastedit_user": 22}}, {"pk": 103, "model": "server.post", "fields": {"rght": 5, "author": 9, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 23:50:05", "lft": 2, "post_type": 109787, "score": 3, "title": "A: List all the tools or write a script to validate that a sequence only contains letters from a given alphabet", "unanswered": false, "content": "Here is an efficient function written in Python:\n\n    dna = set(\"ATGC\")\n    def validate(seq, alphabet=dna):\n        \"Checks that a sequence only contains values from an alphabet\"\n        leftover = set(seq.upper()) - alphabet\n        return not leftover\n    \n    # typical usage below\n    \n    # this will print True\n    print validate('AAAATGCCG')\n    \n    # this will print False\n    print validate('AAANTGCCG')\n    \n    # using it with other alphabets\n    prot = set('ACDEFGHIKLMNPQRSTVWY')\n    print validate(\"mglsdgewql\", alphabet=prot)", "comment_count": 1, "html": "<p>Here is an efficient function written in Python:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">dna</span> <span class=\"o\">=</span> <span class=\"n\">set</span><span class=\"p\">(</span><span class=\"s\">&quot;ATGC&quot;</span><span class=\"p\">)</span>\n    <span class=\"n\">def</span> <span class=\"n\">validate</span><span class=\"p\">(</span><span class=\"n\">seq</span><span class=\"p\">,</span> <span class=\"n\">alphabet</span><span class=\"o\">=</span><span class=\"n\">dna</span><span class=\"p\">):</span>\n        <span class=\"s\">&quot;Checks that a sequence only contains values from an alphabet&quot;</span>\n        <span class=\"n\">leftover</span> <span class=\"o\">=</span> <span class=\"n\">set</span><span class=\"p\">(</span><span class=\"n\">seq</span><span class=\"o\">.</span><span class=\"n\">upper</span><span class=\"p\">())</span> <span class=\"o\">-</span> <span class=\"n\">alphabet</span>\n        <span class=\"k\">return</span> <span class=\"ow\">not</span> <span class=\"n\">leftover</span>\n    \n    <span class=\"c1\"># typical usage below</span>\n    \n    <span class=\"c1\"># this will print True</span>\n    <span class=\"k\">print</span> <span class=\"n\">validate</span><span class=\"p\">(</span><span class=\"s\">&#39;AAAATGCCG&#39;</span><span class=\"p\">)</span>\n    \n    <span class=\"c1\"># this will print False</span>\n    <span class=\"k\">print</span> <span class=\"n\">validate</span><span class=\"p\">(</span><span class=\"s\">&#39;AAANTGCCG&#39;</span><span class=\"p\">)</span>\n    \n    <span class=\"c1\"># using it with other alphabets</span>\n    <span class=\"n\">prot</span> <span class=\"o\">=</span> <span class=\"n\">set</span><span class=\"p\">(</span><span class=\"s\">&#39;ACDEFGHIKLMNPQRSTVWY&#39;</span><span class=\"p\">)</span>\n    <span class=\"k\">print</span> <span class=\"n\">validate</span><span class=\"p\">(</span><span class=\"s\">&quot;mglsdgewql&quot;</span><span class=\"p\">,</span> <span class=\"n\">alphabet</span><span class=\"o\">=</span><span class=\"n\">prot</span><span class=\"p\">)</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 31, "revision_count": 1, "parent": 102, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-list-all-the-tools-or-write-a-script-to-validate-that-a-sequence-only-contains-letters-from-a-given-alphabet", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 9}}, {"pk": 104, "model": "server.post", "fields": {"rght": 13, "author": 60, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 05:22:30", "lft": 12, "post_type": 109787, "score": 3, "title": "A: Using HDF5 to store  bio-data", "unanswered": false, "content": "I've been talking a bit with one of the devs behind BioHDF (being at UIUC, up the road from The HDF Group doesn't hurt). I believe a publication is on the way describing it along with some implementation details. ", "comment_count": 0, "html": "<p>I've been talking a bit with one of the devs behind BioHDF (being at UIUC, up the road from The HDF Group doesn't hurt). I believe a publication is on the way describing it along with some implementation details. </p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 1, "parent": 69, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 60}}, {"pk": 105, "model": "server.post", "fields": {"rght": 13, "author": 39, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 07:54:01", "lft": 12, "post_type": 109787, "score": 4, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "Since i use Ruby quite often, I have found Rake very useful in creating simple pipelines. Rake has an idea of a task(s) and you can have prerequisites for the tasks, thus create pipelines. See An extension to rake that can be used to build database-backed workflows \u2014 at github http://github.com/jandot/biorake\n\n", "comment_count": 0, "html": "<p>Since i use Ruby quite often, I have found Rake very useful in creating simple pipelines. Rake has an idea of a task(s) and you can have prerequisites for the tasks, thus create pipelines. See An extension to rake that can be used to build database-backed workflows \u2014 at github http://github.com/jandot/biorake</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 1, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 39}}, {"pk": 106, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 09:26:39", "lft": 6, "post_type": 109787, "score": 3, "title": "A: Fast interval intersection methodologies", "unanswered": false, "content": "An alternative is to use BED files to store data and [BEDTools][1] to calculate the intersection.\n\nThe [BED][2] format is a format used by UCSC and many other projects to generically store annotations on genomes. Sometimes, it is easier to use just plain BED files to store annotations, instead of complex databases or HDF5, and BEDTools make it also faster to access them. Moreover, with BEDFiles you have other advantages, as you can use custom tracks on ucsc or gbrowse and there are other tools that use BED as input.\n\nAnyway, to solve the problem of intersection with BEDTools, you would do:\n    \n`$: intersectBed -a segdups.bed -b exons.bed`\n\n\n  [1]: http://code.google.com/p/bedtools/\n  [2]: http://genome.ucsc.edu/FAQ/FAQformat#format1", "comment_count": 0, "html": "<p>An alternative is to use BED files to store data and <a href=\"http://code.google.com/p/bedtools/\">BEDTools</a> to calculate the intersection.</p>\n<p>The <a href=\"http://genome.ucsc.edu/FAQ/FAQformat#format1\">BED</a> format is a format used by UCSC and many other projects to generically store annotations on genomes. Sometimes, it is easier to use just plain BED files to store annotations, instead of complex databases or HDF5, and BEDTools make it also faster to access them. Moreover, with BEDFiles you have other advantages, as you can use custom tracks on ucsc or gbrowse and there are other tools that use BED as input.</p>\n<p>Anyway, to solve the problem of intersection with BEDTools, you would do:\n<div class=\"highlight\"><pre>    \n</pre></div>\n\n<code>$: intersectBed -a segdups.bed -b exons.bed</code></p>", "child_count": 0, "closed": false, "tree_id": 30, "revision_count": 1, "parent": 99, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-fast-interval-intersection-methodologies", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 107, "model": "server.post", "fields": {"rght": 17, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 10:37:07", "lft": 14, "post_type": 109787, "score": 2, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "re Biomake:\n\nIt does look like a great tool but it is unsupported. What you get from Sourceforge is a snapshot with README pointing you to one dialect of Prolog (XSB) only to learn running the examples that project moved to another one (SWI-Prolog). Unless you know Prolog and can fix it Biomake is not functional as I last checked (Jan 2010).  ", "comment_count": 1, "html": "<p>re Biomake:</p>\n<p>It does look like a great tool but it is unsupported. What you get from Sourceforge is a snapshot with README pointing you to one dialect of Prolog (XSB) only to learn running the examples that project moved to another one (SWI-Prolog). Unless you know Prolog and can fix it Biomake is not functional as I last checked (Jan 2010).<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 2, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 108, "model": "server.post", "fields": {"rght": 6, "author": 61, "answer_accepted": false, "tag_string": "sequence genome annotation database", "creation_date": "2010-03-02 11:00:20", "lft": 1, "post_type": 164033, "score": 2, "title": "Genome specific database (Gbrowse / Ensembl type)", "unanswered": false, "content": "I am interested in your opinions about database systems used to store, query and visualize genomic sequence and annotations. I am talking about ca 600-700Mb draft genome with a large number of contigs outside scaffolds. Yep, I know that annotating anything before reaching some quality milestones may be considered pointless, but I want to get the back end (DB) and the pipeline   \nworking way before that.\n\nSo far I started testing Gbrowse (1.70), been impressed by Ensembl as an end-user, and looked at (unsuitable) eye candy GenomeProjector  http://www.g-language.org/GenomeProjector/.\n\nI will appreciate any thoughts about ease of installation/maintenance and integration with annotation tools such as Apollo / Artemis.\n\nThanks\n\ndarked89\n\nPS There is no way top add proper tags (genome annotation database) to this post", "comment_count": 1, "html": "<p>I am interested in your opinions about database systems used to store, query and visualize genomic sequence and annotations. I am talking about ca 600-700Mb draft genome with a large number of contigs outside scaffolds. Yep, I know that annotating anything before reaching some quality milestones may be considered pointless, but I want to get the back end (DB) and the pipeline <br />\nworking way before that.</p>\n<p>So far I started testing Gbrowse (1.70), been impressed by Ensembl as an end-user, and looked at (unsuitable) eye candy GenomeProjector  http://www.g-language.org/GenomeProjector/.</p>\n<p>I will appreciate any thoughts about ease of installation/maintenance and integration with annotation tools such as Apollo / Artemis.</p>\n<p>Thanks</p>\n<p>darked89</p>\n<p>PS There is no way top add proper tags (genome annotation database) to this post</p>", "child_count": 0, "closed": false, "tree_id": 32, "revision_count": 2, "parent": null, "views": 602, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:30", "slug": "genome-specific-database-gbrowse-ensembl-type", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [40, 67, 68, 69], "lastedit_user": 22}}, {"pk": 109, "model": "server.post", "fields": {"rght": 3, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 12:06:01", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Genome specific database (Gbrowse / Ensembl type)", "unanswered": false, "content": "This is a really debated topic, whether it is better to store sequences on a database or on simple flat files. I have never had to annotate draft genomes as you so I can't suggest you which is the best approach for you, but I would recommend using flat files, as you will have more support and tools, it will take less time to set it up, and I have the feeling that that is the direction that most projects are taking for the future.\n\nIn case you want to use databases, have a look at [this post][1] and a this type of column type, the [datatype-geometric][2].\n\nIn case you want to try flat files, you will have to study [BED][3], [GFF][4], and maybe [BAM][5] formats, along with [VCF][6] if you have snps. For example, if you BED, you will be able to use [BEDTools][7], which will allow you to merge and work with genomic features and are very fast. You will be surprised to know that GBrowse uses only GFF files to store data, it has no DB backend.\n\nAnother alternative is HDF5, about which you may find some questions here. So, you have a lot of homework here :-)\n\n\n  [1]: http://www.mailund.dk/index.php/2009/01/22/playing-with-spatial-queries-in-mysql/\n  [2]: http://www.postgresql.org/docs/8.1/interactive/datatype-geometric.html\n  [3]: http://genome.ucsc.edu/FAQ/FAQformat.html#format1\n  [4]: http://genome.ucsc.edu/FAQ/FAQformat.html#format3\n  [5]: http://samtools.sourceforge.net/\n  [6]: http://vcftools.sourceforge.net/options.html\n  [7]: http://code.google.com/p/bedtools/", "comment_count": 0, "html": "<p>This is a really debated topic, whether it is better to store sequences on a database or on simple flat files. I have never had to annotate draft genomes as you so I can't suggest you which is the best approach for you, but I would recommend using flat files, as you will have more support and tools, it will take less time to set it up, and I have the feeling that that is the direction that most projects are taking for the future.</p>\n<p>In case you want to use databases, have a look at <a href=\"http://www.mailund.dk/index.php/2009/01/22/playing-with-spatial-queries-in-mysql/\">this post</a> and a this type of column type, the <a href=\"http://www.postgresql.org/docs/8.1/interactive/datatype-geometric.html\">datatype-geometric</a>.</p>\n<p>In case you want to try flat files, you will have to study <a href=\"http://genome.ucsc.edu/FAQ/FAQformat.html#format1\">BED</a>, <a href=\"http://genome.ucsc.edu/FAQ/FAQformat.html#format3\">GFF</a>, and maybe <a href=\"http://samtools.sourceforge.net/\">BAM</a> formats, along with <a href=\"http://vcftools.sourceforge.net/options.html\">VCF</a> if you have snps. For example, if you BED, you will be able to use <a href=\"http://code.google.com/p/bedtools/\">BEDTools</a>, which will allow you to merge and work with genomic features and are very fast. You will be surprised to know that GBrowse uses only GFF files to store data, it has no DB backend.</p>\n<p>Another alternative is HDF5, about which you may find some questions here. So, you have a lot of homework here :-)</p>", "child_count": 0, "closed": false, "tree_id": 32, "revision_count": 1, "parent": 108, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-genome-specific-database-gbrowse-ensembl-type", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 110, "model": "server.post", "fields": {"rght": 17, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 13:10:29", "lft": 14, "post_type": 109787, "score": 2, "title": "A: Using HDF5 to store  bio-data", "unanswered": false, "content": "Not BioHDF5 but probably readable and maintained: \n\nHDF5 for Python\nhttp://code.google.com/p/h5py/", "comment_count": 1, "html": "<p>Not BioHDF5 but probably readable and maintained: </p>\n<p>HDF5 for Python\nhttp://code.google.com/p/h5py/</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 1, "parent": 69, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:17", "slug": "a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 111, "model": "server.post", "fields": {"rght": 26, "author": 61, "answer_accepted": true, "tag_string": "blast taxonomy", "creation_date": "2010-03-02 15:35:52", "lft": 1, "post_type": 164033, "score": 6, "title": "Taxonomy of blast hits", "unanswered": false, "content": "Lets have 200k genomic contigs with some (unknown) bacterial contamination. \n\nI blasted (blastn vs nr) all of them, got tabulated output and passed the uniq acc nos ca 5k to Batch Entrez. Since neither my target genome nor bacterias causing contamination are not sequenced, I got a shotgun of results (3000 Eukaryota, 2000 Bacteria, few viruses). \n\nNow for a tricky part: \nwhat I need is:\nsequence_identifier + taxonomic_id(s) + main_tax_group\n\nsomething along the line:\n\nA000001 573 Bacteria\n\nApart from writing a script storing the sequence & taxonomy info into say MySQL, then going through blast top hits output, are there any tools (taverna work flows?) which can do it for me?\n\n**re Pierre**\n\nPrimary input is text blast output of:\n\n    blastcl3 -p blastn -m 9 -e 0.00001 -b 1 -i frag01 -o out_blastn_frag01\n\nI grep-ed and awk-ed hit acc numbers from second column. Resulting text file (one acc no per line) was feed to Batch Entrez. As far as I can tell there is no way of selecting output in form: \nA000001 573 Bacteria\nThe most parsable output seems to be TinyXML, but then I will download full bacterial genomes / eukaryotic chromosomes worth of sequence which at this stage I do not need.\n\nIdeally instead of two extremes (E.coli K12 + Bacteria) getting a whole taxonomic path:\n\n\n> cellular organisms; Bacteria; Proteobacteria; Gammaproteobacteria;\n> Enterobacteriales; Enterobacteriaceae; Escherichia; Escherichia coli\n\nwill be preferred. That way one can zoom in (select more than just species/strain and  taxonomic Kingdom).\n  \nSo at this moment I am split between using (1) just blast tabulated text output or selecting some Batch Entrez output which then I will be able to combine with (1).\n\n**re giovanni**\nsingle line which gets squezzed a bit  here:\n\ncontig62836  gi|119525916|gb|CP000508.1|     93.18   44      3       0       1109    1152    262350  262393  2e-06   63.9\n\n\n\nBefore each of the top hits there is blast header with hash sign in front:\n\n\n    # Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score\n\n\nSo simple:\n\n     grep -A 1 Fields out_blastn_frag0* | grep contig | awk '{ print $2}' | awk 'FS=\"|\" {print $4}' | sort | uniq > all_uniq_hits_100302.txt\n\ngives me list off unique accession numbers of my top hits suitable for Batch Entrez.\n\n**re XML:**\nyes, but I tried to avoid too much network traffic. XML for half a million contigs is a lot of data. save for oneliners I am using python. \n\n\n", "comment_count": 0, "html": "<p>Lets have 200k genomic contigs with some (unknown) bacterial contamination. </p>\n<p>I blasted (blastn vs nr) all of them, got tabulated output and passed the uniq acc nos ca 5k to Batch Entrez. Since neither my target genome nor bacterias causing contamination are not sequenced, I got a shotgun of results (3000 Eukaryota, 2000 Bacteria, few viruses). </p>\n<p>Now for a tricky part: \nwhat I need is:\nsequence_identifier + taxonomic_id(s) + main_tax_group</p>\n<p>something along the line:</p>\n<p>A000001 573 Bacteria</p>\n<p>Apart from writing a script storing the sequence &amp; taxonomy info into say MySQL, then going through blast top hits output, are there any tools (taverna work flows?) which can do it for me?</p>\n<p><strong>re Pierre</strong></p>\n<p>Primary input is text blast output of:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">blastcl3</span> <span class=\"o\">-</span><span class=\"n\">p</span> <span class=\"n\">blastn</span> <span class=\"o\">-</span><span class=\"n\">m</span> <span class=\"mi\">9</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"mf\">0.00001</span> <span class=\"o\">-</span><span class=\"n\">b</span> <span class=\"mi\">1</span> <span class=\"o\">-</span><span class=\"n\">i</span> <span class=\"n\">frag01</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"n\">out_blastn_frag01</span>\n</pre></div>\n</p>\n<p>I grep-ed and awk-ed hit acc numbers from second column. Resulting text file (one acc no per line) was feed to Batch Entrez. As far as I can tell there is no way of selecting output in form: \nA000001 573 Bacteria\nThe most parsable output seems to be TinyXML, but then I will download full bacterial genomes / eukaryotic chromosomes worth of sequence which at this stage I do not need.</p>\n<p>Ideally instead of two extremes (E.coli K12 + Bacteria) getting a whole taxonomic path:</p>\n<blockquote>\n<p>cellular organisms; Bacteria; Proteobacteria; Gammaproteobacteria;\nEnterobacteriales; Enterobacteriaceae; Escherichia; Escherichia coli</p>\n</blockquote>\n<p>will be preferred. That way one can zoom in (select more than just species/strain and  taxonomic Kingdom).</p>\n<p>So at this moment I am split between using (1) just blast tabulated text output or selecting some Batch Entrez output which then I will be able to combine with (1).</p>\n<p><strong>re giovanni</strong>\nsingle line which gets squezzed a bit  here:</p>\n<p>contig62836  gi|119525916|gb|CP000508.1|     93.18   44      3       0       1109    1152    262350  262393  2e-06   63.9</p>\n<p>Before each of the top hits there is blast header with hash sign in front:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"c\"># Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score</span>\n</pre></div>\n</p>\n<p>So simple:</p>\n<p><div class=\"highlight\"><pre>     <span class=\"nb\">grep</span> <span class=\"o\">-</span><span class=\"n\">A</span> <span class=\"mi\">1</span> <span class=\"n\">Fields</span> <span class=\"n\">out_blastn_frag0</span><span class=\"o\">*</span> <span class=\"o\">|</span> <span class=\"nb\">grep</span> <span class=\"n\">contig</span> <span class=\"o\">|</span> <span class=\"n\">awk</span> <span class=\"s\">&#39;{ print $2}&#39;</span> <span class=\"o\">|</span> <span class=\"n\">awk</span> <span class=\"s\">&#39;FS=&quot;|&quot; {print $4}&#39;</span> <span class=\"o\">|</span> <span class=\"nb\">sort</span> <span class=\"o\">|</span> <span class=\"n\">uniq</span> <span class=\"o\">&gt;</span> <span class=\"n\">all_uniq_hits_100302</span><span class=\"o\">.</span><span class=\"n\">txt</span>\n</pre></div>\n</p>\n<p>gives me list off unique accession numbers of my top hits suitable for Batch Entrez.</p>\n<p><strong>re XML:</strong>\nyes, but I tried to avoid too much network traffic. XML for half a million contigs is a lot of data. save for oneliners I am using python. </p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 4, "parent": null, "views": 890, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:31", "slug": "taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [43, 70], "lastedit_user": 61}}, {"pk": 112, "model": "server.post", "fields": {"rght": 36, "author": 22, "answer_accepted": true, "tag_string": "subjective blog off resources", "creation_date": "2010-03-02 17:25:33", "lft": 1, "post_type": 164033, "score": 15, "title": "Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "I think that for a professional is very important to follow blogs focused on his own speciality, it is a good way to learn without too much effort and to stay updated. Which bioinformatics-related blogs do you usually read?\n\nnote: there is a [similar question][1] posted on stackoverflow.\n\n\n  [1]: http://stackoverflow.com/questions/2051319/bioinformatics-resources", "comment_count": 0, "html": "<p>I think that for a professional is very important to follow blogs focused on his own speciality, it is a good way to learn without too much effort and to stay updated. Which bioinformatics-related blogs do you usually read?</p>\n<p>note: there is a <a href=\"http://stackoverflow.com/questions/2051319/bioinformatics-resources\">similar question</a> posted on stackoverflow.</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 5, "parent": null, "views": 3859, "deleted": false, "answer_count": 18, "touch_date": "2011-11-24 14:49:31", "slug": "your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [32, 71, 72, 73], "lastedit_user": 1}}, {"pk": 113, "model": "server.post", "fields": {"rght": 7, "author": 44, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 17:46:19", "lft": 2, "post_type": 109787, "score": 5, "title": "A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "http://biostar.stackexchange.com", "comment_count": 2, "html": "<p>http://biostar.stackexchange.com</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 1, "parent": 112, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 44}}, {"pk": 114, "model": "server.post", "fields": {"rght": 13, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 18:02:17", "lft": 2, "post_type": 109787, "score": 4, "title": "A: Taxonomy of blast hits", "unanswered": false, "content": "I you want to get the TinySeq XML  *without* getting the sequence, I would create a SAX parser that would only get the value of the **TaxonId** and ignoring the other field (see \"class TinySeqHandler\" in [http://code.google.com/p/lindenb/source/browse/trunk/proj/tinytools/src/org/lindenb/tinytools/TwitterOmics.java][1] for an example). Having the taxonId you can get the full lineage from\n\n    http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=taxonomy&id=YOUR_TAXON_ID&retmode=xml\n\n\n  [1]: http://code.google.com/p/lindenb/source/browse/trunk/proj/tinytools/src/org/lindenb/tinytools/TwitterOmics.java", "comment_count": 5, "html": "<p>I you want to get the TinySeq XML  <em>without</em> getting the sequence, I would create a SAX parser that would only get the value of the <strong>TaxonId</strong> and ignoring the other field (see \"class TinySeqHandler\" in <a href=\"http://code.google.com/p/lindenb/source/browse/trunk/proj/tinytools/src/org/lindenb/tinytools/TwitterOmics.java\">http://code.google.com/p/lindenb/source/browse/trunk/proj/tinytools/src/org/lindenb/tinytools/TwitterOmics.java</a> for an example). Having the taxonId you can get the full lineage from</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">http:</span><span class=\"sr\">//</span><span class=\"n\">eutils</span><span class=\"o\">.</span><span class=\"n\">ncbi</span><span class=\"o\">.</span><span class=\"n\">nlm</span><span class=\"o\">.</span><span class=\"n\">nih</span><span class=\"o\">.</span><span class=\"n\">gov</span><span class=\"sr\">/entrez/</span><span class=\"n\">eutils</span><span class=\"o\">/</span><span class=\"n\">efetch</span><span class=\"o\">.</span><span class=\"n\">fcgi</span><span class=\"p\">?</span><span class=\"n\">db</span><span class=\"o\">=</span><span class=\"n\">taxonomy</span><span class=\"o\">&amp;</span><span class=\"n\">id</span><span class=\"o\">=</span><span class=\"n\">YOUR_TAXON_ID</span><span class=\"o\">&amp;</span><span class=\"n\">retmode</span><span class=\"o\">=</span><span class=\"n\">xml</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 1, "parent": 111, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:17", "slug": "a-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 29}}, {"pk": 115, "model": "server.post", "fields": {"rght": 11, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 18:08:54", "lft": 4, "post_type": 109787, "score": 5, "title": "A: Taxonomy of blast hits", "unanswered": false, "content": "From the description of your input data I guess that you are trying to do a taxonomic classification of sequences in a metagenomics approach. I further assume that you have about 200.000 reads or sequences (or do you alternatively mean assembled contigs of length 200 kB?).\nI am not sure if I completely understand the question, but whatever you do, filtering out the tax ids with your own script might not be the best option. \n \nI assume further you wish to compute a tree of the taxonomic composition of the data in total.\n\n> That way one can zoom in (select more\n> than just species/strain and taxonomic\n> Kingdom)\n\nFor this task you might want to try the [MEGAN][1] (Metagenome Analysis) software. \n\nActually, what you are describing looks very much like one of the publications they have in their publications list:\n\nH. N. Poinar, C. Schwarz, Ji Qi, B. Shapiro, R. D. E. MacPhee, B. Buigues, A. Tikhonov, D. H. Huson, L. P. Tomsho, A. Auch, M. Rampp, W. Miller, S. C. Schuster, [Metagenomics to Paleogenomics: Large-Scale Sequencing of Mammoth DNA][2], Science 311:392-394, 2006\n\nThere is also a [tutorial on setting the right BLAST parameter][3] for use with short reads.\n\nSo in principle, this program could do the job or at least you can have a look at the right parameters for blast. \n\n\n  [1]: http://www-ab.informatik.uni-tuebingen.de/software/megan\n  [2]: http://www.sciencemag.org/cgi/content/abstract/1123360v1\n  [3]: http://www-ab.informatik.uni-tuebingen.de/software/megan/how-to-use-blast", "comment_count": 3, "html": "<p>From the description of your input data I guess that you are trying to do a taxonomic classification of sequences in a metagenomics approach. I further assume that you have about 200.000 reads or sequences (or do you alternatively mean assembled contigs of length 200 kB?).\nI am not sure if I completely understand the question, but whatever you do, filtering out the tax ids with your own script might not be the best option. </p>\n<p>I assume further you wish to compute a tree of the taxonomic composition of the data in total.</p>\n<blockquote>\n<p>That way one can zoom in (select more\nthan just species/strain and taxonomic\nKingdom)</p>\n</blockquote>\n<p>For this task you might want to try the <a href=\"http://www-ab.informatik.uni-tuebingen.de/software/megan\">MEGAN</a> (Metagenome Analysis) software. </p>\n<p>Actually, what you are describing looks very much like one of the publications they have in their publications list:</p>\n<p>H. N. Poinar, C. Schwarz, Ji Qi, B. Shapiro, R. D. E. MacPhee, B. Buigues, A. Tikhonov, D. H. Huson, L. P. Tomsho, A. Auch, M. Rampp, W. Miller, S. C. Schuster, <a href=\"http://www.sciencemag.org/cgi/content/abstract/1123360v1\">Metagenomics to Paleogenomics: Large-Scale Sequencing of Mammoth DNA</a>, Science 311:392-394, 2006</p>\n<p>There is also a <a href=\"http://www-ab.informatik.uni-tuebingen.de/software/megan/how-to-use-blast\">tutorial on setting the right BLAST parameter</a> for use with short reads.</p>\n<p>So in principle, this program could do the job or at least you can have a look at the right parameters for blast. </p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 1, "parent": 111, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:21", "slug": "a-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 116, "model": "server.post", "fields": {"rght": 5, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 18:10:21", "lft": 4, "post_type": 109787, "score": 10, "title": "A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "mine of course ! :-) [http://plindenbaum.blogspot.com][1]\n\nSee also: Bioinformatics blogs on Nature-blogs: http://blogs.nature.com/blogs?tags=bioinformatics\n\nAnd the life-scientists group on FriendFeed: [http://friendfeed.com/the-life-scientists][2]\n\n\n  [1]: http://plindenbaum.blogspot.com\n  [2]: http://friendfeed.com/the-life-scientists", "comment_count": 0, "html": "<p>mine of course ! :-) <a href=\"http://plindenbaum.blogspot.com\">http://plindenbaum.blogspot.com</a></p>\n<p>See also: Bioinformatics blogs on Nature-blogs: http://blogs.nature.com/blogs?tags=bioinformatics</p>\n<p>And the life-scientists group on FriendFeed: <a href=\"http://friendfeed.com/the-life-scientists\">http://friendfeed.com/the-life-scientists</a></p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 1, "parent": 112, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 117, "model": "server.post", "fields": {"rght": 9, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 18:20:20", "lft": 6, "post_type": 109787, "score": 6, "title": "A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "Here is  one that I follow, but I'm interested in adding more blogs to my feed:\n\n - [Blue Collar Bioinformatics][1]\n \n  [1]: http://bcbio.wordpress.com/", "comment_count": 1, "html": "<p>Here is  one that I follow, but I'm interested in adding more blogs to my feed:</p>\n<ul>\n<li><a href=\"http://bcbio.wordpress.com/\">Blue Collar Bioinformatics</a></li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 1, "parent": 112, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 118, "model": "server.post", "fields": {"rght": 9, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 18:35:19", "lft": 8, "post_type": 109787, "score": 5, "title": "A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "[Very large list of bioinformatics blogs][1] from the now defunct Nodalpoint wiki\n\n\n  [1]: http://web.archive.org/web/20080213153458/wiki.nodalpoint.org/blogs", "comment_count": 0, "html": "<p><a href=\"http://web.archive.org/web/20080213153458/wiki.nodalpoint.org/blogs\">Very large list of bioinformatics blogs</a> from the now defunct Nodalpoint wiki</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 1, "parent": 112, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 119, "model": "server.post", "fields": {"rght": 11, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 19:59:25", "lft": 10, "post_type": 109787, "score": 4, "title": "A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "Maybe not The Greatest but these few are covering next gen sequencing:\n\nhttp://www.massgenomics.org/\n\nhttp://www.fejes.ca/labels/DNA.html\n\nhttp://omicsomics.blogspot.com/\n\n", "comment_count": 0, "html": "<p>Maybe not The Greatest but these few are covering next gen sequencing:</p>\n<p>http://www.massgenomics.org/</p>\n<p>http://www.fejes.ca/labels/DNA.html</p>\n<p>http://omicsomics.blogspot.com/</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 2, "parent": 112, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 120, "model": "server.post", "fields": {"rght": 9, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 20:10:25", "lft": 8, "post_type": 109787, "score": 1, "title": "A: Where can I get the secondary structure of a protein?", "unanswered": false, "content": "May be a little bit dated, but let me blow my own trumpet (collection of links):\n\n[Bioinfo_tutorial#Protein_localization_and_structure_prediction](http://openwetware.org/wiki/Wikiomics:Bioinfo_tutorial#Protein_localization_and_structure_prediction)\n", "comment_count": 0, "html": "<p>May be a little bit dated, but let me blow my own trumpet (collection of links):</p>\n<p><a href=\"\">Bioinfo_tutorial#Protein_localization_and_structure_prediction</a></p>", "child_count": 0, "closed": false, "tree_id": 18, "revision_count": 1, "parent": 48, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:17", "slug": "a-where-can-i-get-the-secondary-structure-of-a-protein", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 121, "model": "server.post", "fields": {"rght": 17, "author": 6, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 20:38:44", "lft": 12, "post_type": 109787, "score": 6, "title": "A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "A friend of mine is a very active blogger in bioinformatics. This is his blog site\n\n[Fisheye Perspective][1]\n\n\nHe has also complied a list of bioinformatics and chemo informatics blogs which are very popular. some of you might be interested in it.\n\n[30+ Blogs about Bioinformatics and Chemoinformatics Programming][2] \n\n\n  [1]: http://www.abhishek-tiwari.com/\n  [2]: http://www.abhishek-tiwari.com/2009/02/30-blogs-about-bioinformatics-and.html", "comment_count": 2, "html": "<p>A friend of mine is a very active blogger in bioinformatics. This is his blog site</p>\n<p><a href=\"http://www.abhishek-tiwari.com/\">Fisheye Perspective</a></p>\n<p>He has also complied a list of bioinformatics and chemo informatics blogs which are very popular. some of you might be interested in it.</p>\n<p><a href=\"http://www.abhishek-tiwari.com/2009/02/30-blogs-about-bioinformatics-and.html\">30+ Blogs about Bioinformatics and Chemoinformatics Programming</a> </p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 1, "parent": 112, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:20", "slug": "a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 6}}, {"pk": 122, "model": "server.post", "fields": {"rght": 11, "author": 6, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 22:42:11", "lft": 10, "post_type": 109787, "score": 10, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "I think the emphasis should be more on the way we optimize our program rather than language which we use. I personally use languages based on the kind of problem I am answering.\n\nThis was an interesting paper which I came across some time back although some of the information mentioned in here might sound redundant to some of you but still it's worth a read.\n\n[A Quick Guide for Developing Effective Bioinformatics Programming Skills][1]\n\n\n  [1]: http://www.ploscompbiol.org/article/info:doi%2F10.1371%2Fjournal.pcbi.1000589", "comment_count": 0, "html": "<p>I think the emphasis should be more on the way we optimize our program rather than language which we use. I personally use languages based on the kind of problem I am answering.</p>\n<p>This was an interesting paper which I came across some time back although some of the information mentioned in here might sound redundant to some of you but still it's worth a read.</p>\n<p><a href=\"\">A Quick Guide for Developing Effective Bioinformatics Programming Skills</a></p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 6}}, {"pk": 123, "model": "server.post", "fields": {"rght": 13, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 23:29:26", "lft": 12, "post_type": 109787, "score": 1, "title": "A: Finding common motifs in sequences", "unanswered": false, "content": "You may check out these pages:\n\n[Bioinfo_tutorial#Promoter_prediction](http://openwetware.org/wiki/Wikiomics:Bioinfo_tutorial#Promoter_prediction)\n\n[Wikiomics:Sequence_motifs](http://openwetware.org/wiki/Wikiomics:Sequence_motifs)\n\nThese are ca 2 years old (links may not work etc.) but as a starting point should be OK. \nAlso in unlikely case you did not found it yet: in yeast there has been an extensive motif search study done by Kellis with insane number of citations:\n\n\nNature. 2003 May 15;423(6937):241-54.\n\nKellis M, Patterson N, Endrizzi M, Birren B, Lander ES.\n\n[Sequencing and comparison of yeast species to identify genes and regulatory elements.](http://www.ncbi.nlm.nih.gov/pubmed/12748633)", "comment_count": 0, "html": "<p>You may check out these pages:</p>\n<p><a href=\"\">Bioinfo_tutorial#Promoter_prediction</a></p>\n<p><a href=\"\">Wikiomics:Sequence_motifs</a></p>\n<p>These are ca 2 years old (links may not work etc.) but as a starting point should be OK. \nAlso in unlikely case you did not found it yet: in yeast there has been an extensive motif search study done by Kellis with insane number of citations:</p>\n<p>Nature. 2003 May 15;423(6937):241-54.</p>\n<p>Kellis M, Patterson N, Endrizzi M, Birren B, Lander ES.</p>\n<p><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/12748633\">Sequencing and comparison of yeast species to identify genes and regulatory elements.</a></p>", "child_count": 0, "closed": false, "tree_id": 3, "revision_count": 1, "parent": 4, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:17", "slug": "a-finding-common-motifs-in-sequences", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 124, "model": "server.post", "fields": {"rght": 15, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-03 12:15:23", "lft": 14, "post_type": 109787, "score": 14, "title": "A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "Blogs:\n\n - [programming4scientists.com][1] - tricks for scientists entering the world of programming\n - [mailund on the Internet][2] - nice blog on programming, population genetics, simulations\n - [Open-Bio news][3] - news from the project that hosts bioperl, biopython, etc..\n - [FinchTalk][4] - this one is from a company, but it is interesting and technical worthy of reading it.\n - [Fisheye Perspective][5] - very interesting with news on synthetic biology and else - the author is very active in many bioinformatics communities. note: I suggest you to register to the [feeds][6] directly\n - [88 Proof Synthetic Biology][7]\n - [Learning R][8] - tips to learn R\n - [BioCS][9]\n - [MentalIndigestion][10] \n - [PDB - MOlecule of the Month][11]\n - [The molecule of the Month][12]  - similar style to pdb's, but different authors\n\n\nMoreover, I also find useful to follow the blogs from many bioinformatics services or databases:\n \n - [NCBI][13]'s news\n - [Uniprot][14]'s news\n - [Plos Computational Biology][15]\n - [Gene Ontology][16] news\n - [Ensembl][17] news\n\n\n  [1]: http://www.programming4scientists.com/\n  [2]: http://www.mailund.dk/\n  [3]: http://news.open-bio.org/news/\n  [4]: http://www.geospiza.com/finchtalk/\n  [5]: http://www.abhishek-tiwari.com/\n  [6]: http://feeds2.feedburner.com/AbhishekTiwarisBlog\n  [7]: http://88proof.com/synthetic_biology/blog\n  [8]: http://learnr.wordpress.com/\n  [9]: http://blog.mckuhn.de/\n  [10]: http://www.mentalindigestion.net/\n  [11]: http://www.rcsb.org/pdb/motm.do\n  [12]: http://www.chm.bris.ac.uk/motm/motm.htm\n  [13]: http://www.ncbi.nlm.nih.gov/feed/rss.cgi\n  [14]: http://www.uniprot.org/news/?format=rss\n  [15]: http://feeds.plos.org/ploscompbiol/NewArticles\n  [16]: http://go.berkeleybop.org/news4go/rss.xml\n  [17]: http://www.ensembl.org/common/rss.xml", "comment_count": 0, "html": "<p>Blogs:</p>\n<ul>\n<li><a href=\"http://www.programming4scientists.com/\">programming4scientists.com</a> - tricks for scientists entering the world of programming</li>\n<li><a href=\"http://www.mailund.dk/\">mailund on the Internet</a> - nice blog on programming, population genetics, simulations</li>\n<li><a href=\"http://news.open-bio.org/news/\">Open-Bio news</a> - news from the project that hosts bioperl, biopython, etc..</li>\n<li><a href=\"http://www.geospiza.com/finchtalk/\">FinchTalk</a> - this one is from a company, but it is interesting and technical worthy of reading it.</li>\n<li><a href=\"http://www.abhishek-tiwari.com/\">Fisheye Perspective</a> - very interesting with news on synthetic biology and else - the author is very active in many bioinformatics communities. note: I suggest you to register to the <a href=\"http://feeds2.feedburner.com/AbhishekTiwarisBlog\">feeds</a> directly</li>\n<li><a href=\"http://88proof.com/synthetic_biology/blog\">88 Proof Synthetic Biology</a></li>\n<li><a href=\"http://learnr.wordpress.com/\">Learning R</a> - tips to learn R</li>\n<li><a href=\"http://blog.mckuhn.de/\">BioCS</a></li>\n<li><a href=\"http://www.mentalindigestion.net/\">MentalIndigestion</a> </li>\n<li><a href=\"http://www.rcsb.org/pdb/motm.do\">PDB - MOlecule of the Month</a></li>\n<li><a href=\"http://www.chm.bris.ac.uk/motm/motm.htm\">The molecule of the Month</a>  - similar style to pdb's, but different authors</li>\n</ul>\n<p>Moreover, I also find useful to follow the blogs from many bioinformatics services or databases:</p>\n<ul>\n<li><a href=\"http://www.ncbi.nlm.nih.gov/feed/rss.cgi\">NCBI</a>'s news</li>\n<li><a href=\"http://www.uniprot.org/news/?format=rss\">Uniprot</a>'s news</li>\n<li><a href=\"http://feeds.plos.org/ploscompbiol/NewArticles\">Plos Computational Biology</a></li>\n<li><a href=\"http://go.berkeleybop.org/news4go/rss.xml\">Gene Ontology</a> news</li>\n<li><a href=\"http://www.ensembl.org/common/rss.xml\">Ensembl</a> news</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 2, "parent": 112, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 22}}, {"pk": 125, "model": "server.post", "fields": {"rght": 15, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-03 12:35:31", "lft": 14, "post_type": 109787, "score": 4, "title": "A: Finding common motifs in sequences", "unanswered": false, "content": "The first step when looking for conservation of single bases or motives is often a multiple sequence alignment that will align the sequences in a way such that conserved regions are best visible. This can be a first step before using explicit motif finders like MEME. A good way of visualizing multiple alignments is the [sequence-logo][1] that will give a graphical representation of base conservation.\n\nHere is the [wikipedia list of mult.-sequence alignment][2] tools.\n\nI recommend to start with the [EBI web-server of ClustalW][3] though, if that is not enough you can also try MAFFT or T-Coffee.\n\n[Weblogo][4] can generate sequence-logo graphics from the output and also from fasta input directly.\n\nAdvantage of these tools is that you don't need to install them, so good for a first attempt irrespective of using a Mac.  \n\n\n  [1]: http://en.wikipedia.org/wiki/Sequence_logo\n  [2]: http://en.wikipedia.org/wiki/List_of_sequence_alignment_software#Multiple_sequence_alignment\n  [3]: http://www.ebi.ac.uk/Tools/clustalw2/index.html\n  [4]: http://weblogo.threeplusone.com/", "comment_count": 0, "html": "<p>The first step when looking for conservation of single bases or motives is often a multiple sequence alignment that will align the sequences in a way such that conserved regions are best visible. This can be a first step before using explicit motif finders like MEME. A good way of visualizing multiple alignments is the <a href=\"http://en.wikipedia.org/wiki/Sequence_logo\">sequence-logo</a> that will give a graphical representation of base conservation.</p>\n<p>Here is the <a href=\"http://en.wikipedia.org/wiki/List_of_sequence_alignment_software#Multiple_sequence_alignment\">wikipedia list of mult.-sequence alignment</a> tools.</p>\n<p>I recommend to start with the <a href=\"http://www.ebi.ac.uk/Tools/clustalw2/index.html\">EBI web-server of ClustalW</a> though, if that is not enough you can also try MAFFT or T-Coffee.</p>\n<p><a href=\"http://weblogo.threeplusone.com/\">Weblogo</a> can generate sequence-logo graphics from the output and also from fasta input directly.</p>\n<p>Advantage of these tools is that you don't need to install them, so good for a first attempt irrespective of using a Mac.<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 3, "revision_count": 1, "parent": 4, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-finding-common-motifs-in-sequences", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 126, "model": "server.post", "fields": {"rght": 19, "author": 63, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-03 17:17:24", "lft": 16, "post_type": 109787, "score": 2, "title": "A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "http://manuelcorpas.com/", "comment_count": 1, "html": "<p>http://manuelcorpas.com/</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 1, "parent": 112, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:25", "slug": "a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 63}}, {"pk": 127, "model": "server.post", "fields": {"rght": 19, "author": 64, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-03 21:18:32", "lft": 16, "post_type": 109787, "score": 5, "title": "A: Using HDF5 to store  bio-data", "unanswered": false, "content": "This might be useful for you. This code snippet read the Simulation data and manipulate in HDF5. \n<pre>\n*Chnage first 5 includes from \"\" to open and close tags*\n#include \"stdlib.h\"\n#include \"stdio.h\"\n#include \"string.h\"\n#include \"hdf5.h\"\n#include \"hdf5_hl.h\"\n\n#include \"common.h\"\n#include \"hdf5_data.h\"\n#include \"metadata/simulation.h\"\n#include \"metadata/simulation_list.h\"\n\nenum FileIntent\n{\n  READING,\n  WRITING,\n  NEITHER\n};\n\nstruct HDF5Data\n{\n  hid_t file;\n  hid_t group;\n  int ptCreated;\n  hid_t pt;\n  enum FileIntent intent;\n};\n\n/* Iterator function for pulling out existing simulation data.\n * Currently assumes we are only dealing with our own files but could be\n * made smarter to find only groups that contain the required dataspace's.\n */\nstatic herr_t\nrootIterator(hid_t group,const char *name,void *_iter)\n{\n  struct SimulationList* list = (struct SimulationList*)_iter;\n  if (list)\n  {\n    struct Simulation* s = CreateSimulation();\n    simulationSetName(s,name);\n    simulationListAppend(list,s);\n    DestroySimulation(&s);\n    return(0);\n  }\n  return(-1);\n}\n\nstruct HDF5Data* CreateHDF5Data()\n{\n  struct HDF5Data* hdf5 = (struct HDF5Data*)malloc(sizeof(struct HDF5Data));\n  if (hdf5)\n  {\n    hdf5->file = (hid_t)NULL;\n    hdf5->group = (hid_t)NULL;\n    hdf5->pt = (hid_t)NULL;\n    hdf5->ptCreated = 0;\n    hdf5->intent = NEITHER;\n  }\n  return(hdf5);\n}\n\nint DestroyHDF5Data(struct HDF5Data** hdf5)\n{\n  int code = ERR;\n  struct HDF5Data* h5 = *hdf5;\n  if (h5)\n  {\n    if (h5->ptCreated) H5PTclose(h5->pt);\n    if (h5->group > 0) H5Gclose(h5->group);\n    if (h5->file > 0) H5Fclose(h5->file);\n    free(h5);\n    code = OK;\n  }\n  *hdf5 = (struct HDF5Data*)NULL;\n  return(code);\n}\n\nint hdf5DataOpenFileForWriting(struct HDF5Data* hdf5,const char* filename)\n{\n  /* Open the hdf5 file for writing. */\n  int code = ERR;\n  if (hdf5)\n  {\n    hdf5->file =\n      H5Fcreate(filename,H5F_ACC_TRUNC,H5P_DEFAULT,H5P_DEFAULT);\n    if (hdf5->file < 0) code = ERR;\n    else\n    {\n      hdf5->intent = WRITING;\n      code = OK;\n    }\n  }\n  return(code);\n}\n\nint hdf5DataOpenFileForReading(struct HDF5Data* hdf5,const char* filename)\n{\n  /* Open the hdf5 file for writing. */\n  int code = ERR;\n  if (hdf5)\n  {\n    hdf5->file = H5Fopen(filename,H5F_ACC_RDONLY,H5P_DEFAULT);\n    if (hdf5->file < 0) code = ERR;\n    else\n    {\n      hdf5->intent = READING;\n      code = OK;\n    }\n  }\n  return(code);\n}\n\nint hdf5DataSetGroup(struct HDF5Data* hdf5,const char* groupName)\n{\n  int code = ERR;\n  if (hdf5 && (hdf5->file > 0))\n  {\n    if (hdf5->group > 0) H5Gclose(hdf5->group);\n    if (hdf5->ptCreated) H5PTclose(hdf5->pt);\n    hdf5->ptCreated = 0;\n    if (groupName)\n    {\n      if (hdf5->intent == WRITING) hdf5->group =\n        H5Gcreate(hdf5->file,groupName,/*size_hint*/0);\n      else hdf5->group = H5Gopen(hdf5->file,groupName);\n    }\n    code = OK;\n  }\n  return(code);\n}\n\nint hdf5WriteSimulationModelURI(struct HDF5Data* hdf5,const char* uri)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  hsize_t dim[1];\n\n  if ((hdf5 == NULL) || (hdf5->intent != WRITING))\n  {\n    fprintf(stderr,\"Attempting to write to a reading file.\\n\");\n    return(ERR);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  if (uri == NULL)\n  {\n    fprintf(stderr,\"Attempting to write invalid URI to data file.\\n\");\n    return(ERR);\n  }\n  if (strlen(uri) > HDF5_STRING_LENGTH-1)\n  {\n    fprintf(stderr,\n      \"URI too long - fix the hdf5WriteSimulationModelURI code.\\n\");\n    return(ERR);\n  }\n  char* localURI = (char*)calloc(HDF5_STRING_LENGTH,1);\n  strcpy(localURI,uri);\n  /* Make a string data type */\n  datatype = H5Tcopy(H5T_C_S1);\n  /* set the fixed string length */\n  status = H5Tset_size(datatype,HDF5_STRING_LENGTH);\n  /* and we're gonna use C-like null-terminated string */\n  status = H5Tset_strpad(datatype,H5T_STR_NULLTERM);\n  /* Create a simple memory space of the correct size */\n  dim[0] = 1;\n  dataspace = H5Screate_simple(1,dim,NULL);\n  /* and create the dataset to write to */\n  dataset = H5Dcreate(hdf5->group,SIMULATION_MODEL_URI_NAME,datatype,\n    dataspace,H5P_DEFAULT);\n  /* Write the URI to the file */\n  status = H5Dwrite(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,localURI);\n  /* clean up */\n  H5Dclose(dataset);\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  /*H5Fflush(hdf5->file,H5F_SCOPE_GLOBAL);*/\n  free(localURI);\n  return(OK);\n}\n\nint hdf5WriteFieldHeader(struct HDF5Data* hdf5,int N,char* names)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  hsize_t dim[1];\n\n  if ((hdf5 == NULL) || (hdf5->intent != WRITING))\n  {\n    fprintf(stderr,\"Attempting to write to a reading file.\\n\");\n    return(ERR);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  /* Make a string data type */\n  datatype = H5Tcopy(H5T_C_S1);\n  /* set the fixed string length */\n  status = H5Tset_size(datatype,HDF5_STRING_LENGTH);\n  /* and we're gonna use C-like null-terminated strings */\n  status = H5Tset_strpad(datatype,H5T_STR_NULLTERM);\n  /* Create a simple memory space of the correct size */\n  dim[0] = N;\n  dataspace = H5Screate_simple(1,dim,NULL);\n  /* and create the dataset to write to */\n  dataset = H5Dcreate(hdf5->group,FIELD_HEADER_DATA_NAME,datatype,\n    dataspace,H5P_DEFAULT);\n  /* Write the field names to the file */\n  status = H5Dwrite(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,names);\n  /* clean up */\n  H5Dclose(dataset);\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  /*H5Fflush(hdf5->file,H5F_SCOPE_GLOBAL);*/\n  return(OK);\n}\n\nint hdf5WriteData(struct HDF5Data* hdf5,int N,double* data)\n{\n  herr_t status = 0;\n  \n  if ((hdf5 == NULL) || (hdf5->intent != WRITING))\n  {\n    fprintf(stderr,\"Attempting to write to a reading file.\\n\");\n    return(ERR);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  if (!hdf5->ptCreated)\n  {\n    /* create a fixed length packet table in the file */\n    hdf5->pt = H5PTcreate_fl(hdf5->group,DATA_NAME,H5T_NATIVE_DOUBLE,\n      /*chunk size ??*/sizeof(double)*N);\n    hdf5->ptCreated = 1;\n  }\n  if (hdf5->ptCreated)\n  {\n    /* Write a packet to the packet table */\n    status = H5PTappend(hdf5->pt,N,(void*)data);\n  }\n  return(OK);\n}\n\nchar* hdf5ReadSimulationModelURI(struct HDF5Data* hdf5)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  char *uri = (char*)NULL;\n  \n  if ((hdf5 == NULL) || (hdf5->intent != READING))\n  {\n    fprintf(stderr,\"Attempting to read from a writing file.\\n\");\n    return((char*)NULL);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  /* open the dataset */\n  dataset = H5Dopen(hdf5->group,SIMULATION_MODEL_URI_NAME);\n  dataspace = H5Dget_space(dataset);\n  /* get the data type */\n  datatype = H5Dget_type(dataset);\n  /* allocate memory */\n  uri = (char*)malloc(HDF5_STRING_LENGTH);\n  /* read in the data */\n  status = H5Dread(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,uri);\n  if (status < 0)\n  {\n    fprintf(stderr,\"Error getting the dimension of the field header.\\n\");\n    free(uri);\n    H5Sclose(dataspace);\n    H5Tclose(datatype);\n    H5Dclose(dataset);\n    return((char*)NULL);\n  }\n  /* clean up */\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  H5Dclose(dataset);\n  return(uri);\n}\n\nchar** hdf5ReadFieldHeader(struct HDF5Data* hdf5,int* N)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  hsize_t dim[1];\n  char *tmp,*names = (char*)NULL;\n  char** fields = (char**)NULL;\n  int i;\n  \n  if ((hdf5 == NULL) || (hdf5->intent != READING))\n  {\n    fprintf(stderr,\"Attempting to read from a writing file.\\n\");\n    return((char**)NULL);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  /* open the dataset */\n  dataset = H5Dopen(hdf5->group,FIELD_HEADER_DATA_NAME);\n  dataspace = H5Dget_space(dataset);\n  /* get the data type */\n  datatype = H5Dget_type(dataset);\n  /* get the size and allocate memory */\n  status = H5Sget_simple_extent_dims(dataspace,dim,NULL);\n  if (status < 0)\n  {\n    fprintf(stderr,\"Error getting the dimension of the field header.\\n\");\n    H5Sclose(dataspace);\n    H5Tclose(datatype);\n    H5Dclose(dataset);\n    return((char**)NULL);\n  }\n  names = (char*)malloc(HDF5_STRING_LENGTH*dim[0]);\n  /* read in the data */\n  status = H5Dread(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,names);\n  if (status < 0)\n  {\n    fprintf(stderr,\"Error getting the dimension of the field header.\\n\");\n    free(names);\n    H5Sclose(dataspace);\n    H5Tclose(datatype);\n    H5Dclose(dataset);\n    return((char**)NULL);\n  }\n  /* clean up */\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  H5Dclose(dataset);\n  /* split up the names */\n  fields = (char**)malloc(sizeof(char*)*dim[0]);\n  tmp = names;\n  for (i=0;i<dim[0];i++)\n  {\n    fields[i] = (char*)malloc(strlen(tmp)+1);\n    strcpy(fields[i],tmp);\n    tmp += HDF5_STRING_LENGTH;\n  }\n  free(names);\n  *N = dim[0];\n  return(fields);\n}\n\ndouble* hdf5ReadData(struct HDF5Data* hdf5,int N)\n{\n  herr_t status = 0;\n  double* data = (double*)malloc(sizeof(double)*N);\n  \n  if ((hdf5 == NULL) || (hdf5->intent != READING))\n  {\n    fprintf(stderr,\"Attempting to read from a writing file.\\n\");\n    return((double*)NULL);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  if (!hdf5->ptCreated)\n  {\n    /* open the packet table */\n    hdf5->pt = H5PTopen(hdf5->group,DATA_NAME);\n    /* and make sure we're at the start of the table */\n    H5PTcreate_index(hdf5->pt);\n    hdf5->ptCreated = 1;\n  }\n  if (hdf5->ptCreated)\n  {\n    /* get N packets from the packet table */\n    status = H5PTget_next(hdf5->pt,N,(void*)data);\n    if (status<0)\n    {\n      free(data);\n      data = (double*)NULL;\n    }\n  }\n  return(data);\n}\n\nstruct SimulationList* hdf5ReadSimulations(struct HDF5Data* hdf5)\n{\n  struct SimulationList* simulations = (struct SimulationList*)NULL;\n  \n  if ((hdf5 == NULL) || (hdf5->intent != READING))\n  {\n    fprintf(stderr,\"Attempting to read from a writing file.\\n\");\n    return(simulations);\n  }\n  /* look for any groups which are children of the root group */\n  hid_t rootGroup = H5Gopen(hdf5->file,\"/\");\n  if (rootGroup > 0)\n  {\n    simulations = CreateSimulationList();\n    if (H5Giterate(rootGroup,\"/\",NULL,rootIterator,(void*)simulations)\n      != 0) DestroySimulationList(&simulations);\n    H5Gclose(rootGroup);\n  }\n  return(simulations);\n}\n\n</pre>", "comment_count": 1, "html": "<p>This might be useful for you. This code snippet read the Simulation data and manipulate in HDF5. \n[HTML_REMOVED]\n<em>Chnage first 5 includes from \"\" to open and close tags</em></p>\n<h1>include \"stdlib.h\"</h1>\n<h1>include \"stdio.h\"</h1>\n<h1>include \"string.h\"</h1>\n<h1>include \"hdf5.h\"</h1>\n<h1>include \"hdf5_hl.h\"</h1>\n<h1>include \"common.h\"</h1>\n<h1>include \"hdf5_data.h\"</h1>\n<h1>include \"metadata/simulation.h\"</h1>\n<h1>include \"metadata/simulation_list.h\"</h1>\n<p>enum FileIntent\n{\n  READING,\n  WRITING,\n  NEITHER\n};</p>\n<p>struct HDF5Data\n{\n  hid_t file;\n  hid_t group;\n  int ptCreated;\n  hid_t pt;\n  enum FileIntent intent;\n};</p>\n<p>/<em> Iterator function for pulling out existing simulation data.\n * Currently assumes we are only dealing with our own files but could be\n * made smarter to find only groups that contain the required dataspace's.\n </em>/\nstatic herr_t\nrootIterator(hid_t group,const char <em>name,void </em>_iter)\n{\n  struct SimulationList<em> list = (struct SimulationList</em>)_iter;\n  if (list)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">struct</span> <span class=\"n\">Simulation</span><span class=\"o\">*</span> <span class=\"n\">s</span> <span class=\"o\">=</span> <span class=\"n\">CreateSimulation</span><span class=\"p\">();</span>\n    <span class=\"n\">simulationSetName</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">,</span><span class=\"n\">name</span><span class=\"p\">);</span>\n    <span class=\"n\">simulationListAppend</span><span class=\"p\">(</span><span class=\"n\">list</span><span class=\"p\">,</span><span class=\"n\">s</span><span class=\"p\">);</span>\n    <span class=\"n\">DestroySimulation</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">s</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  return(-1);\n}</p>\n<p>struct HDF5Data<em> CreateHDF5Data()\n{\n  struct HDF5Data</em> hdf5 = (struct HDF5Data*)malloc(sizeof(struct HDF5Data));\n  if (hdf5)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">file</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">hid_t</span><span class=\"p\">)</span><span class=\"n\">NULL</span><span class=\"p\">;</span>\n    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">group</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">hid_t</span><span class=\"p\">)</span><span class=\"n\">NULL</span><span class=\"p\">;</span>\n    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">pt</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">hid_t</span><span class=\"p\">)</span><span class=\"n\">NULL</span><span class=\"p\">;</span>\n    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">ptCreated</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">intent</span> <span class=\"o\">=</span> <span class=\"n\">NEITHER</span><span class=\"p\">;</span>\n</pre></div>\n\n  }\n  return(hdf5);\n}</p>\n<p>int DestroyHDF5Data(struct HDF5Data<em><em> hdf5)\n{\n  int code = ERR;\n  struct HDF5Data</em> h5 = </em>hdf5;\n  if (h5)\n  {\n<div class=\"highlight\"><pre>    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">h5</span><span class=\"o\">-&gt;</span><span class=\"n\">ptCreated</span><span class=\"p\">)</span> <span class=\"n\">H5PTclose</span><span class=\"p\">(</span><span class=\"n\">h5</span><span class=\"o\">-&gt;</span><span class=\"n\">pt</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">h5</span><span class=\"o\">-&gt;</span><span class=\"n\">group</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"n\">H5Gclose</span><span class=\"p\">(</span><span class=\"n\">h5</span><span class=\"o\">-&gt;</span><span class=\"n\">group</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">h5</span><span class=\"o\">-&gt;</span><span class=\"n\">file</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"n\">H5Fclose</span><span class=\"p\">(</span><span class=\"n\">h5</span><span class=\"o\">-&gt;</span><span class=\"n\">file</span><span class=\"p\">);</span>\n    <span class=\"n\">free</span><span class=\"p\">(</span><span class=\"n\">h5</span><span class=\"p\">);</span>\n    <span class=\"n\">code</span> <span class=\"o\">=</span> <span class=\"n\">OK</span><span class=\"p\">;</span>\n</pre></div>\n\n  }\n  <em>hdf5 = (struct HDF5Data</em>)NULL;\n  return(code);\n}</p>\n<p>int hdf5DataOpenFileForWriting(struct HDF5Data<em> hdf5,const char</em> filename)\n{\n  /<em> Open the hdf5 file for writing. </em>/\n  int code = ERR;\n  if (hdf5)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">file</span> <span class=\"o\">=</span>\n      <span class=\"n\">H5Fcreate</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span><span class=\"n\">H5F_ACC_TRUNC</span><span class=\"p\">,</span><span class=\"n\">H5P_DEFAULT</span><span class=\"p\">,</span><span class=\"n\">H5P_DEFAULT</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">file</span> <span class=\"o\">&lt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"n\">code</span> <span class=\"o\">=</span> <span class=\"n\">ERR</span><span class=\"p\">;</span>\n    <span class=\"k\">else</span>\n    <span class=\"p\">{</span>\n      <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">intent</span> <span class=\"o\">=</span> <span class=\"n\">WRITING</span><span class=\"p\">;</span>\n      <span class=\"n\">code</span> <span class=\"o\">=</span> <span class=\"n\">OK</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n</pre></div>\n\n  }\n  return(code);\n}</p>\n<p>int hdf5DataOpenFileForReading(struct HDF5Data<em> hdf5,const char</em> filename)\n{\n  /<em> Open the hdf5 file for writing. </em>/\n  int code = ERR;\n  if (hdf5)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">file</span> <span class=\"o\">=</span> <span class=\"n\">H5Fopen</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span><span class=\"n\">H5F_ACC_RDONLY</span><span class=\"p\">,</span><span class=\"n\">H5P_DEFAULT</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">file</span> <span class=\"o\">&lt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"n\">code</span> <span class=\"o\">=</span> <span class=\"n\">ERR</span><span class=\"p\">;</span>\n    <span class=\"k\">else</span>\n    <span class=\"p\">{</span>\n      <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">intent</span> <span class=\"o\">=</span> <span class=\"n\">READING</span><span class=\"p\">;</span>\n      <span class=\"n\">code</span> <span class=\"o\">=</span> <span class=\"n\">OK</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n</pre></div>\n\n  }\n  return(code);\n}</p>\n<p>int hdf5DataSetGroup(struct HDF5Data<em> hdf5,const char</em> groupName)\n{\n  int code = ERR;\n  if (hdf5 &amp;&amp; (hdf5-&gt;file &gt; 0))\n  {\n<div class=\"highlight\"><pre>    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">group</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"n\">H5Gclose</span><span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">group</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">ptCreated</span><span class=\"p\">)</span> <span class=\"n\">H5PTclose</span><span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">pt</span><span class=\"p\">);</span>\n    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">ptCreated</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">groupName</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n      <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">intent</span> <span class=\"o\">==</span> <span class=\"n\">WRITING</span><span class=\"p\">)</span> <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">group</span> <span class=\"o\">=</span>\n        <span class=\"n\">H5Gcreate</span><span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">file</span><span class=\"p\">,</span><span class=\"n\">groupName</span><span class=\"p\">,</span><span class=\"sr\">/*size_hint*/</span><span class=\"mi\">0</span><span class=\"p\">);</span>\n      <span class=\"k\">else</span> <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">group</span> <span class=\"o\">=</span> <span class=\"n\">H5Gopen</span><span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">file</span><span class=\"p\">,</span><span class=\"n\">groupName</span><span class=\"p\">);</span>\n    <span class=\"p\">}</span>\n    <span class=\"n\">code</span> <span class=\"o\">=</span> <span class=\"n\">OK</span><span class=\"p\">;</span>\n</pre></div>\n\n  }\n  return(code);\n}</p>\n<p>int hdf5WriteSimulationModelURI(struct HDF5Data<em> hdf5,const char</em> uri)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  hsize_t dim[1];</p>\n<p>if ((hdf5 == NULL) || (hdf5-&gt;intent != WRITING))\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Attempting to write to a reading file.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  if (hdf5-&gt;group &lt;= 0)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Missing HDF5 group.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  if (uri == NULL)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Attempting to write invalid URI to data file.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  if (strlen(uri) &gt; HDF5_STRING_LENGTH-1)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span>\n      <span class=\"s\">&quot;URI too long - fix the hdf5WriteSimulationModelURI code.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  char<em> localURI = (char</em>)calloc(HDF5_STRING_LENGTH,1);\n  strcpy(localURI,uri);\n  /<em> Make a string data type </em>/\n  datatype = H5Tcopy(H5T_C_S1);\n  /<em> set the fixed string length </em>/\n  status = H5Tset_size(datatype,HDF5_STRING_LENGTH);\n  /<em> and we're gonna use C-like null-terminated string </em>/\n  status = H5Tset_strpad(datatype,H5T_STR_NULLTERM);\n  /<em> Create a simple memory space of the correct size </em>/\n  dim[0] = 1;\n  dataspace = H5Screate_simple(1,dim,NULL);\n  /<em> and create the dataset to write to </em>/\n  dataset = H5Dcreate(hdf5-&gt;group,SIMULATION_MODEL_URI_NAME,datatype,\n<div class=\"highlight\"><pre>    <span class=\"n\">dataspace</span><span class=\"p\">,</span><span class=\"n\">H5P_DEFAULT</span><span class=\"p\">);</span>\n</pre></div>\n\n  /<em> Write the URI to the file </em>/\n  status = H5Dwrite(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,localURI);\n  /<em> clean up </em>/\n  H5Dclose(dataset);\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  /<em>H5Fflush(hdf5-&gt;file,H5F_SCOPE_GLOBAL);</em>/\n  free(localURI);\n  return(OK);\n}</p>\n<p>int hdf5WriteFieldHeader(struct HDF5Data<em> hdf5,int N,char</em> names)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  hsize_t dim[1];</p>\n<p>if ((hdf5 == NULL) || (hdf5-&gt;intent != WRITING))\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Attempting to write to a reading file.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  if (hdf5-&gt;group &lt;= 0)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Missing HDF5 group.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  /<em> Make a string data type </em>/\n  datatype = H5Tcopy(H5T_C_S1);\n  /<em> set the fixed string length </em>/\n  status = H5Tset_size(datatype,HDF5_STRING_LENGTH);\n  /<em> and we're gonna use C-like null-terminated strings </em>/\n  status = H5Tset_strpad(datatype,H5T_STR_NULLTERM);\n  /<em> Create a simple memory space of the correct size </em>/\n  dim[0] = N;\n  dataspace = H5Screate_simple(1,dim,NULL);\n  /<em> and create the dataset to write to </em>/\n  dataset = H5Dcreate(hdf5-&gt;group,FIELD_HEADER_DATA_NAME,datatype,\n<div class=\"highlight\"><pre>    <span class=\"n\">dataspace</span><span class=\"p\">,</span><span class=\"n\">H5P_DEFAULT</span><span class=\"p\">);</span>\n</pre></div>\n\n  /<em> Write the field names to the file </em>/\n  status = H5Dwrite(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,names);\n  /<em> clean up </em>/\n  H5Dclose(dataset);\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  /<em>H5Fflush(hdf5-&gt;file,H5F_SCOPE_GLOBAL);</em>/\n  return(OK);\n}</p>\n<p>int hdf5WriteData(struct HDF5Data<em> hdf5,int N,double</em> data)\n{\n  herr_t status = 0;</p>\n<p>if ((hdf5 == NULL) || (hdf5-&gt;intent != WRITING))\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Attempting to write to a reading file.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  if (hdf5-&gt;group &lt;= 0)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Missing HDF5 group.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  if (!hdf5-&gt;ptCreated)\n  {\n<div class=\"highlight\"><pre>    <span class=\"sr\">/* create a fixed length packet table in the file */</span>\n    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">pt</span> <span class=\"o\">=</span> <span class=\"n\">H5PTcreate_fl</span><span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">group</span><span class=\"p\">,</span><span class=\"n\">DATA_NAME</span><span class=\"p\">,</span><span class=\"n\">H5T_NATIVE_DOUBLE</span><span class=\"p\">,</span>\n      <span class=\"sr\">/*chunk size ??*/si</span><span class=\"n\">zeof</span><span class=\"p\">(</span><span class=\"n\">double</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"n\">N</span><span class=\"p\">);</span>\n    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">ptCreated</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">;</span>\n</pre></div>\n\n  }\n  if (hdf5-&gt;ptCreated)\n  {\n<div class=\"highlight\"><pre>    <span class=\"sr\">/* Write a packet to the packet table */</span>\n    <span class=\"n\">status</span> <span class=\"o\">=</span> <span class=\"n\">H5PTappend</span><span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">pt</span><span class=\"p\">,</span><span class=\"n\">N</span><span class=\"p\">,(</span><span class=\"n\">void</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">data</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  return(OK);\n}</p>\n<p>char<em> hdf5ReadSimulationModelURI(struct HDF5Data</em> hdf5)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  char <em>uri = (char</em>)NULL;</p>\n<p>if ((hdf5 == NULL) || (hdf5-&gt;intent != READING))\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Attempting to read from a writing file.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">((</span><span class=\"n\">char</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">NULL</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  if (hdf5-&gt;group &lt;= 0)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Missing HDF5 group.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  /<em> open the dataset </em>/\n  dataset = H5Dopen(hdf5-&gt;group,SIMULATION_MODEL_URI_NAME);\n  dataspace = H5Dget_space(dataset);\n  /<em> get the data type </em>/\n  datatype = H5Dget_type(dataset);\n  /<em> allocate memory </em>/\n  uri = (char<em>)malloc(HDF5_STRING_LENGTH);\n  /</em> read in the data <em>/\n  status = H5Dread(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,uri);\n  if (status &lt; 0)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Error getting the dimension of the field header.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"n\">free</span><span class=\"p\">(</span><span class=\"n\">uri</span><span class=\"p\">);</span>\n    <span class=\"n\">H5Sclose</span><span class=\"p\">(</span><span class=\"n\">dataspace</span><span class=\"p\">);</span>\n    <span class=\"n\">H5Tclose</span><span class=\"p\">(</span><span class=\"n\">datatype</span><span class=\"p\">);</span>\n    <span class=\"n\">H5Dclose</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">((</span><span class=\"n\">char</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">NULL</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  /</em> clean up */\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  H5Dclose(dataset);\n  return(uri);\n}</p>\n<p>char<strong> hdf5ReadFieldHeader(struct HDF5Data<em> hdf5,int</em> N)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  hsize_t dim[1];\n  char <em>tmp,</em>names = (char*)NULL;\n  char</strong> fields = (char**)NULL;\n  int i;</p>\n<p>if ((hdf5 == NULL) || (hdf5-&gt;intent != READING))\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Attempting to read from a writing file.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">((</span><span class=\"n\">char</span><span class=\"o\">**</span><span class=\"p\">)</span><span class=\"n\">NULL</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  if (hdf5-&gt;group &lt;= 0)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Missing HDF5 group.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  /<em> open the dataset </em>/\n  dataset = H5Dopen(hdf5-&gt;group,FIELD_HEADER_DATA_NAME);\n  dataspace = H5Dget_space(dataset);\n  /<em> get the data type </em>/\n  datatype = H5Dget_type(dataset);\n  /<em> get the size and allocate memory </em>/\n  status = H5Sget_simple_extent_dims(dataspace,dim,NULL);\n  if (status &lt; 0)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Error getting the dimension of the field header.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"n\">H5Sclose</span><span class=\"p\">(</span><span class=\"n\">dataspace</span><span class=\"p\">);</span>\n    <span class=\"n\">H5Tclose</span><span class=\"p\">(</span><span class=\"n\">datatype</span><span class=\"p\">);</span>\n    <span class=\"n\">H5Dclose</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">((</span><span class=\"n\">char</span><span class=\"o\">**</span><span class=\"p\">)</span><span class=\"n\">NULL</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  names = (char<em>)malloc(HDF5_STRING_LENGTH</em>dim[0]);\n  /<em> read in the data </em>/\n  status = H5Dread(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,names);\n  if (status &lt; 0)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Error getting the dimension of the field header.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"n\">free</span><span class=\"p\">(</span><span class=\"n\">names</span><span class=\"p\">);</span>\n    <span class=\"n\">H5Sclose</span><span class=\"p\">(</span><span class=\"n\">dataspace</span><span class=\"p\">);</span>\n    <span class=\"n\">H5Tclose</span><span class=\"p\">(</span><span class=\"n\">datatype</span><span class=\"p\">);</span>\n    <span class=\"n\">H5Dclose</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">((</span><span class=\"n\">char</span><span class=\"o\">**</span><span class=\"p\">)</span><span class=\"n\">NULL</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  /<em> clean up </em>/\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  H5Dclose(dataset);\n  /<em> split up the names </em>/\n  fields = (char<em><em>)malloc(sizeof(char</em>)</em>dim[0]);\n  tmp = names;\n  for (i=0;i&lt;dim[0];i++)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fields</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">char</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">malloc</span><span class=\"p\">(</span><span class=\"n\">strlen</span><span class=\"p\">(</span><span class=\"n\">tmp</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">);</span>\n    <span class=\"n\">strcpy</span><span class=\"p\">(</span><span class=\"n\">fields</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">tmp</span><span class=\"p\">);</span>\n    <span class=\"n\">tmp</span> <span class=\"o\">+=</span> <span class=\"n\">HDF5_STRING_LENGTH</span><span class=\"p\">;</span>\n</pre></div>\n\n  }\n  free(names);\n  *N = dim[0];\n  return(fields);\n}</p>\n<p>double<em> hdf5ReadData(struct HDF5Data</em> hdf5,int N)\n{\n  herr_t status = 0;\n  double<em> data = (double</em>)malloc(sizeof(double)*N);</p>\n<p>if ((hdf5 == NULL) || (hdf5-&gt;intent != READING))\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Attempting to read from a writing file.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">((</span><span class=\"n\">double</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">NULL</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  if (hdf5-&gt;group &lt;= 0)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Missing HDF5 group.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">ERR</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  if (!hdf5-&gt;ptCreated)\n  {\n<div class=\"highlight\"><pre>    <span class=\"sr\">/* open the packet table */</span>\n    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">pt</span> <span class=\"o\">=</span> <span class=\"n\">H5PTopen</span><span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">group</span><span class=\"p\">,</span><span class=\"n\">DATA_NAME</span><span class=\"p\">);</span>\n    <span class=\"sr\">/* and make sure we&#39;re at the start of the table */</span>\n    <span class=\"n\">H5PTcreate_index</span><span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">pt</span><span class=\"p\">);</span>\n    <span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">ptCreated</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">;</span>\n</pre></div>\n\n  }\n  if (hdf5-&gt;ptCreated)\n  {\n<div class=\"highlight\"><pre>    <span class=\"sr\">/* get N packets from the packet table */</span>\n    <span class=\"n\">status</span> <span class=\"o\">=</span> <span class=\"n\">H5PTget_next</span><span class=\"p\">(</span><span class=\"n\">hdf5</span><span class=\"o\">-&gt;</span><span class=\"n\">pt</span><span class=\"p\">,</span><span class=\"n\">N</span><span class=\"p\">,(</span><span class=\"n\">void</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">data</span><span class=\"p\">);</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">status</span><span class=\"o\">&lt;</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n      <span class=\"n\">free</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">);</span>\n      <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">double</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">NULL</span><span class=\"p\">;</span>\n    <span class=\"p\">}</span>\n</pre></div>\n\n  }\n  return(data);\n}</p>\n<p>struct SimulationList<em> hdf5ReadSimulations(struct HDF5Data</em> hdf5)\n{\n  struct SimulationList<em> simulations = (struct SimulationList</em>)NULL;</p>\n<p>if ((hdf5 == NULL) || (hdf5-&gt;intent != READING))\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">fprintf</span><span class=\"p\">(</span><span class=\"n\">stderr</span><span class=\"p\">,</span><span class=\"s\">&quot;Attempting to read from a writing file.\\n&quot;</span><span class=\"p\">);</span>\n    <span class=\"k\">return</span><span class=\"p\">(</span><span class=\"n\">simulations</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  /<em> look for any groups which are children of the root group </em>/\n  hid_t rootGroup = H5Gopen(hdf5-&gt;file,\"/\");\n  if (rootGroup &gt; 0)\n  {\n<div class=\"highlight\"><pre>    <span class=\"n\">simulations</span> <span class=\"o\">=</span> <span class=\"n\">CreateSimulationList</span><span class=\"p\">();</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">H5Giterate</span><span class=\"p\">(</span><span class=\"n\">rootGroup</span><span class=\"p\">,</span><span class=\"s\">&quot;/&quot;</span><span class=\"p\">,</span><span class=\"n\">NULL</span><span class=\"p\">,</span><span class=\"n\">rootIterator</span><span class=\"p\">,(</span><span class=\"n\">void</span><span class=\"o\">*</span><span class=\"p\">)</span><span class=\"n\">simulations</span><span class=\"p\">)</span>\n      <span class=\"o\">!=</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"n\">DestroySimulationList</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">simulations</span><span class=\"p\">);</span>\n    <span class=\"n\">H5Gclose</span><span class=\"p\">(</span><span class=\"n\">rootGroup</span><span class=\"p\">);</span>\n</pre></div>\n\n  }\n  return(simulations);\n}</p>\n<p>[HTML_REMOVED]</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 1, "parent": 69, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 64}}, {"pk": 128, "model": "server.post", "fields": {"rght": 16, "author": 6, "answer_accepted": true, "tag_string": "annotation protein pfam protein", "creation_date": "2010-03-04 00:14:24", "lft": 1, "post_type": 164033, "score": 4, "title": "Pfam based functional annotaion", "unanswered": false, "content": "I think in one of the [earlier thread][1], Istvan has already asked about the reliability of GO annotation. I was wondering, if any of you have any experience with the functional annotation based upon the [Pfam database][2]. I am looking forward to functionally annotate a large set of peptide library and the easiest way I can think about is to do batch search of those peptides against the Pfam database.In case you guys know a better approach , kindly share it.\n\ncheers\n\n\n  [1]: http://biostar.stackexchange.com/questions/41/how-much-do-you-trust-geneontology\n  [2]: http://pfam.sanger.ac.uk/", "comment_count": 0, "html": "<p>I think in one of the <a href=\"http://biostar.stackexchange.com/questions/41/how-much-do-you-trust-geneontology\">earlier thread</a>, Istvan has already asked about the reliability of GO annotation. I was wondering, if any of you have any experience with the functional annotation based upon the <a href=\"http://pfam.sanger.ac.uk/\">Pfam database</a>. I am looking forward to functionally annotate a large set of peptide library and the easiest way I can think about is to do batch search of those peptides against the Pfam database.In case you guys know a better approach , kindly share it.</p>\n<p>cheers</p>", "child_count": 0, "closed": false, "tree_id": 35, "revision_count": 3, "parent": null, "views": 492, "deleted": false, "answer_count": 8, "touch_date": "2011-11-24 14:49:26", "slug": "pfam-based-functional-annotaion", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [41, 68, 74], "lastedit_user": 22}}, {"pk": 129, "model": "server.post", "fields": {"rght": 7, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 08:49:51", "lft": 2, "post_type": 109787, "score": 4, "title": "A: Pfam based functional annotaion", "unanswered": false, "content": "My experience with Pfam is limited, but I think relevant to your question.\n\nI work on a human pathogen which has been entirely sequenced and therefore we know quite a bit about what's in it. In particular, I'm interested one pfam group (PF02009) that groups similar proteins from this pathogen.\n\nThe problem I have with the pfam group is that it groups several distinct groups of proteins. These proteins are related, I agree, however, **at the level I'm comparing them (which is in detail)**, I would not jump to the conclusion that these proteins share the same function.\n\nThat brings me to the following comment on your question: looking for functional annotation is very vague. What detail of functional annotation are you looking for?\n\n  * Do you want to know if these peptides belong to groups called \"enzymes\" or \"receptors\" or some kind of basic \"building blocks\", without any more detail?\n  * Do you want to know if these peptides belong to a specific class of enzymes?\n  * Do you want to know if these peptides belong to a specific sub-class of enzymes, going all the way down to the substrate specificity?\n\nAnother question I would have is regarding the length of your peptides. I recall one of my collaborators complaining about the fact that Pfam would not detect fragments that were too short. That was with Pfam2. I don't know how this is with Pfam3 though. So, you'll have to test this.\n\nDepending on the answer to these questions (and many more) you may or may not want to ***only*** use Pfam. But in any case, Pfam could be a good start, if your peptides are not too short.\n\n\nAnother way that might be more relevant to short sequences would be to look at BLAST approaches (PSI- or PHI-BLAST in particular) to find what your peptides match to, and then look at the functional annotation of those hits (including whatever Pfam domains they may contain). I think this method would be more sensitive than the Pfam approach.\n\n", "comment_count": 2, "html": "<p>My experience with Pfam is limited, but I think relevant to your question.</p>\n<p>I work on a human pathogen which has been entirely sequenced and therefore we know quite a bit about what's in it. In particular, I'm interested one pfam group (PF02009) that groups similar proteins from this pathogen.</p>\n<p>The problem I have with the pfam group is that it groups several distinct groups of proteins. These proteins are related, I agree, however, <strong>at the level I'm comparing them (which is in detail)</strong>, I would not jump to the conclusion that these proteins share the same function.</p>\n<p>That brings me to the following comment on your question: looking for functional annotation is very vague. What detail of functional annotation are you looking for?</p>\n<ul>\n<li>Do you want to know if these peptides belong to groups called \"enzymes\" or \"receptors\" or some kind of basic \"building blocks\", without any more detail?</li>\n<li>Do you want to know if these peptides belong to a specific class of enzymes?</li>\n<li>Do you want to know if these peptides belong to a specific sub-class of enzymes, going all the way down to the substrate specificity?</li>\n</ul>\n<p>Another question I would have is regarding the length of your peptides. I recall one of my collaborators complaining about the fact that Pfam would not detect fragments that were too short. That was with Pfam2. I don't know how this is with Pfam3 though. So, you'll have to test this.</p>\n<p>Depending on the answer to these questions (and many more) you may or may not want to <strong><em>only</em></strong> use Pfam. But in any case, Pfam could be a good start, if your peptides are not too short.</p>\n<p>Another way that might be more relevant to short sequences would be to look at BLAST approaches (PSI- or PHI-BLAST in particular) to find what your peptides match to, and then look at the functional annotation of those hits (including whatever Pfam domains they may contain). I think this method would be more sensitive than the Pfam approach.</p>", "child_count": 0, "closed": false, "tree_id": 35, "revision_count": 1, "parent": 128, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:18", "slug": "a-pfam-based-functional-annotaion", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 25}}, {"pk": 130, "model": "server.post", "fields": {"rght": 6, "author": 61, "answer_accepted": false, "tag_string": "sequencing k", "creation_date": "2010-03-04 11:41:29", "lft": 1, "post_type": 164033, "score": 5, "title": "k-mer based sequencing contamination detection", "unanswered": false, "content": "In a plant genome project I got a draft assembly (> 500Mbp, >500k contigs). \nA number of contigs is no doubt bacterial in origin. \n\nThere are at least 3 peaks when it comes to GC content (40% - my plant, 50% largest contig, 65-70% another group). \n\nBlastn takes ages, and there is no point of doing it every time we change assembler parameters even slightly. So while rather sooner than later I will have to split 454 sff files into my_plant vs not_my_plant, I will still need a faster method of classifying contigs to not_my_plant group. \n\nIn metagenomics this is often being done by calculating k-mer frequencies, see i.e (not supported anymore) TETRA:  http://www.megx.net/tetra/ (see the manual for the algorithm)\n\nDo you use any program for fast clustering/classification of  sequences from say 150bp to 1Mbp using k-mer frequencies?\n\n", "comment_count": 0, "html": "<p>In a plant genome project I got a draft assembly (&gt; 500Mbp, &gt;500k contigs). \nA number of contigs is no doubt bacterial in origin. </p>\n<p>There are at least 3 peaks when it comes to GC content (40% - my plant, 50% largest contig, 65-70% another group). </p>\n<p>Blastn takes ages, and there is no point of doing it every time we change assembler parameters even slightly. So while rather sooner than later I will have to split 454 sff files into my_plant vs not_my_plant, I will still need a faster method of classifying contigs to not_my_plant group. </p>\n<p>In metagenomics this is often being done by calculating k-mer frequencies, see i.e (not supported anymore) TETRA:  http://www.megx.net/tetra/ (see the manual for the algorithm)</p>\n<p>Do you use any program for fast clustering/classification of  sequences from say 150bp to 1Mbp using k-mer frequencies?</p>", "child_count": 0, "closed": false, "tree_id": 36, "revision_count": 1, "parent": null, "views": 742, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:30", "slug": "k-mer-based-sequencing-contamination-detection", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [23, 75], "lastedit_user": 61}}, {"pk": 131, "model": "server.post", "fields": {"rght": 23, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 13:51:46", "lft": 18, "post_type": 109787, "score": 5, "title": "A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "Shameless plug for the [bioinformatics subreddit][1] (of which I am a moderator).\n\n\n  [1]: http://www.reddit.com/r/bioinformatics", "comment_count": 2, "html": "<p>Shameless plug for the <a href=\"http://www.reddit.com/r/bioinformatics\">bioinformatics subreddit</a> (of which I am a moderator).</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 1, "parent": 112, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 67}}, {"pk": 132, "model": "server.post", "fields": {"rght": 14, "author": 9, "answer_accepted": false, "tag_string": "cloud general", "creation_date": "2010-03-04 14:08:04", "lft": 1, "post_type": 164033, "score": 9, "title": "Experiences with cloud computing in bioinformatics", "unanswered": false, "content": "In the past years cloud computing services such as the [Amazon's Elastic Compute][1] cloud seem to have emerged a recommended alternative for providing high performance computing.\n\nWhat are your experiences when it comes to *bioinformatics in the cloud*?\n\n  [1]: http://aws.amazon.com/ec2/", "comment_count": 0, "html": "<p>In the past years cloud computing services such as the <a href=\"http://aws.amazon.com/ec2/\">Amazon's Elastic Compute</a> cloud seem to have emerged a recommended alternative for providing high performance computing.</p>\n<p>What are your experiences when it comes to <em>bioinformatics in the cloud</em>?</p>", "child_count": 0, "closed": false, "tree_id": 37, "revision_count": 1, "parent": null, "views": 2162, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:31", "slug": "experiences-with-cloud-computing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [31, 76], "lastedit_user": 9}}, {"pk": 133, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 14:24:46", "lft": 2, "post_type": 109787, "score": 13, "title": "A: Experiences with cloud computing in bioinformatics", "unanswered": false, "content": "We have been somewhat *early adopters* of cloud computing, having evaluated it for our bioinformatics needs more than two years ago. We are also what you could call *early abandoners*;  after using it for a year we compared it against a the high computing facility' services at our university ([Penn State HPC][1]) and we found it substantially under-performing.\n\nThis is not to say that Cloud Computing is not a fantastic idea, its just that just about all universities and science oriented organizations have far more powerful computing facilities to begin with.\n\nCould computing is probably ideal for satisfying the temporary needs of a small lab with minimal funds and resources as it allows them to perform computations that otherwise would be out of reach. Yet as soon as the lab has continuous computational needs the cloud based solutions become not only more expensive but also a lot less powerful than a comparable \"traditional\" computing services.\n\nI have come up with my own \"rule of thumb\" estimation: *If within an entire year one only needs to run their computers for less than 30% of time then cloud computing may be worth it.* \n\n  [1]: http://gears.aset.psu.edu/hpc/", "comment_count": 1, "html": "<p>We have been somewhat <em>early adopters</em> of cloud computing, having evaluated it for our bioinformatics needs more than two years ago. We are also what you could call <em>early abandoners</em>;  after using it for a year we compared it against a the high computing facility' services at our university (<a href=\"http://gears.aset.psu.edu/hpc/\">Penn State HPC</a>) and we found it substantially under-performing.</p>\n<p>This is not to say that Cloud Computing is not a fantastic idea, its just that just about all universities and science oriented organizations have far more powerful computing facilities to begin with.</p>\n<p>Could computing is probably ideal for satisfying the temporary needs of a small lab with minimal funds and resources as it allows them to perform computations that otherwise would be out of reach. Yet as soon as the lab has continuous computational needs the cloud based solutions become not only more expensive but also a lot less powerful than a comparable \"traditional\" computing services.</p>\n<p>I have come up with my own \"rule of thumb\" estimation: <em>If within an entire year one only needs to run their computers for less than 30% of time then cloud computing may be worth it.</em> </p>", "child_count": 0, "closed": false, "tree_id": 37, "revision_count": 1, "parent": 132, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-experiences-with-cloud-computing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 134, "model": "server.post", "fields": {"rght": 17, "author": 63, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 14:30:04", "lft": 16, "post_type": 109787, "score": 5, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "This article may shed light onto how to organise bioinformatics projects.\nWilliam Stafford Noble. \"A quick guide to organizing computational biology experiments.\" PLoS Computational Biology. 5(7):e1000424, 2009\n\nlink:\nhttp://noble.gs.washington.edu/papers/noble2009quick.html\n\nFor me using git and the directory structure that Bill Noble mentiones in this articles has been a better approach than what I had before.", "comment_count": 0, "html": "<p>This article may shed light onto how to organise bioinformatics projects.\nWilliam Stafford Noble. \"A quick guide to organizing computational biology experiments.\" PLoS Computational Biology. 5(7):e1000424, 2009</p>\n<p>link:\nhttp://noble.gs.washington.edu/papers/noble2009quick.html</p>\n<p>For me using git and the directory structure that Bill Noble mentiones in this articles has been a better approach than what I had before.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 1, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 63}}, {"pk": 135, "model": "server.post", "fields": {"rght": 5, "author": 63, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 14:33:33", "lft": 4, "post_type": 109787, "score": 11, "title": "A: Experiences with cloud computing in bioinformatics", "unanswered": false, "content": "Cloud computing is becoming a technology mature enough for its use in genome research experiments. The use of large datasets, its highly demanding algorithms and the need for sudden computational resources, make large-scale sequencing experiments an attractive test-case for cloud computing. So far I have seen cloud computing demonstrated [using R][1]. However, it remains to be seen a rigorous comparison of its performance using a [BLAST search][2] and its ability to cope with ever-increasing databases and open source frameworks such as [bioperl][3] or [bioconductor][4].\n\nCloud computing claims to be [a resource where IT power is delivered over the Internet as you need it, rather than drawn from a desktop computer][5], in a fashion seemingly [similar to having your own virtual servers available over the Internet][6]. Some of the most important aspects of cloud computing are:\n\n* Software as a Service (SaaS): where you buy a software license for a determined period of time.\n* Utility Computing: storage and virtual servers that IT can access on demand.\n* Web Services.\n\nMy first exposure to cloud computing came of an email from [Matt Wood][7], a newly established group leader at the [Sanger Institute][8], announcing the [Cloud Computing Group][9] in Cambridge, UK. At that point I had no idea of what it meant. When I attended the meeting at Cambridge University\u2019s [Centre for Mathematical Sciences][10], to my surprise I found there a very select audience, ranging from the director of IT at Sanger, [Phil Butcher][11], one of the [Ensembl][12] software coordinators, [Glenn Proctor][13], and quite a few local start-up companies.\n\nAmong the presenters, we had Simone Brunozzi, from [Amazon\u2019s Cloud Computing][14]. I think he had an interesting story to tell: how Amazon, a well known company, is now involved in the business of cloud computing and selling it. Apparently, this technology they sell was developed for Amazon\u2019s own business. Among their main challenges was to be able to address the capricious shopping habits of customers, with orders peaking around Christmas and quite flat the rest of the year. These trends required rapid adaptability of computational resources. The idea of cloud computing fitted well with their business model of e-commerce: you don\u2019t need to care about where your computation is done, the only thing you care about is that you have the needed resources and do not have to pay for them when you don\u2019t need them. One of the things that stroke me about Amazon\u2019s presentation was that they would not tell us the number of processors they had at their disposal.\n\nWhen it comes to using cloud computing for genomics research, prices may be quite expensive when they add up. The bioinformatics field, greatly influenced by the open-source movement, is not likely to rush to join Amazon\u2019s cloud. Private efforts trying to make money out of human genome technology have remained rather unsuccessful to date: think of Celera Genomics or Lion Bioscience. I am skeptical of the bioinformatics community adopting cloud computing unless open source ideals are embraced: \n\n - allowing people to develop and contribute to the technology if and when they want to, \n - allowing total openness in terms of its achievements and pitfalls and \n - making it free to use for everyone. \n\nI do not think that making it free does not mean there is no margin for profit. Think of the profitability of free-to-use technologies such as [java][15] or [MySQL][16], both components of [SUN Microsystems][17]\u2019 business.\n\nDespite the promise of potential benefits for the bioinformatics community, the way the cloud is being portrayed does not conform the ideals of free access and openness. Unless these ideals are implemented to some extent, I see it difficult for the cloud to take root in the bioinformatics field and become a new standard platform for genome research.\n\n\n  [1]: http://www.r-project.org/\n  [2]: http://blast.ncbi.nlm.nih.gov/Blast.cgi\n  [3]: http://www.bioperl.org/wiki/Main_Page\n  [4]: http://www.bioconductor.org/\n  [5]: http://www.guardian.co.uk/technology/2008/sep/29/cloud.computing.richard.stallman\n  [6]: http://www.infoworld.com/article/08/04/07/15FE-cloud-computing-reality_1.html\n  [7]: http://www.sanger.ac.uk/Users/mw4/\n  [8]: http://www.sanger.ac.uk/\n  [9]: http://cloudcamb.org/\n  [10]: http://www.cms.cam.ac.uk/site/\n  [11]: http://www.yourgenome.org/people/phil_butcher.shtml\n  [12]: http://www.ensembl.org/index.html\n  [13]: http://www.ebi.ac.uk/Information/Staff/person_maintx.php?s_person_id=299\n  [14]: http://aws.amazon.com/ec2/\n  [15]: http://www.java.com/en/\n  [16]: http://www.mysql.com/\n  [17]: http://www.sun.com/ ", "comment_count": 0, "html": "<p>Cloud computing is becoming a technology mature enough for its use in genome research experiments. The use of large datasets, its highly demanding algorithms and the need for sudden computational resources, make large-scale sequencing experiments an attractive test-case for cloud computing. So far I have seen cloud computing demonstrated <a href=\"http://www.r-project.org/\">using R</a>. However, it remains to be seen a rigorous comparison of its performance using a <a href=\"http://blast.ncbi.nlm.nih.gov/Blast.cgi\">BLAST search</a> and its ability to cope with ever-increasing databases and open source frameworks such as <a href=\"http://www.bioperl.org/wiki/Main_Page\">bioperl</a> or <a href=\"http://www.bioconductor.org/\">bioconductor</a>.</p>\n<p>Cloud computing claims to be <a href=\"http://www.guardian.co.uk/technology/2008/sep/29/cloud.computing.richard.stallman\">a resource where IT power is delivered over the Internet as you need it, rather than drawn from a desktop computer</a>, in a fashion seemingly <a href=\"http://www.infoworld.com/article/08/04/07/15FE-cloud-computing-reality_1.html\">similar to having your own virtual servers available over the Internet</a>. Some of the most important aspects of cloud computing are:</p>\n<ul>\n<li>Software as a Service (SaaS): where you buy a software license for a determined period of time.</li>\n<li>Utility Computing: storage and virtual servers that IT can access on demand.</li>\n<li>Web Services.</li>\n</ul>\n<p>My first exposure to cloud computing came of an email from <a href=\"http://www.sanger.ac.uk/Users/mw4/\">Matt Wood</a>, a newly established group leader at the <a href=\"http://www.sanger.ac.uk/\">Sanger Institute</a>, announcing the <a href=\"http://cloudcamb.org/\">Cloud Computing Group</a> in Cambridge, UK. At that point I had no idea of what it meant. When I attended the meeting at Cambridge University\u2019s <a href=\"http://www.cms.cam.ac.uk/site/\">Centre for Mathematical Sciences</a>, to my surprise I found there a very select audience, ranging from the director of IT at Sanger, <a href=\"http://www.yourgenome.org/people/phil_butcher.shtml\">Phil Butcher</a>, one of the <a href=\"http://www.ensembl.org/index.html\">Ensembl</a> software coordinators, <a href=\"http://www.ebi.ac.uk/Information/Staff/person_maintx.php?s_person_id=299\">Glenn Proctor</a>, and quite a few local start-up companies.</p>\n<p>Among the presenters, we had Simone Brunozzi, from <a href=\"http://aws.amazon.com/ec2/\">Amazon\u2019s Cloud Computing</a>. I think he had an interesting story to tell: how Amazon, a well known company, is now involved in the business of cloud computing and selling it. Apparently, this technology they sell was developed for Amazon\u2019s own business. Among their main challenges was to be able to address the capricious shopping habits of customers, with orders peaking around Christmas and quite flat the rest of the year. These trends required rapid adaptability of computational resources. The idea of cloud computing fitted well with their business model of e-commerce: you don\u2019t need to care about where your computation is done, the only thing you care about is that you have the needed resources and do not have to pay for them when you don\u2019t need them. One of the things that stroke me about Amazon\u2019s presentation was that they would not tell us the number of processors they had at their disposal.</p>\n<p>When it comes to using cloud computing for genomics research, prices may be quite expensive when they add up. The bioinformatics field, greatly influenced by the open-source movement, is not likely to rush to join Amazon\u2019s cloud. Private efforts trying to make money out of human genome technology have remained rather unsuccessful to date: think of Celera Genomics or Lion Bioscience. I am skeptical of the bioinformatics community adopting cloud computing unless open source ideals are embraced: </p>\n<ul>\n<li>allowing people to develop and contribute to the technology if and when they want to, </li>\n<li>allowing total openness in terms of its achievements and pitfalls and </li>\n<li>making it free to use for everyone. </li>\n</ul>\n<p>I do not think that making it free does not mean there is no margin for profit. Think of the profitability of free-to-use technologies such as <a href=\"http://www.java.com/en/\">java</a> or <a href=\"http://www.mysql.com/\">MySQL</a>, both components of <a href=\"http://www.sun.com/\">SUN Microsystems</a>\u2019 business.</p>\n<p>Despite the promise of potential benefits for the bioinformatics community, the way the cloud is being portrayed does not conform the ideals of free access and openness. Unless these ideals are implemented to some extent, I see it difficult for the cloud to take root in the bioinformatics field and become a new standard platform for genome research.</p>", "child_count": 0, "closed": false, "tree_id": 37, "revision_count": 2, "parent": 132, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-experiences-with-cloud-computing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 136, "model": "server.post", "fields": {"rght": 13, "author": 63, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 14:36:29", "lft": 12, "post_type": 109787, "score": 5, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "Unix, Perl and MySQL are programming skills that you need to master (I can think of people who would also say Java, Javascript, CSS, etc.). The best way to master the art of programming is to spend as much time as possible reading and writing source code. Some people think Perl is doomed. This is not true in the bioinformatics world. In part due to legacy and in part to the flexibility it provides, Perl is still the language of choice for many biohackers. Perl is used to construct 1) the back end of web applications, 2) pipelines and workflows and 3) quick and dirty scripts for parsing and calling other programs.\n\nYou will also need to be familiar with projects like R and Bioconductor, since a lot of the work will involve providing the computational infrastructure for analyzing data. In addition, you\u2019ll need to know about data formats (fasta, sbml, mmcif\u2026), software toolkits and libraries (Paup, Phylip, EMBOSS, BioPerl\u2026), databases (Ensembl, InterPro, PDB, KEGG\u2026), webservers and portals (Pubmed, ISCB).\n\nFinally keep in mind best practices (like refraining from reinventing the wheel), but above all, give yourself the time to enjoy the learning process. Getting to the top usually takes longer than staying at the top; so what\u2019s the point if you haven\u2019t enjoyed the trip?", "comment_count": 0, "html": "<p>Unix, Perl and MySQL are programming skills that you need to master (I can think of people who would also say Java, Javascript, CSS, etc.). The best way to master the art of programming is to spend as much time as possible reading and writing source code. Some people think Perl is doomed. This is not true in the bioinformatics world. In part due to legacy and in part to the flexibility it provides, Perl is still the language of choice for many biohackers. Perl is used to construct 1) the back end of web applications, 2) pipelines and workflows and 3) quick and dirty scripts for parsing and calling other programs.</p>\n<p>You will also need to be familiar with projects like R and Bioconductor, since a lot of the work will involve providing the computational infrastructure for analyzing data. In addition, you\u2019ll need to know about data formats (fasta, sbml, mmcif\u2026), software toolkits and libraries (Paup, Phylip, EMBOSS, BioPerl\u2026), databases (Ensembl, InterPro, PDB, KEGG\u2026), webservers and portals (Pubmed, ISCB).</p>\n<p>Finally keep in mind best practices (like refraining from reinventing the wheel), but above all, give yourself the time to enjoy the learning process. Getting to the top usually takes longer than staying at the top; so what\u2019s the point if you haven\u2019t enjoyed the trip?</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 63}}, {"pk": 137, "model": "server.post", "fields": {"rght": 24, "author": 9, "answer_accepted": false, "tag_string": "short aligner sequence short", "creation_date": "2010-03-04 14:40:30", "lft": 1, "post_type": 164033, "score": 6, "title": "What methods do you use for short read mapping?", "unanswered": false, "content": "When it comes to short read mapping there seemingly is no shortage of methods or software to choose from. Yet in practice we found that some published methods did now work at all, others exhibited suboptimal behaviors. \n\n - What short read mappers do you use? \n - How many reads do you need align and what is the size of the genome that you align to? \n - What are the typical computational resources: parallel processes/CPU/memory required for the completion of the task?\n - What is your overall assessment of the procedure: easy, tedious, fun?\n\nNote: we're primarily looking to hear of your first hand, personal experiences with any given tool.\n", "comment_count": 0, "html": "<p>When it comes to short read mapping there seemingly is no shortage of methods or software to choose from. Yet in practice we found that some published methods did now work at all, others exhibited suboptimal behaviors. </p>\n<ul>\n<li>What short read mappers do you use? </li>\n<li>How many reads do you need align and what is the size of the genome that you align to? </li>\n<li>What are the typical computational resources: parallel processes/CPU/memory required for the completion of the task?</li>\n<li>What is your overall assessment of the procedure: easy, tedious, fun?</li>\n</ul>\n<p>Note: we're primarily looking to hear of your first hand, personal experiences with any given tool.</p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 1, "parent": null, "views": 2569, "deleted": false, "answer_count": 14, "touch_date": "2011-11-24 14:49:31", "slug": "what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [24, 25, 40], "lastedit_user": 9}}, {"pk": 138, "model": "server.post", "fields": {"rght": 16, "author": 63, "answer_accepted": false, "tag_string": "best subjective bioinformatics", "creation_date": "2010-03-04 14:54:54", "lft": 1, "post_type": 164033, "score": 7, "title": "What is the best place in the world to do Bioinformatics?", "unanswered": false, "content": "I guess the best place would need to:\n\n - Have a critical mass of scientists\n - Be a world leading site for its reputation in science\n - Have well known projects\n - Good facilties\n - Good pay/Well funded\n - Leading Technology Provider\n\n ", "comment_count": 0, "html": "<p>I guess the best place would need to:</p>\n<ul>\n<li>Have a critical mass of scientists</li>\n<li>Be a world leading site for its reputation in science</li>\n<li>Have well known projects</li>\n<li>Good facilties</li>\n<li>Good pay/Well funded</li>\n<li>Leading Technology Provider</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 39, "revision_count": 2, "parent": null, "views": 636, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:30", "slug": "what-is-the-best-place-in-the-world-to-do-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [32, 58, 152], "lastedit_user": 63}}, {"pk": 139, "model": "server.post", "fields": {"rght": 10, "author": 6, "answer_accepted": false, "tag_string": "sequencing genomics", "creation_date": "2010-03-04 14:57:03", "lft": 1, "post_type": 164033, "score": 2, "title": "State of computational genomics", "unanswered": false, "content": "The other day on facebook, I posted this link and some of my friend started discussing about this article. \n\n[It's \"Watson Meets Moore\" as Ion Torrent founder Jonatha Rothberg introduces post-light semiconductor sequencing.][1] \n\n\nfew comments from my friends\n\nKrishna : \"I dont understand this rat race for next gen sequencing. While its true that a cheaper and faster sequencing technology would revolutionalize personal genomics, its more important to develop effective algorithms that could make sense of the zillions of data that would be generated. We do have hundreds of organisms sequenced, but still dont seem to understand a bit of the complexity of the genome!!\"\n\n[Abhishek Tiwari][2]\n@Krishna I could not agree more. People think by commoditizing the genome sequencing some day miracle will happen and we will be able to understand the complexity of Genome. I am afraid we are going to lost in data without any clue what we are looking for. See this in other way, diverting to much funding in these sequencing projects makes it very hard to sustain to bioinformatics research. \n\n\n  [1]: http://bit.ly/9YIW7k\n  [2]: http://biostar.stackexchange.com/users/65/abhishek-tiwari\n\nWe were unison in observation that computational genomics is not at par with it's experimental counter part at the moment. I was wondering what do you guys think about it and how can we make sure that we don't loose the \"interesting information\" coming out of the sequencing projects ?", "comment_count": 0, "html": "<p>The other day on facebook, I posted this link and some of my friend started discussing about this article. </p>\n<p><a href=\"http://bit.ly/9YIW7k\">It's \"Watson Meets Moore\" as Ion Torrent founder Jonatha Rothberg introduces post-light semiconductor sequencing.</a> </p>\n<p>few comments from my friends</p>\n<p>Krishna : \"I dont understand this rat race for next gen sequencing. While its true that a cheaper and faster sequencing technology would revolutionalize personal genomics, its more important to develop effective algorithms that could make sense of the zillions of data that would be generated. We do have hundreds of organisms sequenced, but still dont seem to understand a bit of the complexity of the genome!!\"</p>\n<p><a href=\"http://biostar.stackexchange.com/users/65/abhishek-tiwari\">Abhishek Tiwari</a>\n@Krishna I could not agree more. People think by commoditizing the genome sequencing some day miracle will happen and we will be able to understand the complexity of Genome. I am afraid we are going to lost in data without any clue what we are looking for. See this in other way, diverting to much funding in these sequencing projects makes it very hard to sustain to bioinformatics research. </p>\n<p>We were unison in observation that computational genomics is not at par with it's experimental counter part at the moment. I was wondering what do you guys think about it and how can we make sure that we don't loose the \"interesting information\" coming out of the sequencing projects ?</p>", "child_count": 0, "closed": false, "tree_id": 40, "revision_count": 3, "parent": null, "views": 173, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:18", "slug": "state-of-computational-genomics", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [23, 64], "lastedit_user": 1}}, {"pk": 140, "model": "server.post", "fields": {"rght": 11, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 14:58:13", "lft": 2, "post_type": 109787, "score": 3, "title": "A: What methods do you use for short read mapping?", "unanswered": false, "content": "I implemented my personnal suffix-array algorithm ( = **perfect match** ) because **bowtie** was too slow for **my needs**. I wrote about it here : [http://plindenbaum.blogspot.com/2010/01/elementary-school-for-bioinformatics.html][1].\n\nIt aligned all the 60 mers for each side of each SNPs (17E6 * 2 sequences) from dbSNP in about ~12H00.\n\n\n  [1]: http://plindenbaum.blogspot.com/2010/01/elementary-school-for-bioinformatics.html", "comment_count": 4, "html": "<p>I implemented my personnal suffix-array algorithm ( = <strong>perfect match</strong> ) because <strong>bowtie</strong> was too slow for <strong>my needs</strong>. I wrote about it here : <a href=\"http://plindenbaum.blogspot.com/2010/01/elementary-school-for-bioinformatics.html\">http://plindenbaum.blogspot.com/2010/01/elementary-school-for-bioinformatics.html</a>.</p>\n<p>It aligned all the 60 mers for each side of each SNPs (17E6 * 2 sequences) from dbSNP in about ~12H00.</p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 1, "parent": 137, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 141, "model": "server.post", "fields": {"rght": 5, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 14:59:37", "lft": 4, "post_type": 109787, "score": 2, "title": "A: What methods do you use for short read mapping?", "unanswered": false, "content": "A group in my institute has developed a tool called [GEM][1] for mapping short reads and in general working with next gen sequencing data, like mapping cDNAs, find splicing isoforms, etc... I never used it directly but I have attended some talks on this and it seems convincing. \n\nIn particular, to map short reads you should use the tool [gem_mapper][2].\n\n\n  [1]: http://sourceforge.net/apps/mediawiki/gemlibrary/index.php?title=The_GEM_library\n  [2]:  http://sourceforge.net/apps/mediawiki/gemlibrary/index.php?title=Gem_mapper_man_page", "comment_count": 0, "html": "<p>A group in my institute has developed a tool called <a href=\"http://sourceforge.net/apps/mediawiki/gemlibrary/index.php?title=The_GEM_library\">GEM</a> for mapping short reads and in general working with next gen sequencing data, like mapping cDNAs, find splicing isoforms, etc... I never used it directly but I have attended some talks on this and it seems convincing. </p>\n<p>In particular, to map short reads you should use the tool <a href=\"http://sourceforge.net/apps/mediawiki/gemlibrary/index.php?title=Gem_mapper_man_page\">gem_mapper</a>.</p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 1, "parent": 137, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 142, "model": "server.post", "fields": {"rght": 18, "author": 29, "answer_accepted": false, "tag_string": "snp genotyping pathways genes mining", "creation_date": "2010-03-04 15:08:48", "lft": 1, "post_type": 164033, "score": 6, "title": "Mapping SNPs to Pathways", "unanswered": false, "content": "Hi all,\ngiven a set of **SNPs**, what would be your favorite way to find theirs related **pathways**/ **diseases** ?\n\nThanks\n", "comment_count": 0, "html": "<p>Hi all,\ngiven a set of <strong>SNPs</strong>, what would be your favorite way to find theirs related <strong>pathways</strong>/ <strong>diseases</strong> ?</p>\n<p>Thanks</p>", "child_count": 0, "closed": false, "tree_id": 41, "revision_count": 1, "parent": null, "views": 2030, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:30", "slug": "mapping-snps-to-pathways", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [78, 79, 197, 198, 199], "lastedit_user": 29}}, {"pk": 143, "model": "server.post", "fields": {"rght": 7, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:13:53", "lft": 6, "post_type": 109787, "score": 3, "title": "A: What methods do you use for short read mapping?", "unanswered": false, "content": "For mapping reads obtained from the [SOLiD platform][1] we use [SHRiMP][2];\n\n - 47 million 50bp long reads in colorspace\n - We are aligning against the human genome, ~ 3 billion bases\n - A typical runtime is 12 hours for every 1 million reads. We split the 47 million reads into about 25 datasets and run them in parallel. SHRiMP's memory use depends on the size of the reads that needs to align: approx 1.6 GB per 1 million reads.\n - Overall we process the entire dataset in about a day\n - We like using the SHRiMP program. It is simple to use, has very clear documentation and no other dependencies. Importantly it easy to teach people how to use it. On the other hand it is probably a slower method than many others.\n\n  [1]: http://www3.appliedbiosystems.com/AB_Home/applicationstechnologies/SOLiD-System-Sequencing-B/index.htm\n  [2]: http://compbio.cs.toronto.edu/shrimp/", "comment_count": 0, "html": "<p>For mapping reads obtained from the <a href=\"http://www3.appliedbiosystems.com/AB_Home/applicationstechnologies/SOLiD-System-Sequencing-B/index.htm\">SOLiD platform</a> we use <a href=\"http://compbio.cs.toronto.edu/shrimp/\">SHRiMP</a>;</p>\n<ul>\n<li>47 million 50bp long reads in colorspace</li>\n<li>We are aligning against the human genome, ~ 3 billion bases</li>\n<li>A typical runtime is 12 hours for every 1 million reads. We split the 47 million reads into about 25 datasets and run them in parallel. SHRiMP's memory use depends on the size of the reads that needs to align: approx 1.6 GB per 1 million reads.</li>\n<li>Overall we process the entire dataset in about a day</li>\n<li>We like using the SHRiMP program. It is simple to use, has very clear documentation and no other dependencies. Importantly it easy to teach people how to use it. On the other hand it is probably a slower method than many others.</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 1, "parent": 137, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 144, "model": "server.post", "fields": {"rght": 7, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:14:13", "lft": 6, "post_type": 109787, "score": 5, "title": "A: Experiences with cloud computing in bioinformatics", "unanswered": false, "content": "We've had a couple of Amazon education grants to try out EC2 here, and the service is very impressive. However, it would be extremely expensive to use it as a long-term replacement for our local grid service (which does have its own limitations, but is at least effectively free at the point of delivery) or clusters (in which a considerable amount of capital has already been invested). I think for the amount of grunt work we do, and particularly for the amount of data that needs to be shunted around, cloud computing is not quite there yet.", "comment_count": 0, "html": "<p>We've had a couple of Amazon education grants to try out EC2 here, and the service is very impressive. However, it would be extremely expensive to use it as a long-term replacement for our local grid service (which does have its own limitations, but is at least effectively free at the point of delivery) or clusters (in which a considerable amount of capital has already been invested). I think for the amount of grunt work we do, and particularly for the amount of data that needs to be shunted around, cloud computing is not quite there yet.</p>", "child_count": 0, "closed": false, "tree_id": 37, "revision_count": 1, "parent": 132, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-experiences-with-cloud-computing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 145, "model": "server.post", "fields": {"rght": 5, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:19:58", "lft": 2, "post_type": 109787, "score": 4, "title": "A: What is the best place in the world to do Bioinformatics?", "unanswered": false, "content": "From a UK perspective, Cambridge has to be up there. I'm pretty sure it ticks all of your points, and you can't get much better for density of bioinformaticians than the [Genome Campus][1] in Hinxton.\n\n\n  [1]: http://www.wellcome.ac.uk/Achievements-and-Impact/Initiatives/UK-biomedical-science/Genome-Campus-and-Sanger-Institute/WTD003482.htm", "comment_count": 1, "html": "<p>From a UK perspective, Cambridge has to be up there. I'm pretty sure it ticks all of your points, and you can't get much better for density of bioinformaticians than the <a href=\"http://www.wellcome.ac.uk/Achievements-and-Impact/Initiatives/UK-biomedical-science/Genome-Campus-and-Sanger-Institute/WTD003482.htm\">Genome Campus</a> in Hinxton.</p>", "child_count": 0, "closed": false, "tree_id": 39, "revision_count": 1, "parent": 138, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-is-the-best-place-in-the-world-to-do-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 146, "model": "server.post", "fields": {"rght": 5, "author": 63, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:20:35", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Mapping SNPs to Pathways", "unanswered": false, "content": "I would use DAS -- Distributed Annotated System to retrieve all genes/phenotypes associated to a specific SNP.\n\nDAS is a webservice for decentralised annotation that provides an esy protocol to retrieve features providing an url.\n\nFor example, retrieve me all OMIM genes in chromosome 18 between base pair 1 and 1000000\n\nhttp://das.sanger.ac.uk/das/ens_36_omim_genes/features?segment=18:1,1000000\n\nMore on DAS [here][1]\n \n\n\n  [1]: http://www.biodas.org/wiki/Main_Page", "comment_count": 1, "html": "<p>I would use DAS -- Distributed Annotated System to retrieve all genes/phenotypes associated to a specific SNP.</p>\n<p>DAS is a webservice for decentralised annotation that provides an esy protocol to retrieve features providing an url.</p>\n<p>For example, retrieve me all OMIM genes in chromosome 18 between base pair 1 and 1000000</p>\n<p>http://das.sanger.ac.uk/das/ens_36_omim_genes/features?segment=18:1,1000000</p>\n<p>More on DAS <a href=\"http://www.biodas.org/wiki/Main_Page\">here</a></p>", "child_count": 0, "closed": false, "tree_id": 41, "revision_count": 1, "parent": 142, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-mapping-snps-to-pathways", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 63}}, {"pk": 147, "model": "server.post", "fields": {"rght": 3, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:22:42", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Looking for a 'Hello world\" plugin for Taverna.", "unanswered": false, "content": "Pierre, I feel your pain; Maven is not quite my friend either... Taverna is a really modular, and comes with very many dependencies... these are recursively defined and resolved using Maven... I'd love to build a plugin without it too, but never dared setting up such a system myself :)\n\nHowever, the Taverna developers have written up a [tutorial for creating new plugins][1] all from within an Eclipse (with Maven plugin) environment, which I used on Friday to set up a functional plugin from scratch in a few hours. I first thought it was typical for calling SOAP services, but in fact is pretty general. You may find yourself removing a lot of template code, as the template you install (a Maven archetype) is a full 'activity', and not a simple one port in, one port out one.\n\n  [1]: http://www.mygrid.org.uk/dev/wiki/display/developer/Tutorial+-+Service+invocation+plugin", "comment_count": 0, "html": "<p>Pierre, I feel your pain; Maven is not quite my friend either... Taverna is a really modular, and comes with very many dependencies... these are recursively defined and resolved using Maven... I'd love to build a plugin without it too, but never dared setting up such a system myself :)</p>\n<p>However, the Taverna developers have written up a <a href=\"http://www.mygrid.org.uk/dev/wiki/display/developer/Tutorial+-+Service+invocation+plugin\">tutorial for creating new plugins</a> all from within an Eclipse (with Maven plugin) environment, which I used on Friday to set up a functional plugin from scratch in a few hours. I first thought it was typical for calling SOAP services, but in fact is pretty general. You may find yourself removing a lot of template code, as the template you install (a Maven archetype) is a full 'activity', and not a simple one port in, one port out one.</p>", "child_count": 0, "closed": false, "tree_id": 24, "revision_count": 2, "parent": 76, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:18", "slug": "a-looking-for-a-hello-world-plugin-for-taverna", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 148, "model": "server.post", "fields": {"rght": 15, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:25:23", "lft": 14, "post_type": 109787, "score": 2, "title": "A: What is the best way to share scripts between members of a lab?", "unanswered": false, "content": "I can very much recommend [MyExperiment.org][1]. You can set up a category for a certain class of scripts, as the system has no limitation to Taverna 'scripts' anymore. MyExperiment is a true social services, provides tagging, setting up groups, etc.\n\n\n  [1]: http://www.myexperiment.org/", "comment_count": 0, "html": "<p>I can very much recommend <a href=\"http://www.myexperiment.org/\">MyExperiment.org</a>. You can set up a category for a certain class of scripts, as the system has no limitation to Taverna 'scripts' anymore. MyExperiment is a true social services, provides tagging, setting up groups, etc.</p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 1, "parent": 58, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:18", "slug": "a-what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 149, "model": "server.post", "fields": {"rght": 12, "author": 70, "answer_accepted": false, "tag_string": "meta subjective", "creation_date": "2010-03-04 15:34:11", "lft": 1, "post_type": 164033, "score": 3, "title": "How far does bioinformatics go?", "unanswered": false, "content": "Being a metabolomics, and drug discovery dude, I consider myself a bioinformatician (well, I also consider myself a chemist, cheminformatician, statistician, and chemometrician, but that's not relevant to my question).\n\nHowever, some peers see bioinformatics restricted to stuff to do with DNA sequences, that is genomics. So, from a historical and literature perspective, *what is bioinformatics*? Please do back up your answer and argument with citations to primary literature.", "comment_count": 0, "html": "<p>Being a metabolomics, and drug discovery dude, I consider myself a bioinformatician (well, I also consider myself a chemist, cheminformatician, statistician, and chemometrician, but that's not relevant to my question).</p>\n<p>However, some peers see bioinformatics restricted to stuff to do with DNA sequences, that is genomics. So, from a historical and literature perspective, <em>what is bioinformatics</em>? Please do back up your answer and argument with citations to primary literature.</p>", "child_count": 0, "closed": false, "tree_id": 42, "revision_count": 4, "parent": null, "views": 951, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:28", "slug": "how-far-does-bioinformatics-go", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [32, 82], "lastedit_user": 58}}, {"pk": 150, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:36:35", "lft": 2, "post_type": 109787, "score": 2, "title": "A: State of computational genomics", "unanswered": false, "content": "I think every advance in technology creates new opportunities for those who know computation. ", "comment_count": 0, "html": "<p>I think every advance in technology creates new opportunities for those who know computation. </p>", "child_count": 0, "closed": false, "tree_id": 40, "revision_count": 1, "parent": 139, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-state-of-computational-genomics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 151, "model": "server.post", "fields": {"rght": 9, "author": 73, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:54:25", "lft": 8, "post_type": 109787, "score": 5, "title": "A: What methods do you use for short read mapping?", "unanswered": false, "content": "I have used tophat (which also calls bowtie). It seemed pretty straightforward, I'm not sure I would call it \"fun\", but I think tophat does a good job providing useful output formats. Other people around here use Eland.\n\nI was aligning 60-mer reads - 15-20 million per lane? \n\nThis was to the mouse genome, so about 2.7 gigabases.\n\nI don't know what computational resources were required, but I was running it on a server with 96 gigs of RAM and 16 cpus. Much more than I needed.\n\nI'm actually not sure how long it took per lane, I just set it up and then left it while I worked on other stuff for awhile. ", "comment_count": 0, "html": "<p>I have used tophat (which also calls bowtie). It seemed pretty straightforward, I'm not sure I would call it \"fun\", but I think tophat does a good job providing useful output formats. Other people around here use Eland.</p>\n<p>I was aligning 60-mer reads - 15-20 million per lane? </p>\n<p>This was to the mouse genome, so about 2.7 gigabases.</p>\n<p>I don't know what computational resources were required, but I was running it on a server with 96 gigs of RAM and 16 cpus. Much more than I needed.</p>\n<p>I'm actually not sure how long it took per lane, I just set it up and then left it while I worked on other stuff for awhile. </p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 1, "parent": 137, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 73}}, {"pk": 152, "model": "server.post", "fields": {"rght": 15, "author": 73, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 16:07:04", "lft": 14, "post_type": 109787, "score": 3, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "I have found useful: Perl, MySQL, Unix commands and shell scripts, R, and knowing some web stuff (HTML/php). \n\nIt's good to be familiar with a variety of tools, so you can choose the right one for the problem (and not force a tool to do something it's not really designed for, just because you don't know how to do it any other way).\n\nIf I was starting out, I might consider something like ruby or python instead of perl, but maybe not. There's a lot of code out there already written in perl.", "comment_count": 0, "html": "<p>I have found useful: Perl, MySQL, Unix commands and shell scripts, R, and knowing some web stuff (HTML/php). </p>\n<p>It's good to be familiar with a variety of tools, so you can choose the right one for the problem (and not force a tool to do something it's not really designed for, just because you don't know how to do it any other way).</p>\n<p>If I was starting out, I might consider something like ruby or python instead of perl, but maybe not. There's a lot of code out there already written in perl.</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 73}}, {"pk": 153, "model": "server.post", "fields": {"rght": 23, "author": 73, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 16:10:28", "lft": 18, "post_type": 109787, "score": 3, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "I generally use a simple shell script if I have multiple commands or scripts to run. I also try to make a notes.txt file to remind myself of what I did. Doesn't take long and comes in handy. \n\nThings that you didn't plan to re-use get re-used all the time, in my experience...", "comment_count": 2, "html": "<p>I generally use a simple shell script if I have multiple commands or scripts to run. I also try to make a notes.txt file to remind myself of what I did. Doesn't take long and comes in handy. </p>\n<p>Things that you didn't plan to re-use get re-used all the time, in my experience...</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 1, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 73}}, {"pk": 154, "model": "server.post", "fields": {"rght": 7, "author": 73, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 16:12:31", "lft": 6, "post_type": 109787, "score": 5, "title": "A: How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "Just click \"DNA\" at the top of the screen.", "comment_count": 0, "html": "<p>Just click \"DNA\" at the top of the screen.</p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 1, "parent": 56, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 73}}, {"pk": 155, "model": "server.post", "fields": {"rght": 13, "author": 73, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 16:38:10", "lft": 12, "post_type": 109787, "score": 3, "title": "A: Gene ID conversion tool", "unanswered": false, "content": "If you have just a few, I just saw someone use the R package [BioIDMapper][1] and it seemed kind of neat. But it's slow.\n\n\n  [1]: http://cran.r-project.org/web/packages/BioIDMapper/", "comment_count": 0, "html": "<p>If you have just a few, I just saw someone use the R package <a href=\"http://cran.r-project.org/web/packages/BioIDMapper/\">BioIDMapper</a> and it seemed kind of neat. But it's slow.</p>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 1, "parent": 22, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 73}}, {"pk": 156, "model": "server.post", "fields": {"rght": 7, "author": 78, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 18:59:06", "lft": 4, "post_type": 109787, "score": 1, "title": "A: Looking for a 'Hello world\" plugin for Taverna.", "unanswered": false, "content": "Stop being silly and just learn Maven.\n\nIt's not that hard and once you get to know it you'll never want to go back to finding and downloading jars, settings up the classpath, etc..", "comment_count": 1, "html": "<p>Stop being silly and just learn Maven.</p>\n<p>It's not that hard and once you get to know it you'll never want to go back to finding and downloading jars, settings up the classpath, etc..</p>", "child_count": 0, "closed": false, "tree_id": 24, "revision_count": 1, "parent": 76, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:18", "slug": "a-looking-for-a-hello-world-plugin-for-taverna", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 78}}, {"pk": 157, "model": "server.post", "fields": {"rght": 17, "author": 81, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 19:59:41", "lft": 16, "post_type": 109787, "score": 3, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "I find that a healthy knowledge of R & Bioconductor tools has been the most helpful.  In my work I also write a large amount of Python code.  Beyond those, having a strong Unix background - complete with scripts and tools such as sed & awk have been very valuable.  Knowledge of HTML (don't need to be a javascript wiz, just the ability to make basic tables & such) and SQL are also plusses.", "comment_count": 0, "html": "<p>I find that a healthy knowledge of R &amp; Bioconductor tools has been the most helpful.  In my work I also write a large amount of Python code.  Beyond those, having a strong Unix background - complete with scripts and tools such as sed &amp; awk have been very valuable.  Knowledge of HTML (don't need to be a javascript wiz, just the ability to make basic tables &amp; such) and SQL are also plusses.</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 81}}, {"pk": 158, "model": "server.post", "fields": {"rght": 11, "author": 81, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 20:02:58", "lft": 10, "post_type": 109787, "score": 1, "title": "A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "In my group, all primary computational folks (currently, a new person will be bucking this trend and going with OSX) have linux desktops that they have root access to.  Most of us have a secondary machine which varies between windows & Mac OSX for various side tasks.  Beyond that we have several linux based servers that people use as well (via SSH).  The very few people who do any sort of computational work w/o a linux desktop ssh into these servers to do all of their real work.", "comment_count": 0, "html": "<p>In my group, all primary computational folks (currently, a new person will be bucking this trend and going with OSX) have linux desktops that they have root access to.  Most of us have a secondary machine which varies between windows &amp; Mac OSX for various side tasks.  Beyond that we have several linux based servers that people use as well (via SSH).  The very few people who do any sort of computational work w/o a linux desktop ssh into these servers to do all of their real work.</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 1, "parent": 33, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:18", "slug": "a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 81}}, {"pk": 159, "model": "server.post", "fields": {"rght": 9, "author": 81, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 20:04:45", "lft": 8, "post_type": 109787, "score": 2, "title": "A: Recommend easy to use microarray clustering software", "unanswered": false, "content": "One thing you might look at is the Broad Institute's <a href=\"https://www.broad.harvard.edu/cancer/software/genepattern/\">genepattern</a> software.  It can be clunky at times but it will do most common tasks in a fairly straightforward fashion.", "comment_count": 0, "html": "<p>One thing you might look at is the Broad Institute's [HTML_REMOVED]genepattern[HTML_REMOVED] software.  It can be clunky at times but it will do most common tasks in a fairly straightforward fashion.</p>", "child_count": 0, "closed": false, "tree_id": 4, "revision_count": 1, "parent": 5, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-recommend-easy-to-use-microarray-clustering-software", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 81}}, {"pk": 160, "model": "server.post", "fields": {"rght": 17, "author": 81, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 20:08:07", "lft": 16, "post_type": 109787, "score": 3, "title": "A: What is the best way to share scripts between members of a lab?", "unanswered": false, "content": "I'm the only person in my group who uses software control, other people are averse to it.  What we've ended up with is a by-convention approach within our large NAS block (which everyone mounts).  Any code which is deemed to be generally useful is essentially \"checked in\" to a particular directory tree w/ a designated format for keeping track of versioning, builds (where appropriate), etc.  Code which is specific to a project, dataset, etc is stored in a designated manner within the appropriate directory trees for that project, dataset, etc.", "comment_count": 0, "html": "<p>I'm the only person in my group who uses software control, other people are averse to it.  What we've ended up with is a by-convention approach within our large NAS block (which everyone mounts).  Any code which is deemed to be generally useful is essentially \"checked in\" to a particular directory tree w/ a designated format for keeping track of versioning, builds (where appropriate), etc.  Code which is specific to a project, dataset, etc is stored in a designated manner within the appropriate directory trees for that project, dataset, etc.</p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 1, "parent": 58, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 81}}, {"pk": 161, "model": "server.post", "fields": {"rght": 8, "author": 83, "answer_accepted": false, "tag_string": "sequence alignment scoring", "creation_date": "2010-03-04 20:37:52", "lft": 1, "post_type": 164033, "score": 5, "title": "Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "unanswered": false, "content": "Hi,\n\nI am trying to implement protein pairwise sequence alignment using \"Global Alignment\" algorithm by 'Needleman -Wunsch'. I am using VB.NET. \n\nI am not clear about how to include 'Blosum62 Matrix' in my source code to do the scoring or to fill the two-dimensional matrix?\n\nI have googled and found that most people suggested to use flat file which contains the standard 'Blosum62 Matrix'. Does it mean that I need to read from this flat file and fill my coded \"Blosum62 Martrix' ?\n\nAlso, the other approach could be is to use some mathematical formula and include it in your programming logic to construct 'Blosum62 Matrix'. But not very sure about this option.\n\nAny ideas or insights are appreciated.\n\nAlso, is there any pesudo algorithm to do the protein pairwise alignment using Global available? I tired to find the basic steps of the alogrithm online but no luck so I am planning to do the same steps as I did for the global pairwise alignment of Nucleotides\n\nThanks.\n", "comment_count": 0, "html": "<p>Hi,</p>\n<p>I am trying to implement protein pairwise sequence alignment using \"Global Alignment\" algorithm by 'Needleman -Wunsch'. I am using VB.NET. </p>\n<p>I am not clear about how to include 'Blosum62 Matrix' in my source code to do the scoring or to fill the two-dimensional matrix?</p>\n<p>I have googled and found that most people suggested to use flat file which contains the standard 'Blosum62 Matrix'. Does it mean that I need to read from this flat file and fill my coded \"Blosum62 Martrix' ?</p>\n<p>Also, the other approach could be is to use some mathematical formula and include it in your programming logic to construct 'Blosum62 Matrix'. But not very sure about this option.</p>\n<p>Any ideas or insights are appreciated.</p>\n<p>Also, is there any pesudo algorithm to do the protein pairwise alignment using Global available? I tired to find the basic steps of the alogrithm online but no luck so I am planning to do the same steps as I did for the global pairwise alignment of Nucleotides</p>\n<p>Thanks.</p>", "child_count": 0, "closed": false, "tree_id": 43, "revision_count": 4, "parent": null, "views": 975, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:27", "slug": "implementation-of-blosum62-in-the-source-code-of-global-pairwise-alignment-of-proteins", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [40, 83, 84], "lastedit_user": 215}}, {"pk": 162, "model": "server.post", "fields": {"rght": 8, "author": 84, "answer_accepted": false, "tag_string": "multiple alignment dna", "creation_date": "2010-03-04 20:49:12", "lft": 1, "post_type": 164033, "score": 3, "title": "Repeat subunit based multiple alignment of DNA", "unanswered": false, "content": "I want to align over 50 sequences of a polymorphic stretch of promoter DNA. The sequences consist of repeats of selections from 174 incompletely homologous subunits (14-31 subunits per sequence), the subunits are 18-29 bases in length, with a four-part internal structure.  I wish the alignment to be guided by the subunits more than by unstructured primary DNA sequence. Is there any software out there that can do this?\n\nThank you.", "comment_count": 0, "html": "<p>I want to align over 50 sequences of a polymorphic stretch of promoter DNA. The sequences consist of repeats of selections from 174 incompletely homologous subunits (14-31 subunits per sequence), the subunits are 18-29 bases in length, with a four-part internal structure.  I wish the alignment to be guided by the subunits more than by unstructured primary DNA sequence. Is there any software out there that can do this?</p>\n<p>Thank you.</p>", "child_count": 0, "closed": false, "tree_id": 44, "revision_count": 3, "parent": null, "views": 186, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:19", "slug": "repeat-subunit-based-multiple-alignment-of-dna", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [65, 83, 85], "lastedit_user": 215}}, {"pk": 163, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 21:28:09", "lft": 2, "post_type": 109787, "score": 5, "title": "A: Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "unanswered": false, "content": "There are no mathematical formulas for this.\n\nWhat you need is a data structure that you can use to retrieve the score for substitutions that you observe. It could be as simple as as hash map. For example in Python you could initialize it like so:\n\n    blosum = dict()\n    blosum['Ala'] = dict()\n    blosum['Ala']['Ala'] = 4\n    blosum['Ala']['Arg'] = -1\n    blosum['Ala']['Asn'] = -2 \n    ... etc ...\n\nOf course you would not need to initialize it by hand, the information should be read from a file, that way you can load different scoring matrices. Later during alignment when you observe an Ala -> Arg substitution you could retrieve the value as:\n\n    blosum['Ala']['Arg']\n\nUse the corresponding data structure from your programming language to build the same construct.\n\n", "comment_count": 1, "html": "<p>There are no mathematical formulas for this.</p>\n<p>What you need is a data structure that you can use to retrieve the score for substitutions that you observe. It could be as simple as as hash map. For example in Python you could initialize it like so:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">blosum</span> <span class=\"o\">=</span> <span class=\"n\">dict</span><span class=\"p\">()</span>\n    <span class=\"n\">blosum</span><span class=\"p\">[</span><span class=\"s\">&#39;Ala&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">dict</span><span class=\"p\">()</span>\n    <span class=\"n\">blosum</span><span class=\"p\">[</span><span class=\"s\">&#39;Ala&#39;</span><span class=\"p\">][</span><span class=\"s\">&#39;Ala&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>\n    <span class=\"n\">blosum</span><span class=\"p\">[</span><span class=\"s\">&#39;Ala&#39;</span><span class=\"p\">][</span><span class=\"s\">&#39;Arg&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">1</span>\n    <span class=\"n\">blosum</span><span class=\"p\">[</span><span class=\"s\">&#39;Ala&#39;</span><span class=\"p\">][</span><span class=\"s\">&#39;Asn&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"o\">-</span><span class=\"mi\">2</span> \n    <span class=\"o\">...</span> <span class=\"n\">etc</span> <span class=\"o\">...</span>\n</pre></div>\n</p>\n<p>Of course you would not need to initialize it by hand, the information should be read from a file, that way you can load different scoring matrices. Later during alignment when you observe an Ala -&gt; Arg substitution you could retrieve the value as:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">blosum</span><span class=\"p\">[</span><span class=\"s\">&#39;Ala&#39;</span><span class=\"p\">][</span><span class=\"s\">&#39;Arg&#39;</span><span class=\"p\">]</span>\n</pre></div>\n</p>\n<p>Use the corresponding data structure from your programming language to build the same construct.</p>", "child_count": 0, "closed": false, "tree_id": 43, "revision_count": 2, "parent": 161, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-implementation-of-blosum62-in-the-source-code-of-global-pairwise-alignment-of-proteins", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 164, "model": "server.post", "fields": {"rght": 5, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 22:10:31", "lft": 4, "post_type": 109787, "score": 3, "title": "A: State of computational genomics", "unanswered": false, "content": "I agree that there is a bit of lag between the advancement of sequencing technologies (physico-chemical point of view) and the computational requirements to actually take advantage of these advances... \n\nBut is it really a problem?\n\n  - All these technologies have strengths and weaknesses, so it's good that there are different technologies.\n  - The processing of the data will eventually come around to a mature state.\n  - The deluge of data is certainly not delved into yet, but would we even imagine how to do so if the data were not already available?\n  - We are doing science, not selling cars: we need to be at the forefront of any and all advancements and not hold on to old vintage tech just because we \"know\" how to process it (or how to make money with it, e.g. old combustion vs. electrical engines).\n\nAs for your last question, about how to make sure we don't loose the \"interesting information\" coming out of the sequencing projects, well I'd say we aren't loosing anything since the raw data is well preserved in databanks! And concerning future discoveries from that data, you can't loose what you haven't found yet ;)\n\nTo sum up: advances are good, rat-race is good, lots of poorly understood data means we've got lots of work to do! And since I like what I do, I'm happy I won't have to go into another field of research ;)\n\nForward the Foundation!", "comment_count": 0, "html": "<p>I agree that there is a bit of lag between the advancement of sequencing technologies (physico-chemical point of view) and the computational requirements to actually take advantage of these advances... </p>\n<p>But is it really a problem?</p>\n<ul>\n<li>All these technologies have strengths and weaknesses, so it's good that there are different technologies.</li>\n<li>The processing of the data will eventually come around to a mature state.</li>\n<li>The deluge of data is certainly not delved into yet, but would we even imagine how to do so if the data were not already available?</li>\n<li>We are doing science, not selling cars: we need to be at the forefront of any and all advancements and not hold on to old vintage tech just because we \"know\" how to process it (or how to make money with it, e.g. old combustion vs. electrical engines).</li>\n</ul>\n<p>As for your last question, about how to make sure we don't loose the \"interesting information\" coming out of the sequencing projects, well I'd say we aren't loosing anything since the raw data is well preserved in databanks! And concerning future discoveries from that data, you can't loose what you haven't found yet ;)</p>\n<p>To sum up: advances are good, rat-race is good, lots of poorly understood data means we've got lots of work to do! And since I like what I do, I'm happy I won't have to go into another field of research ;)</p>\n<p>Forward the Foundation!</p>", "child_count": 0, "closed": false, "tree_id": 40, "revision_count": 1, "parent": 139, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-state-of-computational-genomics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 165, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 22:58:49", "lft": 4, "post_type": 109787, "score": 4, "title": "A: What is the best place in the world to do Bioinformatics?", "unanswered": false, "content": "One annecdota: when I was looking for a place to start a phd, the first of my criterias to determine where I liked or not a place was the position of the monitors.\n\nI think that at least 90% of the bioinformaticians I have seen working simply sit down like monkeys in front of their monitor. I just don't understand this. I think that a place where somebody takes the time to correct behaviours like these is a good place to work; therefore, for me in the best place of the world to do bioinformatics, seats are comfortable and monitors are positioned at an ergonomic height.\n\nOther than this, I would like to work for the 1000genomes consortium. I don't know what the conditions and the quality of work are, but there is a lot of data there and it would be good to be the among the first persons to use it.", "comment_count": 1, "html": "<p>One annecdota: when I was looking for a place to start a phd, the first of my criterias to determine where I liked or not a place was the position of the monitors.</p>\n<p>I think that at least 90% of the bioinformaticians I have seen working simply sit down like monkeys in front of their monitor. I just don't understand this. I think that a place where somebody takes the time to correct behaviours like these is a good place to work; therefore, for me in the best place of the world to do bioinformatics, seats are comfortable and monitors are positioned at an ergonomic height.</p>\n<p>Other than this, I would like to work for the 1000genomes consortium. I don't know what the conditions and the quality of work are, but there is a lot of data there and it would be good to be the among the first persons to use it.</p>", "child_count": 0, "closed": false, "tree_id": 39, "revision_count": 1, "parent": 138, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-is-the-best-place-in-the-world-to-do-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 166, "model": "server.post", "fields": {"rght": 3, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 23:09:59", "lft": 2, "post_type": 109787, "score": 2, "title": "A: How far does bioinformatics go?", "unanswered": false, "content": "Many people consider that bioinformatics began with the work of [Margaret Dayhoff][1] and the Pam matrixes. She compiled the first collection of protein sequences available at the time, publishing the Atlas of Protein Sequences and Structure, and she developed the first method to give a score to the similarity of two proteins, the PAM matrix.\n\nFor me, bioinformatics is everything that derived from Margaret Dayhoff's work. Compiling data and organizing it, developing tools to compare and handle informations, share the data with other people: if you read her biography you will find everything already there.\n\nAbout the modern bioinformatics, I like to think of it as the science of doing experiments or part of them using computers at least for some steps. I like to think that there is no difference between the work in a wet lab and that in front of computer: when you are planning a bioinformatics project, you also have to think of an hypothesis, on how to verify it and on which tests and controls you will use. This is probably something that many people didn't understand yet, as they think that bioinformatics is just 'writing programs' and the don't even know what a test is and how much time it takes to write a program. \n\n\n  [1]: http://www.answers.com/main/ntquery?s=margaret+dayhoff&gwp=13", "comment_count": 0, "html": "<p>Many people consider that bioinformatics began with the work of <a href=\"http://www.answers.com/main/ntquery?s=margaret+dayhoff&amp;gwp=13\">Margaret Dayhoff</a> and the Pam matrixes. She compiled the first collection of protein sequences available at the time, publishing the Atlas of Protein Sequences and Structure, and she developed the first method to give a score to the similarity of two proteins, the PAM matrix.</p>\n<p>For me, bioinformatics is everything that derived from Margaret Dayhoff's work. Compiling data and organizing it, developing tools to compare and handle informations, share the data with other people: if you read her biography you will find everything already there.</p>\n<p>About the modern bioinformatics, I like to think of it as the science of doing experiments or part of them using computers at least for some steps. I like to think that there is no difference between the work in a wet lab and that in front of computer: when you are planning a bioinformatics project, you also have to think of an hypothesis, on how to verify it and on which tests and controls you will use. This is probably something that many people didn't understand yet, as they think that bioinformatics is just 'writing programs' and the don't even know what a test is and how much time it takes to write a program. </p>", "child_count": 0, "closed": false, "tree_id": 42, "revision_count": 1, "parent": 149, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-far-does-bioinformatics-go", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 167, "model": "server.post", "fields": {"rght": 5, "author": 85, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 23:27:54", "lft": 4, "post_type": 109787, "score": 2, "title": "A: Mapping SNPs to Pathways", "unanswered": false, "content": "Biomart's Martview (http://www.biomart.org/biomart/martview/) will get you from SNP IDs to many gene/protein identifiers.  In a second step, Martview will also get you from gene IDs to GO Biological Process terms, but there are probably better tools that are specifically targeted toward pathways (KEGG, Reactome, WikiPathways, etc.)", "comment_count": 0, "html": "<p>Biomart's Martview (http://www.biomart.org/biomart/martview/) will get you from SNP IDs to many gene/protein identifiers.  In a second step, Martview will also get you from gene IDs to GO Biological Process terms, but there are probably better tools that are specifically targeted toward pathways (KEGG, Reactome, WikiPathways, etc.)</p>", "child_count": 0, "closed": false, "tree_id": 41, "revision_count": 1, "parent": 142, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-mapping-snps-to-pathways", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 85}}, {"pk": 168, "model": "server.post", "fields": {"rght": 24, "author": 86, "answer_accepted": false, "tag_string": "bioinformatics hardware linux server", "creation_date": "2010-03-05 04:20:04", "lft": 1, "post_type": 164033, "score": 4, "title": "Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "I am looking for an experienced Linux vendors to order a pre-installed CentOS/Ubuntu based webserver to host bioinformatics apps. Any suggestions or recommendations ? ", "comment_count": 4, "html": "<p>I am looking for an experienced Linux vendors to order a pre-installed CentOS/Ubuntu based webserver to host bioinformatics apps. Any suggestions or recommendations ? </p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 1, "parent": null, "views": 313, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:26", "slug": "looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [86, 87, 88, 152], "lastedit_user": 86}}, {"pk": 169, "model": "server.post", "fields": {"rght": 7, "author": 71, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 04:40:36", "lft": 6, "post_type": 109787, "score": 3, "title": "A: State of computational genomics", "unanswered": false, "content": "I don't understand why this is a problem either.  You need to take that next step in data production and there is a lot of innovation going on there, as well as in the computational aspects of primary analysis.  The downstream innovation will happen (and it is based on some work that I am aware of).\n\nThe best innovation comes from rat races.  The market (in this case science, which fundamentally likes choice) will decide who gets to \"win\" and the algorithmic/analytics innovation will follow.", "comment_count": 0, "html": "<p>I don't understand why this is a problem either.  You need to take that next step in data production and there is a lot of innovation going on there, as well as in the computational aspects of primary analysis.  The downstream innovation will happen (and it is based on some work that I am aware of).</p>\n<p>The best innovation comes from rat races.  The market (in this case science, which fundamentally likes choice) will decide who gets to \"win\" and the algorithmic/analytics innovation will follow.</p>", "child_count": 0, "closed": false, "tree_id": 40, "revision_count": 1, "parent": 139, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-state-of-computational-genomics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 71}}, {"pk": 170, "model": "server.post", "fields": {"rght": 11, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 04:48:15", "lft": 6, "post_type": 109787, "score": 4, "title": "A: What is your experience with the STRING (interactions) database?", "unanswered": false, "content": "I have used STRING in three projects and I am still using it for large scale [protein-protein interaction][1] data analysis. I have downloaded the data and worked on PPI data of 5 eukaryotic model organisms. I strongly recommend [STRING][2] if you are looking for prokaryotic PPI data or if you working on a global scale of PPI network analysis in any given organism. An exceptional advantage about STRING is that they derive the PPI information from multiple approaches, still every single single interaction is scored using a scoring scheme. This gives a higher advantage to filter specific interactions that you are interested in (for example you can get PPI from human that have a score >0.7 from experimental approach) and thus you can reduce the false positive rate. Another interesting aspect of [STRING][3] is the predicted interactions that are not reported in DIP or [HPRD][4] (If you are looking for literature curated, experimental annotations I strongly recommend HPRD ), this is something really exciting. You may get an interesting connections (not yet proven, though) that can lead you to new biological insights. The STRING team also maintain an interesting [blog][5], with the new releases, code-snippets, API detailes etc. \n\n\n  [1]: http://en.wikipedia.org/wiki/Protein%E2%80%93protein_interaction\n  [2]: http://string.embl.de/\n  [3]: http://string.embl.de/\n  [4]: http://www.hprd.org/\n  [5]: http://string-stitch.blogspot.com/", "comment_count": 2, "html": "<p>I have used STRING in three projects and I am still using it for large scale <a href=\"http://en.wikipedia.org/wiki/Protein%E2%80%93protein_interaction\">protein-protein interaction</a> data analysis. I have downloaded the data and worked on PPI data of 5 eukaryotic model organisms. I strongly recommend <a href=\"http://string.embl.de/\">STRING</a> if you are looking for prokaryotic PPI data or if you working on a global scale of PPI network analysis in any given organism. An exceptional advantage about STRING is that they derive the PPI information from multiple approaches, still every single single interaction is scored using a scoring scheme. This gives a higher advantage to filter specific interactions that you are interested in (for example you can get PPI from human that have a score &gt;0.7 from experimental approach) and thus you can reduce the false positive rate. Another interesting aspect of <a href=\"http://string.embl.de/\">STRING</a> is the predicted interactions that are not reported in DIP or <a href=\"http://www.hprd.org/\">HPRD</a> (If you are looking for literature curated, experimental annotations I strongly recommend HPRD ), this is something really exciting. You may get an interesting connections (not yet proven, though) that can lead you to new biological insights. The STRING team also maintain an interesting <a href=\"http://string-stitch.blogspot.com/\">blog</a>, with the new releases, code-snippets, API detailes etc. </p>", "child_count": 0, "closed": false, "tree_id": 17, "revision_count": 1, "parent": 46, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-is-your-experience-with-the-string-interactions-database", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 171, "model": "server.post", "fields": {"rght": 11, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 04:54:16", "lft": 10, "post_type": 109787, "score": 4, "title": "A: Recommend easy to use microarray clustering software", "unanswered": false, "content": "I am currently using [Cluster 3.0][1] for clustering and [TreeView][2]. \n\n\n  [1]: http://bonsai.ims.u-tokyo.ac.jp/~mdehoon/software/cluster/software.htm\n  [2]: http://sourceforge.net/projects/jtreeview/", "comment_count": 0, "html": "<p>I am currently using <a href=\"http://bonsai.ims.u-tokyo.ac.jp/~mdehoon/software/cluster/software.htm\">Cluster 3.0</a> for clustering and <a href=\"http://sourceforge.net/projects/jtreeview/\">TreeView</a>. </p>", "child_count": 0, "closed": false, "tree_id": 4, "revision_count": 1, "parent": 5, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-recommend-easy-to-use-microarray-clustering-software", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 172, "model": "server.post", "fields": {"rght": 5, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 06:53:16", "lft": 2, "post_type": 109787, "score": 3, "title": "A: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "Have you looked into the [Ubuntu Amazon EC2 server][1] thing?\n\n\n  [1]: http://www.ubuntu.com/cloud", "comment_count": 1, "html": "<p>Have you looked into the <a href=\"http://www.ubuntu.com/cloud\">Ubuntu Amazon EC2 server</a> thing?</p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 1, "parent": 168, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 173, "model": "server.post", "fields": {"rght": 10, "author": 6, "answer_accepted": false, "tag_string": "protein structure", "creation_date": "2010-03-05 09:56:57", "lft": 1, "post_type": 164033, "score": 2, "title": "How to charecterize a residue in a protein based on it's ASA", "unanswered": false, "content": "How can we characterize a residue in a protein as a buried, exposed or intermediate based on it's accessible surface area(ASA) ? \n\nI came across a paper in which they are taking the ratio between the residue's ASA at a particular position to the maximum ASA observed for that residue in the whole protein.Further they apply a cut off on these ratios to characterize a residue as buried , exposed or intermediate. I am not sure about the basis of these cut offs.\n\ncan any one validate or provide a better approach for doing this ?  ", "comment_count": 0, "html": "<p>How can we characterize a residue in a protein as a buried, exposed or intermediate based on it's accessible surface area(ASA) ? </p>\n<p>I came across a paper in which they are taking the ratio between the residue's ASA at a particular position to the maximum ASA observed for that residue in the whole protein.Further they apply a cut off on these ratios to characterize a residue as buried , exposed or intermediate. I am not sure about the basis of these cut offs.</p>\n<p>can any one validate or provide a better approach for doing this ?<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 46, "revision_count": 1, "parent": null, "views": 184, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:28", "slug": "how-to-charecterize-a-residue-in-a-protein-based-on-its-asa", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [41, 42], "lastedit_user": 6}}, {"pk": 174, "model": "server.post", "fields": {"rght": 7, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 10:33:25", "lft": 4, "post_type": 109787, "score": 5, "title": "A: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "[System 76][1] is a vendor that *only* sells \"laptops, desktops, and servers with Ubuntu pre-installed, and is committed to the ideals of open source software.\" You can [compare the servers they sell][2]. They are also a [Ubuntu solution provider][3] so I am sure they can make you a system that fits your needs to a tee.\n\n\n  [1]: http://www.system76.com/\n  [2]: http://www.system76.com/index.php?cPath=29\n  [3]: http://www.ubuntu.com/partners/solutionprovider", "comment_count": 1, "html": "<p><a href=\"http://www.system76.com/\">System 76</a> is a vendor that <em>only</em> sells \"laptops, desktops, and servers with Ubuntu pre-installed, and is committed to the ideals of open source software.\" You can <a href=\"http://www.system76.com/index.php?cPath=29\">compare the servers they sell</a>. They are also a <a href=\"http://www.ubuntu.com/partners/solutionprovider\">Ubuntu solution provider</a> so I am sure they can make you a system that fits your needs to a tee.</p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 1, "parent": 168, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 67}}, {"pk": 175, "model": "server.post", "fields": {"rght": 9, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 12:31:43", "lft": 4, "post_type": 109787, "score": 9, "title": "A: How far does bioinformatics go?", "unanswered": false, "content": "Bioinformatics is the field of science in which biology and computer science/information technology merge into a single discipline. The ultimate goal of the field is to enable the discovery of new biological insights as well as to create a global perspective from which unifying principles in biology can be discerned. \n\nListed below are some of the major events in bioinformatics over the last several decades. Most of the events in the list occurred long before the term, \"bioinformatics\", was coined.\n\nI've tagged each entry with either:\n\n - ***(BIO)*** if it was an event which was predominantly important in the field of biology.\n - ***(IT)*** if it was an event which was predominantly important in the field of computer science/information technology\n - ***(BIOINFO)*** if it was an event where biology and computer science/information technology truly merged and we can really speak from bioinformatics.\n\nAs you will notice, it becomes increasingly difficult/subjective to catalogue events with exclusively one tag, so the main point to take away is that in the course of bioinformatics history there has been a constant exchange of ideas between biology, computer science/information technology and bioinformatics.\n\n - **1665**  ***(BIO)*** Robert Hooke published Micrographia, described the cellular structure of cork. He also described microscopic examinations of fossilized plants and animals, comparing their microscopic structure to that of the living organisms they resembled. He argued for an organic origin of fossils, and suggested a plausible mechanism for their formation.\n\n - **1683** ***(BIO)*** Antoni van Leeuwenhoek discovered bacteria.\n\n - **1686** ***(BIO)*** John Ray, John Ray's in his book \"Historia Plantarum\" catalogued and described 18,600 kinds of plants. His book gave the first definition of species based upon common descent.\n\n - **1843** ***(BIO)*** Richard Owen elaborated the distinction of homology and analogy.\n\n - **1864** ***(BIO)*** Ernst Haeckel (H\u00e4ckel) outlined the essential elements of modern zoological classification.\n\n - **1865** ***(BIO)*** Gregory Mendel (1823-1884), Austria,  established the theory of genetic inheritance.\n\n - **1902** ***(BIO)*** The chromosome theory of heredity is proposed by Sutton and Boveri, working independently.\n\n - **1905** ***(BIO)*** The word \"genetics\" is coined by William Bateson.\n\n - **1913** ***(BIO)*** First ever linkage map created by Columbia undergraduate Alfred Sturtevant (working with T.H. Morgan).\n\n - **1930** ***(BIO)*** Tiselius, Uppsala University, Sweden, A new technique, electrophoresis, is introduced by Tiselius for separating proteins in solution. \"The moving-boundary method of studying the electrophoresis of proteins\" (published in Nova Acta Regiae Societatis Scientiarum Upsaliensis, Ser. IV, Vol. 7, No. 4)\n\n - **1946** ***(BIO)*** Genetic material can be transferred laterally between bacterial cells, as shown by Lederberg and Tatum.\n\n - **1951** ***(BIO)*** Pauling and Corey propose the structure for the alpha-helix and beta-sheet (Proc. Natl. Acad. Sci. USA, 27: 205-211, 1951; Proc. Natl. Acad. Sci. USA, 37: 729-740, 1951).\n\n - **1952** ***(BIO)*** Alfred Day Hershey and Martha Chase proved that the DNA alone carries genetic information. This was proved on the basis of their bacteriophage research.\n\n - **1953** ***(BIO)*** Watson and Crick propose the double helix model for DNA based on x-ray data obtained by Franklin and Wilkins (Nature, 171: 737-738, 1953).\n\n - **1954** ***(BIO)*** Perutz's group develop heavy atom methods to solve the phase problem in protein crystallography.\n\n - **1955** ***(BIO)*** The sequence of the first protein to be analyzed, bovine insulin, is announced by F. Sanger.\n\n - **1958** ***(IT)*** The Advanced Research Projects Agency (ARPA) is formed in the US\n\n - **1958** ***(IT)*** The first integrated circuit is constructed by Jack Kilby at Texas Instruments.\n\n - **1961** ***(BIO)*** Sidney Brenner, Fran\u00e7ois Jacob, Matthew Meselson, identify messenger RNA\n\n - **1962** ***(BIO)*** Pauling's theory of molecular evolution\n\n - **1965** ***(BIO)*** Margaret Dayhoff's Atlas of Protein Sequences\n\n - **1968** ***(IT)*** Packet-switching network protocols are presented to ARPA\n\n - **1969** ***(IT)*** The ARPANET is created by linking computers at Stanford, UCSB, The University of Utah and UCLA.\n\n - **1970** ***(BIOINFO)*** The details of the Needleman-Wunsch algorithm for sequence comparison are published.\n\n - **1971** ***(IT)*** Ray Tomlinson (BBN) invents the email program.\n\n - **1972** ***(BIO)*** The first recombinant DNA molecule is created by Paul Berg and his group.\n\n - **1973** ***(IT)*** Robert Metcalfe receives his Ph.D. from Harvard University. His thesis describes Ethernet.\n\n - **1973** ***(BIOINFO)*** The Brookhaven Protein Data Bank is announced (Acta. Cryst. B, 1973, 29: 1746).\n\n - **1974** ***(IT)*** Charles Goldfarb invents SGML (Standardized General Markup Language).\n\n - **1974** ***(IT)*** Vint Cerf and Robert Kahn develop the concept of connecting networks of computers into an \"internet\" and develop the Transmission Control Protocol (TCP).\n\n - **1975** ***(BIO)*** E. M. Southern published the experimental details for the Southern Blot technique of specific sequences of DNA (J. Mol. Biol., 98: 503-517, 1975).\n\n - **1975** ***(IT)*** Microsoft Corporation is founded by Bill Gates and Paul Allen.\n\n - **1975** ***(BIO)*** Two-dimensional electrophoresis, where separation of proteins on SDS polyacrylamide gel is combined with separation according to isoelectric points, is announced by P. H. O'Farrell (J. Biol. Chem., 250: 4007-4021, 1975).\n\n - **1976** ***(IT)*** The Unix-To-Unix Copy Protocol (UUCP) is developed at Bell Labs.\n\n - **1977** ***(BIOINFO)*** Allan Maxam and Walter Gilbert (Harvard) and Frederick Sanger (U.K. Medical Research Council), report methods for sequencing DNA.\n\n - **1977** ***(BIOINFO)*** DNA sequencing and software to analyze it (Staden)\n\n - **1977** ***(BIOINFO)*** The full description of the Brookhaven PDB (http://www.pdb.bnl.gov) is published (Bernstein, F.C.; Koetzle, T.F.; Williams, G.J.B.; Meyer, E.F.; Brice, M.D.; Rodgers, J.R.; Kennard, O.; Shimanouchi, T.; Tasumi, M.J.; J. Mol. Biol., 1977, 112:, 535).\n\n - **1978** ***(IT)*** The first Usenet connection is established between Duke and the University of North Carolina at Chapel Hill by Tom Truscott, Jim Ellis and Steve Bellovin.\n\n - **1980** ***(BIOINFO)*** IntelliGenetics, Inc. founded in California. Their primary product is the IntelliGenetics Suite of programs for DNA and protein sequence analysis.\n\n - **1980** ***(BIO)*** The first complete gene sequence for an organism (FX174) is published. The gene consists of 5,386 base pairs which code nine proteins.\n\n - **1980** ***(BIO)*** W\u00fcthrich et. al. publish paper detailing the use of multi-dimensional NMR for protein structure determination (Kumar, A.; Ernst, R.R.; W\u00fcthrich, K.; Biochem. Biophys. Res. Comm., 1980, 95:, 1).\n\n - **1981** ***(IT)*** IBM introduces its Personal Computer to the market.\n\n - **1981** ***(BIOINFO)*** The Smith-Waterman algorithm for sequence alignment is published.\n\n - **1981** ***(BIO)*** The concept of a sequence motif (Doolittle)\n\n - **1982** ***(BIOINFO)*** GenBank Release 3 made public\n\n - **1982** ***(BIO)*** Genetics Computer Group (GCG) created as a part of the University of Wisconsin of Wisconsin Biotechnology Center. The company's primary product is The Wisconsin Suite of molecular biology tools.\n\n - **1982** ***(BIO)*** Phage lambda genome sequenced\n\n - **1983** ***(IT)*** Name servers are developed at the University of Wisconsin.\n\n - **1983** ***(BIOINFO)*** Sequence database searching algorithm (Wilbur-Lipman)\n\n - **1983** ***(IT)*** The Compact Disk (CD) is launched.\n\n - **1984** ***(IT)*** Jon Postel's Domain Name System (DNS) is placed on-line.\n\n - **1984** ***(IT)*** The Macintosh is announced by Apple Computer.\n\n - **1985** ***(BIOINFO)*** FASTP/FASTN: fast sequence similarity searching algorithm is published.\n\n - **1985** ***(BIO)*** The PCR reaction is described by Kary Mullis and co-workers.\n\n - **1986** ***(IT)*** NSFnet debuts.\n\n - **1986** ***(BIOINFO)*** The SWISS-PROT database is created by the Department of Medical Biochemistry of the University of Geneva and the European Molecular Biology Laboratory (EMBL).\n\n - **1986** ***(BIO)*** The term \"Genomics\" appeared for the first time to describe the scientific discipline of mapping, sequencing, and analyzing genes. The term was coined by Thomas Roderick as a name for the new journal.\n\n - **1987** ***(BIO)*** The physical map of e. coli is published (Y. Kohara, et. al., Cell 51: 319-337).\n\n - **1987** ***(BIO)*** The use of yeast artifical chromosomes (YAC) is described (David T. Burke, et. al., Science, 236: 806-812).\n\n - **1988** ***(IT)*** A new program, an Internet computer virus designed by a student, infects 6,000 military computers in the US.\n\n - **1988** ***(BIOINFO)*** Des Higgins and Paul Sharpe announce the development of CLUSTAL (Higgins, D.G.; Sharp, P.M. Fast and sensitive multiple sequence alignments on a microcomputer. Comput. Appl. Biosci. 1989, 5, 151-153; Higgins, D.G.; Sharp, P.M. CLUSTAL: a package for performing multiple sequence alignment on a microcomputer. Gene 1988, 73, 237-244.)\n\n - **1988** ***(IT)*** EMBnet network for database distribution\n\n - **1988** ***(BIO)*** National Center for Biotechnology Information (NCBI) created at NIH/NLM\n\n - **1988** ***(IT)*** Perl (Practical Extraction Report Language) is released by Larry Wall.\n\n - **1988** ***(BIOINFO)*** The FASTA algorithm for sequence comparison is published by Pearson and Lupman.\n\n - **1988** ***(BIO)*** The Human Genome Initiative is started (Commission on Life Sciences, National Research Council. Mapping and Sequencing the Human Genome, National Academy Press: Washington, D.C.), 1988.\n\n - **1988** ***(BIO)*** The National Center for Biotechnology Information (NCBI) is established at the National Cancer Institute.\n\n - **1990** ***(BIOINFO)*** BLAST: fast sequence similarity searching (Altschul, et. al.) is implemented.\n\n - **1990** ***(IT)*** The HTTP 1.0 specification is published. Tim Berners-Lee publishes the first HTML document.\n\n - **1991** ***(BIO)*** EST: expressed sequence tag sequencing\n\n - **1991** ***(IT)*** Linus Torvalds announces a Unix-Like operating system which later becomes Linux.\n\n - **1991** ***(BIO)*** Myriad Genetics, Inc. is founded in Utah. The company's goal is to lead in the discovery of major common human disease genes and their related pathways. The Company has discovered and sequenced, with its academic collaborators, the following major genes: BRCA1, BRCA2, CHD1, MMAC1, MMSC1, MMSC2, CtIP, p16, p19, and MTS2.\n\n - **1991** ***(BIO)*** The creation and use of expressed sequence tags (ESTs) is described (J. Craig Venter, et. al., Science, 252: 1651-1656).\n\n - **1991** ***(IT)*** The research institute in Geneva (CERN) announces the creation of the protocols which make-up the World Wide Web.\n\n - **1992** ***(BIO)*** Mel Simon and coworkers announce the use of BACs for cloning.\n\n - **1992** ***(BIO)*** The Institute for Genomic Research (TIGR) is established by Craig Venter.\n\n - **1993** ***(BIO)*** Affymetrix begins independent operations in Santa Clara, California\n\n - **1993** ***(BIO)*** Sanger Centre, Hinxton, UK\n\n - **1994** ***(BIOINFO)*** EMBL European Bioinformatics Institute, Hinxton, UK\n\n - **1994** ***(IT)*** Netscape Comminications Corporation founded and releases Navigator, the commercial version of NCSA's Mozilla.\n\n - **1994** ***(BIOINFO)*** The PRINTS database of protein motifs is published by Attwood and Beck.\n\n - **1995** ***(BIO)*** First bacterial genomes completely sequenced\n\n - **1995** ***(IT)*** Microsoft releases version 1.0 of Internet Explorer.\n\n - **1995** ***(IT)*** Sun releases version 1.0 of Java. Sun and Netscape release version 1.0 of JavaScript\n\n - **1995** ***(BIO)*** The Haemophilus influenzea genome (1.8 Mb) is sequenced.\n\n - **1995** ***(BIO)*** The Mycoplasma genitalium genome is sequenced.\n\n - **1995** ***(IT)*** Version 1.0 of Apache is released.\n\n - **1996** ***(BIO)*** Affymetrix produces the first commercial DNA chips.\n\n - **1996** ***(BIO)*** Oxford Molecular Group acquires the MacVector product from Eastman Kodak.\n\n - **1996** ***(BIOINFO)*** Structural Bioinformatics, Inc. founded in San Diego, CA.\n\n - **1996** ***(BIO)*** The Prosite database is reported by Bairoch, et.al.\n\n - **1996** ***(BIO)*** The genome for Saccharomyces cerevisiae (baker's yeast, 12.1 Mb) is sequenced.\n\n - **1996** ***(IT)*** The working draft for XML is released by W3C.\n\n - **1996** ***(BIO)*** Yeast genome completely sequenced\n\n - **1997** ***(BIOINFO)*** LION bioscience AG founded as an integrated genomics company with strong focus on bioinformatics. The company is built from IP out of the European Molecular Biology Laboratory (EMBL), the European Bioinformatics Institute (EBI), the German Cancer Research Center (DKFZ), and the University of Heidelberg.\n\n - **1997** ***(BIOINFO)*** PSI-BLAST\n\n - **1997** ***(BIO)*** The genome for E. coli (4.7 Mbp) is published.\n\n - **1998** ***(BIO)*** Craig Venter forms Celera in Rockville, Maryland.\n\n - **1998** ***(BIOINFO)*** Inpharmatica, a new Genomics and Bioinformatics company, is established by University College London, the Wolfson Institute for Biomedical Research, five leading scientists from major British academic centers and Unibio Limited.\n\n - **1998** ***(BIOINFO)*** The Swiss Institute of Bioinformatics is established as a non-profit foundation.\n\n - **1998** ***(BIO)*** The genomes for Caenorhabditis elegans and baker's yeast are published.\n\n - **1998** ***(BIO)*** Worm (multicellular) genome completely sequenced\n\n - **1998** ***(BIO)*** deCode genetics publishes a paper that described the location of the FET1 gene, which is responsible for familial essential tremor, on chromosome 13 (Nature Genetics).\n\n - **1999** ***(BIO)*** Fly genome completely sequenced\n\n - **1999** ***(BIO)*** deCode genetics maps the gene linked to pre-eclampsia as a locus on chromosome 2p13.\n\n - **2000** ***(BIO)*** Jeong H, Tombor B, Albert R, Oltvai ZN, Barabasi AL. The large-scale organization of metabolic networks. Nature 2000 Oct 5;407(6804):651-4, PubMed\n\n - **2000** ***(BIO)*** The A. thaliana genome (100 Mb) is secquenced.\n\n - **2000** ***(BIO)*** The D. melanogaster genome (180Mb) is secquenced.\n\n - **2000** ***(BIO)*** The genome for Pseudomonas aeruginosa (6.3 Mbp) is published.\n\n - **2001** ***(BIO)*** The human genome (3,000 Mbp) is published.\n\n - **2002** ***(BIO)*** An international sequencing consortium published the full genome sequence of the common house mouse (2.5 Gb). Whitehead Institute researcher Kerstin Lindblad-Toh is the lead author on the paper; her institution lead the project and contributed about half of the sequence. Washington University School of Medicine delivered about 30 percent of the sequence, and created the mouse BAC-based physical map. The Wellcome Trust Sanger Institute in the UK was the third major partner. Other institutes in the International Mouse Genome Sequencing Consortium included the University of California at Santa Cruz, the Institute for Systems Biology, and the University of Geneva.\n\n - **2004** ***(BIO)*** The draft genome sequence of the brown Norway laboratory rat, Rattus norvegicus, was completed by the Rat Genome Sequencing project Consortium. The paper appears in the April 1 edition of Nature.\n\nCompiled from different sources, including: \n\n - A [Short History of Bioinformatics][1], by Allen B. Richon\n - [History of Bioinformatics][2]\n - [Bioinformatics Milestones][3]\n - [History, Origin & Bioinformatics Events][4] \n\n\n  [1]: http://www.netsci.org/Science/Bioinform/feature06.html\n  [2]: http://www.roseindia.net/bioinformatics/history_of_bioinformatics.shtml\n  [3]: http://www.ncbi.nlm.nih.gov/Education/BLASTinfo/milestones.html\n  [4]: http://www.cbclickbank.com/bioinformatics/history.htm", "comment_count": 2, "html": "<p>Bioinformatics is the field of science in which biology and computer science/information technology merge into a single discipline. The ultimate goal of the field is to enable the discovery of new biological insights as well as to create a global perspective from which unifying principles in biology can be discerned. </p>\n<p>Listed below are some of the major events in bioinformatics over the last several decades. Most of the events in the list occurred long before the term, \"bioinformatics\", was coined.</p>\n<p>I've tagged each entry with either:</p>\n<ul>\n<li><strong><em>(BIO)</em></strong> if it was an event which was predominantly important in the field of biology.</li>\n<li><strong><em>(IT)</em></strong> if it was an event which was predominantly important in the field of computer science/information technology</li>\n<li><strong><em>(BIOINFO)</em></strong> if it was an event where biology and computer science/information technology truly merged and we can really speak from bioinformatics.</li>\n</ul>\n<p>As you will notice, it becomes increasingly difficult/subjective to catalogue events with exclusively one tag, so the main point to take away is that in the course of bioinformatics history there has been a constant exchange of ideas between biology, computer science/information technology and bioinformatics.</p>\n<ul>\n<li>\n<p><strong>1665</strong>  <strong><em>(BIO)</em></strong> Robert Hooke published Micrographia, described the cellular structure of cork. He also described microscopic examinations of fossilized plants and animals, comparing their microscopic structure to that of the living organisms they resembled. He argued for an organic origin of fossils, and suggested a plausible mechanism for their formation.</p>\n</li>\n<li>\n<p><strong>1683</strong> <strong><em>(BIO)</em></strong> Antoni van Leeuwenhoek discovered bacteria.</p>\n</li>\n<li>\n<p><strong>1686</strong> <strong><em>(BIO)</em></strong> John Ray, John Ray's in his book \"Historia Plantarum\" catalogued and described 18,600 kinds of plants. His book gave the first definition of species based upon common descent.</p>\n</li>\n<li>\n<p><strong>1843</strong> <strong><em>(BIO)</em></strong> Richard Owen elaborated the distinction of homology and analogy.</p>\n</li>\n<li>\n<p><strong>1864</strong> <strong><em>(BIO)</em></strong> Ernst Haeckel (H\u00e4ckel) outlined the essential elements of modern zoological classification.</p>\n</li>\n<li>\n<p><strong>1865</strong> <strong><em>(BIO)</em></strong> Gregory Mendel (1823-1884), Austria,  established the theory of genetic inheritance.</p>\n</li>\n<li>\n<p><strong>1902</strong> <strong><em>(BIO)</em></strong> The chromosome theory of heredity is proposed by Sutton and Boveri, working independently.</p>\n</li>\n<li>\n<p><strong>1905</strong> <strong><em>(BIO)</em></strong> The word \"genetics\" is coined by William Bateson.</p>\n</li>\n<li>\n<p><strong>1913</strong> <strong><em>(BIO)</em></strong> First ever linkage map created by Columbia undergraduate Alfred Sturtevant (working with T.H. Morgan).</p>\n</li>\n<li>\n<p><strong>1930</strong> <strong><em>(BIO)</em></strong> Tiselius, Uppsala University, Sweden, A new technique, electrophoresis, is introduced by Tiselius for separating proteins in solution. \"The moving-boundary method of studying the electrophoresis of proteins\" (published in Nova Acta Regiae Societatis Scientiarum Upsaliensis, Ser. IV, Vol. 7, No. 4)</p>\n</li>\n<li>\n<p><strong>1946</strong> <strong><em>(BIO)</em></strong> Genetic material can be transferred laterally between bacterial cells, as shown by Lederberg and Tatum.</p>\n</li>\n<li>\n<p><strong>1951</strong> <strong><em>(BIO)</em></strong> Pauling and Corey propose the structure for the alpha-helix and beta-sheet (Proc. Natl. Acad. Sci. USA, 27: 205-211, 1951; Proc. Natl. Acad. Sci. USA, 37: 729-740, 1951).</p>\n</li>\n<li>\n<p><strong>1952</strong> <strong><em>(BIO)</em></strong> Alfred Day Hershey and Martha Chase proved that the DNA alone carries genetic information. This was proved on the basis of their bacteriophage research.</p>\n</li>\n<li>\n<p><strong>1953</strong> <strong><em>(BIO)</em></strong> Watson and Crick propose the double helix model for DNA based on x-ray data obtained by Franklin and Wilkins (Nature, 171: 737-738, 1953).</p>\n</li>\n<li>\n<p><strong>1954</strong> <strong><em>(BIO)</em></strong> Perutz's group develop heavy atom methods to solve the phase problem in protein crystallography.</p>\n</li>\n<li>\n<p><strong>1955</strong> <strong><em>(BIO)</em></strong> The sequence of the first protein to be analyzed, bovine insulin, is announced by F. Sanger.</p>\n</li>\n<li>\n<p><strong>1958</strong> <strong><em>(IT)</em></strong> The Advanced Research Projects Agency (ARPA) is formed in the US</p>\n</li>\n<li>\n<p><strong>1958</strong> <strong><em>(IT)</em></strong> The first integrated circuit is constructed by Jack Kilby at Texas Instruments.</p>\n</li>\n<li>\n<p><strong>1961</strong> <strong><em>(BIO)</em></strong> Sidney Brenner, Fran\u00e7ois Jacob, Matthew Meselson, identify messenger RNA</p>\n</li>\n<li>\n<p><strong>1962</strong> <strong><em>(BIO)</em></strong> Pauling's theory of molecular evolution</p>\n</li>\n<li>\n<p><strong>1965</strong> <strong><em>(BIO)</em></strong> Margaret Dayhoff's Atlas of Protein Sequences</p>\n</li>\n<li>\n<p><strong>1968</strong> <strong><em>(IT)</em></strong> Packet-switching network protocols are presented to ARPA</p>\n</li>\n<li>\n<p><strong>1969</strong> <strong><em>(IT)</em></strong> The ARPANET is created by linking computers at Stanford, UCSB, The University of Utah and UCLA.</p>\n</li>\n<li>\n<p><strong>1970</strong> <strong><em>(BIOINFO)</em></strong> The details of the Needleman-Wunsch algorithm for sequence comparison are published.</p>\n</li>\n<li>\n<p><strong>1971</strong> <strong><em>(IT)</em></strong> Ray Tomlinson (BBN) invents the email program.</p>\n</li>\n<li>\n<p><strong>1972</strong> <strong><em>(BIO)</em></strong> The first recombinant DNA molecule is created by Paul Berg and his group.</p>\n</li>\n<li>\n<p><strong>1973</strong> <strong><em>(IT)</em></strong> Robert Metcalfe receives his Ph.D. from Harvard University. His thesis describes Ethernet.</p>\n</li>\n<li>\n<p><strong>1973</strong> <strong><em>(BIOINFO)</em></strong> The Brookhaven Protein Data Bank is announced (Acta. Cryst. B, 1973, 29: 1746).</p>\n</li>\n<li>\n<p><strong>1974</strong> <strong><em>(IT)</em></strong> Charles Goldfarb invents SGML (Standardized General Markup Language).</p>\n</li>\n<li>\n<p><strong>1974</strong> <strong><em>(IT)</em></strong> Vint Cerf and Robert Kahn develop the concept of connecting networks of computers into an \"internet\" and develop the Transmission Control Protocol (TCP).</p>\n</li>\n<li>\n<p><strong>1975</strong> <strong><em>(BIO)</em></strong> E. M. Southern published the experimental details for the Southern Blot technique of specific sequences of DNA (J. Mol. Biol., 98: 503-517, 1975).</p>\n</li>\n<li>\n<p><strong>1975</strong> <strong><em>(IT)</em></strong> Microsoft Corporation is founded by Bill Gates and Paul Allen.</p>\n</li>\n<li>\n<p><strong>1975</strong> <strong><em>(BIO)</em></strong> Two-dimensional electrophoresis, where separation of proteins on SDS polyacrylamide gel is combined with separation according to isoelectric points, is announced by P. H. O'Farrell (J. Biol. Chem., 250: 4007-4021, 1975).</p>\n</li>\n<li>\n<p><strong>1976</strong> <strong><em>(IT)</em></strong> The Unix-To-Unix Copy Protocol (UUCP) is developed at Bell Labs.</p>\n</li>\n<li>\n<p><strong>1977</strong> <strong><em>(BIOINFO)</em></strong> Allan Maxam and Walter Gilbert (Harvard) and Frederick Sanger (U.K. Medical Research Council), report methods for sequencing DNA.</p>\n</li>\n<li>\n<p><strong>1977</strong> <strong><em>(BIOINFO)</em></strong> DNA sequencing and software to analyze it (Staden)</p>\n</li>\n<li>\n<p><strong>1977</strong> <strong><em>(BIOINFO)</em></strong> The full description of the Brookhaven PDB (http://www.pdb.bnl.gov) is published (Bernstein, F.C.; Koetzle, T.F.; Williams, G.J.B.; Meyer, E.F.; Brice, M.D.; Rodgers, J.R.; Kennard, O.; Shimanouchi, T.; Tasumi, M.J.; J. Mol. Biol., 1977, 112:, 535).</p>\n</li>\n<li>\n<p><strong>1978</strong> <strong><em>(IT)</em></strong> The first Usenet connection is established between Duke and the University of North Carolina at Chapel Hill by Tom Truscott, Jim Ellis and Steve Bellovin.</p>\n</li>\n<li>\n<p><strong>1980</strong> <strong><em>(BIOINFO)</em></strong> IntelliGenetics, Inc. founded in California. Their primary product is the IntelliGenetics Suite of programs for DNA and protein sequence analysis.</p>\n</li>\n<li>\n<p><strong>1980</strong> <strong><em>(BIO)</em></strong> The first complete gene sequence for an organism (FX174) is published. The gene consists of 5,386 base pairs which code nine proteins.</p>\n</li>\n<li>\n<p><strong>1980</strong> <strong><em>(BIO)</em></strong> W\u00fcthrich et. al. publish paper detailing the use of multi-dimensional NMR for protein structure determination (Kumar, A.; Ernst, R.R.; W\u00fcthrich, K.; Biochem. Biophys. Res. Comm., 1980, 95:, 1).</p>\n</li>\n<li>\n<p><strong>1981</strong> <strong><em>(IT)</em></strong> IBM introduces its Personal Computer to the market.</p>\n</li>\n<li>\n<p><strong>1981</strong> <strong><em>(BIOINFO)</em></strong> The Smith-Waterman algorithm for sequence alignment is published.</p>\n</li>\n<li>\n<p><strong>1981</strong> <strong><em>(BIO)</em></strong> The concept of a sequence motif (Doolittle)</p>\n</li>\n<li>\n<p><strong>1982</strong> <strong><em>(BIOINFO)</em></strong> GenBank Release 3 made public</p>\n</li>\n<li>\n<p><strong>1982</strong> <strong><em>(BIO)</em></strong> Genetics Computer Group (GCG) created as a part of the University of Wisconsin of Wisconsin Biotechnology Center. The company's primary product is The Wisconsin Suite of molecular biology tools.</p>\n</li>\n<li>\n<p><strong>1982</strong> <strong><em>(BIO)</em></strong> Phage lambda genome sequenced</p>\n</li>\n<li>\n<p><strong>1983</strong> <strong><em>(IT)</em></strong> Name servers are developed at the University of Wisconsin.</p>\n</li>\n<li>\n<p><strong>1983</strong> <strong><em>(BIOINFO)</em></strong> Sequence database searching algorithm (Wilbur-Lipman)</p>\n</li>\n<li>\n<p><strong>1983</strong> <strong><em>(IT)</em></strong> The Compact Disk (CD) is launched.</p>\n</li>\n<li>\n<p><strong>1984</strong> <strong><em>(IT)</em></strong> Jon Postel's Domain Name System (DNS) is placed on-line.</p>\n</li>\n<li>\n<p><strong>1984</strong> <strong><em>(IT)</em></strong> The Macintosh is announced by Apple Computer.</p>\n</li>\n<li>\n<p><strong>1985</strong> <strong><em>(BIOINFO)</em></strong> FASTP/FASTN: fast sequence similarity searching algorithm is published.</p>\n</li>\n<li>\n<p><strong>1985</strong> <strong><em>(BIO)</em></strong> The PCR reaction is described by Kary Mullis and co-workers.</p>\n</li>\n<li>\n<p><strong>1986</strong> <strong><em>(IT)</em></strong> NSFnet debuts.</p>\n</li>\n<li>\n<p><strong>1986</strong> <strong><em>(BIOINFO)</em></strong> The SWISS-PROT database is created by the Department of Medical Biochemistry of the University of Geneva and the European Molecular Biology Laboratory (EMBL).</p>\n</li>\n<li>\n<p><strong>1986</strong> <strong><em>(BIO)</em></strong> The term \"Genomics\" appeared for the first time to describe the scientific discipline of mapping, sequencing, and analyzing genes. The term was coined by Thomas Roderick as a name for the new journal.</p>\n</li>\n<li>\n<p><strong>1987</strong> <strong><em>(BIO)</em></strong> The physical map of e. coli is published (Y. Kohara, et. al., Cell 51: 319-337).</p>\n</li>\n<li>\n<p><strong>1987</strong> <strong><em>(BIO)</em></strong> The use of yeast artifical chromosomes (YAC) is described (David T. Burke, et. al., Science, 236: 806-812).</p>\n</li>\n<li>\n<p><strong>1988</strong> <strong><em>(IT)</em></strong> A new program, an Internet computer virus designed by a student, infects 6,000 military computers in the US.</p>\n</li>\n<li>\n<p><strong>1988</strong> <strong><em>(BIOINFO)</em></strong> Des Higgins and Paul Sharpe announce the development of CLUSTAL (Higgins, D.G.; Sharp, P.M. Fast and sensitive multiple sequence alignments on a microcomputer. Comput. Appl. Biosci. 1989, 5, 151-153; Higgins, D.G.; Sharp, P.M. CLUSTAL: a package for performing multiple sequence alignment on a microcomputer. Gene 1988, 73, 237-244.)</p>\n</li>\n<li>\n<p><strong>1988</strong> <strong><em>(IT)</em></strong> EMBnet network for database distribution</p>\n</li>\n<li>\n<p><strong>1988</strong> <strong><em>(BIO)</em></strong> National Center for Biotechnology Information (NCBI) created at NIH/NLM</p>\n</li>\n<li>\n<p><strong>1988</strong> <strong><em>(IT)</em></strong> Perl (Practical Extraction Report Language) is released by Larry Wall.</p>\n</li>\n<li>\n<p><strong>1988</strong> <strong><em>(BIOINFO)</em></strong> The FASTA algorithm for sequence comparison is published by Pearson and Lupman.</p>\n</li>\n<li>\n<p><strong>1988</strong> <strong><em>(BIO)</em></strong> The Human Genome Initiative is started (Commission on Life Sciences, National Research Council. Mapping and Sequencing the Human Genome, National Academy Press: Washington, D.C.), 1988.</p>\n</li>\n<li>\n<p><strong>1988</strong> <strong><em>(BIO)</em></strong> The National Center for Biotechnology Information (NCBI) is established at the National Cancer Institute.</p>\n</li>\n<li>\n<p><strong>1990</strong> <strong><em>(BIOINFO)</em></strong> BLAST: fast sequence similarity searching (Altschul, et. al.) is implemented.</p>\n</li>\n<li>\n<p><strong>1990</strong> <strong><em>(IT)</em></strong> The HTTP 1.0 specification is published. Tim Berners-Lee publishes the first HTML document.</p>\n</li>\n<li>\n<p><strong>1991</strong> <strong><em>(BIO)</em></strong> EST: expressed sequence tag sequencing</p>\n</li>\n<li>\n<p><strong>1991</strong> <strong><em>(IT)</em></strong> Linus Torvalds announces a Unix-Like operating system which later becomes Linux.</p>\n</li>\n<li>\n<p><strong>1991</strong> <strong><em>(BIO)</em></strong> Myriad Genetics, Inc. is founded in Utah. The company's goal is to lead in the discovery of major common human disease genes and their related pathways. The Company has discovered and sequenced, with its academic collaborators, the following major genes: BRCA1, BRCA2, CHD1, MMAC1, MMSC1, MMSC2, CtIP, p16, p19, and MTS2.</p>\n</li>\n<li>\n<p><strong>1991</strong> <strong><em>(BIO)</em></strong> The creation and use of expressed sequence tags (ESTs) is described (J. Craig Venter, et. al., Science, 252: 1651-1656).</p>\n</li>\n<li>\n<p><strong>1991</strong> <strong><em>(IT)</em></strong> The research institute in Geneva (CERN) announces the creation of the protocols which make-up the World Wide Web.</p>\n</li>\n<li>\n<p><strong>1992</strong> <strong><em>(BIO)</em></strong> Mel Simon and coworkers announce the use of BACs for cloning.</p>\n</li>\n<li>\n<p><strong>1992</strong> <strong><em>(BIO)</em></strong> The Institute for Genomic Research (TIGR) is established by Craig Venter.</p>\n</li>\n<li>\n<p><strong>1993</strong> <strong><em>(BIO)</em></strong> Affymetrix begins independent operations in Santa Clara, California</p>\n</li>\n<li>\n<p><strong>1993</strong> <strong><em>(BIO)</em></strong> Sanger Centre, Hinxton, UK</p>\n</li>\n<li>\n<p><strong>1994</strong> <strong><em>(BIOINFO)</em></strong> EMBL European Bioinformatics Institute, Hinxton, UK</p>\n</li>\n<li>\n<p><strong>1994</strong> <strong><em>(IT)</em></strong> Netscape Comminications Corporation founded and releases Navigator, the commercial version of NCSA's Mozilla.</p>\n</li>\n<li>\n<p><strong>1994</strong> <strong><em>(BIOINFO)</em></strong> The PRINTS database of protein motifs is published by Attwood and Beck.</p>\n</li>\n<li>\n<p><strong>1995</strong> <strong><em>(BIO)</em></strong> First bacterial genomes completely sequenced</p>\n</li>\n<li>\n<p><strong>1995</strong> <strong><em>(IT)</em></strong> Microsoft releases version 1.0 of Internet Explorer.</p>\n</li>\n<li>\n<p><strong>1995</strong> <strong><em>(IT)</em></strong> Sun releases version 1.0 of Java. Sun and Netscape release version 1.0 of JavaScript</p>\n</li>\n<li>\n<p><strong>1995</strong> <strong><em>(BIO)</em></strong> The Haemophilus influenzea genome (1.8 Mb) is sequenced.</p>\n</li>\n<li>\n<p><strong>1995</strong> <strong><em>(BIO)</em></strong> The Mycoplasma genitalium genome is sequenced.</p>\n</li>\n<li>\n<p><strong>1995</strong> <strong><em>(IT)</em></strong> Version 1.0 of Apache is released.</p>\n</li>\n<li>\n<p><strong>1996</strong> <strong><em>(BIO)</em></strong> Affymetrix produces the first commercial DNA chips.</p>\n</li>\n<li>\n<p><strong>1996</strong> <strong><em>(BIO)</em></strong> Oxford Molecular Group acquires the MacVector product from Eastman Kodak.</p>\n</li>\n<li>\n<p><strong>1996</strong> <strong><em>(BIOINFO)</em></strong> Structural Bioinformatics, Inc. founded in San Diego, CA.</p>\n</li>\n<li>\n<p><strong>1996</strong> <strong><em>(BIO)</em></strong> The Prosite database is reported by Bairoch, et.al.</p>\n</li>\n<li>\n<p><strong>1996</strong> <strong><em>(BIO)</em></strong> The genome for Saccharomyces cerevisiae (baker's yeast, 12.1 Mb) is sequenced.</p>\n</li>\n<li>\n<p><strong>1996</strong> <strong><em>(IT)</em></strong> The working draft for XML is released by W3C.</p>\n</li>\n<li>\n<p><strong>1996</strong> <strong><em>(BIO)</em></strong> Yeast genome completely sequenced</p>\n</li>\n<li>\n<p><strong>1997</strong> <strong><em>(BIOINFO)</em></strong> LION bioscience AG founded as an integrated genomics company with strong focus on bioinformatics. The company is built from IP out of the European Molecular Biology Laboratory (EMBL), the European Bioinformatics Institute (EBI), the German Cancer Research Center (DKFZ), and the University of Heidelberg.</p>\n</li>\n<li>\n<p><strong>1997</strong> <strong><em>(BIOINFO)</em></strong> PSI-BLAST</p>\n</li>\n<li>\n<p><strong>1997</strong> <strong><em>(BIO)</em></strong> The genome for E. coli (4.7 Mbp) is published.</p>\n</li>\n<li>\n<p><strong>1998</strong> <strong><em>(BIO)</em></strong> Craig Venter forms Celera in Rockville, Maryland.</p>\n</li>\n<li>\n<p><strong>1998</strong> <strong><em>(BIOINFO)</em></strong> Inpharmatica, a new Genomics and Bioinformatics company, is established by University College London, the Wolfson Institute for Biomedical Research, five leading scientists from major British academic centers and Unibio Limited.</p>\n</li>\n<li>\n<p><strong>1998</strong> <strong><em>(BIOINFO)</em></strong> The Swiss Institute of Bioinformatics is established as a non-profit foundation.</p>\n</li>\n<li>\n<p><strong>1998</strong> <strong><em>(BIO)</em></strong> The genomes for Caenorhabditis elegans and baker's yeast are published.</p>\n</li>\n<li>\n<p><strong>1998</strong> <strong><em>(BIO)</em></strong> Worm (multicellular) genome completely sequenced</p>\n</li>\n<li>\n<p><strong>1998</strong> <strong><em>(BIO)</em></strong> deCode genetics publishes a paper that described the location of the FET1 gene, which is responsible for familial essential tremor, on chromosome 13 (Nature Genetics).</p>\n</li>\n<li>\n<p><strong>1999</strong> <strong><em>(BIO)</em></strong> Fly genome completely sequenced</p>\n</li>\n<li>\n<p><strong>1999</strong> <strong><em>(BIO)</em></strong> deCode genetics maps the gene linked to pre-eclampsia as a locus on chromosome 2p13.</p>\n</li>\n<li>\n<p><strong>2000</strong> <strong><em>(BIO)</em></strong> Jeong H, Tombor B, Albert R, Oltvai ZN, Barabasi AL. The large-scale organization of metabolic networks. Nature 2000 Oct 5;407(6804):651-4, PubMed</p>\n</li>\n<li>\n<p><strong>2000</strong> <strong><em>(BIO)</em></strong> The A. thaliana genome (100 Mb) is secquenced.</p>\n</li>\n<li>\n<p><strong>2000</strong> <strong><em>(BIO)</em></strong> The D. melanogaster genome (180Mb) is secquenced.</p>\n</li>\n<li>\n<p><strong>2000</strong> <strong><em>(BIO)</em></strong> The genome for Pseudomonas aeruginosa (6.3 Mbp) is published.</p>\n</li>\n<li>\n<p><strong>2001</strong> <strong><em>(BIO)</em></strong> The human genome (3,000 Mbp) is published.</p>\n</li>\n<li>\n<p><strong>2002</strong> <strong><em>(BIO)</em></strong> An international sequencing consortium published the full genome sequence of the common house mouse (2.5 Gb). Whitehead Institute researcher Kerstin Lindblad-Toh is the lead author on the paper; her institution lead the project and contributed about half of the sequence. Washington University School of Medicine delivered about 30 percent of the sequence, and created the mouse BAC-based physical map. The Wellcome Trust Sanger Institute in the UK was the third major partner. Other institutes in the International Mouse Genome Sequencing Consortium included the University of California at Santa Cruz, the Institute for Systems Biology, and the University of Geneva.</p>\n</li>\n<li>\n<p><strong>2004</strong> <strong><em>(BIO)</em></strong> The draft genome sequence of the brown Norway laboratory rat, Rattus norvegicus, was completed by the Rat Genome Sequencing project Consortium. The paper appears in the April 1 edition of Nature.</p>\n</li>\n</ul>\n<p>Compiled from different sources, including: </p>\n<ul>\n<li>A <a href=\"http://www.netsci.org/Science/Bioinform/feature06.html\">Short History of Bioinformatics</a>, by Allen B. Richon</li>\n<li><a href=\"http://www.roseindia.net/bioinformatics/history_of_bioinformatics.shtml\">History of Bioinformatics</a></li>\n<li><a href=\"http://www.ncbi.nlm.nih.gov/Education/BLASTinfo/milestones.html\">Bioinformatics Milestones</a></li>\n<li><a href=\"http://www.cbclickbank.com/bioinformatics/history.htm\">History, Origin &amp; Bioinformatics Events</a> </li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 42, "revision_count": 1, "parent": 149, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-far-does-bioinformatics-go", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 67}}, {"pk": 176, "model": "server.post", "fields": {"rght": 5, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 12:47:09", "lft": 2, "post_type": 109787, "score": 1, "title": "A: Repeat subunit based multiple alignment of DNA", "unanswered": false, "content": "No idea how to do it exactly but I can think about two routes to investigate:\n\n* LASTZ has something called \"quantum DNA\":\n\nhttp://www.bx.psu.edu/miller_lab/dist/README.lastz-1.02.00/README.lastz-1.02.00.html#fmt_qdna\n\n* instead of using \"linear\" aligner go for graph based ones:\n\n POA     http://bioinfo.mbi.ucla.edu/poa/\n\n AliWABA http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1538870/\n\n", "comment_count": 1, "html": "<p>No idea how to do it exactly but I can think about two routes to investigate:</p>\n<ul>\n<li>LASTZ has something called \"quantum DNA\":</li>\n</ul>\n<p>http://www.bx.psu.edu/miller_lab/dist/README.lastz-1.02.00/README.lastz-1.02.00.html#fmt_qdna</p>\n<ul>\n<li>instead of using \"linear\" aligner go for graph based ones:</li>\n</ul>\n<p>POA     http://bioinfo.mbi.ucla.edu/poa/</p>\n<p>AliWABA http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1538870/</p>", "child_count": 0, "closed": false, "tree_id": 44, "revision_count": 2, "parent": 162, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-repeat-subunit-based-multiple-alignment-of-dna", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 177, "model": "server.post", "fields": {"rght": 15, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 12:56:39", "lft": 12, "post_type": 109787, "score": 5, "title": "A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "I have no experience with them, but there are several Linux distributions out there that come preloaded with bioinformatics software.\n\nFor example:\n\n - **[biobuntu][1]** which comes preloaded with amapalign, biococoa, biomode, bioperl, biopython, biosquid, blast2, boxshade, chemtool, clustalw, clustalx, dialign, easychem, fastdnaml, fastlink, garlic, gchempaint, gcubin, gff2aplot, gff2ps, EMBOSS, gmt, gromacs, hmmer, ifeffit, ifrit, imview, kalign, leksbot, libbioruby, meltinggui, mipe, molphy, mozillabiofox, mpqc/support, mummer, muscle, mustang, ncbiepcr, ncbitoolsbin, ncbitoolsx11, njplot, openbabel, perlprimer, phylip, poa, polyxmass, primer3, probcons, proda, pybliographerA, rasmol, readseq, seaview, sibsim4, sigmaalignSimple, sim4, SixpackDisplay, tcoffeeMultiple, tigrglimmerGene, treepuzzleReconstruction, treetool, treeviewxDisplays, viewmol, wise, xbs, xdrawchem and xmakemol\n\n - **[Bio-Linux][2]**  a fully featured, powerful, configurable and easy to maintain bioinformatics workstation. Bio-Linux provides more than 500 bioinformatics programs on an Ubuntu Linux base. There is a graphical menu for bioinformatics programs, as well as easy access to the Bio-Linux bioinformatics documentation system and sample data useful for testing programs. You can also install Bio-Linux packages to handle new generation sequence data types.\n\n - The vision for **[Cloud BioLinux][3]** is to offer a base image of genome analysis resources for cloud computing platforms, such as Amazon EC2.  This Science as a Service model (ScaaS) will allow us to incorporate, develop and optimize life science software as well as supporting data sets on compute clouds.  This project is driven by the observation that commonly-used bioinformatics tools are hard to build and maintain, require high amounts of resources, or just too numerous to choose from.\n\n - **[BioBrew][4]** is a collection of open-source applications for life scientists and an in-house project at Bioinformatics.Org. The BioBrew Roll for Rocks can be used to create Rocks/BioBrew Linux, a distribution customized for both cluster and bioinformatics computing: it automates cluster installation, includes all the HPC software a cluster enthusiast needs, and contains popular bioinformatics applications.\n\n - **[Debian Med][5]** is a \"Debian Pure Blend\" with the aim to develop Debian into an operating system that is particularly well fit for the requirements for medical practice and research. The goal of Debian Med is a complete system for all tasks in medical care which is built completely on free software.\n\n\n  [1]: http://bicmku.in:8082/bioubuntu/\n  [2]: http://nebc.nox.ac.uk/tools/bio-linux/bio-linux-5.0\n  [3]: http://www.cloudbiolinux.com/\n  [4]: http://biobrew.bioinformatics.org/\n  [5]: http://www.debian.org/devel/debian-med/", "comment_count": 1, "html": "<p>I have no experience with them, but there are several Linux distributions out there that come preloaded with bioinformatics software.</p>\n<p>For example:</p>\n<ul>\n<li>\n<p><strong><a href=\"http://bicmku.in:8082/bioubuntu/\">biobuntu</a></strong> which comes preloaded with amapalign, biococoa, biomode, bioperl, biopython, biosquid, blast2, boxshade, chemtool, clustalw, clustalx, dialign, easychem, fastdnaml, fastlink, garlic, gchempaint, gcubin, gff2aplot, gff2ps, EMBOSS, gmt, gromacs, hmmer, ifeffit, ifrit, imview, kalign, leksbot, libbioruby, meltinggui, mipe, molphy, mozillabiofox, mpqc/support, mummer, muscle, mustang, ncbiepcr, ncbitoolsbin, ncbitoolsx11, njplot, openbabel, perlprimer, phylip, poa, polyxmass, primer3, probcons, proda, pybliographerA, rasmol, readseq, seaview, sibsim4, sigmaalignSimple, sim4, SixpackDisplay, tcoffeeMultiple, tigrglimmerGene, treepuzzleReconstruction, treetool, treeviewxDisplays, viewmol, wise, xbs, xdrawchem and xmakemol</p>\n</li>\n<li>\n<p><strong><a href=\"http://nebc.nox.ac.uk/tools/bio-linux/bio-linux-5.0\">Bio-Linux</a></strong>  a fully featured, powerful, configurable and easy to maintain bioinformatics workstation. Bio-Linux provides more than 500 bioinformatics programs on an Ubuntu Linux base. There is a graphical menu for bioinformatics programs, as well as easy access to the Bio-Linux bioinformatics documentation system and sample data useful for testing programs. You can also install Bio-Linux packages to handle new generation sequence data types.</p>\n</li>\n<li>\n<p>The vision for <strong><a href=\"http://www.cloudbiolinux.com/\">Cloud BioLinux</a></strong> is to offer a base image of genome analysis resources for cloud computing platforms, such as Amazon EC2.  This Science as a Service model (ScaaS) will allow us to incorporate, develop and optimize life science software as well as supporting data sets on compute clouds.  This project is driven by the observation that commonly-used bioinformatics tools are hard to build and maintain, require high amounts of resources, or just too numerous to choose from.</p>\n</li>\n<li>\n<p><strong><a href=\"http://biobrew.bioinformatics.org/\">BioBrew</a></strong> is a collection of open-source applications for life scientists and an in-house project at Bioinformatics.Org. The BioBrew Roll for Rocks can be used to create Rocks/BioBrew Linux, a distribution customized for both cluster and bioinformatics computing: it automates cluster installation, includes all the HPC software a cluster enthusiast needs, and contains popular bioinformatics applications.</p>\n</li>\n<li>\n<p><strong><a href=\"http://www.debian.org/devel/debian-med/\">Debian Med</a></strong> is a \"Debian Pure Blend\" with the aim to develop Debian into an operating system that is particularly well fit for the requirements for medical practice and research. The goal of Debian Med is a complete system for all tasks in medical care which is built completely on free software.</p>\n</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 1, "parent": 33, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 67}}, {"pk": 178, "model": "server.post", "fields": {"rght": 12, "author": 22, "answer_accepted": false, "tag_string": "ensembl annotation genes", "creation_date": "2010-03-05 13:06:24", "lft": 1, "post_type": 164033, "score": 1, "title": "I was studying a gene but it disappeared in the latest ensembl release. What should I do now?", "unanswered": false, "content": "I am studying a set of genes involved in the same pathway, but this week, after looking at the new release of ensembl, I discovered that the gene was removed. What should I do now? There are references to this gene in several articles and the fact that it disappeared intrigues me - to which sequence these articles were referring to? Is it possible that the ensembl's curators have made an error?\n\ncheers", "comment_count": 0, "html": "<p>I am studying a set of genes involved in the same pathway, but this week, after looking at the new release of ensembl, I discovered that the gene was removed. What should I do now? There are references to this gene in several articles and the fact that it disappeared intrigues me - to which sequence these articles were referring to? Is it possible that the ensembl's curators have made an error?</p>\n<p>cheers</p>", "child_count": 0, "closed": false, "tree_id": 47, "revision_count": 1, "parent": null, "views": 169, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:18", "slug": "i-was-studying-a-gene-but-it-disappeared-in-the-latest-ensembl-release-what-should-i-do-now", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [68, 89, 198], "lastedit_user": 22}}, {"pk": 179, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 13:15:48", "lft": 2, "post_type": 109787, "score": 1, "title": "A: I was studying a gene but it disappeared in the latest ensembl release. What should I do now?", "unanswered": false, "content": "The best course of action would be to contact the people (curators) who made the decision of removing that gene. Keep us posted on what they say, it might be an interesting tidbit about data evolution inside databases ;-0", "comment_count": 1, "html": "<p>The best course of action would be to contact the people (curators) who made the decision of removing that gene. Keep us posted on what they say, it might be an interesting tidbit about data evolution inside databases ;-0</p>", "child_count": 0, "closed": false, "tree_id": 47, "revision_count": 1, "parent": 178, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:18", "slug": "a-i-was-studying-a-gene-but-it-disappeared-in-the-latest-ensembl-release-what-should-i-do-now", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 180, "model": "server.post", "fields": {"rght": 5, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 13:21:15", "lft": 4, "post_type": 109787, "score": 3, "title": "A: I was studying a gene but it disappeared in the latest ensembl release. What should I do now?", "unanswered": false, "content": "1. keep on using Ensembl Archive: http://www.ensembl.org/info/website/archives/index.html\n2. there is no general answer to question \"is gene X real one or it is an artifact removed from Ensembl\". \n3. you may check i.e. ESTs if they assemble into sensible transcript /compare few species on the genomic level watching for pseudogenes. \n\n", "comment_count": 0, "html": "<ol>\n<li>keep on using Ensembl Archive: http://www.ensembl.org/info/website/archives/index.html</li>\n<li>there is no general answer to question \"is gene X real one or it is an artifact removed from Ensembl\". </li>\n<li>you may check i.e. ESTs if they assemble into sensible transcript /compare few species on the genomic level watching for pseudogenes. </li>\n</ol>", "child_count": 0, "closed": false, "tree_id": 47, "revision_count": 1, "parent": 178, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-i-was-studying-a-gene-but-it-disappeared-in-the-latest-ensembl-release-what-should-i-do-now", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 181, "model": "server.post", "fields": {"rght": 36, "author": 1, "answer_accepted": false, "tag_string": "bioinformatics books resources", "creation_date": "2010-03-05 13:30:44", "lft": 1, "post_type": 164033, "score": 12, "title": "Recommend your favorite bioinformatics books", "unanswered": false, "content": "I am looking for personal experiences and short opinions regarding bioinformatics books. \n\nSo far I have noticed the following trend: many books titled *Bioinformatics with Perl/Python/Java/R* etc end up being introductions into the programming language in question, often  only minor code examples are related to bioinformatics.\n\n**Help us find some good books!**\n\n*PS. If you are willing to write a standalone book review is even better. Please do so by creating a new question titled: \"Book review for X\" then answer it with your own review.*", "comment_count": 0, "html": "<p>I am looking for personal experiences and short opinions regarding bioinformatics books. </p>\n<p>So far I have noticed the following trend: many books titled <em>Bioinformatics with Perl/Python/Java/R</em> etc end up being introductions into the programming language in question, often  only minor code examples are related to bioinformatics.</p>\n<p><strong>Help us find some good books!</strong></p>\n<p><em>PS. If you are willing to write a standalone book review is even better. Please do so by creating a new question titled: \"Book review for X\" then answer it with your own review.</em></p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 3, "parent": null, "views": 2901, "deleted": false, "answer_count": 20, "touch_date": "2011-11-24 14:49:31", "slug": "recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [73, 90, 152], "lastedit_user": 1}}, {"pk": 182, "model": "server.post", "fields": {"rght": 3, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 13:39:58", "lft": 2, "post_type": 109787, "score": 7, "title": "A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "Ok well I think I will just stick to R for now.  I do some work with BioConductor and have the following texts on my desk:\n\nBioinformatics and Computational Biology Solutions Using R and Bioconductor ([http://www.bioconductor.org/docs/mogr/][1]) is a good text to get to grips with common data processing tasks for microarray and proteomics analysis which covers QC, normalisation, one and two colour array data, and downstream data analysis.  It needs an update, some of the example code does not work with more modern BioConductor releases but it is still a useful resource.\n\nBioconductor Case Studies ([http://www.bioconductor.org/pub/biocases/][2]) focuses less on the specifics of the packages and more on the workflows of common bioinformatics analyses, including GSEA, machine learning, pulling data from remote resources, statistical modelling and visualisation.   It also benefits from being a more recent release than it's counterpart above.\n\nNeither of these books will teach you R however.  My general R programming reference is:\n\nR Programming for Bioinformatics [(http://www.bioconductor.org/pub/RBioinf/][3]) which tells you more about R than you probably ever want to (or care) to know.  Whilst it is aimed at a bioinformatics audience it does not skip it's role as a text primarily to teach you how to program in R.\n\nIf youre looking for a tome that brings your statistics up to speed instead within the R framework then I have long had a copy of Introductory Statistics With R ([http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20][4]) it's not a long book by any means but will get you used to handling data and applying statistical tests in R.\n\n\n  [1]: http://www.bioconductor.org/docs/mogr/\n  [2]: http://www.bioconductor.org/pub/biocases/\n  [3]: (http://www.bioconductor.org/pub/RBioinf/\n  [4]: http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20", "comment_count": 0, "html": "<p>Ok well I think I will just stick to R for now.  I do some work with BioConductor and have the following texts on my desk:</p>\n<p>Bioinformatics and Computational Biology Solutions Using R and Bioconductor (<a href=\"http://www.bioconductor.org/docs/mogr/\">http://www.bioconductor.org/docs/mogr/</a>) is a good text to get to grips with common data processing tasks for microarray and proteomics analysis which covers QC, normalisation, one and two colour array data, and downstream data analysis.  It needs an update, some of the example code does not work with more modern BioConductor releases but it is still a useful resource.</p>\n<p>Bioconductor Case Studies (<a href=\"http://www.bioconductor.org/pub/biocases/\">http://www.bioconductor.org/pub/biocases/</a>) focuses less on the specifics of the packages and more on the workflows of common bioinformatics analyses, including GSEA, machine learning, pulling data from remote resources, statistical modelling and visualisation.   It also benefits from being a more recent release than it's counterpart above.</p>\n<p>Neither of these books will teach you R however.  My general R programming reference is:</p>\n<p>R Programming for Bioinformatics <a href=\"\">(http://www.bioconductor.org/pub/RBioinf/</a>) which tells you more about R than you probably ever want to (or care) to know.  Whilst it is aimed at a bioinformatics audience it does not skip it's role as a text primarily to teach you how to program in R.</p>\n<p>If youre looking for a tome that brings your statistics up to speed instead within the R framework then I have long had a copy of Introductory Statistics With R (<a href=\"http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20\">http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20</a>) it's not a long book by any means but will get you used to handling data and applying statistical tests in R.</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 2, "parent": 181, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 183, "model": "server.post", "fields": {"rght": 8, "author": 78, "answer_accepted": false, "tag_string": "protein sequence multiple scoring", "creation_date": "2010-03-05 14:37:21", "lft": 1, "post_type": 164033, "score": 5, "title": "Score protein variants based on frequency of AA in multiple sequence alignment", "unanswered": false, "content": "For reference, please read this excerpt from  \n**Human non-synonymous SNPs: server and survey**  \nVasily Ramensky, Peer Bork, and Shamil Sunyaev\n\n\n> *Profile analysis of homologous\n> sequences*. The amino acid replacement\n> may be incompatible with the spectrum\n> of substitutions observed at that\n> position in a family of homologous\n> proteins. PolyPhen identifies\n> homologues of the input sequences via\n> a BLAST (23) search of the NRDB\n> database. The set of aligned sequences\n> with sequence identity to the input\n> sequence in the range 30\u00b194%\n> (inclusive) is used by the new version\n> of the PSIC (position-specific\n> independent counts) software (24) to\n> calculate the so-called profile matrix\n> (http://strand.imb.ac.ru/PSIC/).\n> Elements of the matrix (pro- file\n> scores) are logarithmic ratios of the\n> likelihood of a given amino acid\n> occurring at a particular site to the\n> likelihood of this amino acid\n> occurring at any site (background\n> frequency). PolyPhen computes the\n> absolute value of the difference\n> between profile scores of both allelic\n> variants in the polymorphic position.\n> PolyPhen also shows the number of\n> aligned sequences at the query\n> position; this may be used to assess\n> the reliability of profile score\n> calculations.\n\nI'd like to calculate something similar (score variants based on frequency that AA in aligned sequences) to what's mentioned here **programmatically**, but I can't find any implementation of the above described system.\n\nDoes anyone know of a working implementation of this or something similar, that's available either in code or as a web service?\n\nOr should it is easy enough to implement something like this ourselves?", "comment_count": 0, "html": "<p>For reference, please read this excerpt from<br />\n<strong>Human non-synonymous SNPs: server and survey</strong><br />\nVasily Ramensky, Peer Bork, and Shamil Sunyaev</p>\n<blockquote>\n<p><em>Profile analysis of homologous\nsequences</em>. The amino acid replacement\nmay be incompatible with the spectrum\nof substitutions observed at that\nposition in a family of homologous\nproteins. PolyPhen identifies\nhomologues of the input sequences via\na BLAST (23) search of the NRDB\ndatabase. The set of aligned sequences\nwith sequence identity to the input\nsequence in the range 30\u00b194%\n(inclusive) is used by the new version\nof the PSIC (position-specific\nindependent counts) software (24) to\ncalculate the so-called profile matrix\n(http://strand.imb.ac.ru/PSIC/).\nElements of the matrix (pro- file\nscores) are logarithmic ratios of the\nlikelihood of a given amino acid\noccurring at a particular site to the\nlikelihood of this amino acid\noccurring at any site (background\nfrequency). PolyPhen computes the\nabsolute value of the difference\nbetween profile scores of both allelic\nvariants in the polymorphic position.\nPolyPhen also shows the number of\naligned sequences at the query\nposition; this may be used to assess\nthe reliability of profile score\ncalculations.</p>\n</blockquote>\n<p>I'd like to calculate something similar (score variants based on frequency that AA in aligned sequences) to what's mentioned here <strong>programmatically</strong>, but I can't find any implementation of the above described system.</p>\n<p>Does anyone know of a working implementation of this or something similar, that's available either in code or as a web service?</p>\n<p>Or should it is easy enough to implement something like this ourselves?</p>", "child_count": 0, "closed": false, "tree_id": 49, "revision_count": 5, "parent": null, "views": 269, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:27", "slug": "score-protein-variants-based-on-frequency-of-aa-in-multiple-sequence-alignment", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [40, 41, 84, 85], "lastedit_user": 215}}, {"pk": 184, "model": "server.post", "fields": {"rght": 9, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 15:06:55", "lft": 4, "post_type": 109787, "score": 4, "title": "A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "I'll tell an acedote about the book that introduced me to bioinformatics. \n\nLet me preface that I have three big interests in my life: biology, computer science and sailing. The year was around 2000, and I had found the book [The New New Thing : A Silicon Valley Story][1] by [Michael M. Lewis][2]. It was about two of my interests: computer science and sailing.\n\nIt is the biography of [Jim Clark][3], a technology entrepreneur who is about to create his third, separate, billion-dollar company: first Silicon Graphics, then Netscape--and now Healtheon, a startup which he hopes will turn the $1 trillion healthcare industry on its head. But after coming up with the basic idea for Healtheon, securing the initial seed money, and hiring the people to make it happen, Clark concentrated on the building of [Hyperion][4], a sailboat with a 197-foot mast (at the time of her launch, she was the largest sloop ever build and the tallest mast ever built), whose functions are controlled by 25 SGI workstations. As the title implies, Jim Clark is a restless man who was always looking for the *new new thing*, the next big breaktrough. Near the end of the book Michael Lewis tells about one of the new things of Jim Clarks radar, a new emerging field called bioinformatics. \n\nI remember sitting there in my chair, staring at that sentence and thinking \"What! I can combine both biology and computer science!\" From that moment on I was hooked.\n\n*(The book with the ultimate triumvirate, where the three of my interest -biology, computer science and sailing- were combined, came later with the autobiography of  Craig Venter, [A life decoded][5], where he writes about the [Global Ocean Sampling Expedition][6] he undertook with his personal 95-foot sailboat named the Sorcerer II. The expedition sampled water from Halifax, Nova Scotia to the Eastern Tropical Pacific while undertaking a two year circumnavigation. The micro-organisms in the water were sequenced and the results were [published][7], more then doubling the amount of genetic sequences available up to that point.)*\n\n\n  [1]: http://www.nytimes.com/books/99/10/31/reviews/991031.31anderst.html?_r=1\n  [2]: http://en.wikipedia.org/wiki/Michael_Lewis_(author)\n  [3]: http://en.wikipedia.org/wiki/James_H._Clark\n  [4]: http://www.charterworld.com/?sub=yacht-charter&charter=sailing-yacht-hyperion-1095\n  [5]: http://www.nytimes.com/2007/11/11/books/review/Dizikes-t.html\n  [6]: http://www.jcvi.org/cms/research/projects/gos/overview/\n  [7]: http://www.ploscollections.org/article/browseIssue.action?issue=info:doi/10.1371/issue.pcol.v06.i02", "comment_count": 2, "html": "<p>I'll tell an acedote about the book that introduced me to bioinformatics. </p>\n<p>Let me preface that I have three big interests in my life: biology, computer science and sailing. The year was around 2000, and I had found the book <a href=\"http://www.nytimes.com/books/99/10/31/reviews/991031.31anderst.html?_r=1\">The New New Thing : A Silicon Valley Story</a> by <a href=\"http://en.wikipedia.org/wiki/Michael_Lewis_(author)\">Michael M. Lewis</a>. It was about two of my interests: computer science and sailing.</p>\n<p>It is the biography of <a href=\"http://en.wikipedia.org/wiki/James_H._Clark\">Jim Clark</a>, a technology entrepreneur who is about to create his third, separate, billion-dollar company: first Silicon Graphics, then Netscape--and now Healtheon, a startup which he hopes will turn the $1 trillion healthcare industry on its head. But after coming up with the basic idea for Healtheon, securing the initial seed money, and hiring the people to make it happen, Clark concentrated on the building of <a href=\"http://www.charterworld.com/?sub=yacht-charter&amp;charter=sailing-yacht-hyperion-1095\">Hyperion</a>, a sailboat with a 197-foot mast (at the time of her launch, she was the largest sloop ever build and the tallest mast ever built), whose functions are controlled by 25 SGI workstations. As the title implies, Jim Clark is a restless man who was always looking for the <em>new new thing</em>, the next big breaktrough. Near the end of the book Michael Lewis tells about one of the new things of Jim Clarks radar, a new emerging field called bioinformatics. </p>\n<p>I remember sitting there in my chair, staring at that sentence and thinking \"What! I can combine both biology and computer science!\" From that moment on I was hooked.</p>\n<p><em>(The book with the ultimate triumvirate, where the three of my interest -biology, computer science and sailing- were combined, came later with the autobiography of  Craig Venter, <a href=\"http://www.nytimes.com/2007/11/11/books/review/Dizikes-t.html\">A life decoded</a>, where he writes about the <a href=\"http://www.jcvi.org/cms/research/projects/gos/overview/\">Global Ocean Sampling Expedition</a> he undertook with his personal 95-foot sailboat named the Sorcerer II. The expedition sampled water from Halifax, Nova Scotia to the Eastern Tropical Pacific while undertaking a two year circumnavigation. The micro-organisms in the water were sequenced and the results were <a href=\"\">published</a>, more then doubling the amount of genetic sequences available up to that point.)</em></p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 1, "parent": 181, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 185, "model": "server.post", "fields": {"rght": 10, "author": 67, "answer_accepted": true, "tag_string": "books python bioinformatics", "creation_date": "2010-03-05 15:18:17", "lft": 1, "post_type": 164033, "score": 3, "title": "Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "unanswered": false, "content": "**Bioinformatics Programming Using Python**\n\nPractical Programming for Biological Data\n\nBy [Mitchell L Model][1]\n\n![alt text][2]\n\n\nPublisher:[O'Reilly Media][3]\n\nReleased: December 2009 \n\nPages: 528\n\n*As [asked][4] by moderator [Istvan Albert][5] I made a separate question for this book review, so that the best review can come to the top.*\n\n\n  [1]: http://www.oreillynet.com/pub/au/3752\n  [2]: http://covers.oreilly.com/images/9780596154516/cat.gif\n  [3]: http://oreilly.com/catalog/9780596154516\n  [4]: http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books\n  [5]: http://biostar.stackexchange.com/users/2/istvan-albert", "comment_count": 0, "html": "<p><strong>Bioinformatics Programming Using Python</strong></p>\n<p>Practical Programming for Biological Data</p>\n<p>By <a href=\"http://www.oreillynet.com/pub/au/3752\">Mitchell L Model</a></p>\n<p><img alt=\"alt text\" src=\"http://covers.oreilly.com/images/9780596154516/cat.gif\" /></p>\n<p>Publisher:<a href=\"http://oreilly.com/catalog/9780596154516\">O'Reilly Media</a></p>\n<p>Released: December 2009 </p>\n<p>Pages: 528</p>\n<p><em>As <a href=\"http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books\">asked</a> by moderator <a href=\"http://biostar.stackexchange.com/users/2/istvan-albert\">Istvan Albert</a> I made a separate question for this book review, so that the best review can come to the top.</em></p>", "child_count": 0, "closed": false, "tree_id": 50, "revision_count": 4, "parent": null, "views": 485, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:30", "slug": "provide-a-book-review-for-bioinformatics-programming-using-python-by-mitchell-l-model", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [11, 90, 152], "lastedit_user": 418}}, {"pk": 186, "model": "server.post", "fields": {"rght": 6, "author": 61, "answer_accepted": false, "tag_string": "blast gff annotation genome bacteria", "creation_date": "2010-03-05 15:51:48", "lft": 1, "post_type": 164033, "score": 2, "title": "merging blastx hits from overlapping bacterial genome segments", "unanswered": false, "content": "I blastx-ed 1Mbp bacterial genome fragment against NCBI nr database. I have split it into 2000bp fragments with 500bp overlap into a one multiple fasta file (splitter from EMBOSS) \n\n    splitter -sequence my_contig.fa  -size 2000 -overlap 500 \n\nAs on output I picked tabulated blast (-m 9). \n\nNext step was to convert blastx output into gff3. Got that one, with absolute positions (positions in intact contig). \n\nSeems that often one ORF / predicted gene is covered by 2-3 blast hits to the same protein. Hits may or may not overlap. Hence my questions:\n\n1. what are the fragment sizes / overlaps typically used for blastx in such situation?\n2. are there any advantages of improving blast hits, by say merging overlapping segments (e-scores will be invalid), or by using blast2 (blastx mode) and comparing DNA sequence from region of overlapping/almost-touching hits against already detected protein? \n\n", "comment_count": 0, "html": "<p>I blastx-ed 1Mbp bacterial genome fragment against NCBI nr database. I have split it into 2000bp fragments with 500bp overlap into a one multiple fasta file (splitter from EMBOSS) </p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">splitter</span> <span class=\"o\">-</span><span class=\"n\">sequence</span> <span class=\"n\">my_contig</span><span class=\"o\">.</span><span class=\"n\">fa</span>  <span class=\"o\">-</span><span class=\"n\">size</span> <span class=\"mi\">2000</span> <span class=\"o\">-</span><span class=\"n\">overlap</span> <span class=\"mi\">500</span> \n</pre></div>\n</p>\n<p>As on output I picked tabulated blast (-m 9). </p>\n<p>Next step was to convert blastx output into gff3. Got that one, with absolute positions (positions in intact contig). </p>\n<p>Seems that often one ORF / predicted gene is covered by 2-3 blast hits to the same protein. Hits may or may not overlap. Hence my questions:</p>\n<ol>\n<li>what are the fragment sizes / overlaps typically used for blastx in such situation?</li>\n<li>are there any advantages of improving blast hits, by say merging overlapping segments (e-scores will be invalid), or by using blast2 (blastx mode) and comparing DNA sequence from region of overlapping/almost-touching hits against already detected protein? </li>\n</ol>", "child_count": 0, "closed": false, "tree_id": 51, "revision_count": 1, "parent": null, "views": 153, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:28", "slug": "merging-blastx-hits-from-overlapping-bacterial-genome-segments", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [3, 43, 67, 68, 92], "lastedit_user": 61}}, {"pk": 187, "model": "server.post", "fields": {"rght": 8, "author": 87, "answer_accepted": false, "tag_string": "genetic map cm", "creation_date": "2010-03-05 15:59:48", "lft": 1, "post_type": 164033, "score": 5, "title": "Compute genetic map", "unanswered": false, "content": "Dear all,\n\nI would like to get the position in cM for a set of SNPs (SNPs from 1000Genomes Project).\nWhat I have is:\n- list of SNPs with their physical position\n- Genotype (or infered genotype) for each SNP for around 50 individuals\n\nSome of these snps (around 25%) are among the HapMap II SNPs used to compute the genetic map available on HapMap webpage (http://ftp.hapmap.org/recombination/2008-03_rel22_B36/rates).\nBut it is way too little information to think about calculing the cM position for 1000genomes SNPs from HapMap II genetic map, isn't it?\n\nWhat do you suggest?\n\nThanks for your help.\n\nYours truly\nPierre\n \n", "comment_count": 0, "html": "<p>Dear all,</p>\n<p>I would like to get the position in cM for a set of SNPs (SNPs from 1000Genomes Project).\nWhat I have is:\n- list of SNPs with their physical position\n- Genotype (or infered genotype) for each SNP for around 50 individuals</p>\n<p>Some of these snps (around 25%) are among the HapMap II SNPs used to compute the genetic map available on HapMap webpage (http://ftp.hapmap.org/recombination/2008-03_rel22_B36/rates).\nBut it is way too little information to think about calculing the cM position for 1000genomes SNPs from HapMap II genetic map, isn't it?</p>\n<p>What do you suggest?</p>\n<p>Thanks for your help.</p>\n<p>Yours truly\nPierre</p>", "child_count": 0, "closed": false, "tree_id": 52, "revision_count": 1, "parent": null, "views": 500, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:31", "slug": "compute-genetic-map", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [93, 94, 204], "lastedit_user": 87}}, {"pk": 188, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 16:06:14", "lft": 2, "post_type": 109787, "score": 2, "title": "A: merging blastx hits from overlapping bacterial genome segments", "unanswered": false, "content": "Isn't the size of the protein that causes multiple hits? No matter what fragment size or overlap you choose, if two or more fragments cover different sections of the same protein, you'll get mulitple hits.\n\nIf your fragment sizes are too large you'll miss regions, if they are too small you'll get multiple hits. This latter problem does not seem to preclude any downstream analysis, so it may not be worth trying to optimize it away.", "comment_count": 1, "html": "<p>Isn't the size of the protein that causes multiple hits? No matter what fragment size or overlap you choose, if two or more fragments cover different sections of the same protein, you'll get mulitple hits.</p>\n<p>If your fragment sizes are too large you'll miss regions, if they are too small you'll get multiple hits. This latter problem does not seem to preclude any downstream analysis, so it may not be worth trying to optimize it away.</p>", "child_count": 0, "closed": false, "tree_id": 51, "revision_count": 1, "parent": 186, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-merging-blastx-hits-from-overlapping-bacterial-genome-segments", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 189, "model": "server.post", "fields": {"rght": 9, "author": 81, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 16:53:24", "lft": 6, "post_type": 109787, "score": 3, "title": "A: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "We've been buying our servers from HP via pcconnection.com (don't be fooled by the name), with good success.  All of our desktops have been coming from Penguin Computing.", "comment_count": 1, "html": "<p>We've been buying our servers from HP via pcconnection.com (don't be fooled by the name), with good success.  All of our desktops have been coming from Penguin Computing.</p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 1, "parent": 168, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 81}}, {"pk": 190, "model": "server.post", "fields": {"rght": 7, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 16:57:17", "lft": 2, "post_type": 109787, "score": 3, "title": "A: Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "unanswered": false, "content": "The book assumes no prior programming experience, uses real-world examples with biological data, and uses Python 3 (the programming language's first non-backwards-compatible release).\n\nThe first chapters are about primitive datatypes. At the end of each chapter there is a Tips, Traps and Trackbacks section where you can learn things that make your programming life easier, things that you have to watch out for and the meaning of some representative error messages that you might encounter.\n\nThe next chapter covers control statements and has several extended examples that are useful in the day-to-day work of a bioinformatician, like parsing Genbank files, translating RNA sequences, or constructing a table from a text file. Especially handy are the several templates that explain the general control flow . Suppose for example that you have a text file and that you need to collect all the lines that that meet both a preliminary test and a primary test. Then you just look up the template for **filtered collect of roup of lines** in the book:\n\n    lines = []\n    with open(inputfilename) as file:\n        for line in file:\n            if preliminary-test:\n                flag = preliminary-test(file)\n                lines.append(line)\n    return lines\n\nSubsequent chapters explore object-oriented programming using Classes, pattern matching using regular expressions, fetching pages from the web and displaying webpages, processing HTML and XML and working with relational databases. \n\nThe last chapter introduces displaying data using graphical toolkits and as Scalable Vector Graphics. I have been enthusiastic about the last possibility ever since I read the great article [How to Make a US County Thematic Map Using Free Tools][5] on [FlowingData][6]. It hadn't occurred to me to use this technique in the context of bioinformatics. \n\nI do miss a section on the use of matplotlib or other graphical packages that are often used. Another glaring omission is any reference to BioPython. The auther [states in a mailing list message][2] that this is because there is no Python 3 version of BioPython. \n\nThis book comes a decade after \"[Beginning Perl for Bioinformatics][3]\". Now that we have a good introductory level bioinformatics books in Python, I hope to see (Bio)Python gain strength in the bioinformatics community (a more in-depth description about the tension between Perl and Python can be read in the blog post [Not the Biopythonista I thought I'd be][4])\n\n\n  \n\n\n  [1]: http://flowingdata.com/2009/11/12/how-to-make-a-us-county-thematic-map-using-free-tools/\n  [2]: http://www.mail-archive.com/python-list@python.org/msg273660.html\n  [3]: http://oreilly.com/catalog/9780596000806\n  [4]: http://igotgenes.blogspot.com/2008/08/not-biopythonista-i-thought-id-be.html\n  [5]: http://flowingdata.com/2009/11/12/how-to-make-a-us-county-thematic-map-using-free-tools/\n  [6]: http://flowingdata.com/", "comment_count": 2, "html": "<p>The book assumes no prior programming experience, uses real-world examples with biological data, and uses Python 3 (the programming language's first non-backwards-compatible release).</p>\n<p>The first chapters are about primitive datatypes. At the end of each chapter there is a Tips, Traps and Trackbacks section where you can learn things that make your programming life easier, things that you have to watch out for and the meaning of some representative error messages that you might encounter.</p>\n<p>The next chapter covers control statements and has several extended examples that are useful in the day-to-day work of a bioinformatician, like parsing Genbank files, translating RNA sequences, or constructing a table from a text file. Especially handy are the several templates that explain the general control flow . Suppose for example that you have a text file and that you need to collect all the lines that that meet both a preliminary test and a primary test. Then you just look up the template for <strong>filtered collect of roup of lines</strong> in the book:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">lines</span> <span class=\"o\">=</span> <span class=\"o\">[]</span>\n    <span class=\"n\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">inputfilename</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">file:</span>\n        <span class=\"k\">for</span> <span class=\"n\">line</span> <span class=\"n\">in</span> <span class=\"n\">file:</span>\n            <span class=\"k\">if</span> <span class=\"n\">preliminary</span><span class=\"o\">-</span><span class=\"n\">test:</span>\n                <span class=\"n\">flag</span> <span class=\"o\">=</span> <span class=\"n\">preliminary</span><span class=\"o\">-</span><span class=\"n\">test</span><span class=\"p\">(</span><span class=\"n\">file</span><span class=\"p\">)</span>\n                <span class=\"n\">lines</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">line</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">lines</span>\n</pre></div>\n</p>\n<p>Subsequent chapters explore object-oriented programming using Classes, pattern matching using regular expressions, fetching pages from the web and displaying webpages, processing HTML and XML and working with relational databases. </p>\n<p>The last chapter introduces displaying data using graphical toolkits and as Scalable Vector Graphics. I have been enthusiastic about the last possibility ever since I read the great article <a href=\"http://flowingdata.com/2009/11/12/how-to-make-a-us-county-thematic-map-using-free-tools/\">How to Make a US County Thematic Map Using Free Tools</a> on <a href=\"http://flowingdata.com/\">FlowingData</a>. It hadn't occurred to me to use this technique in the context of bioinformatics. </p>\n<p>I do miss a section on the use of matplotlib or other graphical packages that are often used. Another glaring omission is any reference to BioPython. The auther <a href=\"http://www.mail-archive.com/python-list@python.org/msg273660.html\">states in a mailing list message</a> that this is because there is no Python 3 version of BioPython. </p>\n<p>This book comes a decade after \"<a href=\"http://oreilly.com/catalog/9780596000806\">Beginning Perl for Bioinformatics</a>\". Now that we have a good introductory level bioinformatics books in Python, I hope to see (Bio)Python gain strength in the bioinformatics community (a more in-depth description about the tension between Perl and Python can be read in the blog post <a href=\"http://igotgenes.blogspot.com/2008/08/not-biopythonista-i-thought-id-be.html\">Not the Biopythonista I thought I'd be</a>)</p>", "child_count": 0, "closed": false, "tree_id": 50, "revision_count": 1, "parent": 185, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-provide-a-book-review-for-bioinformatics-programming-using-python-by-mitchell-l-model", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 67}}, {"pk": 191, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 18:47:14", "lft": 4, "post_type": 109787, "score": 4, "title": "A: Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "unanswered": false, "content": "I have partially read through this book. It is more software engineering oriented than bioinformatics. I have noticed many typos in the examples.\n\nI think that covering the new Python (3.0) language was a premature undertaking that hurts the value of this book. One must realize that Python 3 is less usable for a bioinformatician as currently few if any of the scientific libraries have been ported to it. Sadly that is not a shortcoming that we can hope to see resolved any time soon.\n\nIt will probably be a decade (if ever!) that we can leave the Python 2 versions behind. ", "comment_count": 0, "html": "<p>I have partially read through this book. It is more software engineering oriented than bioinformatics. I have noticed many typos in the examples.</p>\n<p>I think that covering the new Python (3.0) language was a premature undertaking that hurts the value of this book. One must realize that Python 3 is less usable for a bioinformatician as currently few if any of the scientific libraries have been ported to it. Sadly that is not a shortcoming that we can hope to see resolved any time soon.</p>\n<p>It will probably be a decade (if ever!) that we can leave the Python 2 versions behind. </p>", "child_count": 0, "closed": false, "tree_id": 50, "revision_count": 1, "parent": 185, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-provide-a-book-review-for-bioinformatics-programming-using-python-by-mitchell-l-model", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 192, "model": "server.post", "fields": {"rght": 9, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 19:24:00", "lft": 6, "post_type": 109787, "score": 5, "title": "A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "I think you are spot on with your observation. For some reason most of the recent bioinformatics books, particularly the expensive hardcover ones from CRC and Springer, are written by non-practitioners. By non-practitioners I mean professors who teach statistics, biological science or computer science, as opposed to software developers working in the field of bioinformatics. The result has read like a cross-section of stodgy textbooks and research articles, with little in the way of practical code or analysis strategy. Others, as you mention, are \"mildly bio-flavored\" introductions to a programming language. I love technical books but with a couple exceptions (Beginning Perl for Bioinformatics) I have never felt bioinformatics books were worth the money.\n\nI am looking forward to reading Bioinformatics Programming Using Python. I think it will be a good one.\n\nMy reviews:\n\n - [Statistical Bioinformatics: with R][1]\n - [A Primer of Genome Science, Third Edition][2], \n - [R Programming for Bioinformatics][3]\n\n  [1]: http://www.amazon.com/review/R391IS6TF2K3WW/ref=cm_cr_rdp_perm\n  [2]: http://www.amazon.com/review/R19MANDXOUZY5R/ref=cm_cr_rdp_perm\n  [3]: http://www.amazon.com/review/R19FZ31NTXE89O/ref=cm_cr_rdp_perm", "comment_count": 1, "html": "<p>I think you are spot on with your observation. For some reason most of the recent bioinformatics books, particularly the expensive hardcover ones from CRC and Springer, are written by non-practitioners. By non-practitioners I mean professors who teach statistics, biological science or computer science, as opposed to software developers working in the field of bioinformatics. The result has read like a cross-section of stodgy textbooks and research articles, with little in the way of practical code or analysis strategy. Others, as you mention, are \"mildly bio-flavored\" introductions to a programming language. I love technical books but with a couple exceptions (Beginning Perl for Bioinformatics) I have never felt bioinformatics books were worth the money.</p>\n<p>I am looking forward to reading Bioinformatics Programming Using Python. I think it will be a good one.</p>\n<p>My reviews:</p>\n<ul>\n<li><a href=\"http://www.amazon.com/review/R391IS6TF2K3WW/ref=cm_cr_rdp_perm\">Statistical Bioinformatics: with R</a></li>\n<li><a href=\"http://www.amazon.com/review/R19MANDXOUZY5R/ref=cm_cr_rdp_perm\">A Primer of Genome Science, Third Edition</a>, </li>\n<li><a href=\"http://www.amazon.com/review/R19FZ31NTXE89O/ref=cm_cr_rdp_perm\">R Programming for Bioinformatics</a></li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 3, "parent": 181, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 193, "model": "server.post", "fields": {"rght": 15, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 21:58:06", "lft": 14, "post_type": 109787, "score": 2, "title": "A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "In my Master's in Bioinformatics I used [RedHat][1] 7-8 and  first edition of [Fedora][2], then for the first two years of my PhD I continued with Fedora, then moved to [Ubuntu][3] and For servers to host I used RHEL earlier and now CentOS and Ubuntu server edition. I strongly vote for Ubuntu distro for it's ease of use and strong community presence. \n\n  [1]: http://en.wikipedia.org/wiki/Red_Hat_Linux\n  [2]: http://en.wikipedia.org/wiki/Fedora_%28operating_system%29\n  [3]: http://en.wikipedia.org/wiki/Ubuntu_%28operating_system%29", "comment_count": 0, "html": "<p>In my Master's in Bioinformatics I used <a href=\"http://en.wikipedia.org/wiki/Red_Hat_Linux\">RedHat</a> 7-8 and  first edition of <a href=\"http://en.wikipedia.org/wiki/Fedora_%28operating_system%29\">Fedora</a>, then for the first two years of my PhD I continued with Fedora, then moved to <a href=\"http://en.wikipedia.org/wiki/Ubuntu_%28operating_system%29\">Ubuntu</a> and For servers to host I used RHEL earlier and now CentOS and Ubuntu server edition. I strongly vote for Ubuntu distro for it's ease of use and strong community presence. </p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 1, "parent": 33, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 194, "model": "server.post", "fields": {"rght": 7, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 22:02:46", "lft": 6, "post_type": 109787, "score": 3, "title": "A: Mapping SNPs to Pathways", "unanswered": false, "content": "There are actually two questions in \n\n> related pathways/ diseases ?\n\nThe first first part can be solved by database queries such as biomart and KEGG, but the second part is about complex studies. Actually, IMHO, a large part of the already known SNPs \nare not connected to disease, they might not even have a phenotype (I would bet >99%) . As far as I understand, the known SNPs are sampled from \"healthy\" individuals and represent a large mix. So it seems likely to assume that they are not easily connected to diseases.\n\nIn short, the answer might be exome sequencing of affected individuals. I found this recent article which I think is really great to answer this question: \n\nNg SB, et al.,\n[Exome sequencing identifies the cause of a mendelian disorder.][1]\nNat Genet. 2010 Jan;42(1):30-5. Epub 2009 Nov 13.\n\nIn short they discovered point mutations common in few affected individuals and subtracted synonymously coding SNPs and already known SNPs until they retained only one gene. \n\n\n  [1]: http://www.ncbi.nlm.nih.gov/pubmed/19915526", "comment_count": 0, "html": "<p>There are actually two questions in </p>\n<blockquote>\n<p>related pathways/ diseases ?</p>\n</blockquote>\n<p>The first first part can be solved by database queries such as biomart and KEGG, but the second part is about complex studies. Actually, IMHO, a large part of the already known SNPs \nare not connected to disease, they might not even have a phenotype (I would bet &gt;99%) . As far as I understand, the known SNPs are sampled from \"healthy\" individuals and represent a large mix. So it seems likely to assume that they are not easily connected to diseases.</p>\n<p>In short, the answer might be exome sequencing of affected individuals. I found this recent article which I think is really great to answer this question: </p>\n<p>Ng SB, et al.,\n<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/19915526\">Exome sequencing identifies the cause of a mendelian disorder.</a>\nNat Genet. 2010 Jan;42(1):30-5. Epub 2009 Nov 13.</p>\n<p>In short they discovered point mutations common in few affected individuals and subtracted synonymously coding SNPs and already known SNPs until they retained only one gene. </p>", "child_count": 0, "closed": false, "tree_id": 41, "revision_count": 1, "parent": 142, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-mapping-snps-to-pathways", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 195, "model": "server.post", "fields": {"rght": 9, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 22:19:27", "lft": 8, "post_type": 109787, "score": 9, "title": "A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "I would like to recommend the following books to any one who is interested in Bioinformatics (Not in order): \n\n1. [Genes, Proteins and Computers][1] : A concise introduction to the subject, mainly from a biological view point, yet provide a solid understanding of fundamental concepts in biology, computing, algorithm and statistics related to bioinformatics. Must read. \n2. [Bioinformatics by David Mount][2] : A very detailed account of bioinformatics concepts. I think its high time to revise this book. I am looking forward for the next edition. You should have a copy of this if you are Masters' or PhD in Bioinformatics. \n3. [Bioinformatics : Unix/Linux, Data Processing and Programming][3] : This is a cute little book that gives you an edge over Unix, linux, basic data processing and little bit of Perl programming. I appreciate this book for its handy examples. Highly recommend to those who are from biology and interest to get their hands on programming. \n4. [Bioinformatics : Machine learning approaches][4] Machine learning is now an integral part of bioinformatics and bioinformatics is an emerging area for the application of machine learning techniques. For computer science students : here is the real dose of bioinformatics algorithms. One of the first authentic books on bioinformatics algorithms. \n5. [An Introduction to Bioinformatics Algorithms][5] This one is my favorite, especially the pseudocode section and classification of algorithms and its concise description. Book features extensive content on the algorithms used in bioinforamtics categorized into different groups with interesting cartoons. A unique concept introduced in the book is profile of the authors. If you are really in to bioinformatics algorithms, this should be on your desk. \n\nPS. I have couple of more like [Computational Genome Analysis][6], [Programming Collective Intelligence][7] etc. But they are more of specialized in to different sub-domains of bioinformatics. \n\n  [1]: http://www.amazon.com/Bioinformatics-Genes-Proteins-Computers-Advanced/dp/1859960545\n  [2]: http://www.amazon.com/Bioinformatics-Sequence-Analysis-David-Mount/dp/0879696087\n  [3]: http://www.springer.com/life+sciences/bioinformatics/book/978-3-540-21142-6\n  [4]: http://books.google.com/books?id=pxSM7R1sdeQC&dq=Pierre+baldi+%2B+bioinformatics&printsec=frontcover&source=bn&hl=en&ei=IoGRS6uCIJT-NYLA8Z0N&sa=X&oi=book_result&ct=result&resnum=4&ved=0CBUQ6AEwAw#v=onepage&q=&f=false\n  [5]: http://mitpress.mit.edu/catalog/item/default.asp?tid=10337&ttype=2\n  [6]: http://www.amazon.com/Computational-Genome-Analysis-Introduction-Statistics/dp/0387987851\n  [7]: http://oreilly.com/catalog/9780596529321", "comment_count": 0, "html": "<p>I would like to recommend the following books to any one who is interested in Bioinformatics (Not in order): </p>\n<ol>\n<li><a href=\"http://www.amazon.com/Bioinformatics-Genes-Proteins-Computers-Advanced/dp/1859960545\">Genes, Proteins and Computers</a> : A concise introduction to the subject, mainly from a biological view point, yet provide a solid understanding of fundamental concepts in biology, computing, algorithm and statistics related to bioinformatics. Must read. </li>\n<li><a href=\"http://www.amazon.com/Bioinformatics-Sequence-Analysis-David-Mount/dp/0879696087\">Bioinformatics by David Mount</a> : A very detailed account of bioinformatics concepts. I think its high time to revise this book. I am looking forward for the next edition. You should have a copy of this if you are Masters' or PhD in Bioinformatics. </li>\n<li><a href=\"http://www.springer.com/life+sciences/bioinformatics/book/978-3-540-21142-6\">Bioinformatics : Unix/Linux, Data Processing and Programming</a> : This is a cute little book that gives you an edge over Unix, linux, basic data processing and little bit of Perl programming. I appreciate this book for its handy examples. Highly recommend to those who are from biology and interest to get their hands on programming. </li>\n<li><a href=\"http://books.google.com/books?id=pxSM7R1sdeQC&amp;dq=Pierre+baldi+%2B+bioinformatics&amp;printsec=frontcover&amp;source=bn&amp;hl=en&amp;ei=IoGRS6uCIJT-NYLA8Z0N&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=4&amp;ved=0CBUQ6AEwAw#v=onepage&amp;q=&amp;f=false\">Bioinformatics : Machine learning approaches</a> Machine learning is now an integral part of bioinformatics and bioinformatics is an emerging area for the application of machine learning techniques. For computer science students : here is the real dose of bioinformatics algorithms. One of the first authentic books on bioinformatics algorithms. </li>\n<li><a href=\"http://mitpress.mit.edu/catalog/item/default.asp?tid=10337&amp;ttype=2\">An Introduction to Bioinformatics Algorithms</a> This one is my favorite, especially the pseudocode section and classification of algorithms and its concise description. Book features extensive content on the algorithms used in bioinforamtics categorized into different groups with interesting cartoons. A unique concept introduced in the book is profile of the authors. If you are really in to bioinformatics algorithms, this should be on your desk. </li>\n</ol>\n<p>PS. I have couple of more like <a href=\"http://www.amazon.com/Computational-Genome-Analysis-Introduction-Statistics/dp/0387987851\">Computational Genome Analysis</a>, <a href=\"http://oreilly.com/catalog/9780596529321\">Programming Collective Intelligence</a> etc. But they are more of specialized in to different sub-domains of bioinformatics. </p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 2, "parent": 181, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 196, "model": "server.post", "fields": {"rght": 3, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 22:29:25", "lft": 2, "post_type": 109787, "score": 1, "title": "A: How to charecterize a residue in a protein based on it's ASA", "unanswered": false, "content": "This depends on the program you use, I have calculated surface accessibility using [PSA from JOY package][1]. Another programs which I have seen frequently in literature is [NACCESS][2]. \n\n  [1]: http://bioinformatics.oxfordjournals.org/cgi/content/short/14/7/617\n  [2]: http://www.bioinf.manchester.ac.uk/naccess/", "comment_count": 0, "html": "<p>This depends on the program you use, I have calculated surface accessibility using <a href=\"http://bioinformatics.oxfordjournals.org/cgi/content/short/14/7/617\">PSA from JOY package</a>. Another programs which I have seen frequently in literature is <a href=\"http://www.bioinf.manchester.ac.uk/naccess/\">NACCESS</a>. </p>", "child_count": 0, "closed": false, "tree_id": 46, "revision_count": 1, "parent": 173, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-how-to-charecterize-a-residue-in-a-protein-based-on-its-asa", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 197, "model": "server.post", "fields": {"rght": 5, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 23:13:37", "lft": 2, "post_type": 109787, "score": 5, "title": "A: k-mer based sequencing contamination detection", "unanswered": false, "content": "I would recommend R/Bioconductor to do these kinds of analysis even though I personally doubt that this method is precise enough to separate the reads correctly. You can find the function\n`oligonucleotideFrequency` in the `Biostrings` package. The code for the first step would look somewhat like this: \n\n> library(Biostrings)\n\n> reads = read.DNAStringSet(\"yourReads.fas\", format=\"fasta\")\n\n> nf = oligonucleotideFrequency(reads[1:100], width=4)\n\n> hclust(dist(nf)) # do hierarchical clustering of your tetra freq.\n\nThat would be a very simple form of clustering. Then you have all the powerful  \nclassification algorithms built in R available, for example a support vector machine classifier. Create a training and test set of reads from 2 or more sequenced genomes and mix them. Then you will see if it is possible.\n\nBut if you look at your frequencies it might look like this:\n\n           TACG TACT TAGA TAGC TAGG TAGT TATA TATC TATG TATT TCAA TCAC TCAG TCAT TCCA TCCC TCCG TCCT\n      [1,]    0    0    0    0    0    0    0    0    1    0    0    1    2    0    0    4    0    0\n      [2,]    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0\n      [3,]    0    0    0    1    1    1    0    0    0    1    0    0    0    0    0    1    0    0\n      [4,]    0    0    1    1    0    1    0    2    0    0    1    0    2    1    0    0    1    1\n      [5,]    0    1    0    \n\nSo, lots of 0 or 1. Maybe not enough to classify correctly. That's from some 454 reads as an example and it seems that one should try di- and tri- nucleotides as well.\n\nAlternative: blastx on the individual reads and discard only those with good best hit to a bacterium. A few wrong reads should do no big harm, so it is maybe good not to risk to filter out too many beforehand.", "comment_count": 1, "html": "<p>I would recommend R/Bioconductor to do these kinds of analysis even though I personally doubt that this method is precise enough to separate the reads correctly. You can find the function\n<code>oligonucleotideFrequency</code> in the <code>Biostrings</code> package. The code for the first step would look somewhat like this: </p>\n<blockquote>\n<p>library(Biostrings)</p>\n<p>reads = read.DNAStringSet(\"yourReads.fas\", format=\"fasta\")</p>\n<p>nf = oligonucleotideFrequency(reads[1:100], width=4)</p>\n<p>hclust(dist(nf)) # do hierarchical clustering of your tetra freq.</p>\n</blockquote>\n<p>That would be a very simple form of clustering. Then you have all the powerful<br />\nclassification algorithms built in R available, for example a support vector machine classifier. Create a training and test set of reads from 2 or more sequenced genomes and mix them. Then you will see if it is possible.</p>\n<p>But if you look at your frequencies it might look like this:</p>\n<p><div class=\"highlight\"><pre>           <span class=\"n\">TACG</span> <span class=\"n\">TACT</span> <span class=\"n\">TAGA</span> <span class=\"n\">TAGC</span> <span class=\"n\">TAGG</span> <span class=\"n\">TAGT</span> <span class=\"n\">TATA</span> <span class=\"n\">TATC</span> <span class=\"n\">TATG</span> <span class=\"n\">TATT</span> <span class=\"n\">TCAA</span> <span class=\"n\">TCAC</span> <span class=\"n\">TCAG</span> <span class=\"n\">TCAT</span> <span class=\"n\">TCCA</span> <span class=\"n\">TCCC</span> <span class=\"n\">TCCG</span> <span class=\"n\">TCCT</span>\n      <span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">,]</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">2</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">4</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>\n      <span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,]</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>\n      <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,]</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">1</span>    <span class=\"mi\">1</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>\n      <span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">,]</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">1</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">0</span>    <span class=\"mi\">2</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">0</span>    <span class=\"mi\">2</span>    <span class=\"mi\">1</span>    <span class=\"mi\">0</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">1</span>\n      <span class=\"p\">[</span><span class=\"mi\">5</span><span class=\"p\">,]</span>    <span class=\"mi\">0</span>    <span class=\"mi\">1</span>    <span class=\"mi\">0</span>    \n</pre></div>\n</p>\n<p>So, lots of 0 or 1. Maybe not enough to classify correctly. That's from some 454 reads as an example and it seems that one should try di- and tri- nucleotides as well.</p>\n<p>Alternative: blastx on the individual reads and discard only those with good best hit to a bacterium. A few wrong reads should do no big harm, so it is maybe good not to risk to filter out too many beforehand.</p>", "child_count": 0, "closed": false, "tree_id": 36, "revision_count": 2, "parent": 130, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-k-mer-based-sequencing-contamination-detection", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 198, "model": "server.post", "fields": {"rght": 11, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 23:31:04", "lft": 10, "post_type": 109787, "score": 2, "title": "A: Where can I get the secondary structure of a protein?", "unanswered": false, "content": "If it is only one sequence you may try [PSIPRED][1] server. If you need to work on a large sequence dataset, better to install PSIPRED locally. [PSIPRED][2] runs are typically computational intensive. \n\n\n  [1]: http://bioinf4.cs.ucl.ac.uk:3000/psipred/\n  [2]: http://www.ncbi.nlm.nih.gov/pubmed/10869041", "comment_count": 0, "html": "<p>If it is only one sequence you may try <a href=\"http://bioinf4.cs.ucl.ac.uk:3000/psipred/\">PSIPRED</a> server. If you need to work on a large sequence dataset, better to install PSIPRED locally. <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/10869041\">PSIPRED</a> runs are typically computational intensive. </p>", "child_count": 0, "closed": false, "tree_id": 18, "revision_count": 1, "parent": 48, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-where-can-i-get-the-secondary-structure-of-a-protein", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 199, "model": "server.post", "fields": {"rght": 7, "author": 46, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 23:38:05", "lft": 2, "post_type": 109787, "score": 1, "title": "A: Score protein variants based on frequency of AA in multiple sequence alignment", "unanswered": false, "content": "I'm not sure if I understand you correctly. If you are looking for a webservice that returns the PSIC scoring matrix, why don't you just follow the URL mentioned in the paper's abstract, i.e. http://strand.imb.ac.ru/PSIC/ which leads you to a html form where you can paste your mutliple alignment and returns the PSIC matrix.\nOr did I misunderstand you?\n\n", "comment_count": 2, "html": "<p>I'm not sure if I understand you correctly. If you are looking for a webservice that returns the PSIC scoring matrix, why don't you just follow the URL mentioned in the paper's abstract, i.e. http://strand.imb.ac.ru/PSIC/ which leads you to a html form where you can paste your mutliple alignment and returns the PSIC matrix.\nOr did I misunderstand you?</p>", "child_count": 0, "closed": false, "tree_id": 49, "revision_count": 1, "parent": 183, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-score-protein-variants-based-on-frequency-of-aa-in-multiple-sequence-alignment", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 46}}, {"pk": 200, "model": "server.post", "fields": {"rght": 5, "author": 46, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 23:44:55", "lft": 4, "post_type": 109787, "score": 1, "title": "A: Pfam based functional annotaion", "unanswered": false, "content": "You might also consider to blast against Swissprot and transfer residue annotations.", "comment_count": 0, "html": "<p>You might also consider to blast against Swissprot and transfer residue annotations.</p>", "child_count": 0, "closed": false, "tree_id": 35, "revision_count": 1, "parent": 128, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-pfam-based-functional-annotaion", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 46}}, {"pk": 201, "model": "server.post", "fields": {"rght": 12, "author": 89, "answer_accepted": false, "tag_string": "cis module dnase transcription", "creation_date": "2010-03-06 07:43:23", "lft": 1, "post_type": 164033, "score": 4, "title": "Has enhancer and transcription factor binding site prediction already been made redundant?", "unanswered": false, "content": "ENCODE soon provides DNase I hypersensitivity data for the whole genome in a multitude of different tissues. DNase I hypersensitivity marks genomic positions that are exposed and can hence be used to pinpoint active promoters or enhancers in the studied tissue. DNase I resistant regions, in contrast, mark genomic areas that are protected, e.g. because a transcription factor (TF) is bound. Since the data provides a base-pair resolution, it is possible to \"zoom\" in on the protected areas (== transcription factor binding sites) of the otherwise exposed regions (== enhancers). One can hence identify the shadow-prints on the genome left by the regulatory TFs in a given tissue. To identify which TFs are casting the shadows one could use ChIP-seq (rough binding regions) or Protein Binding Arrays (binding motif).\n\nThe question is: has the *in-silico* prediction of enhancers, binding sites or partners still merit or will we be soon able to look-up the binding events of TFs in the different tissues? ", "comment_count": 0, "html": "<p>ENCODE soon provides DNase I hypersensitivity data for the whole genome in a multitude of different tissues. DNase I hypersensitivity marks genomic positions that are exposed and can hence be used to pinpoint active promoters or enhancers in the studied tissue. DNase I resistant regions, in contrast, mark genomic areas that are protected, e.g. because a transcription factor (TF) is bound. Since the data provides a base-pair resolution, it is possible to \"zoom\" in on the protected areas (== transcription factor binding sites) of the otherwise exposed regions (== enhancers). One can hence identify the shadow-prints on the genome left by the regulatory TFs in a given tissue. To identify which TFs are casting the shadows one could use ChIP-seq (rough binding regions) or Protein Binding Arrays (binding motif).</p>\n<p>The question is: has the <em>in-silico</em> prediction of enhancers, binding sites or partners still merit or will we be soon able to look-up the binding events of TFs in the different tissues? </p>", "child_count": 0, "closed": false, "tree_id": 53, "revision_count": 2, "parent": null, "views": 995, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:30", "slug": "has-enhancer-and-transcription-factor-binding-site-prediction-already-been-made-redundant", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [96, 97, 206, 207], "lastedit_user": 9}}, {"pk": 202, "model": "server.post", "fields": {"rght": 7, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 09:11:59", "lft": 6, "post_type": 109787, "score": 4, "title": "A: How far does bioinformatics go?", "unanswered": false, "content": "As much as I agree with the impressive list from BioGeek, I have to say that it is a non-exhaustive, genomics centric list.\n\nIf we look at the first statement he mentions: \"Bioinformatics is the field of science in which biology and computer science/information technology merge into a single discipline.\"\n\nFrom that statement I understand that anything \"biological\" studied using a \"computer\" should have its place in what we call \"Bioinformatics\".\n\nOne perfect example would be all those people working on proteins and not DNA/RNA. I wouldn't say that those are the same field in Bioinformatics, however you may argue that they fit together... As an example of a \"Bioinformatics Center\" that focuses on proteins I would give: [Stockholm Bioinformatics Center][1]\n\nAnother example would be those people trying to understand how molecules diffuse within the cell cytoplasm. That is a lot of computer work that's directly looking at understanding a phenomenon in a biological context. This type of project is bordering on many disciplines and not just biology and informatics, but also physics. Nevertheless, shouldn't that be a \"bioinformatics\" discipline too? In this category I would give the [Biomatter @ MOSAIC ETH Zurich][2]\n\nWhat about Systems Biology (even if they don't want to be called bioinformaticians), shouldn't they be called bioinformaticians too?\n\nAnd finally (although far from exhaustive) I'll give one last example of something I consider bioinformatics: the [E-Cell Project][3] \n\nI hope this answers your question! In my opinion, bioinformatics is NOT only \"genome stuff\" and I would extend it to yourself too ;)\n\n\n  [1]: http://www.sbc.su.se/research/\n  [2]: http://www.biomatter.ethz.ch/Biomatter/Welcome.html\n  [3]: http://www.e-cell.org/ecell/", "comment_count": 0, "html": "<p>As much as I agree with the impressive list from BioGeek, I have to say that it is a non-exhaustive, genomics centric list.</p>\n<p>If we look at the first statement he mentions: \"Bioinformatics is the field of science in which biology and computer science/information technology merge into a single discipline.\"</p>\n<p>From that statement I understand that anything \"biological\" studied using a \"computer\" should have its place in what we call \"Bioinformatics\".</p>\n<p>One perfect example would be all those people working on proteins and not DNA/RNA. I wouldn't say that those are the same field in Bioinformatics, however you may argue that they fit together... As an example of a \"Bioinformatics Center\" that focuses on proteins I would give: <a href=\"http://www.sbc.su.se/research/\">Stockholm Bioinformatics Center</a></p>\n<p>Another example would be those people trying to understand how molecules diffuse within the cell cytoplasm. That is a lot of computer work that's directly looking at understanding a phenomenon in a biological context. This type of project is bordering on many disciplines and not just biology and informatics, but also physics. Nevertheless, shouldn't that be a \"bioinformatics\" discipline too? In this category I would give the <a href=\"http://www.biomatter.ethz.ch/Biomatter/Welcome.html\">Biomatter @ MOSAIC ETH Zurich</a></p>\n<p>What about Systems Biology (even if they don't want to be called bioinformaticians), shouldn't they be called bioinformaticians too?</p>\n<p>And finally (although far from exhaustive) I'll give one last example of something I consider bioinformatics: the <a href=\"http://www.e-cell.org/ecell/\">E-Cell Project</a> </p>\n<p>I hope this answers your question! In my opinion, bioinformatics is NOT only \"genome stuff\" and I would extend it to yourself too ;)</p>", "child_count": 0, "closed": false, "tree_id": 42, "revision_count": 1, "parent": 149, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-how-far-does-bioinformatics-go", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 203, "model": "server.post", "fields": {"rght": 9, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 11:04:51", "lft": 8, "post_type": 109787, "score": 4, "title": "A: Experiences with cloud computing in bioinformatics", "unanswered": false, "content": "The J. Craig Venter Institute has released the [JCVI Cloud BioLinux image][1], which *\"enables scientists to quickly provision computation infrastructures supporting bioinformatics using cloud computing platforms such as Amazon EC2 and Eucalyptus.   Upon deployment users will have instant access to a host of software including BLAST, glimmer, hmmer, phylip, rasmol, genespring, clustalw, the Celera Assembler, and the EMBOSS collection of utilities.  JCVI Cloud BioLinux is built on a 64-bit instance of Ubuntu virtual server customized with bioinformatics packages from the BioLinux repository, and will be updated periodically.\"*\n\nThey give as their motivation for releasing this image *\"cloud computing can provide researchers with the ability to perform computations using a practically unlimited pool of virtual machines, without facing the burden of owning or maintaining any hardware infrastructure. (...) This Science as a Service model (ScaaS) will allow JCVI to incorporate, develop and optimize life science software as well as supporting data sets on compute clouds.  This project is driven by the observation that commonly-used bioinformatics tools are hard to build and maintain, require high amounts of resources, or just too numerous to choose from.\"*\n\n\n  [1]: http://www.jcvi.org/cms/research/projects/jcvi-cloud-biolinux/overview/", "comment_count": 0, "html": "<p>The J. Craig Venter Institute has released the <a href=\"http://www.jcvi.org/cms/research/projects/jcvi-cloud-biolinux/overview/\">JCVI Cloud BioLinux image</a>, which <em>\"enables scientists to quickly provision computation infrastructures supporting bioinformatics using cloud computing platforms such as Amazon EC2 and Eucalyptus.   Upon deployment users will have instant access to a host of software including BLAST, glimmer, hmmer, phylip, rasmol, genespring, clustalw, the Celera Assembler, and the EMBOSS collection of utilities.  JCVI Cloud BioLinux is built on a 64-bit instance of Ubuntu virtual server customized with bioinformatics packages from the BioLinux repository, and will be updated periodically.\"</em></p>\n<p>They give as their motivation for releasing this image <em>\"cloud computing can provide researchers with the ability to perform computations using a practically unlimited pool of virtual machines, without facing the burden of owning or maintaining any hardware infrastructure. (...) This Science as a Service model (ScaaS) will allow JCVI to incorporate, develop and optimize life science software as well as supporting data sets on compute clouds.  This project is driven by the observation that commonly-used bioinformatics tools are hard to build and maintain, require high amounts of resources, or just too numerous to choose from.\"</em></p>", "child_count": 0, "closed": false, "tree_id": 37, "revision_count": 1, "parent": 132, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-experiences-with-cloud-computing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 204, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 12:48:41", "lft": 2, "post_type": 109787, "score": 5, "title": "A: Has enhancer and transcription factor binding site prediction already been made redundant?", "unanswered": false, "content": "I wouldn't venture to hypothesize on what will happen; *making predictions is difficult, especially about the future*.\n\nWhat seems prudent to assume however is that there may be several reasons of why genomic regions are accessible or protected. For example: is it a transcription factor that protects the region or is there some other reason of why the TF will bind to that location to begin with. For example chromatin structure and nucleosome positioning may favor or disfavor certain events.\n\nAny *in-silico* modeling will need to take into account the various mechanisms that may take place.", "comment_count": 0, "html": "<p>I wouldn't venture to hypothesize on what will happen; <em>making predictions is difficult, especially about the future</em>.</p>\n<p>What seems prudent to assume however is that there may be several reasons of why genomic regions are accessible or protected. For example: is it a transcription factor that protects the region or is there some other reason of why the TF will bind to that location to begin with. For example chromatin structure and nucleosome positioning may favor or disfavor certain events.</p>\n<p>Any <em>in-silico</em> modeling will need to take into account the various mechanisms that may take place.</p>", "child_count": 0, "closed": false, "tree_id": 53, "revision_count": 1, "parent": 201, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-has-enhancer-and-transcription-factor-binding-site-prediction-already-been-made-redundant", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 205, "model": "server.post", "fields": {"rght": 4, "author": 1, "answer_accepted": false, "tag_string": "general contact faq", "creation_date": "2010-03-06 13:46:31", "lft": 1, "post_type": 164033, "score": 1, "title": "How do I contact the moderators or supervisors of this site?", "unanswered": false, "content": "What options do I have for contacting the individuals responsible for the proper functioning of this site? \n\nHow do I suggest improvements, recommend features or report a problem using this site?", "comment_count": 0, "html": "<p>What options do I have for contacting the individuals responsible for the proper functioning of this site? </p>\n<p>How do I suggest improvements, recommend features or report a problem using this site?</p>", "child_count": 0, "closed": false, "tree_id": 54, "revision_count": 2, "parent": null, "views": 108, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:19", "slug": "how-do-i-contact-the-moderators-or-supervisors-of-this-site", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [31, 99, 100], "lastedit_user": 22}}, {"pk": 206, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 13:54:52", "lft": 2, "post_type": 109787, "score": 1, "title": "A: How do I contact the moderators or supervisors of this site?", "unanswered": false, "content": "The **BioStar** site will be primarily moderated and regulated by the users who have high reputation. \n\nWe have also created a Google group called [**Biostar-Central**][1] that is intended to be used for administrative purposes. Use this group to suggest improvements, provide feedback or report problems that otherwise would not be appropriate to ask on the main site.\n\nOccasional **BioStar** related announcements will be made public via this group.\n\nThank you,\n\n[Istvan Albert][2]\n\nPS. First posts by new users to this group will be held for moderation. \n\n\n\n  \n\n\n  [1]: http://groups.google.com/group/biostar-central/\n  [2]: http://www.personal.psu.edu/iua1/", "comment_count": 0, "html": "<p>The <strong>BioStar</strong> site will be primarily moderated and regulated by the users who have high reputation. </p>\n<p>We have also created a Google group called <a href=\"http://groups.google.com/group/biostar-central/\"><strong>Biostar-Central</strong></a> that is intended to be used for administrative purposes. Use this group to suggest improvements, provide feedback or report problems that otherwise would not be appropriate to ask on the main site.</p>\n<p>Occasional <strong>BioStar</strong> related announcements will be made public via this group.</p>\n<p>Thank you,</p>\n<p><a href=\"http://www.personal.psu.edu/iua1/\">Istvan Albert</a></p>\n<p>PS. First posts by new users to this group will be held for moderation. </p>", "child_count": 0, "closed": false, "tree_id": 54, "revision_count": 1, "parent": 205, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:21", "slug": "a-how-do-i-contact-the-moderators-or-supervisors-of-this-site", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 207, "model": "server.post", "fields": {"rght": 5, "author": 90, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 14:58:53", "lft": 4, "post_type": 109787, "score": 3, "title": "A: How to do quality trimming of SoLid Reads in colour space?", "unanswered": false, "content": "I know of two quality filtering methods for SOLiD reads, besides the already suggested SAET:\n\n- [A set of tools][1] from [a recent publication][2]\n\n\n- The csfasta_quality_filter.pl script from ABI's [de novo accessory tools package][3]\n\nHaven't actually tried any of them yet, but will do so pretty soon.\n\n  [1]: http://hts.rutgers.edu/filter/\n  [2]: http://bioinformatics.oxfordjournals.org/cgi/content/short/26/6/849?rss=1\n  [3]: http://solidsoftwaretools.com/gf/project/denovo/frs/", "comment_count": 0, "html": "<p>I know of two quality filtering methods for SOLiD reads, besides the already suggested SAET:</p>\n<ul>\n<li>\n<p><a href=\"http://hts.rutgers.edu/filter/\">A set of tools</a> from <a href=\"http://bioinformatics.oxfordjournals.org/cgi/content/short/26/6/849?rss=1\">a recent publication</a></p>\n</li>\n<li>\n<p>The csfasta_quality_filter.pl script from ABI's <a href=\"http://solidsoftwaretools.com/gf/project/denovo/frs/\">de novo accessory tools package</a></p>\n</li>\n</ul>\n<p>Haven't actually tried any of them yet, but will do so pretty soon.</p>", "child_count": 0, "closed": false, "tree_id": 20, "revision_count": 1, "parent": 53, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-do-quality-trimming-of-solid-reads-in-colour-space", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 90}}, {"pk": 208, "model": "server.post", "fields": {"rght": 9, "author": 90, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 15:18:14", "lft": 6, "post_type": 109787, "score": 6, "title": "A: How do I map, align, and plot my SOLiD results?", "unanswered": false, "content": "First of all, you should not convert to base sequence first and then map - you should do the mapping directly on the color-space reads. The short-read mapper will (typically) report the genome matches for you in base sequence format. There are several short read mappers / aligners that handle color space alignment: Bowtie, BFAST, BWA, SHRiMP, PerM and many others including ABI's own mapreads and Bioscope. You can get the mapping output in SAM format, a handy format which contains a lot of information about the alignments and which you can manipulate in Galaxy (via the NGS: SAM tools menu) to get the \"pileup\" of reads in certain regions and so on.  \n\nEdit: I just noticed that Galaxy now features Bowtie mapping for color space.", "comment_count": 1, "html": "<p>First of all, you should not convert to base sequence first and then map - you should do the mapping directly on the color-space reads. The short-read mapper will (typically) report the genome matches for you in base sequence format. There are several short read mappers / aligners that handle color space alignment: Bowtie, BFAST, BWA, SHRiMP, PerM and many others including ABI's own mapreads and Bioscope. You can get the mapping output in SAM format, a handy format which contains a lot of information about the alignments and which you can manipulate in Galaxy (via the NGS: SAM tools menu) to get the \"pileup\" of reads in certain regions and so on.<br />\n</p>\n<p>Edit: I just noticed that Galaxy now features Bowtie mapping for color space.</p>", "child_count": 0, "closed": false, "tree_id": 13, "revision_count": 2, "parent": 31, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-do-i-map-align-and-plot-my-solid-results", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 90}}, {"pk": 209, "model": "server.post", "fields": {"rght": 3, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 15:42:42", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Compute genetic map", "unanswered": false, "content": "I hope I understand your question: The UCSC genome database contains the position in both **base index** and **cM** for the STS. e.g.:\n\n\n    ~> mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -D hg18 -e 'select name,chrom,chromStart,chromEnd,genethonPos from stsMap where genethonPos!=0 limit 2\\G'\n    *************************** 1. row ***************************\n           name: AFM280WE5\n          chrom: chr1\n     chromStart: 3574721\n       chromEnd: 3575045\n    genethonPos: 6.2\n    *************************** 2. row ***************************\n           name: AFM344WE9\n          chrom: chr1\n     chromStart: 4358261\n       chromEnd: 4358654\n    genethonPos: 11.1\n\nSo you can use this STS map as a 'reference' to map your collection of SNP from **bp** to **cM**.\n\n", "comment_count": 0, "html": "<p>I hope I understand your question: The UCSC genome database contains the position in both <strong>base index</strong> and <strong>cM</strong> for the STS. e.g.:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"o\">~&gt;</span> <span class=\"n\">mysql</span> <span class=\"o\">--</span><span class=\"n\">user</span><span class=\"o\">=</span><span class=\"n\">genome</span> <span class=\"o\">--</span><span class=\"n\">host</span><span class=\"o\">=</span><span class=\"n\">genome</span><span class=\"o\">-</span><span class=\"n\">mysql</span><span class=\"o\">.</span><span class=\"n\">cse</span><span class=\"o\">.</span><span class=\"n\">ucsc</span><span class=\"o\">.</span><span class=\"n\">edu</span> <span class=\"o\">-</span><span class=\"n\">A</span> <span class=\"o\">-</span><span class=\"n\">D</span> <span class=\"n\">hg18</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"s\">&#39;select name,chrom,chromStart,chromEnd,genethonPos from stsMap where genethonPos!=0 limit 2\\G&#39;</span>\n    <span class=\"o\">***************************</span> <span class=\"mi\">1</span><span class=\"o\">.</span> <span class=\"n\">row</span> <span class=\"o\">***************************</span>\n           <span class=\"n\">name:</span> <span class=\"n\">AFM280WE5</span>\n          <span class=\"n\">chrom:</span> <span class=\"n\">chr1</span>\n     <span class=\"n\">chromStart:</span> <span class=\"mi\">3574721</span>\n       <span class=\"n\">chromEnd:</span> <span class=\"mi\">3575045</span>\n    <span class=\"n\">genethonPos:</span> <span class=\"mf\">6.2</span>\n    <span class=\"o\">***************************</span> <span class=\"mi\">2</span><span class=\"o\">.</span> <span class=\"n\">row</span> <span class=\"o\">***************************</span>\n           <span class=\"n\">name:</span> <span class=\"n\">AFM344WE9</span>\n          <span class=\"n\">chrom:</span> <span class=\"n\">chr1</span>\n     <span class=\"n\">chromStart:</span> <span class=\"mi\">4358261</span>\n       <span class=\"n\">chromEnd:</span> <span class=\"mi\">4358654</span>\n    <span class=\"n\">genethonPos:</span> <span class=\"mf\">11.1</span>\n</pre></div>\n</p>\n<p>So you can use this STS map as a 'reference' to map your collection of SNP from <strong>bp</strong> to <strong>cM</strong>.</p>", "child_count": 0, "closed": false, "tree_id": 52, "revision_count": 1, "parent": 187, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-compute-genetic-map", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 210, "model": "server.post", "fields": {"rght": 15, "author": 91, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 16:42:34", "lft": 14, "post_type": 109787, "score": 3, "title": "A: Gene ID conversion tool", "unanswered": false, "content": "[BridgeDB][1] provides a nice API and REST interface, so you can put ID mapping queries in your scripts.\n\n\n  [1]: http://www.biomedcentral.com/1471-2105/11/5", "comment_count": 0, "html": "<p><a href=\"http://www.biomedcentral.com/1471-2105/11/5\">BridgeDB</a> provides a nice API and REST interface, so you can put ID mapping queries in your scripts.</p>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 1, "parent": 22, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 91}}, {"pk": 211, "model": "server.post", "fields": {"rght": 13, "author": 93, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 17:26:09", "lft": 12, "post_type": 109787, "score": 2, "title": "A: Where can I get the secondary structure of a protein?", "unanswered": false, "content": "If you do have the protein structure (PDB file) [link text][1] is also a good option for assigning the secondary structure.\n\n\n  [1]: http://webclu.bio.wzw.tum.de/cgi-bin/stride/stridecgi.py \"Stride\"", "comment_count": 0, "html": "<p>If you do have the protein structure (PDB file) <a href=\"http://webclu.bio.wzw.tum.de/cgi-bin/stride/stridecgi.py\" title=\"Stride\">link text</a> is also a good option for assigning the secondary structure.</p>", "child_count": 0, "closed": false, "tree_id": 18, "revision_count": 1, "parent": 48, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-where-can-i-get-the-secondary-structure-of-a-protein", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 93}}, {"pk": 212, "model": "server.post", "fields": {"rght": 5, "author": 93, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 17:36:39", "lft": 4, "post_type": 109787, "score": 2, "title": "A: How to charecterize a residue in a protein based on it's ASA", "unanswered": false, "content": "[ASA-view][1] is a server that can help you visualize the burial of each amino acid in your protein\n\n\n  [1]: http://www.netasa.org/asaview/ \"ASA-view\"", "comment_count": 0, "html": "<p><a href=\"http://www.netasa.org/asaview/\" title=\"ASA-view\">ASA-view</a> is a server that can help you visualize the burial of each amino acid in your protein</p>", "child_count": 0, "closed": false, "tree_id": 46, "revision_count": 1, "parent": 173, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-charecterize-a-residue-in-a-protein-based-on-its-asa", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 93}}, {"pk": 213, "model": "server.post", "fields": {"rght": 21, "author": 96, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 18:14:16", "lft": 18, "post_type": 109787, "score": 2, "title": "A: Using HDF5 to store  bio-data", "unanswered": false, "content": "Our [Genomedata][1] system stores multiple tracks of 1-bp resolution genomic data in a HDF5 array. Documentation and full source code is available on that page. It has a Python (PyTables) interface for reading the data. For originally loading it into HDF5, we wrote a C loader for added speed.\n\n\n  [1]: http://noble.gs.washington.edu/proj/genomedata/", "comment_count": 1, "html": "<p>Our <a href=\"http://noble.gs.washington.edu/proj/genomedata/\">Genomedata</a> system stores multiple tracks of 1-bp resolution genomic data in a HDF5 array. Documentation and full source code is available on that page. It has a Python (PyTables) interface for reading the data. For originally loading it into HDF5, we wrote a C loader for added speed.</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 1, "parent": 69, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 96}}, {"pk": 214, "model": "server.post", "fields": {"rght": 17, "author": 97, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 18:20:20", "lft": 16, "post_type": 109787, "score": 2, "title": "A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "I have a Mac Pro dual quad core that I use for everything. I use the Mac OS for day to day email, most graphics, browsing, I run a VMWare virtual Windows machine, and I do most analysis in the unix terminal. Windows runs much better on the Mac hardware, Excel is much faster in Window, and I can fileshare between the Windows and Mac systems. So far this has been sufficient for me. If I run into a situation where I need more computing power, I can ssh to a Linux server, but I haven't needed to yet. I configured the machine with 16 GB RAM, leaving slots open to add another 16 if needed. I've been happy with this.", "comment_count": 0, "html": "<p>I have a Mac Pro dual quad core that I use for everything. I use the Mac OS for day to day email, most graphics, browsing, I run a VMWare virtual Windows machine, and I do most analysis in the unix terminal. Windows runs much better on the Mac hardware, Excel is much faster in Window, and I can fileshare between the Windows and Mac systems. So far this has been sufficient for me. If I run into a situation where I need more computing power, I can ssh to a Linux server, but I haven't needed to yet. I configured the machine with 16 GB RAM, leaving slots open to add another 16 if needed. I've been happy with this.</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 1, "parent": 33, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 97}}, {"pk": 215, "model": "server.post", "fields": {"rght": 4, "author": 98, "answer_accepted": false, "tag_string": "assembly unambiguous fastq ngs sequencing", "creation_date": "2010-03-06 18:22:30", "lft": 1, "post_type": 164033, "score": 1, "title": "Unambiguous assembly of next-gen fastq reads into fastq contigs?", "unanswered": false, "content": "Hi,\n\nDoes anybody know of any tool that will produce an unambiguous assembly of next-gen fastq files and give the assembled output back as fastq with consensus/combined scores?\n\nBy unambiguous I mean something like this in abyss:\n\nABYSS -k$k -b0 -t0 -e0 -c0\n\nCheers,\n\nAlbert. ", "comment_count": 0, "html": "<p>Hi,</p>\n<p>Does anybody know of any tool that will produce an unambiguous assembly of next-gen fastq files and give the assembled output back as fastq with consensus/combined scores?</p>\n<p>By unambiguous I mean something like this in abyss:</p>\n<p>ABYSS -k$k -b0 -t0 -e0 -c0</p>\n<p>Cheers,</p>\n<p>Albert. </p>", "child_count": 0, "closed": false, "tree_id": 55, "revision_count": 3, "parent": null, "views": 616, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:20", "slug": "unambiguous-assembly-of-next-gen-fastq-reads-into-fastq-contigs", "lastedit_date": "2011-11-24 14:48:32", "level": 0, "post_accepted": false, "tag_set": [23, 101, 102, 103, 215], "lastedit_user": 141}}, {"pk": 216, "model": "server.post", "fields": {"rght": 19, "author": 71, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 18:33:14", "lft": 18, "post_type": 109787, "score": 2, "title": "A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "Highly subjective answer of course, but I don't think you can go wrong with Linux at the backend.  In general, you will find a vast variety of software, great community support, better work/$ numbers at scale.  I tend to prefer debian-based distro's (Ubuntu, Debian, etc) but that's a personal choice.  On the front end, I've successfully used IRIX (dating myself), Ubuntu, and OSX.", "comment_count": 0, "html": "<p>Highly subjective answer of course, but I don't think you can go wrong with Linux at the backend.  In general, you will find a vast variety of software, great community support, better work/$ numbers at scale.  I tend to prefer debian-based distro's (Ubuntu, Debian, etc) but that's a personal choice.  On the front end, I've successfully used IRIX (dating myself), Ubuntu, and OSX.</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 1, "parent": 33, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:32", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 71}}, {"pk": 217, "model": "server.post", "fields": {"rght": 7, "author": 99, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 19:03:07", "lft": 6, "post_type": 109787, "score": 3, "title": "A: How to charecterize a residue in a protein based on it's ASA", "unanswered": false, "content": "yeah, the better answer is not to use surface area to calculate depth. use depth.\nhttp://dx.doi.org/10.1016/j.tibs.2003.09.004", "comment_count": 0, "html": "<p>yeah, the better answer is not to use surface area to calculate depth. use depth.\nhttp://dx.doi.org/10.1016/j.tibs.2003.09.004</p>", "child_count": 0, "closed": false, "tree_id": 46, "revision_count": 1, "parent": 173, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-charecterize-a-residue-in-a-protein-based-on-its-asa", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 99}}, {"pk": 218, "model": "server.post", "fields": {"rght": 23, "author": 91, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 20:38:38", "lft": 20, "post_type": 109787, "score": 3, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "Most of my work is in python, so I use [paver][1], which is similar to makefiles or rake for ruby, but gives you access to all python libraries.\n\n\n  [1]: http://www.blueskyonmars.com/projects/paver/", "comment_count": 1, "html": "<p>Most of my work is in python, so I use <a href=\"http://www.blueskyonmars.com/projects/paver/\">paver</a>, which is similar to makefiles or rake for ruby, but gives you access to all python libraries.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 1, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 91}}, {"pk": 219, "model": "server.post", "fields": {"rght": 5, "author": 50, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 23:19:21", "lft": 4, "post_type": 109787, "score": 6, "title": "A: Has enhancer and transcription factor binding site prediction already been made redundant?", "unanswered": false, "content": "I don't work on prediction of transcription factor binding or enhancers so I will just give a very general answer that could apply to any sort of prediction. \n\nI think there is a big difference between observing an event (ex. transcription factor binding to region X) and knowing why you observe it. To put it in another way .. if we can solve protein structures should we still try to predict how a protein might fold ? Prediction  tries to encapsulates our knowledge of the system so I think the answer is that we will never stop trying to predict/model a system even if we can just easily measure it. Until we can model it we don't really know how it works. If you are only interested in knowing where a TF might bind to then the observations are enough but if you want to know **why** a protein with those characteristics is binding to that DNA region then the observations are just the starting point. \n\n", "comment_count": 0, "html": "<p>I don't work on prediction of transcription factor binding or enhancers so I will just give a very general answer that could apply to any sort of prediction. </p>\n<p>I think there is a big difference between observing an event (ex. transcription factor binding to region X) and knowing why you observe it. To put it in another way .. if we can solve protein structures should we still try to predict how a protein might fold ? Prediction  tries to encapsulates our knowledge of the system so I think the answer is that we will never stop trying to predict/model a system even if we can just easily measure it. Until we can model it we don't really know how it works. If you are only interested in knowing where a TF might bind to then the observations are enough but if you want to know <strong>why</strong> a protein with those characteristics is binding to that DNA region then the observations are just the starting point. </p>", "child_count": 0, "closed": false, "tree_id": 53, "revision_count": 1, "parent": 201, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-has-enhancer-and-transcription-factor-binding-site-prediction-already-been-made-redundant", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 50}}, {"pk": 220, "model": "server.post", "fields": {"rght": 31, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 03:26:37", "lft": 22, "post_type": 109787, "score": 4, "title": "A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "I have done some with [ruffus][1] but have reverted back to using make files.\nRuffus is a nice idea and implemented very nicely, but often, in a pipeline, I just want to overwrite files--since I'm exploring and making lots of changes and mistakes. With rufus, I found I was spending a lot of time tracking down which files had/had not changed. For some reason, it's easier for me to deal with a Makefile, with or without using dependencies. YMMV. I just order the make with steps that come first at the top and add stuff to the bottom as I extend the pipeline. This is very simple, but works well for now. I'm interested to see what other responses are added here. \n\nAs others have mentioned, a README.txt and documentation at the top of the script are a good idea. Also, for any script that takes more than 2 arguments, use a getopt equivalent e.g. [optparse][2] in python).\n\nFinally, extract as much code as possible into tested/test-able libraries.\n\n  [1]: http://wwwfgu.anat.ox.ac.uk/~lg/oss/ruffus/\n  [2]: http://docs.python.org/library/optparse.html", "comment_count": 4, "html": "<p>I have done some with <a href=\"http://wwwfgu.anat.ox.ac.uk/~lg/oss/ruffus/\">ruffus</a> but have reverted back to using make files.\nRuffus is a nice idea and implemented very nicely, but often, in a pipeline, I just want to overwrite files--since I'm exploring and making lots of changes and mistakes. With rufus, I found I was spending a lot of time tracking down which files had/had not changed. For some reason, it's easier for me to deal with a Makefile, with or without using dependencies. YMMV. I just order the make with steps that come first at the top and add stuff to the bottom as I extend the pipeline. This is very simple, but works well for now. I'm interested to see what other responses are added here. </p>\n<p>As others have mentioned, a README.txt and documentation at the top of the script are a good idea. Also, for any script that takes more than 2 arguments, use a getopt equivalent e.g. <a href=\"http://docs.python.org/library/optparse.html\">optparse</a> in python).</p>\n<p>Finally, extract as much code as possible into tested/test-able libraries.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 1, "parent": 79, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 35}}, {"pk": 221, "model": "server.post", "fields": {"rght": 11, "author": 26, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 05:26:39", "lft": 10, "post_type": 109787, "score": 7, "title": "A: What methods do you use for short read mapping?", "unanswered": false, "content": "We map the reads from the illumina and SoLid platform by using BWA. http://bio-bwa.sourceforge.net/\n\nFor bacterial genomes, we choses the illumina platform. About 50X coverage of the total reads was obtained against the ~4Mb reference genome. The mapping process took about 1 hour by using 7 cpus.\n\nFor eukaryotic genomes, we choses the SoLid platform. About 25x coverage of the total reads were obtained against the ~500Mb reference genome. The mapping process took about 2 days by using 7 cpus.\n\nGenerally reads mapping by using BWA is reliable. ", "comment_count": 0, "html": "<p>We map the reads from the illumina and SoLid platform by using BWA. http://bio-bwa.sourceforge.net/</p>\n<p>For bacterial genomes, we choses the illumina platform. About 50X coverage of the total reads was obtained against the ~4Mb reference genome. The mapping process took about 1 hour by using 7 cpus.</p>\n<p>For eukaryotic genomes, we choses the SoLid platform. About 25x coverage of the total reads were obtained against the ~500Mb reference genome. The mapping process took about 2 days by using 7 cpus.</p>\n<p>Generally reads mapping by using BWA is reliable. </p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 1, "parent": 137, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 26}}, {"pk": 222, "model": "server.post", "fields": {"rght": 16, "author": 104, "answer_accepted": false, "tag_string": "sequence genome search tool primer", "creation_date": "2010-03-07 12:53:55", "lft": 1, "post_type": 164033, "score": 4, "title": "How to find a 28bp 'primer' sequence in a genome?", "unanswered": false, "content": "Dumb question I know, but...\n\nWhat tool to use?\n\nI'd like to find forward and reverse primers within an approximate distance of each other... I'd like to accept 1 or two mismatches. The genome is ~1 Gbp. I have ~500 forward reverse pairs to find in the genome.\n\nAny hints appreciated :-)", "comment_count": 1, "html": "<p>Dumb question I know, but...</p>\n<p>What tool to use?</p>\n<p>I'd like to find forward and reverse primers within an approximate distance of each other... I'd like to accept 1 or two mismatches. The genome is ~1 Gbp. I have ~500 forward reverse pairs to find in the genome.</p>\n<p>Any hints appreciated :-)</p>", "child_count": 0, "closed": false, "tree_id": 56, "revision_count": 1, "parent": null, "views": 832, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:27", "slug": "how-to-find-a-28bp-primer-sequence-in-a-genome", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [40, 67, 105, 106, 107], "lastedit_user": 104}}, {"pk": 223, "model": "server.post", "fields": {"rght": 3, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 13:24:06", "lft": 2, "post_type": 109787, "score": 3, "title": "A: How to find a 28bp 'primer' sequence in a genome?", "unanswered": false, "content": "I know that many people use the [primer3 software][1] to design primers. There are also two web-interfaces where you can try out the parameters, and there are many of them.\nThe program **[eprimer3][2]** is part of the [EMBOSS tools][3], maybe the best way of getting a command-line executable of primer3.\n\nI didn't see a mismatch parameter though, because for a 'real' PCR-primer to allow for mismatches is a bad idea. I noted the '' in your question, so you might not really be looking for primers. So what is it then? If this is just a piece of sequence then you do not need to bother with uniqueness or melting temperature constraints.\n\n\n  [1]: http://primer3.sourceforge.net/\n  [2]: http://emboss.sourceforge.net/apps/release/6.2/emboss/apps/eprimer3.html\n  [3]: http://emboss.sourceforge.net/", "comment_count": 0, "html": "<p>I know that many people use the <a href=\"http://primer3.sourceforge.net/\">primer3 software</a> to design primers. There are also two web-interfaces where you can try out the parameters, and there are many of them.\nThe program <strong><a href=\"http://emboss.sourceforge.net/apps/release/6.2/emboss/apps/eprimer3.html\">eprimer3</a></strong> is part of the <a href=\"http://emboss.sourceforge.net/\">EMBOSS tools</a>, maybe the best way of getting a command-line executable of primer3.</p>\n<p>I didn't see a mismatch parameter though, because for a 'real' PCR-primer to allow for mismatches is a bad idea. I noted the '' in your question, so you might not really be looking for primers. So what is it then? If this is just a piece of sequence then you do not need to bother with uniqueness or melting temperature constraints.</p>", "child_count": 0, "closed": false, "tree_id": 56, "revision_count": 1, "parent": 222, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-how-to-find-a-28bp-primer-sequence-in-a-genome", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 224, "model": "server.post", "fields": {"rght": 13, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 15:20:02", "lft": 12, "post_type": 109787, "score": 2, "title": "A: What methods do you use for short read mapping?", "unanswered": false, "content": "I've only used [bowtie][1], but it seems to be extremely fast and makes use of multiple cores with no extra work on my part. Also, builds an index for the reference sequence which can be re-used after the first build. \n\nThis is mapping to Arabidopsis Thaliana, up to 5 or so Gigs of raw reads, so fastq of 4x that size. Using a pretty standard 8 core machine, it's relatively painless.\n\n\nUPDATE:\n\nWe've also found [gsnap][2] to be excellent. It can do fasta/fastq, spliced alignment (RNA-Seq), BS-Seq, and general mapping very quickly. It is a bit slower than bowtie but handles indels much better. Though it can read fastq files, it does not use the quality information so it is best to trim reads before sending through gsnap.\n\n\n  [1]: http://bowtie-bio.sourceforge.net/index.shtml\n  [2]: http://share.gene.com/gmap/", "comment_count": 0, "html": "<p>I've only used <a href=\"http://bowtie-bio.sourceforge.net/index.shtml\">bowtie</a>, but it seems to be extremely fast and makes use of multiple cores with no extra work on my part. Also, builds an index for the reference sequence which can be re-used after the first build. </p>\n<p>This is mapping to Arabidopsis Thaliana, up to 5 or so Gigs of raw reads, so fastq of 4x that size. Using a pretty standard 8 core machine, it's relatively painless.</p>\n<p>UPDATE:</p>\n<p>We've also found <a href=\"http://share.gene.com/gmap/\">gsnap</a> to be excellent. It can do fasta/fastq, spliced alignment (RNA-Seq), BS-Seq, and general mapping very quickly. It is a bit slower than bowtie but handles indels much better. Though it can read fastq files, it does not use the quality information so it is best to trim reads before sending through gsnap.</p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 2, "parent": 137, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:20", "slug": "a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 35}}, {"pk": 225, "model": "server.post", "fields": {"rght": 5, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 16:22:36", "lft": 4, "post_type": 109787, "score": 2, "title": "A: How to find a 28bp 'primer' sequence in a genome?", "unanswered": false, "content": "[EDIT]\nJust saw [this][1] today (http://www.biomedcentral.com/1471-2105/11/143) which could be another piece of software to check out. I didnt read it carefully, but it looks like it builds on primer3.\n[/EDIT]\n\n\nSince you have so few pairs, you could just run them through a read-aligner allowing mismatches, and find pairs that are aligned within X basepairs in the reference genome. \nActually, you could probably even use the paired-end feature of most aligners so that the aligner only find the pairs with nearby matches. For either of those methods, you could use [bowtie][2].\n\nAs far as I know, [primer3][3] does allow gaps and mismatches, so that may also be an option if you just want to see if you have good primers, but you'd probably have to use the command-line version.\n\nor, you could use BLAST and find nearby hits between the pairs.\n\n\n  [1]: http://www.biomedcentral.com/1471-2105/11/143\n  [2]: http://bowtie-bio.sourceforge.net/index.shtml\n  [3]: http://primer3.sourceforge.net/", "comment_count": 0, "html": "<p>[EDIT]\nJust saw <a href=\"http://www.biomedcentral.com/1471-2105/11/143\">this</a> today (http://www.biomedcentral.com/1471-2105/11/143) which could be another piece of software to check out. I didnt read it carefully, but it looks like it builds on primer3.\n[/EDIT]</p>\n<p>Since you have so few pairs, you could just run them through a read-aligner allowing mismatches, and find pairs that are aligned within X basepairs in the reference genome. \nActually, you could probably even use the paired-end feature of most aligners so that the aligner only find the pairs with nearby matches. For either of those methods, you could use <a href=\"http://bowtie-bio.sourceforge.net/index.shtml\">bowtie</a>.</p>\n<p>As far as I know, <a href=\"http://primer3.sourceforge.net/\">primer3</a> does allow gaps and mismatches, so that may also be an option if you just want to see if you have good primers, but you'd probably have to use the command-line version.</p>\n<p>or, you could use BLAST and find nearby hits between the pairs.</p>", "child_count": 0, "closed": false, "tree_id": 56, "revision_count": 2, "parent": 222, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-how-to-find-a-28bp-primer-sequence-in-a-genome", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 35}}, {"pk": 226, "model": "server.post", "fields": {"rght": 7, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 19:22:29", "lft": 6, "post_type": 109787, "score": 5, "title": "A: Has enhancer and transcription factor binding site prediction already been made redundant?", "unanswered": false, "content": "I agree with Istvan and pedrobeltrao.\n\nI would just add that we should all be careful when we look at the type of experiments that you describe as well as protein structures and many other biochemical experiments.\n\nThey are, most often, ***snapshots*** of what is happening in an ***extremely dynamic*** environment, which is the cell and its components.\n\nWhat holds true at one moment (when the cell was fixed, the proteins extracted or crystalized) is not the whole picture of what's happening or how things look.\n\nI think you'll need more than a few biochemical experiments to ***know*** how the cell really works. Until that day, predictions and modeling will always be useful.", "comment_count": 0, "html": "<p>I agree with Istvan and pedrobeltrao.</p>\n<p>I would just add that we should all be careful when we look at the type of experiments that you describe as well as protein structures and many other biochemical experiments.</p>\n<p>They are, most often, <strong><em>snapshots</em></strong> of what is happening in an <strong><em>extremely dynamic</em></strong> environment, which is the cell and its components.</p>\n<p>What holds true at one moment (when the cell was fixed, the proteins extracted or crystalized) is not the whole picture of what's happening or how things look.</p>\n<p>I think you'll need more than a few biochemical experiments to <strong><em>know</em></strong> how the cell really works. Until that day, predictions and modeling will always be useful.</p>", "child_count": 0, "closed": false, "tree_id": 53, "revision_count": 1, "parent": 201, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-has-enhancer-and-transcription-factor-binding-site-prediction-already-been-made-redundant", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 227, "model": "server.post", "fields": {"rght": 7, "author": 87, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 10:01:03", "lft": 4, "post_type": 109787, "score": 2, "title": "A: Compute genetic map", "unanswered": false, "content": "Hey Pierre,\n\nthanks for your answer!\nI already got the genetic map provided by USCS database with STS markers.\nBut my issue remains the same: the density of markers of the available genetic maps (the USCS one or HapMap II one) is much lower than the density of my SNP set. For example I have 4054 SNPs between the 2 STS markers above (in your comment).\n \nTherefore I don't know how to attribute to each SNPs of my set a position in cM  without doing a very important approximation.\n\nAnyway, what do you suggest? To use a rule of three approach to attribute a cM position to my collection's SNPs?\n \nThanks for your advice!\nPierre\n\n\n", "comment_count": 1, "html": "<p>Hey Pierre,</p>\n<p>thanks for your answer!\nI already got the genetic map provided by USCS database with STS markers.\nBut my issue remains the same: the density of markers of the available genetic maps (the USCS one or HapMap II one) is much lower than the density of my SNP set. For example I have 4054 SNPs between the 2 STS markers above (in your comment).</p>\n<p>Therefore I don't know how to attribute to each SNPs of my set a position in cM  without doing a very important approximation.</p>\n<p>Anyway, what do you suggest? To use a rule of three approach to attribute a cM position to my collection's SNPs?</p>\n<p>Thanks for your advice!\nPierre</p>", "child_count": 0, "closed": false, "tree_id": 52, "revision_count": 1, "parent": 187, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-compute-genetic-map", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 87}}, {"pk": 228, "model": "server.post", "fields": {"rght": 12, "author": 109, "answer_accepted": false, "tag_string": "clustering map", "creation_date": "2010-03-08 12:57:32", "lft": 1, "post_type": 164033, "score": 3, "title": "Hierarchical Clustering, Cluster Heat Maps in Java", "unanswered": false, "content": "Hello all,\nI am new to this forum and I am glad I found one in Bioinformatics too.\nI hope I can ask this question here.\n**Has anyone been able to generate cluster heatmaps using any library in Java ?**\nI recently got to learn that heatmaps are different from cluster heat maps in just that in the cluster heatmaps there are dendrograms for both genes as well as samples. So essentially Hierarchical clustering (thats what I am working on) is to be performed once on the genes and once on the samples.\nI was looking at JFreechart, JTreeview. In JFreechart I did not find any method to directly get a cluster heat map. And with JTreeview,  it needs 3 input files in particular format like the .CDT file, .gtr file, .atr file. I am curious to know if there is any other direct way to generate these cluster heat maps. \n\nPlease enlighten me\n\nThanks in advance", "comment_count": 0, "html": "<p>Hello all,\nI am new to this forum and I am glad I found one in Bioinformatics too.\nI hope I can ask this question here.\n<strong>Has anyone been able to generate cluster heatmaps using any library in Java ?</strong>\nI recently got to learn that heatmaps are different from cluster heat maps in just that in the cluster heatmaps there are dendrograms for both genes as well as samples. So essentially Hierarchical clustering (thats what I am working on) is to be performed once on the genes and once on the samples.\nI was looking at JFreechart, JTreeview. In JFreechart I did not find any method to directly get a cluster heat map. And with JTreeview,  it needs 3 input files in particular format like the .CDT file, .gtr file, .atr file. I am curious to know if there is any other direct way to generate these cluster heat maps. </p>\n<p>Please enlighten me</p>\n<p>Thanks in advance</p>", "child_count": 0, "closed": false, "tree_id": 57, "revision_count": 1, "parent": null, "views": 1469, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:27", "slug": "hierarchical-clustering-cluster-heat-maps-in-java", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [8, 94], "lastedit_user": 109}}, {"pk": 229, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 13:49:18", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Hierarchical Clustering, Cluster Heat Maps in Java", "unanswered": false, "content": "\nI know that the [Multiexperiment Viewer suite][1] is written in Java. \n\nWhile it is not usually used as a library I think you might be able to import some of its internals in your own code. It is worth a try, as you could get access to numerous other tools as well. \n\n\n  [1]: http://www.tm4.org/mev/", "comment_count": 1, "html": "<p>I know that the <a href=\"http://www.tm4.org/mev/\">Multiexperiment Viewer suite</a> is written in Java. </p>\n<p>While it is not usually used as a library I think you might be able to import some of its internals in your own code. It is worth a try, as you could get access to numerous other tools as well. </p>", "child_count": 0, "closed": false, "tree_id": 57, "revision_count": 1, "parent": 228, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-hierarchical-clustering-cluster-heat-maps-in-java", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 230, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 13:50:54", "lft": 2, "post_type": 109787, "score": 0, "title": "A: Computing the reverse and complement of a sequence with Pygr", "unanswered": false, "content": "This post was not formulated in a question/answer format  therefore will be closed.", "comment_count": 1, "html": "<p>This post was not formulated in a question/answer format  therefore will be closed.</p>", "child_count": 0, "closed": false, "tree_id": 29, "revision_count": 2, "parent": 92, "views": 0, "deleted": true, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "a-computing-the-reverse-and-complement-of-a-sequence-with-pygr", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 231, "model": "server.post", "fields": {"rght": 9, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 14:39:24", "lft": 6, "post_type": 109787, "score": 4, "title": "A: How to find a 28bp 'primer' sequence in a genome?", "unanswered": false, "content": "Did not used it myself yet, but there is a new program claiming to be better than primer3:\n\nSee:\nhttp://nar.oxfordjournals.org/cgi/content/abstract/37/13/e95\n\nDownload it from:\nhttp://pythia.sourceforge.net\n\n", "comment_count": 1, "html": "<p>Did not used it myself yet, but there is a new program claiming to be better than primer3:</p>\n<p>See:\nhttp://nar.oxfordjournals.org/cgi/content/abstract/37/13/e95</p>\n<p>Download it from:\nhttp://pythia.sourceforge.net</p>", "child_count": 0, "closed": false, "tree_id": 56, "revision_count": 1, "parent": 222, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-to-find-a-28bp-primer-sequence-in-a-genome", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 232, "model": "server.post", "fields": {"rght": 12, "author": 63, "answer_accepted": false, "tag_string": "professional career subjective assessment", "creation_date": "2010-03-08 16:54:31", "lft": 1, "post_type": 164033, "score": 9, "title": "How Important is it to belong to a Professional Society in Computational Biology?", "unanswered": false, "content": "It is clear that in Computational Biology there are certain organisations, societies and the like, global and regional, that intend to cater the needs for conferences, networking and scientific exchange, proper of any scientific community.\n\nHowever, the benefits of joining a society are still elusive. In an American setting it seems that there is this culture of supporting your own community by joining your society. In Europe it does not seem to have any value attached in one's CV to belong or form part of a society, other than anecdotal. Other regions in the world may be somewhere in between.\n\nI would like to ask people what they think their perception of belonging to a professional society is, whether this should be something that should be encouraged in settings where this is not so valued and what their expectations are.", "comment_count": 0, "html": "<p>It is clear that in Computational Biology there are certain organisations, societies and the like, global and regional, that intend to cater the needs for conferences, networking and scientific exchange, proper of any scientific community.</p>\n<p>However, the benefits of joining a society are still elusive. In an American setting it seems that there is this culture of supporting your own community by joining your society. In Europe it does not seem to have any value attached in one's CV to belong or form part of a society, other than anecdotal. Other regions in the world may be somewhere in between.</p>\n<p>I would like to ask people what they think their perception of belonging to a professional society is, whether this should be something that should be encouraged in settings where this is not so valued and what their expectations are.</p>", "child_count": 0, "closed": false, "tree_id": 58, "revision_count": 1, "parent": null, "views": 333, "deleted": false, "answer_count": 8, "touch_date": "2011-11-24 14:49:29", "slug": "how-important-is-it-to-belong-to-a-professional-society-in-computational-biology", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [32, 109, 110, 111], "lastedit_user": 63}}, {"pk": 233, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 18:28:21", "lft": 2, "post_type": 109787, "score": 1, "title": "A: How Important is it to belong to a Professional Society in Computational Biology?", "unanswered": false, "content": "I think the benefits of being in a professional society do not readily lend themselves to quantification. \n\nThe positives are more about personal fulfillment, a sense of belonging, better understanding of the field and building interpersonal relationships that in the end may strongly shape one's future.", "comment_count": 0, "html": "<p>I think the benefits of being in a professional society do not readily lend themselves to quantification. </p>\n<p>The positives are more about personal fulfillment, a sense of belonging, better understanding of the field and building interpersonal relationships that in the end may strongly shape one's future.</p>", "child_count": 0, "closed": false, "tree_id": 58, "revision_count": 1, "parent": 232, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:19", "slug": "a-how-important-is-it-to-belong-to-a-professional-society-in-computational-biology", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 234, "model": "server.post", "fields": {"rght": 5, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 21:51:44", "lft": 4, "post_type": 109787, "score": 5, "title": "A: How Important is it to belong to a Professional Society in Computational Biology?", "unanswered": false, "content": "This is a very interesting question.  I think today, and especially in a modern field like bioinformatics, the idea of belonging to a professional society is almost quaint.\n\nHaving once been a bench scientist, the only reasons I could ever ascertain to belonging to a society were that\n\n 1. They might pay your fees to go to a conference if they fund this kind of thing\n 2. You might get reduced conference fees for certain conferences\n 3. You get a little ribbon on your badge to let everyone know at the conference you're a member\n\nCertainly, from my current position - I have never felt that belonging to a professional body distinguished my CV or resume from any other candidate.  As someone who hires, it would not make a jot of difference to me if you were a member of a society or not.\n\nI would go so far as to suggest that even the networking aspects of a society are largely oversold in the wake of the professional relationships I build over Twitter, LinkedIn or FriendFeed.  Whether or not I am a member of a professional organisation would not have any bearing on which conferences I attended, or who I spoke to at them.\n\n", "comment_count": 0, "html": "<p>This is a very interesting question.  I think today, and especially in a modern field like bioinformatics, the idea of belonging to a professional society is almost quaint.</p>\n<p>Having once been a bench scientist, the only reasons I could ever ascertain to belonging to a society were that</p>\n<ol>\n<li>They might pay your fees to go to a conference if they fund this kind of thing</li>\n<li>You might get reduced conference fees for certain conferences</li>\n<li>You get a little ribbon on your badge to let everyone know at the conference you're a member</li>\n</ol>\n<p>Certainly, from my current position - I have never felt that belonging to a professional body distinguished my CV or resume from any other candidate.  As someone who hires, it would not make a jot of difference to me if you were a member of a society or not.</p>\n<p>I would go so far as to suggest that even the networking aspects of a society are largely oversold in the wake of the professional relationships I build over Twitter, LinkedIn or FriendFeed.  Whether or not I am a member of a professional organisation would not have any bearing on which conferences I attended, or who I spoke to at them.</p>", "child_count": 0, "closed": false, "tree_id": 58, "revision_count": 1, "parent": 232, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-important-is-it-to-belong-to-a-professional-society-in-computational-biology", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 235, "model": "server.post", "fields": {"rght": 7, "author": 115, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 22:08:45", "lft": 6, "post_type": 109787, "score": 4, "title": "A: Pfam based functional annotaion", "unanswered": false, "content": "I think the Pfam approach may return something useful, but you need to be careful about how you interpret your results. Pfam is primarily a tool to assign sequences to protein families. It also does a good job of recognizing functional domains. It provides information about the usual function of the domains/family members- but I do not think it should be viewed as a tool to assign function directly, and I think the Pfam curators would agree with me. It is making an assignment based on sequence similarity, and is inferring structural and functional similarity. These inferences may or may not be correct. You have several risks you need to keep in mind. Two biggies that pop out too me are:\n\n1. Your sequences are all shorter than most protein domains. So you may get false negatives where if you had the full sequence, you might have hit a domain, but because you only have a fragment, the similarity is too weak to produce a hit.\n\n2. You might get false positives because you match a domain but have a few key residues in your sequence mutated, and therefore the protein from which your sequence was derived actually does not perform the function assigned to that domain in Pfam. \n\nYou asked about direct experience. Mine is roughly 5 years old now, but it was that Pfam was one of the best tools to identify functional domains, and was a good way to annotate sequences as long as I kept its limitations in mind. However, I was working with full length sequences, not fragments. My gut instinct is that it will not perform as well on small fragments, but I have no direct experience to back me up- just my knowledge that your fragments are shorter than most domains.\n\nBack when I did function assignment for a living, I considered it very risky to rely on one tool to make an assignment. And I never considered any assignment anything more than a hypothesis that could then be tested in the lab.", "comment_count": 0, "html": "<p>I think the Pfam approach may return something useful, but you need to be careful about how you interpret your results. Pfam is primarily a tool to assign sequences to protein families. It also does a good job of recognizing functional domains. It provides information about the usual function of the domains/family members- but I do not think it should be viewed as a tool to assign function directly, and I think the Pfam curators would agree with me. It is making an assignment based on sequence similarity, and is inferring structural and functional similarity. These inferences may or may not be correct. You have several risks you need to keep in mind. Two biggies that pop out too me are:</p>\n<ol>\n<li>\n<p>Your sequences are all shorter than most protein domains. So you may get false negatives where if you had the full sequence, you might have hit a domain, but because you only have a fragment, the similarity is too weak to produce a hit.</p>\n</li>\n<li>\n<p>You might get false positives because you match a domain but have a few key residues in your sequence mutated, and therefore the protein from which your sequence was derived actually does not perform the function assigned to that domain in Pfam. </p>\n</li>\n</ol>\n<p>You asked about direct experience. Mine is roughly 5 years old now, but it was that Pfam was one of the best tools to identify functional domains, and was a good way to annotate sequences as long as I kept its limitations in mind. However, I was working with full length sequences, not fragments. My gut instinct is that it will not perform as well on small fragments, but I have no direct experience to back me up- just my knowledge that your fragments are shorter than most domains.</p>\n<p>Back when I did function assignment for a living, I considered it very risky to rely on one tool to make an assignment. And I never considered any assignment anything more than a hypothesis that could then be tested in the lab.</p>", "child_count": 0, "closed": false, "tree_id": 35, "revision_count": 1, "parent": 128, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-pfam-based-functional-annotaion", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 115}}, {"pk": 236, "model": "server.post", "fields": {"rght": 7, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 22:46:36", "lft": 6, "post_type": 109787, "score": 2, "title": "A: How Important is it to belong to a Professional Society in Computational Biology?", "unanswered": false, "content": "From the practical point of view, I heard when you apply for a green card in US as extraordinary/outstanding scientist, being a member of professional societies gives you some additional \"points\".\n\nAnother example. AACR (The American Association for Cancer Research) became to large, that it accepts papers/posters for a conference only from its members. If you are not, you have to find a full member to be a \"sponsor\" for your paper.\n\nAs for many societies, members usually get early event notices (I get them by e-mail all the time anyway), some free publications (sometime just another junk), fee reduction (do you care if your lab is paying? :). ", "comment_count": 0, "html": "<p>From the practical point of view, I heard when you apply for a green card in US as extraordinary/outstanding scientist, being a member of professional societies gives you some additional \"points\".</p>\n<p>Another example. AACR (The American Association for Cancer Research) became to large, that it accepts papers/posters for a conference only from its members. If you are not, you have to find a full member to be a \"sponsor\" for your paper.</p>\n<p>As for many societies, members usually get early event notices (I get them by e-mail all the time anyway), some free publications (sometime just another junk), fee reduction (do you care if your lab is paying? :). </p>", "child_count": 0, "closed": false, "tree_id": 58, "revision_count": 1, "parent": 232, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:20", "slug": "a-how-important-is-it-to-belong-to-a-professional-society-in-computational-biology", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 237, "model": "server.post", "fields": {"rght": 11, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 23:29:23", "lft": 8, "post_type": 109787, "score": 6, "title": "A: How Important is it to belong to a Professional Society in Computational Biology?", "unanswered": false, "content": "The sole benefit that I have gained from my two experiences with society membership was a discounted rate for conference registration.  For the remainder of my subscription, I received no information via email or any other means apart from a reminder to renew (in one case, nothing in the other case).\n\nI'd agree with Daniel, above; the \"informal\" connections that I've made via online social networks have been far more valuable to me than any formal society.", "comment_count": 1, "html": "<p>The sole benefit that I have gained from my two experiences with society membership was a discounted rate for conference registration.  For the remainder of my subscription, I received no information via email or any other means apart from a reminder to renew (in one case, nothing in the other case).</p>\n<p>I'd agree with Daniel, above; the \"informal\" connections that I've made via online social networks have been far more valuable to me than any formal society.</p>", "child_count": 0, "closed": false, "tree_id": 58, "revision_count": 1, "parent": 232, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-important-is-it-to-belong-to-a-professional-society-in-computational-biology", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 238, "model": "server.post", "fields": {"rght": 26, "author": 89, "answer_accepted": false, "tag_string": "gene protein", "creation_date": "2010-03-09 02:39:53", "lft": 1, "post_type": 164033, "score": 2, "title": "How to determine if a gene is active from expression data", "unanswered": false, "content": "I have RMA (Robust Multi-Array) scores for the different genes (and their isoforms) on the Affymetrix chip. I want to know which of these genes are \"active\" (or in other words: are likely to produce enough protein products to have an effect). I'm not interested in them being differentially expressed or X-fold over- or under-expressed. All I want is the classification of them being likely \"on\" or \"off\". \n\nSo far I log-transformed (basis 10) the RMA score and centered them (subtracted the median). I called all genes which had a transformed score <0 as being inactive and scores >0 as being active. \n\nDoes anyone have a better methodology ?\n\n", "comment_count": 0, "html": "<p>I have RMA (Robust Multi-Array) scores for the different genes (and their isoforms) on the Affymetrix chip. I want to know which of these genes are \"active\" (or in other words: are likely to produce enough protein products to have an effect). I'm not interested in them being differentially expressed or X-fold over- or under-expressed. All I want is the classification of them being likely \"on\" or \"off\". </p>\n<p>So far I log-transformed (basis 10) the RMA score and centered them (subtracted the median). I called all genes which had a transformed score &lt;0 as being inactive and scores &gt;0 as being active. </p>\n<p>Does anyone have a better methodology ?</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 2, "parent": null, "views": 516, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:29", "slug": "how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [36, 41], "lastedit_user": 25}}, {"pk": 239, "model": "server.post", "fields": {"rght": 7, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 05:15:16", "lft": 2, "post_type": 109787, "score": 4, "title": "A: How to determine if a gene is active from expression data", "unanswered": false, "content": "You're right in thinking that your methodology isn't a very good representation of the system. mRNAs (and their protein products) have a huge dynamic range. Some are going to be expressed constantly at extremely low levels, and at the other extremes, you'll have genes that are highly expressed, but only for a short period of time.  Taking the median level as the dividing line between on and off is going to give you huge numbers of false negatives (genes that are actually being transcribed and translated, but that you'll classify as \"off\")\n\nI'd look at what the background noise level is, then run some stats to determine which probes give you signal significantly above that level. Any gene meeting that criteria should probably be considered \"on\". I suspect that may not divide the set as nicely as you'd hope, though.\n\nMaybe if you tell us more about what exactly you're trying to do, we can offer more constructive advice.", "comment_count": 2, "html": "<p>You're right in thinking that your methodology isn't a very good representation of the system. mRNAs (and their protein products) have a huge dynamic range. Some are going to be expressed constantly at extremely low levels, and at the other extremes, you'll have genes that are highly expressed, but only for a short period of time.  Taking the median level as the dividing line between on and off is going to give you huge numbers of false negatives (genes that are actually being transcribed and translated, but that you'll classify as \"off\")</p>\n<p>I'd look at what the background noise level is, then run some stats to determine which probes give you signal significantly above that level. Any gene meeting that criteria should probably be considered \"on\". I suspect that may not divide the set as nicely as you'd hope, though.</p>\n<p>Maybe if you tell us more about what exactly you're trying to do, we can offer more constructive advice.</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 1, "parent": 238, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:21", "slug": "a-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 240, "model": "server.post", "fields": {"rght": 15, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 05:20:42", "lft": 14, "post_type": 109787, "score": 3, "title": "A: What methods do you use for short read mapping?", "unanswered": false, "content": "It's worth noting that a lot of people also use [Novoalign][1]\n\n\n  [1]: http://www.novocraft.com/index.html", "comment_count": 0, "html": "<p>It's worth noting that a lot of people also use <a href=\"http://www.novocraft.com/index.html\">Novoalign</a></p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 1, "parent": 137, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 241, "model": "server.post", "fields": {"rght": 19, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 12:12:40", "lft": 18, "post_type": 109787, "score": 1, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "I use a combination of things for different purposes, including C, R, Perl and Delphi. For anything to run on windows, whether command-line or with a nice-to-use UI for less technical users, **Delphi** still rocks.", "comment_count": 0, "html": "<p>I use a combination of things for different purposes, including C, R, Perl and Delphi. For anything to run on windows, whether command-line or with a nice-to-use UI for less technical users, <strong>Delphi</strong> still rocks.</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:20", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 118}}, {"pk": 242, "model": "server.post", "fields": {"rght": 9, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 12:59:45", "lft": 8, "post_type": 109787, "score": 4, "title": "A: Has enhancer and transcription factor binding site prediction already been made redundant?", "unanswered": false, "content": "In addition to what's already been said, I'd like to add that even if these data did completely abolish the need to predict TF binding sites (which I'm not entirely sure about), there are still many cases - **and many organisms** - where such data aren't available, implying that there's still a niche for computational approaches.", "comment_count": 0, "html": "<p>In addition to what's already been said, I'd like to add that even if these data did completely abolish the need to predict TF binding sites (which I'm not entirely sure about), there are still many cases - <strong>and many organisms</strong> - where such data aren't available, implying that there's still a niche for computational approaches.</p>", "child_count": 0, "closed": false, "tree_id": 53, "revision_count": 1, "parent": 201, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-has-enhancer-and-transcription-factor-binding-site-prediction-already-been-made-redundant", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 118}}, {"pk": 243, "model": "server.post", "fields": {"rght": 11, "author": 90, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 15:44:54", "lft": 10, "post_type": 109787, "score": 3, "title": "A: Has enhancer and transcription factor binding site prediction already been made redundant?", "unanswered": false, "content": "We still have a long way to go when it comes to enhancer discovery. The fact that a genomic region comes out as DNAse I hypersensitive in a certain tissue does not necessarily mean it is an enhancer region in that tissue. Here, I think the DNAse I hypersensitivity (and FAIRE) data should be regarded as a necessary input to improved enhancer prediction algorithms, rather than something to replace them. (In fact I think there are very few enhancer prediction algorithms out there, so the help is sorely needed!)\n\nSimilarly, I don't think DNAse or FAIRE *in themselves* say much about transcription factor binding, although they can be very informative in combination with knowledge of the TF motif (or so I've heard). ChIP-seq, on the other hand, does give pretty solid information on TF binding which I agree would more or less supersede computational predictions in the relevant tissue in the given organism. As others have pointed out in this thread, though, there are many organisms and/or tissues for which we won't have ChIP-seq within a foreseeable time, and for those cases (and others) we can hopefully use existing ChIP-seq data to refine computational models of TF binding. So I would regard ChIP-seq data as something that helps us refine our understanding of TF binding, including the prediction of binding events in various systems.", "comment_count": 0, "html": "<p>We still have a long way to go when it comes to enhancer discovery. The fact that a genomic region comes out as DNAse I hypersensitive in a certain tissue does not necessarily mean it is an enhancer region in that tissue. Here, I think the DNAse I hypersensitivity (and FAIRE) data should be regarded as a necessary input to improved enhancer prediction algorithms, rather than something to replace them. (In fact I think there are very few enhancer prediction algorithms out there, so the help is sorely needed!)</p>\n<p>Similarly, I don't think DNAse or FAIRE <em>in themselves</em> say much about transcription factor binding, although they can be very informative in combination with knowledge of the TF motif (or so I've heard). ChIP-seq, on the other hand, does give pretty solid information on TF binding which I agree would more or less supersede computational predictions in the relevant tissue in the given organism. As others have pointed out in this thread, though, there are many organisms and/or tissues for which we won't have ChIP-seq within a foreseeable time, and for those cases (and others) we can hopefully use existing ChIP-seq data to refine computational models of TF binding. So I would regard ChIP-seq data as something that helps us refine our understanding of TF binding, including the prediction of binding events in various systems.</p>", "child_count": 0, "closed": false, "tree_id": 53, "revision_count": 1, "parent": 201, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-has-enhancer-and-transcription-factor-binding-site-prediction-already-been-made-redundant", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 90}}, {"pk": 244, "model": "server.post", "fields": {"rght": 21, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 17:57:12", "lft": 20, "post_type": 109787, "score": 2, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "Just my two cents and since nobody mentioned yet, I'm using **MATLAB**. Yes, it's commercial and expensive. It might be behind **R/Bioconductor** in amount of contributed algorithms (this is why I sometime have to use R as well). But the environment is very friendly for fast development, figures are great, and making GUIs is pretty easy. Many useful for bioinformatician toolboxes, like Statistics, Bioinformatics, Optimization. Someone may find SimBiology cool (although I haven't used it). As others mentioned **Perl** is still rules for text processing and workflows, although I agree with giovanni on its problems.", "comment_count": 0, "html": "<p>Just my two cents and since nobody mentioned yet, I'm using <strong>MATLAB</strong>. Yes, it's commercial and expensive. It might be behind <strong>R/Bioconductor</strong> in amount of contributed algorithms (this is why I sometime have to use R as well). But the environment is very friendly for fast development, figures are great, and making GUIs is pretty easy. Many useful for bioinformatician toolboxes, like Statistics, Bioinformatics, Optimization. Someone may find SimBiology cool (although I haven't used it). As others mentioned <strong>Perl</strong> is still rules for text processing and workflows, although I agree with giovanni on its problems.</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:20", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 245, "model": "server.post", "fields": {"rght": 22, "author": 9, "answer_accepted": false, "tag_string": "gene enrichment tool go", "creation_date": "2010-03-09 18:13:46", "lft": 1, "post_type": 164033, "score": 5, "title": "Tools to find gene ontology term enrichment", "unanswered": false, "content": "I need to make a recommendation to people working in a wet-lab looking for an easy to use tool that does GO term enrichment determination. For those unfamiliar with the concept it means that given a list of gene names they want to find out which gene ontology terms are present in numbers that are above random chance.\n\nThere is a huge [list here][1] yet a random sampling of the tools mentioned there has lead me to many non-working sites. Other tools seem out of date or just not reliable.\n\nWhat tool do you use to solve this problem?\n\nThanks.\n\n  [1]: http://www.geneontology.org/GO.tools.microarray.shtml", "comment_count": 0, "html": "<p>I need to make a recommendation to people working in a wet-lab looking for an easy to use tool that does GO term enrichment determination. For those unfamiliar with the concept it means that given a list of gene names they want to find out which gene ontology terms are present in numbers that are above random chance.</p>\n<p>There is a huge <a href=\"http://www.geneontology.org/GO.tools.microarray.shtml\">list here</a> yet a random sampling of the tools mentioned there has lead me to many non-working sites. Other tools seem out of date or just not reliable.</p>\n<p>What tool do you use to solve this problem?</p>\n<p>Thanks.</p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 3, "parent": null, "views": 1992, "deleted": false, "answer_count": 16, "touch_date": "2011-11-24 14:49:26", "slug": "tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [36, 81, 106, 190], "lastedit_user": 215}}, {"pk": 246, "model": "server.post", "fields": {"rght": 7, "author": 57, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 18:55:53", "lft": 2, "post_type": 109787, "score": 7, "title": "A: Tools to find gene ontology term enrichment", "unanswered": false, "content": "I prefer to use DAVID ( http://david.abcc.ncifcrf.gov/ ) but id be interested to hear what other people like.  There are also R packages available through Bioconductor (GOstats; http://www.bioconductor.org/packages/2.3/bioc/html/GOstats.html) that can do enrichment determination, but I am less familiar with those, and you need a good working knowlege of R to use these.\n", "comment_count": 2, "html": "<p>I prefer to use DAVID ( http://david.abcc.ncifcrf.gov/ ) but id be interested to hear what other people like.  There are also R packages available through Bioconductor (GOstats; http://www.bioconductor.org/packages/2.3/bioc/html/GOstats.html) that can do enrichment determination, but I am less familiar with those, and you need a good working knowlege of R to use these.</p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 1, "parent": 245, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:25", "slug": "a-tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 57}}, {"pk": 247, "model": "server.post", "fields": {"rght": 5, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 19:35:32", "lft": 4, "post_type": 109787, "score": 1, "title": "A: Tools to find gene ontology term enrichment", "unanswered": false, "content": "You can try one of the tools at [babelomics][1], in particular FatiGO; or as an alternative, you can use the same AmiGO [Term Enrichment tool][2].\n\nHowever, be careful when using GeneOntology: it is a very active and supported project, so they make big enhancements between two releases. If you look at thei bug tracker, there are at least 8-10 changes to geneontology terms every day. So, annotate the version and date of GeneOntology if you want your experiment to be reproducible.\n\n\n  [1]: http://babelomics.bioinfo.cipf.es/\n  [2]: http://amigo.geneontology.org/cgi-bin/amigo/term_enrichment", "comment_count": 0, "html": "<p>You can try one of the tools at <a href=\"http://babelomics.bioinfo.cipf.es/\">babelomics</a>, in particular FatiGO; or as an alternative, you can use the same AmiGO <a href=\"http://amigo.geneontology.org/cgi-bin/amigo/term_enrichment\">Term Enrichment tool</a>.</p>\n<p>However, be careful when using GeneOntology: it is a very active and supported project, so they make big enhancements between two releases. If you look at thei bug tracker, there are at least 8-10 changes to geneontology terms every day. So, annotate the version and date of GeneOntology if you want your experiment to be reproducible.</p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 1, "parent": 245, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:20", "slug": "a-tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 248, "model": "server.post", "fields": {"rght": 15, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 20:15:02", "lft": 4, "post_type": 109787, "score": 5, "title": "A: How to determine if a gene is active from expression data", "unanswered": false, "content": "I would suggest the following question instead of the one you're asking:\n\n**Can you actually determine if a gene is \"active\" (i.e. translated into protein) from [gene] expression data?**\n\nAnd I'll point you towards people who have published papers about it:\n\n  * [Correlation between protein and mRNA abundance in yeast.][1]\n  * [Correlation of mRNA and protein levels: Cell type-specific gene expression of cluster designation antigens in the prostate][2]\n  * [Comparing protein abundance and mRNA expression levels on a genomic scale][3]\n  * [Insights into the relation between mrna and protein expression patterns: ii. Experimental observations in Escherichia coli][4]\n\nThese are just a few papers that seem critical towards such a correlation. That is not to say that there is no good correlation for any gene. But I would be very surprised if you can make a general rule about it without checking in every cell type, tissue type and for every gene to see if such a correlation is or not acceptable.\n\nNow, if you do a Pubmed search for the terms \"[correlation mRNA protein][5]\", you will find many papers that check for such correlations, but mostly for specific genes in specific tissues (often for cancer diagnostics purposes).\n\nIf you do find papers that state such correlations, genome wide using microarray data, I'd be highly suspicious of that paper.\n\nSo, obviously, you can not set \"a\" cut-off for determining this. My personal experience tells me that you can have gene transcription with ***no*** protein expression following it... Unfortunately, I have not published it yet :(\n\n\n  [1]: http://www.ncbi.nlm.nih.gov/pubmed/10022859\n  [2]: http://www.biomedcentral.com/1471-2164/9/246\n  [3]: http://genomebiology.com/2003/4/9/117\n  [4]: http://www3.interscience.wiley.com/journal/106577988/abstract?CRETRY=1&SRETRY=0\n  [5]: http://www.ncbi.nlm.nih.gov/pubmed?term=correlation+mrna+protein", "comment_count": 5, "html": "<p>I would suggest the following question instead of the one you're asking:</p>\n<p><strong>Can you actually determine if a gene is \"active\" (i.e. translated into protein) from [gene] expression data?</strong></p>\n<p>And I'll point you towards people who have published papers about it:</p>\n<ul>\n<li><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/10022859\">Correlation between protein and mRNA abundance in yeast.</a></li>\n<li><a href=\"http://www.biomedcentral.com/1471-2164/9/246\">Correlation of mRNA and protein levels: Cell type-specific gene expression of cluster designation antigens in the prostate</a></li>\n<li><a href=\"http://genomebiology.com/2003/4/9/117\">Comparing protein abundance and mRNA expression levels on a genomic scale</a></li>\n<li><a href=\"http://www3.interscience.wiley.com/journal/106577988/abstract?CRETRY=1&amp;SRETRY=0\">Insights into the relation between mrna and protein expression patterns: ii. Experimental observations in Escherichia coli</a></li>\n</ul>\n<p>These are just a few papers that seem critical towards such a correlation. That is not to say that there is no good correlation for any gene. But I would be very surprised if you can make a general rule about it without checking in every cell type, tissue type and for every gene to see if such a correlation is or not acceptable.</p>\n<p>Now, if you do a Pubmed search for the terms \"<a href=\"http://www.ncbi.nlm.nih.gov/pubmed?term=correlation+mrna+protein\">correlation mRNA protein</a>\", you will find many papers that check for such correlations, but mostly for specific genes in specific tissues (often for cancer diagnostics purposes).</p>\n<p>If you do find papers that state such correlations, genome wide using microarray data, I'd be highly suspicious of that paper.</p>\n<p>So, obviously, you can not set \"a\" cut-off for determining this. My personal experience tells me that you can have gene transcription with <strong><em>no</em></strong> protein expression following it... Unfortunately, I have not published it yet :(</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 1, "parent": 238, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 249, "model": "server.post", "fields": {"rght": 9, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 22:41:33", "lft": 4, "post_type": 109787, "score": 2, "title": "A: Hierarchical Clustering, Cluster Heat Maps in Java", "unanswered": false, "content": "[GenePilot][1]\u2122 is a Java-based Analysis suite, which provides a MicroArray Analysis capabilities. \n\nYou can export your results as Cluster Heatmaps. They give the following example of a local heatmap of the currently selected cluster along with the top dendigram (if applicable), column information, average thumbnail, row info and Gene Ontology Information (if applicable):\n\n![alt text][2]\n\n\n  [1]: http://www.genepilot.com/index.html\n  [2]: http://www.genepilot.com/assets/gifs/HC_Select_right.gif", "comment_count": 2, "html": "<p><a href=\"http://www.genepilot.com/index.html\">GenePilot</a>\u2122 is a Java-based Analysis suite, which provides a MicroArray Analysis capabilities. </p>\n<p>You can export your results as Cluster Heatmaps. They give the following example of a local heatmap of the currently selected cluster along with the top dendigram (if applicable), column information, average thumbnail, row info and Gene Ontology Information (if applicable):</p>\n<p><img alt=\"alt text\" src=\"http://www.genepilot.com/assets/gifs/HC_Select_right.gif\" /></p>", "child_count": 0, "closed": false, "tree_id": 57, "revision_count": 1, "parent": 228, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-hierarchical-clustering-cluster-heat-maps-in-java", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 250, "model": "server.post", "fields": {"rght": 7, "author": 89, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 23:15:00", "lft": 6, "post_type": 109787, "score": 2, "title": "A: Tools to find gene ontology term enrichment", "unanswered": false, "content": "Another option is GONOME (http://gonome.imb.uq.edu.au/), which finds the over- and under-represented\nGO terms for a given set of genomic positions.", "comment_count": 0, "html": "<p>Another option is GONOME (http://gonome.imb.uq.edu.au/), which finds the over- and under-represented\nGO terms for a given set of genomic positions.</p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 1, "parent": 245, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:20", "slug": "a-tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 89}}, {"pk": 251, "model": "server.post", "fields": {"rght": 4, "author": 70, "answer_accepted": false, "tag_string": "metabolomics chemoinformatics java open", "creation_date": "2010-03-10 11:57:11", "lft": 1, "post_type": 164033, "score": 2, "title": "What open source Java library can I use to query online, free databases in which pathways a metabolite is participating?", "unanswered": false, "content": "What opensource Java solutions are available to query online pathway databases like [KEGG][1] (or [BioMeta][2]), [MACiE][3] and [Brenda][4] for the pathways a certain metabolite is available, for example, based on the [InChI][5]? Preferably, the library would have a good data model for the pathway information, possibly [SMBL][6] or [RDF][7]-based. What would the code look like to make such a query?\n\n\n  [1]: http://www.genome.jp/kegg/\n  [2]: http://biometa.cmbi.ru.nl/\n  [3]: http://www.ebi.ac.uk/thornton-srv/databases/MACiE/\n  [4]: http://www.brenda-enzymes.org/\n  [5]: http://en.wikipedia.org/wiki/International_Chemical_Identifier\n  [6]: http://sbml.org/\n  [7]: http://en.wikipedia.org/wiki/Resource_description_framework", "comment_count": 0, "html": "<p>What opensource Java solutions are available to query online pathway databases like <a href=\"http://www.genome.jp/kegg/\">KEGG</a> (or <a href=\"http://biometa.cmbi.ru.nl/\">BioMeta</a>), <a href=\"http://www.ebi.ac.uk/thornton-srv/databases/MACiE/\">MACiE</a> and <a href=\"http://www.brenda-enzymes.org/\">Brenda</a> for the pathways a certain metabolite is available, for example, based on the <a href=\"http://en.wikipedia.org/wiki/International_Chemical_Identifier\">InChI</a>? Preferably, the library would have a good data model for the pathway information, possibly <a href=\"http://sbml.org/\">SMBL</a> or <a href=\"http://en.wikipedia.org/wiki/Resource_description_framework\">RDF</a>-based. What would the code look like to make such a query?</p>", "child_count": 0, "closed": false, "tree_id": 61, "revision_count": 3, "parent": null, "views": 469, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:20", "slug": "what-open-source-java-library-can-i-use-to-query-online-free-databases-in-which-pathways-a-metabolite-is-participating", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [112, 113, 114, 115], "lastedit_user": 313}}, {"pk": 252, "model": "server.post", "fields": {"rght": 3, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-10 15:48:37", "lft": 2, "post_type": 109787, "score": 4, "title": "A: What open source Java library can I use to query online, free databases in which pathways a metabolite is participating?", "unanswered": false, "content": "There is no explicit Brenda Java-API I know of, but kegg provides [a jar-file][1] which I recommend you ***don't*** use. \nThere is a solution anyhow, I have never used MACiE btw.\nBoth database provide a standard compliant web-services interface over SOAP messages.\nWeb-services are a standardized way of language and system independent programmatic communication. \n\n[KEGG soap: http://www.genome.jp/kegg/soap/][2]\n\n[Brenda SOAP: http://www.brenda-enzymes.org/soap/][3]\n\nBoth services have a [WSDL file][4] to describe the interface.\n\nThis description can be used to automatically generate client code using for example [Axis2 a free open-source][5] implementation of the [SOAP protocol][6]. IMHO this is the way to go.\nSo you will use Axis2 wsdl2code (or the Axis2 Eclipse-plugin) to generate exactly the free-open-source Java API you need.\n\n\n----------\n A little edit and some issues from myself after having a look at the KEGG soap interface:\n\nAs often, KEGG is a bit misbehaving, so what I answered above is the theory, it is true *in principle*, but....\n\n1. The databinding (mapping of xml-schema types to Java types) that seems to work is\n**xmlbeans**. The **adb** databinding gives an error. This is due to non-standard use of some\nstructures in the wsdl. \n\n2. Below is some source code demonstrating how an axis2 interface with xmlbeans data binding can be used. The only glitch is I cannot tell, how to set or read the *ArrayOfstring*. This glitch is IMHO KEGG's fault because they did only test with Axis1.\n\n3. Alternatives if nobody knows a better solution, try Axis1 with [the jar-file][7] from KEGG or try the [Brenda WSDL][8].\n\nExample use of Axis2/xmlbeans generated classes. The principle is the same for Brenda:\n\n  \n\n     package keggtest;\n            \n       import java.rmi.RemoteException;\n            \n       import kegg.soap.ArrayOfstring;\n       import kegg.soap.GetPathwaysByGenesDocument;\n       import kegg.soap.GetPathwaysByGenesResponseDocument;\n       import kegg.soap.KEGGStub;\n       import kegg.soap.GetPathwaysByGenesDocument.GetPathwaysByGenes;\n            \n       import org.apache.axis2.AxisFault;\n    \n    public class keggclient {\n    \n    \t/**\n    \t * @param args\n    \t */\n    \tpublic static void main(String[] args) {\n    \n    \t\ttry {\n    \t\t\tKEGGStub stub = new KEGGStub(\"http://soap.genome.jp/KEGG.wsdl\");\n    \n    \t\t\tGetPathwaysByGenes getPathwaysByGenes = GetPathwaysByGenes.Factory\n    \t\t\t\t\t.newInstance();\n    \t\t\tArrayOfstring genesIdList = ArrayOfstring.Factory.newInstance();\n    \t\t\t// add items to ArrayOfstring, but how?\n    \t\t\tgetPathwaysByGenes.setGenesIdList(genesIdList);\n    \t\t\tGetPathwaysByGenesDocument get_pathways_by_genes = GetPathwaysByGenesDocument.Factory\n    \t\t\t\t\t.newInstance();\n    \t\t\tget_pathways_by_genes.setGetPathwaysByGenes(getPathwaysByGenes);\n    \t\t\ttry {\n    \t\t\t\tGetPathwaysByGenesResponseDocument res = stub\n    \t\t\t\t\t\t.get_pathways_by_genes(get_pathways_by_genes);\n    \t\t\t\tSystem.err.println(res.getGetPathwaysByGenesResponse()\n    \t\t\t\t\t\t.getReturn());\n    \t\t\t} catch (RemoteException e) {\n    \t\t\t\t// TODO Auto-generated catch block\n    \t\t\t\te.printStackTrace();\n    \t\t\t}\n    \n    \t\t} catch (AxisFault e) {\n    \t\t\t// TODO Auto-generated catch block\n    \n    \t\t\te.printStackTrace();\n    \t\t}\n    \n    \t}\n    }\n\n\n----------\nAnd another edit, after trying the Brenda WSDL with axis2 wsdl2code, the result is not \nvery promising:\n...\nSEVERE: The binding operation getKeggPathway is RPC/literal. The message parts for this operation must use the type attribute as specificed by WS-I Basic Profile specification (4.4.1).  Message part, ecNumber, violatesthis rule.  Please remove the element attribute and use the type attribute.\n...\n\nSo, if somebody has a better answer, including asking the service providers to adhere to standards. Apologies for testing after answering.... \n\n\n\n\n\n  [1]: http://www.genome.jp/kegg/soap/support/keggapi.jar\n  [2]: http://www.genome.jp/kegg/soap/\n  [3]: http://www.brenda-enzymes.org/soap/\n  [4]: http://en.wikipedia.org/wiki/Web_Services_Description_Language\n  [5]: http://ws.apache.org/axis2/\n  [6]: http://en.wikipedia.org/wiki/SOAP\n  [7]: http://www.genome.jp/kegg/soap/support/keggapi.jar\n  [8]: http://www.brenda-enzymes.org/soap/brenda.wsdl", "comment_count": 0, "html": "<p>There is no explicit Brenda Java-API I know of, but kegg provides <a href=\"http://www.genome.jp/kegg/soap/support/keggapi.jar\">a jar-file</a> which I recommend you <strong><em>don't</em></strong> use. \nThere is a solution anyhow, I have never used MACiE btw.\nBoth database provide a standard compliant web-services interface over SOAP messages.\nWeb-services are a standardized way of language and system independent programmatic communication. </p>\n<p><a href=\"http://www.genome.jp/kegg/soap/\">KEGG soap: http://www.genome.jp/kegg/soap/</a></p>\n<p><a href=\"http://www.brenda-enzymes.org/soap/\">Brenda SOAP: http://www.brenda-enzymes.org/soap/</a></p>\n<p>Both services have a <a href=\"http://en.wikipedia.org/wiki/Web_Services_Description_Language\">WSDL file</a> to describe the interface.</p>\n<p>This description can be used to automatically generate client code using for example <a href=\"http://ws.apache.org/axis2/\">Axis2 a free open-source</a> implementation of the <a href=\"http://en.wikipedia.org/wiki/SOAP\">SOAP protocol</a>. IMHO this is the way to go.\nSo you will use Axis2 wsdl2code (or the Axis2 Eclipse-plugin) to generate exactly the free-open-source Java API you need.</p>\n<hr />\n<p>A little edit and some issues from myself after having a look at the KEGG soap interface:</p>\n<p>As often, KEGG is a bit misbehaving, so what I answered above is the theory, it is true <em>in principle</em>, but....</p>\n<ol>\n<li>\n<p>The databinding (mapping of xml-schema types to Java types) that seems to work is\n<strong>xmlbeans</strong>. The <strong>adb</strong> databinding gives an error. This is due to non-standard use of some\nstructures in the wsdl. </p>\n</li>\n<li>\n<p>Below is some source code demonstrating how an axis2 interface with xmlbeans data binding can be used. The only glitch is I cannot tell, how to set or read the <em>ArrayOfstring</em>. This glitch is IMHO KEGG's fault because they did only test with Axis1.</p>\n</li>\n<li>\n<p>Alternatives if nobody knows a better solution, try Axis1 with <a href=\"http://www.genome.jp/kegg/soap/support/keggapi.jar\">the jar-file</a> from KEGG or try the <a href=\"http://www.brenda-enzymes.org/soap/brenda.wsdl\">Brenda WSDL</a>.</p>\n</li>\n</ol>\n<p>Example use of Axis2/xmlbeans generated classes. The principle is the same for Brenda:</p>\n<p><div class=\"highlight\"><pre>     <span class=\"nb\">package</span> <span class=\"n\">keggtest</span><span class=\"p\">;</span>\n            \n       <span class=\"nb\">import</span> <span class=\"n\">java</span><span class=\"o\">.</span><span class=\"n\">rmi</span><span class=\"o\">.</span><span class=\"n\">RemoteException</span><span class=\"p\">;</span>\n            \n       <span class=\"nb\">import</span> <span class=\"n\">kegg</span><span class=\"o\">.</span><span class=\"n\">soap</span><span class=\"o\">.</span><span class=\"n\">ArrayOfstring</span><span class=\"p\">;</span>\n       <span class=\"nb\">import</span> <span class=\"n\">kegg</span><span class=\"o\">.</span><span class=\"n\">soap</span><span class=\"o\">.</span><span class=\"n\">GetPathwaysByGenesDocument</span><span class=\"p\">;</span>\n       <span class=\"nb\">import</span> <span class=\"n\">kegg</span><span class=\"o\">.</span><span class=\"n\">soap</span><span class=\"o\">.</span><span class=\"n\">GetPathwaysByGenesResponseDocument</span><span class=\"p\">;</span>\n       <span class=\"nb\">import</span> <span class=\"n\">kegg</span><span class=\"o\">.</span><span class=\"n\">soap</span><span class=\"o\">.</span><span class=\"n\">KEGGStub</span><span class=\"p\">;</span>\n       <span class=\"nb\">import</span> <span class=\"n\">kegg</span><span class=\"o\">.</span><span class=\"n\">soap</span><span class=\"o\">.</span><span class=\"n\">GetPathwaysByGenesDocument</span><span class=\"o\">.</span><span class=\"n\">GetPathwaysByGenes</span><span class=\"p\">;</span>\n            \n       <span class=\"nb\">import</span> <span class=\"n\">org</span><span class=\"o\">.</span><span class=\"n\">apache</span><span class=\"o\">.</span><span class=\"n\">axis2</span><span class=\"o\">.</span><span class=\"n\">AxisFault</span><span class=\"p\">;</span>\n    \n    <span class=\"n\">public</span> <span class=\"n\">class</span> <span class=\"n\">keggclient</span> <span class=\"p\">{</span>\n    \n    \t<span class=\"o\">/**</span>\n    \t <span class=\"o\">*</span> <span class=\"nv\">@param</span> <span class=\"n\">args</span>\n    \t <span class=\"o\">*/</span>\n    \t<span class=\"n\">public</span> <span class=\"n\">static</span> <span class=\"n\">void</span> <span class=\"n\">main</span><span class=\"p\">(</span><span class=\"n\">String</span><span class=\"o\">[]</span> <span class=\"n\">args</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    \n    \t\t<span class=\"n\">try</span> <span class=\"p\">{</span>\n    \t\t\t<span class=\"n\">KEGGStub</span> <span class=\"n\">stub</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"n\">KEGGStub</span><span class=\"p\">(</span><span class=\"s\">&quot;http://soap.genome.jp/KEGG.wsdl&quot;</span><span class=\"p\">);</span>\n    \n    \t\t\t<span class=\"n\">GetPathwaysByGenes</span> <span class=\"n\">getPathwaysByGenes</span> <span class=\"o\">=</span> <span class=\"n\">GetPathwaysByGenes</span><span class=\"o\">.</span><span class=\"n\">Factory</span>\n    \t\t\t\t\t<span class=\"o\">.</span><span class=\"n\">newInstance</span><span class=\"p\">();</span>\n    \t\t\t<span class=\"n\">ArrayOfstring</span> <span class=\"n\">genesIdList</span> <span class=\"o\">=</span> <span class=\"n\">ArrayOfstring</span><span class=\"o\">.</span><span class=\"n\">Factory</span><span class=\"o\">.</span><span class=\"n\">newInstance</span><span class=\"p\">();</span>\n    \t\t\t<span class=\"sr\">//</span> <span class=\"n\">add</span> <span class=\"n\">items</span> <span class=\"n\">to</span> <span class=\"n\">ArrayOfstring</span><span class=\"p\">,</span> <span class=\"n\">but</span> <span class=\"n\">how</span><span class=\"p\">?</span>\n    \t\t\t<span class=\"n\">getPathwaysByGenes</span><span class=\"o\">.</span><span class=\"n\">setGenesIdList</span><span class=\"p\">(</span><span class=\"n\">genesIdList</span><span class=\"p\">);</span>\n    \t\t\t<span class=\"n\">GetPathwaysByGenesDocument</span> <span class=\"n\">get_pathways_by_genes</span> <span class=\"o\">=</span> <span class=\"n\">GetPathwaysByGenesDocument</span><span class=\"o\">.</span><span class=\"n\">Factory</span>\n    \t\t\t\t\t<span class=\"o\">.</span><span class=\"n\">newInstance</span><span class=\"p\">();</span>\n    \t\t\t<span class=\"n\">get_pathways_by_genes</span><span class=\"o\">.</span><span class=\"n\">setGetPathwaysByGenes</span><span class=\"p\">(</span><span class=\"n\">getPathwaysByGenes</span><span class=\"p\">);</span>\n    \t\t\t<span class=\"n\">try</span> <span class=\"p\">{</span>\n    \t\t\t\t<span class=\"n\">GetPathwaysByGenesResponseDocument</span> <span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">stub</span>\n    \t\t\t\t\t\t<span class=\"o\">.</span><span class=\"n\">get_pathways_by_genes</span><span class=\"p\">(</span><span class=\"n\">get_pathways_by_genes</span><span class=\"p\">);</span>\n    \t\t\t\t<span class=\"n\">System</span><span class=\"o\">.</span><span class=\"n\">err</span><span class=\"o\">.</span><span class=\"n\">println</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"o\">.</span><span class=\"n\">getGetPathwaysByGenesResponse</span><span class=\"p\">()</span>\n    \t\t\t\t\t\t<span class=\"o\">.</span><span class=\"n\">getReturn</span><span class=\"p\">());</span>\n    \t\t\t<span class=\"p\">}</span> <span class=\"n\">catch</span> <span class=\"p\">(</span><span class=\"n\">RemoteException</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    \t\t\t\t<span class=\"sr\">//</span> <span class=\"n\">TODO</span> <span class=\"n\">Auto</span><span class=\"o\">-</span><span class=\"n\">generated</span> <span class=\"n\">catch</span> <span class=\"n\">block</span>\n    \t\t\t\t<span class=\"n\">e</span><span class=\"o\">.</span><span class=\"n\">printStackTrace</span><span class=\"p\">();</span>\n    \t\t\t<span class=\"p\">}</span>\n    \n    \t\t<span class=\"p\">}</span> <span class=\"n\">catch</span> <span class=\"p\">(</span><span class=\"n\">AxisFault</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    \t\t\t<span class=\"sr\">//</span> <span class=\"n\">TODO</span> <span class=\"n\">Auto</span><span class=\"o\">-</span><span class=\"n\">generated</span> <span class=\"n\">catch</span> <span class=\"n\">block</span>\n    \n    \t\t\t<span class=\"n\">e</span><span class=\"o\">.</span><span class=\"n\">printStackTrace</span><span class=\"p\">();</span>\n    \t\t<span class=\"p\">}</span>\n    \n    \t<span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n</pre></div>\n</p>\n<hr />\n<p>And another edit, after trying the Brenda WSDL with axis2 wsdl2code, the result is not \nvery promising:\n...\nSEVERE: The binding operation getKeggPathway is RPC/literal. The message parts for this operation must use the type attribute as specificed by WS-I Basic Profile specification (4.4.1).  Message part, ecNumber, violatesthis rule.  Please remove the element attribute and use the type attribute.\n...</p>\n<p>So, if somebody has a better answer, including asking the service providers to adhere to standards. Apologies for testing after answering.... </p>", "child_count": 0, "closed": false, "tree_id": 61, "revision_count": 3, "parent": 251, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-open-source-java-library-can-i-use-to-query-online-free-databases-in-which-pathways-a-metabolite-is-participating", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 54}}, {"pk": 253, "model": "server.post", "fields": {"rght": 9, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-10 16:24:01", "lft": 8, "post_type": 109787, "score": 3, "title": "A: Tools to find gene ontology term enrichment", "unanswered": false, "content": "it's very much in progress, but a colleague and I (mostly him) have been working on this for python:\nhttp://github.com/tanghaibao/goatools/\n\nit has a command-line script to find terms that are enriched in a study group. it reports p-value for various multiple testing corrections as well as the false discovery rate.\n\nIt can also be used to plot the DAG of a particular GO term. ", "comment_count": 0, "html": "<p>it's very much in progress, but a colleague and I (mostly him) have been working on this for python:\nhttp://github.com/tanghaibao/goatools/</p>\n<p>it has a command-line script to find terms that are enriched in a study group. it reports p-value for various multiple testing corrections as well as the false discovery rate.</p>\n<p>It can also be used to plot the DAG of a particular GO term. </p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 1, "parent": 245, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:20", "slug": "a-tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 35}}, {"pk": 254, "model": "server.post", "fields": {"rght": 9, "author": 23, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-10 21:05:39", "lft": 8, "post_type": 109787, "score": 1, "title": "A: Pfam based functional annotaion", "unanswered": false, "content": "This review article may be helpful or at least interesting to you:\n\n[\"Automated protein function prediction -- the genomic challenge\"][1] (Friedberg 2006)\n\nHere's a relevant excerpt:\n\n> Pfam is arguably the database of choice for those seeking order within the protein sequence universe. [...] As we shall see, Pfam annotation is used by function prediction programs, either by directly querying Pfam or by using umbrella databases that include Pfam information such as InterPro. SMART, CDD, and PRODOM are other databases consisting of multiple alignments of protein domains. All these databases have proteins arranged in homologous clusters, which, when possible, are annotated. These databases are often deferred to when producing homology-based annotation transfers. It should be emphasized that the use of these databases for homology transfer should be done with caution, as they annotate proteins on a domain level. A multi-domain query aligned to Pfam, for example, should be carefully checked for mis-annotations due to domain shuffling, as mentioned eariler. Also, the 'granularity' of these databases varies. For example, a single Pfam family may contain several proteins which perform the same enzymatic reaction on different substrates.\n\n  [1]: http://bib.oxfordjournals.org/cgi/content/full/7/3/225", "comment_count": 0, "html": "<p>This review article may be helpful or at least interesting to you:</p>\n<p><a href=\"http://bib.oxfordjournals.org/cgi/content/full/7/3/225\">\"Automated protein function prediction -- the genomic challenge\"</a> (Friedberg 2006)</p>\n<p>Here's a relevant excerpt:</p>\n<blockquote>\n<p>Pfam is arguably the database of choice for those seeking order within the protein sequence universe. [...] As we shall see, Pfam annotation is used by function prediction programs, either by directly querying Pfam or by using umbrella databases that include Pfam information such as InterPro. SMART, CDD, and PRODOM are other databases consisting of multiple alignments of protein domains. All these databases have proteins arranged in homologous clusters, which, when possible, are annotated. These databases are often deferred to when producing homology-based annotation transfers. It should be emphasized that the use of these databases for homology transfer should be done with caution, as they annotate proteins on a domain level. A multi-domain query aligned to Pfam, for example, should be carefully checked for mis-annotations due to domain shuffling, as mentioned eariler. Also, the 'granularity' of these databases varies. For example, a single Pfam family may contain several proteins which perform the same enzymatic reaction on different substrates.</p>\n</blockquote>", "child_count": 0, "closed": false, "tree_id": 35, "revision_count": 1, "parent": 128, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-pfam-based-functional-annotaion", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 23}}, {"pk": 255, "model": "server.post", "fields": {"rght": 10, "author": 72, "answer_accepted": true, "tag_string": "base phred fastq bustard", "creation_date": "2010-03-10 21:26:16", "lft": 1, "post_type": 164033, "score": 2, "title": "How can a base-called position be \"unknown\" but have a non-minimal score?", "unanswered": false, "content": "Let's say I extract something like this from a qseq or FASTQ file\n\n    TTCAGATGTTCATATGCGGATCGGCGCTGGGCCCACGAGATCTAGCAGAGCTCGT.GGGACCACGACCACCGACCC\n    a`bbbbbbaabbab`ab^`bVa^^bab^[``bba^`]_Ya^`_`^^_Xa\\_KYTYD[PY^Y_^[P[V_BBBBBBBB\n\nSo the dot is like an N - it can't call the base. So if I look at the FASTQ scores in integer format I would expect that position to have a minimal score. But in fact its score is 'D' or 4, not great but some other called bases at the tail end are 'B' or 2. What gives?", "comment_count": 1, "html": "<p>Let's say I extract something like this from a qseq or FASTQ file</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">TTCAGATGTTCATATGCGGATCGGCGCTGGGCCCACGAGATCTAGCAGAGCTCGT</span><span class=\"o\">.</span><span class=\"n\">GGGACCACGACCACCGACCC</span>\n    <span class=\"n\">a</span><span class=\"sb\">`bbbbbbaabbab`</span><span class=\"n\">ab</span><span class=\"o\">^</span><span class=\"sb\">`bVa^^bab^[``bba^`</span><span class=\"p\">]</span><span class=\"n\">_Ya</span><span class=\"o\">^</span><span class=\"sb\">`_`</span><span class=\"o\">^^</span><span class=\"n\">_Xa</span><span class=\"o\">\\</span><span class=\"n\">_KYTYD</span><span class=\"p\">[</span><span class=\"n\">PY</span><span class=\"o\">^</span><span class=\"n\">Y_</span><span class=\"o\">^</span><span class=\"p\">[</span><span class=\"n\">P</span><span class=\"p\">[</span><span class=\"n\">V_BBBBBBBB</span>\n</pre></div>\n</p>\n<p>So the dot is like an N - it can't call the base. So if I look at the FASTQ scores in integer format I would expect that position to have a minimal score. But in fact its score is 'D' or 4, not great but some other called bases at the tail end are 'B' or 2. What gives?</p>", "child_count": 0, "closed": false, "tree_id": 62, "revision_count": 1, "parent": null, "views": 177, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:30", "slug": "how-can-a-base-called-position-be-unknown-but-have-a-non-minimal-score", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [103, 116, 117, 118], "lastedit_user": 72}}, {"pk": 256, "model": "server.post", "fields": {"rght": 20, "author": 120, "answer_accepted": true, "tag_string": "sequencing dna", "creation_date": "2010-03-10 23:46:35", "lft": 1, "post_type": 164033, "score": 3, "title": "If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "unanswered": false, "content": "I have a plate of colonies to sequence.  I pick 2 colonies and sequence each in Fwd and Rev directions.   I get back a single bp difference between the 2 strands.  2 bp have an T, two have a C.   How should I call this base?  Can I call it a Y (C or T) and leave it at that, or do I need to sequence another colony to be sure? \n", "comment_count": 5, "html": "<p>I have a plate of colonies to sequence.  I pick 2 colonies and sequence each in Fwd and Rev directions.   I get back a single bp difference between the 2 strands.  2 bp have an T, two have a C.   How should I call this base?  Can I call it a Y (C or T) and leave it at that, or do I need to sequence another colony to be sure? </p>", "child_count": 0, "closed": false, "tree_id": 63, "revision_count": 1, "parent": null, "views": 95, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:29", "slug": "if-i-have-4-sequence-runs-2-in-each-direction-1-bp-is-different-on-each-should-i-resequence", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [23, 65], "lastedit_user": 120}}, {"pk": 257, "model": "server.post", "fields": {"rght": 25, "author": 121, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 01:09:56", "lft": 24, "post_type": 109787, "score": 0, "title": "A: How to determine if a gene is active from expression data", "unanswered": false, "content": "Sounds like your trying to find genes which actually switch from on-to-off (or vice-versa) based on cell-type, condition, etc.  Not all genes have this type of behavior ... some are graded (like a dimer switch).  There are numerous papers that discuss techniques for finding genes which have \"bi-modal\" expression patterns.  Since they are a mixture of two expressions patterns it is likely that they have \"on\" and \"off\" pattern.\n\nThis article explain the technique and includes Matlab code that should do the whole thing for you.\n\n[Human and mouse switch-like genes share common transcriptional regulatory mechanisms for bimodality.][1]\n\n\n  [1]: http://www.ncbi.nlm.nih.gov/pubmed/19105848", "comment_count": 0, "html": "<p>Sounds like your trying to find genes which actually switch from on-to-off (or vice-versa) based on cell-type, condition, etc.  Not all genes have this type of behavior ... some are graded (like a dimer switch).  There are numerous papers that discuss techniques for finding genes which have \"bi-modal\" expression patterns.  Since they are a mixture of two expressions patterns it is likely that they have \"on\" and \"off\" pattern.</p>\n<p>This article explain the technique and includes Matlab code that should do the whole thing for you.</p>\n<p><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/19105848\">Human and mouse switch-like genes share common transcriptional regulatory mechanisms for bimodality.</a></p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 1, "parent": 238, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:49", "slug": "a-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 121}}, {"pk": 258, "model": "server.post", "fields": {"rght": 16, "author": 121, "answer_accepted": true, "tag_string": "python geneid conversion", "creation_date": "2010-03-11 01:27:26", "lft": 1, "post_type": 164033, "score": 5, "title": "Programatic technique for gene-name/id conversion", "unanswered": false, "content": "Does anyone know of a good gene-id conversion tool written in Python.  I've come across numerous webtools but I'd like something a little more automated.  I have the knowledge/ability to do it myself I was just wondering if there was something already out there.  There's no point in re-inventing the wheel each time.\n\nThanks in advance", "comment_count": 0, "html": "<p>Does anyone know of a good gene-id conversion tool written in Python.  I've come across numerous webtools but I'd like something a little more automated.  I have the knowledge/ability to do it myself I was just wondering if there was something already out there.  There's no point in re-inventing the wheel each time.</p>\n<p>Thanks in advance</p>", "child_count": 0, "closed": false, "tree_id": 64, "revision_count": 1, "parent": null, "views": 540, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:21", "slug": "programatic-technique-for-gene-nameid-conversion", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [11, 18, 21], "lastedit_user": 121}}, {"pk": 259, "model": "server.post", "fields": {"rght": 11, "author": 121, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 01:50:51", "lft": 10, "post_type": 109787, "score": 3, "title": "A: Experiences with cloud computing in bioinformatics", "unanswered": false, "content": "I've started using [PiCloud][1].  It is a super simple library for Python that facilitates running your code in the cloud.  The client will copy your interpreter's state and then run the code on their Amazon EC2 cluster.  They then charge you based on your program's run time.  They're currently doing beta trials so its actually free (for now).\n\nThe only disadvantage is that they abstract everything away from you ... so its actually impossible to run on your own Amazon EC2 cluster.  Its also virtually impossible to run anything that's not Python.\n\nBut overall I've found it really easy to implement some of my algorithms using their client.\n\n\n  [1]: http://www.picloud.com/", "comment_count": 0, "html": "<p>I've started using <a href=\"http://www.picloud.com/\">PiCloud</a>.  It is a super simple library for Python that facilitates running your code in the cloud.  The client will copy your interpreter's state and then run the code on their Amazon EC2 cluster.  They then charge you based on your program's run time.  They're currently doing beta trials so its actually free (for now).</p>\n<p>The only disadvantage is that they abstract everything away from you ... so its actually impossible to run on your own Amazon EC2 cluster.  Its also virtually impossible to run anything that's not Python.</p>\n<p>But overall I've found it really easy to implement some of my algorithms using their client.</p>", "child_count": 0, "closed": false, "tree_id": 37, "revision_count": 1, "parent": 132, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-experiences-with-cloud-computing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 121}}, {"pk": 260, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 03:36:20", "lft": 2, "post_type": 109787, "score": 0, "title": "A: Programatic technique for gene-name/id conversion", "unanswered": false, "content": "You could automate the access to the website with Python ;-)", "comment_count": 0, "html": "<p>You could automate the access to the website with Python ;-)</p>", "child_count": 0, "closed": false, "tree_id": 64, "revision_count": 1, "parent": 258, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:49", "slug": "a-programatic-technique-for-gene-nameid-conversion", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 261, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 03:59:56", "lft": 2, "post_type": 109787, "score": 3, "title": "A: How can a base-called position be \"unknown\" but have a non-minimal score?", "unanswered": false, "content": "I recall a situation where one of our students (Gue-Su Chang) tracked down a few undocumented behaviors in the Illumina pipeline. Basically once the basecalling is done there are additional filters applied during post-processing to handle a few odd cases. This might be on of those, the score D refers to the original call, but  later that gets overridden by another step. I know that's pretty vague. Long story short: I think the score does not apply here.\n ", "comment_count": 1, "html": "<p>I recall a situation where one of our students (Gue-Su Chang) tracked down a few undocumented behaviors in the Illumina pipeline. Basically once the basecalling is done there are additional filters applied during post-processing to handle a few odd cases. This might be on of those, the score D refers to the original call, but  later that gets overridden by another step. I know that's pretty vague. Long story short: I think the score does not apply here.</p>", "child_count": 0, "closed": false, "tree_id": 62, "revision_count": 1, "parent": 255, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-how-can-a-base-called-position-be-unknown-but-have-a-non-minimal-score", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 1}}, {"pk": 262, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 04:16:58", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Unambiguous assembly of next-gen fastq reads into fastq contigs?", "unanswered": false, "content": "I think combining the quality score is not the intended use case for the p-values. The quality scores refer to the probability of a basecall being incorrect. So during assembly it is an important information. \n\nBut once the reads are assembled if we were to keep it, it would need to reflect not just the chance of one base being wrong but that for an entire overlap to occur by chance. That is a different quantity than the original.\n\nThis is just an opinion, I could be wrong.\n", "comment_count": 0, "html": "<p>I think combining the quality score is not the intended use case for the p-values. The quality scores refer to the probability of a basecall being incorrect. So during assembly it is an important information. </p>\n<p>But once the reads are assembled if we were to keep it, it would need to reflect not just the chance of one base being wrong but that for an entire overlap to occur by chance. That is a different quantity than the original.</p>\n<p>This is just an opinion, I could be wrong.</p>", "child_count": 0, "closed": false, "tree_id": 55, "revision_count": 1, "parent": 215, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-unambiguous-assembly-of-next-gen-fastq-reads-into-fastq-contigs", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 263, "model": "server.post", "fields": {"rght": 3, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 05:03:27", "lft": 2, "post_type": 109787, "score": 2, "title": "A: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "unanswered": false, "content": "There are lots of factors to consider here:\n\n1) What do the quality scores tell you about the base call at that position?\n\n2) How deep is your coverage?  If you've got 1x coverage, it's possible that you may be seeing a miscalled base. If you're taking consensus from 30x coverage, it's much less likely.\n\n3) You're sequencing from a population. It's completely possible that within this population there are individuals with both alleles that you're describing, right?", "comment_count": 0, "html": "<p>There are lots of factors to consider here:</p>\n<p>1) What do the quality scores tell you about the base call at that position?</p>\n<p>2) How deep is your coverage?  If you've got 1x coverage, it's possible that you may be seeing a miscalled base. If you're taking consensus from 30x coverage, it's much less likely.</p>\n<p>3) You're sequencing from a population. It's completely possible that within this population there are individuals with both alleles that you're describing, right?</p>", "child_count": 0, "closed": false, "tree_id": 63, "revision_count": 1, "parent": 256, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:20", "slug": "a-if-i-have-4-sequence-runs-2-in-each-direction-1-bp-is-different-on-each-should-i-resequence", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 116}}, {"pk": 264, "model": "server.post", "fields": {"rght": 5, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 05:42:31", "lft": 4, "post_type": 109787, "score": 2, "title": "A: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "unanswered": false, "content": "As chrisamiller says, it depends on the details of what you're trying to do. **The question is whether what you're seeing is variation due to technical error or due to biological variation.** \n\nHowever, without any additional information, if you've essentially only got 2 reads per sequence with contradicting information at a given position, you can't really call the base with any degree of certainty. In this case, the use of an ambiguity base call (i.e. Y instead of C or T) would be justified, in my view.", "comment_count": 0, "html": "<p>As chrisamiller says, it depends on the details of what you're trying to do. <strong>The question is whether what you're seeing is variation due to technical error or due to biological variation.</strong> </p>\n<p>However, without any additional information, if you've essentially only got 2 reads per sequence with contradicting information at a given position, you can't really call the base with any degree of certainty. In this case, the use of an ambiguity base call (i.e. Y instead of C or T) would be justified, in my view.</p>", "child_count": 0, "closed": false, "tree_id": 63, "revision_count": 1, "parent": 256, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-if-i-have-4-sequence-runs-2-in-each-direction-1-bp-is-different-on-each-should-i-resequence", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 118}}, {"pk": 265, "model": "server.post", "fields": {"rght": 7, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 08:39:15", "lft": 6, "post_type": 109787, "score": 3, "title": "A: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "unanswered": false, "content": "I agree with chrisamiller and PhiS. I'll just add that it also ***greatly depends on what you will do with your sequence***.\n\nI understand from your question that:\n\n  * You have picked only 2 [bacterial] colonies for sequencing\n  * These colonies result from the cloning of a PCR product (?)\n  * They were sequenced using Sanger sequencing\n\n[NOTE: when describing your problem it is very important to give these kind of details, so please correct me if my assumptions are wrong.]\n\nI am guessing that:\n\n  * You might want to check that the sequence is correct (maybe verifying that your qPCR product is correct)?\n  * You might be cloning a gene (or fragment thereof) in order to express a protein?\n\n[NOTE: here again, these kind of details are crucial in determining if you can accept an ambiguous base or not. Please add a comment or edit your post if it is yet another purpose]\n\nFinally, as Istvan has asked, you need to be clear as to what the difference is: are you looking at a different base call ***between the two sequenced colonies*** or ***between the forward and reverse sequencing events***?\n\nIf it is the first (i.e. difference between the two colonies) then you need to check the quality of the call at that base (quality scores if you have them, or look at the chromatogram to see if there's a mistake or a double pic etc.). If they are good quality, then you probably have at least these two different variants of the sequence you're targeting.\n\nIf it is the second (i.e. difference between the forward and reverse) then you should also look at the quality in each read. If they are bad quality, sequence again. If they are good quality, then I'm scratching my head making a funny face. Start over from scratch.\n\nNow to your question about leaving it ambiguous or not: \n\n  * If you just wanted to check that the sequence is \"fairly\" OK, then fine, leave it as a Y.\n  * If you're checking the amplicon of a qPCR event, then it is crucial to know if you have only one sequence or two different ones (even if it's a SNP). This will change your interpretation.\n  * If you want to express a protein from this sequence, then you need to check if the difference (T or C) changes the resulting protein sequence: if yes, you need to choose the correct clone. If not, you can go with either.\n\n", "comment_count": 0, "html": "<p>I agree with chrisamiller and PhiS. I'll just add that it also <strong><em>greatly depends on what you will do with your sequence</em></strong>.</p>\n<p>I understand from your question that:</p>\n<ul>\n<li>You have picked only 2 [bacterial] colonies for sequencing</li>\n<li>These colonies result from the cloning of a PCR product (?)</li>\n<li>They were sequenced using Sanger sequencing</li>\n</ul>\n<p>[NOTE: when describing your problem it is very important to give these kind of details, so please correct me if my assumptions are wrong.]</p>\n<p>I am guessing that:</p>\n<ul>\n<li>You might want to check that the sequence is correct (maybe verifying that your qPCR product is correct)?</li>\n<li>You might be cloning a gene (or fragment thereof) in order to express a protein?</li>\n</ul>\n<p>[NOTE: here again, these kind of details are crucial in determining if you can accept an ambiguous base or not. Please add a comment or edit your post if it is yet another purpose]</p>\n<p>Finally, as Istvan has asked, you need to be clear as to what the difference is: are you looking at a different base call <strong><em>between the two sequenced colonies</em></strong> or <strong><em>between the forward and reverse sequencing events</em></strong>?</p>\n<p>If it is the first (i.e. difference between the two colonies) then you need to check the quality of the call at that base (quality scores if you have them, or look at the chromatogram to see if there's a mistake or a double pic etc.). If they are good quality, then you probably have at least these two different variants of the sequence you're targeting.</p>\n<p>If it is the second (i.e. difference between the forward and reverse) then you should also look at the quality in each read. If they are bad quality, sequence again. If they are good quality, then I'm scratching my head making a funny face. Start over from scratch.</p>\n<p>Now to your question about leaving it ambiguous or not: </p>\n<ul>\n<li>If you just wanted to check that the sequence is \"fairly\" OK, then fine, leave it as a Y.</li>\n<li>If you're checking the amplicon of a qPCR event, then it is crucial to know if you have only one sequence or two different ones (even if it's a SNP). This will change your interpretation.</li>\n<li>If you want to express a protein from this sequence, then you need to check if the difference (T or C) changes the resulting protein sequence: if yes, you need to choose the correct clone. If not, you can go with either.</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 63, "revision_count": 1, "parent": 256, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-if-i-have-4-sequence-runs-2-in-each-direction-1-bp-is-different-on-each-should-i-resequence", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 266, "model": "server.post", "fields": {"rght": 11, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 11:03:45", "lft": 4, "post_type": 109787, "score": 8, "title": "A: Programatic technique for gene-name/id conversion", "unanswered": false, "content": "Writing a small tool to automate access to the website/service is pretty simple. Here's a method I wrote for the UniProt ID mapping service:\n\n    import urllib\n    import urllib2\n    \n    def uniprot_mapping(fromtype, totype, identifier):\n        base = 'http://www.uniprot.org'\n        tool = 'mapping'\n        params = {'from':fromtype,\n                    'to':totype,\n                    'format':'tab',\n                    'query':identifier,\n        }\n        data = urllib.urlencode(params)\n        url = base+'/'+tool+'?'+data\n        response = urllib2.urlopen(url)\n        return response.read()\n\nIt's not extensively tested, but should work. You can find a list of fromtypes and totypes here: [http://www.uniprot.org/faq/28#id_mapping_examples][1]\n\n\n  [1]: http://www.uniprot.org/faq/28#id_mapping_examples", "comment_count": 3, "html": "<p>Writing a small tool to automate access to the website/service is pretty simple. Here's a method I wrote for the UniProt ID mapping service:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"nb\">import</span> <span class=\"n\">urllib</span>\n    <span class=\"nb\">import</span> <span class=\"n\">urllib2</span>\n    \n    <span class=\"n\">def</span> <span class=\"n\">uniprot_mapping</span><span class=\"p\">(</span><span class=\"n\">fromtype</span><span class=\"p\">,</span> <span class=\"n\">totype</span><span class=\"p\">,</span> <span class=\"n\">identifier</span><span class=\"p\">):</span>\n        <span class=\"n\">base</span> <span class=\"o\">=</span> <span class=\"s\">&#39;http://www.uniprot.org&#39;</span>\n        <span class=\"n\">tool</span> <span class=\"o\">=</span> <span class=\"s\">&#39;mapping&#39;</span>\n        <span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s\">&#39;from&#39;</span><span class=\"p\">:</span><span class=\"n\">fromtype</span><span class=\"p\">,</span>\n                    <span class=\"s\">&#39;to&#39;</span><span class=\"p\">:</span><span class=\"n\">totype</span><span class=\"p\">,</span>\n                    <span class=\"s\">&#39;format&#39;</span><span class=\"p\">:</span><span class=\"s\">&#39;tab&#39;</span><span class=\"p\">,</span>\n                    <span class=\"s\">&#39;query&#39;</span><span class=\"p\">:</span><span class=\"n\">identifier</span><span class=\"p\">,</span>\n        <span class=\"p\">}</span>\n        <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">urllib</span><span class=\"o\">.</span><span class=\"n\">urlencode</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span>\n        <span class=\"n\">url</span> <span class=\"o\">=</span> <span class=\"n\">base</span><span class=\"o\">+</span><span class=\"s\">&#39;/&#39;</span><span class=\"o\">+</span><span class=\"n\">tool</span><span class=\"o\">+</span><span class=\"s\">&#39;?&#39;</span><span class=\"o\">+</span><span class=\"n\">data</span>\n        <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">urllib2</span><span class=\"o\">.</span><span class=\"n\">urlopen</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"nb\">read</span><span class=\"p\">()</span>\n</pre></div>\n</p>\n<p>It's not extensively tested, but should work. You can find a list of fromtypes and totypes here: <a href=\"http://www.uniprot.org/faq/28#id_mapping_examples\">http://www.uniprot.org/faq/28#id_mapping_examples</a></p>", "child_count": 0, "closed": false, "tree_id": 64, "revision_count": 1, "parent": 258, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-programatic-technique-for-gene-nameid-conversion", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 37}}, {"pk": 267, "model": "server.post", "fields": {"rght": 11, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 11:19:47", "lft": 10, "post_type": 109787, "score": 4, "title": "A: Tools to find gene ontology term enrichment", "unanswered": false, "content": "The [BiNGO plugin][1] for [Cytoscape][2] will allow you to determine term enrichment in a Cytoscape network. It's quite a neat tool.\n\n\n  [1]: http://www.psb.ugent.be/cbd/papers/BiNGO/\n  [2]: http://www.cytoscape.org/", "comment_count": 0, "html": "<p>The <a href=\"http://www.psb.ugent.be/cbd/papers/BiNGO/\">BiNGO plugin</a> for <a href=\"http://www.cytoscape.org/\">Cytoscape</a> will allow you to determine term enrichment in a Cytoscape network. It's quite a neat tool.</p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 1, "parent": 245, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 268, "model": "server.post", "fields": {"rght": 44, "author": 58, "answer_accepted": true, "tag_string": "podcast subjective recommendations vodcast", "creation_date": "2010-03-12 09:52:17", "lft": 1, "post_type": 164033, "score": 10, "title": "Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "What podcasts are the bioinformaticians here listening to that tie in with their work?  \n\nThe most relevant podcast that I know of (the currently even more irregular than normal) [Coast to Coast Bio Podcast][1] is still in my list of podcasts.\n\nFor programming related topics I still find the [StackOverflow podcast][2] an interesting and engaging listen.\n\nWhilst at one point or another I subscribed to both [Nature][3] and [Science][4] podcasts for general science I no longer do so.\n\nWhat podcasts might I be missing out on that other people are enjoying related to their work?\n\n\n  [1]: http://www.c2cbio.com/\n  [2]: http://blog.stackoverflow.com/category/podcasts/\n  [3]: http://www.nature.com/nature/podcast/\n  [4]: http://www.sciencemag.org/about/podcast.dtl", "comment_count": 0, "html": "<p>What podcasts are the bioinformaticians here listening to that tie in with their work?<br />\n</p>\n<p>The most relevant podcast that I know of (the currently even more irregular than normal) <a href=\"http://www.c2cbio.com/\">Coast to Coast Bio Podcast</a> is still in my list of podcasts.</p>\n<p>For programming related topics I still find the <a href=\"http://blog.stackoverflow.com/category/podcasts/\">StackOverflow podcast</a> an interesting and engaging listen.</p>\n<p>Whilst at one point or another I subscribed to both <a href=\"http://www.nature.com/nature/podcast/\">Nature</a> and <a href=\"http://www.sciencemag.org/about/podcast.dtl\">Science</a> podcasts for general science I no longer do so.</p>\n<p>What podcasts might I be missing out on that other people are enjoying related to their work?</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 2, "parent": null, "views": 976, "deleted": false, "answer_count": 12, "touch_date": "2011-11-24 14:49:23", "slug": "appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [32, 119, 120, 121], "lastedit_user": 89}}, {"pk": 269, "model": "server.post", "fields": {"rght": 5, "author": 89, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 11:47:06", "lft": 2, "post_type": 109787, "score": 4, "title": "A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "That is a great question. I am not aware of any podcast or vodcast(video) that specifically cover  bioinformatics topics so far.\nBut there are other services that provide bioinformatics content in a audio-visual form:\n\nhttp://www.scivee.tv/\n\nhttp://videolectures.net/Top/Computer_Science/Bioinformatics/\n\nhttp://www.bioscreencast.com/\n\n", "comment_count": 1, "html": "<p>That is a great question. I am not aware of any podcast or vodcast(video) that specifically cover  bioinformatics topics so far.\nBut there are other services that provide bioinformatics content in a audio-visual form:</p>\n<p>http://www.scivee.tv/</p>\n<p>http://videolectures.net/Top/Computer_Science/Bioinformatics/</p>\n<p>http://www.bioscreencast.com/</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 1, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 89}}, {"pk": 270, "model": "server.post", "fields": {"rght": 7, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 11:55:57", "lft": 4, "post_type": 109787, "score": 4, "title": "A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "Related, but not bioinformatics, BBC podcasts:\n\n - Material World - popsci http://www.bbc.co.uk/podcasts/series/material/\n - More or Less - statistics etc. http://www.bbc.co.uk/podcasts/series/moreorless\n\nBoth have very good presenters, and make for an entertaining listen.", "comment_count": 1, "html": "<p>Related, but not bioinformatics, BBC podcasts:</p>\n<ul>\n<li>Material World - popsci http://www.bbc.co.uk/podcasts/series/material/</li>\n<li>More or Less - statistics etc. http://www.bbc.co.uk/podcasts/series/moreorless</li>\n</ul>\n<p>Both have very good presenters, and make for an entertaining listen.</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 1, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 271, "model": "server.post", "fields": {"rght": 22, "author": 124, "answer_accepted": true, "tag_string": "alignment trna sequence", "creation_date": "2010-03-12 13:58:39", "lft": 1, "post_type": 164033, "score": 4, "title": "How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": "(Sorry for the long header)\n\nHello all.\n\nI wish to have a FASTA file (or similar) of a tRNA sequences that are aligned.\n\nHere is an example of a FASTA file I would like to align:\n\nhttp://gtrnadb.ucsc.edu/Aero_pern/aerPer1-tRNAs.fa\n\nHere is how the sequence would look aligned:\n\nhttp://gtrnadb.ucsc.edu/Aero_pern/Aero_pern-align.html\n\nIt uses a software called COVE, which can be found here:\n\nhttp://selab.janelia.org/software.html\n\nAnd it is said to do it by doing: \"Structural alignments are generated by aligning tRNA sequences against domain-specific tRNA covariance models with the use of COVE.\"\n\nWhich leads me to my questions:\n\n1. Where might I find the \"domain-specific tRNA\" to run the COVE model with ?\n2. How can I do this on windows ?\n3. Is there a better way to do this alignment ?\n\n\nThis is my first question, and I am very new to bioinformatics, so I am sorry if I am missing something very basic, or am asking something to which not many people would know to answer.\n\nThanks in advance,\n\nTal\n", "comment_count": 2, "html": "<p>(Sorry for the long header)</p>\n<p>Hello all.</p>\n<p>I wish to have a FASTA file (or similar) of a tRNA sequences that are aligned.</p>\n<p>Here is an example of a FASTA file I would like to align:</p>\n<p>http://gtrnadb.ucsc.edu/Aero_pern/aerPer1-tRNAs.fa</p>\n<p>Here is how the sequence would look aligned:</p>\n<p>http://gtrnadb.ucsc.edu/Aero_pern/Aero_pern-align.html</p>\n<p>It uses a software called COVE, which can be found here:</p>\n<p>http://selab.janelia.org/software.html</p>\n<p>And it is said to do it by doing: \"Structural alignments are generated by aligning tRNA sequences against domain-specific tRNA covariance models with the use of COVE.\"</p>\n<p>Which leads me to my questions:</p>\n<ol>\n<li>Where might I find the \"domain-specific tRNA\" to run the COVE model with ?</li>\n<li>How can I do this on windows ?</li>\n<li>Is there a better way to do this alignment ?</li>\n</ol>\n<p>This is my first question, and I am very new to bioinformatics, so I am sorry if I am missing something very basic, or am asking something to which not many people would know to answer.</p>\n<p>Thanks in advance,</p>\n<p>Tal</p>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 2, "parent": null, "views": 560, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:29", "slug": "how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [40, 83, 122], "lastedit_user": 118}}, {"pk": 272, "model": "server.post", "fields": {"rght": 13, "author": 90, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 14:17:58", "lft": 6, "post_type": 109787, "score": 4, "title": "A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "I enjoy [Futures in Biotech][1], which is about life science in general but does touch on bioinformatics sometimes.\n\n\n  [1]: http://twit.tv/FIB", "comment_count": 3, "html": "<p>I enjoy <a href=\"http://twit.tv/FIB\">Futures in Biotech</a>, which is about life science in general but does touch on bioinformatics sometimes.</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 1, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 90}}, {"pk": 273, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 15:51:14", "lft": 2, "post_type": 109787, "score": 4, "title": "A: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": " 1. The site is a little short on information but it gave me the impression that it will build the covariance model from the multiple sequence alignment itself. Try contacting the author for more information.\n 2. You can compile cove on Windows under [Cygwin][1], I just gave it a try and compiled it with no problem.\n\n\n  [1]: http://www.cygwin.com/", "comment_count": 1, "html": "<ol>\n<li>The site is a little short on information but it gave me the impression that it will build the covariance model from the multiple sequence alignment itself. Try contacting the author for more information.</li>\n<li>You can compile cove on Windows under <a href=\"http://www.cygwin.com/\">Cygwin</a>, I just gave it a try and compiled it with no problem.</li>\n</ol>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 1, "parent": 271, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 274, "model": "server.post", "fields": {"rght": 13, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 16:23:51", "lft": 8, "post_type": 109787, "score": 7, "title": "A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "It's not bioinformatic-specific, but <a href=\"http://www.wnyc.org/shows/radiolab/\">RadioLab</a> is a great science show. I especially like listening on days when I'm frustrated with my work - it helps me remember why I have a passion for science.", "comment_count": 2, "html": "<p>It's not bioinformatic-specific, but [HTML_REMOVED]RadioLab[HTML_REMOVED] is a great science show. I especially like listening on days when I'm frustrated with my work - it helps me remember why I have a passion for science.</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 1, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 275, "model": "server.post", "fields": {"rght": 7, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 16:24:10", "lft": 4, "post_type": 109787, "score": 3, "title": "A: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": "I had a quick look into the documentation of the software. If you donwload and unpack the soucecode archive, there is a Guide.tex file that can be compiled with Latex, you could look into this. So, to answer your questions partially without trying anything myself: \n \n1. Where do I find the covariance Models to run COVE with? As Istvan said: you have to make them yourself. From the manual:\nUsing these programs, you can:\n - generate new models, by training them on example sequences (covet) ....\n\n2. See Istvan's answer\n3. Possibly not:\n\n    The tRNA identification program  tRNAscan-SE is based on a tRNA CM and COVE  (Lowe and Eddy, 1997). \n\nAnd this program is still state-of-the art in tRNA discovery. If you want to look at RNAs in general an learn about their structure then [Rfam][1]/Infernal is nice.\n\nIf you are interested in RNA structure and visualization the [BiBiServ RNA-Studio][2] are an interesting resource.\n\n\n  [1]: http://rfam.janelia.org/\n  [2]: http://bibiserv.techfak.uni-bielefeld.de/bibi/Tools_RNA_Studio.html", "comment_count": 1, "html": "<p>I had a quick look into the documentation of the software. If you donwload and unpack the soucecode archive, there is a Guide.tex file that can be compiled with Latex, you could look into this. So, to answer your questions partially without trying anything myself: </p>\n<ol>\n<li>Where do I find the covariance Models to run COVE with? As Istvan said: you have to make them yourself. From the manual:\nUsing these programs, you can:</li>\n<li>\n<p>generate new models, by training them on example sequences (covet) ....</p>\n</li>\n<li>\n<p>See Istvan's answer</p>\n</li>\n<li>Possibly not:</li>\n</ol>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">The</span> <span class=\"n\">tRNA</span> <span class=\"n\">identification</span> <span class=\"n\">program</span>  <span class=\"n\">tRNAscan</span><span class=\"o\">-</span><span class=\"n\">SE</span> <span class=\"n\">is</span> <span class=\"n\">based</span> <span class=\"n\">on</span> <span class=\"n\">a</span> <span class=\"n\">tRNA</span> <span class=\"n\">CM</span> <span class=\"ow\">and</span> <span class=\"n\">COVE</span>  <span class=\"p\">(</span><span class=\"n\">Lowe</span> <span class=\"ow\">and</span> <span class=\"n\">Eddy</span><span class=\"p\">,</span> <span class=\"mi\">1997</span><span class=\"p\">)</span><span class=\"o\">.</span> \n</pre></div>\n</p>\n<p>And this program is still state-of-the art in tRNA discovery. If you want to look at RNAs in general an learn about their structure then <a href=\"http://rfam.janelia.org/\">Rfam</a>/Infernal is nice.</p>\n<p>If you are interested in RNA structure and visualization the <a href=\"http://bibiserv.techfak.uni-bielefeld.de/bibi/Tools_RNA_Studio.html\">BiBiServ RNA-Studio</a> are an interesting resource.</p>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 1, "parent": 271, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:21", "slug": "a-how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 54}}, {"pk": 276, "model": "server.post", "fields": {"rght": 9, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 16:31:28", "lft": 6, "post_type": 109787, "score": 5, "title": "A: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": "There is a recent review:\n\nComputational analysis of tRNA identity\nFEBS Letters, Volume 584, Issue 2, Pages 325-333\n\nD. Ardell\n\nhttp://dx.doi.org/10.1016/j.febslet.2009.11.084\n\nYou may check if COVE is your only option. ", "comment_count": 1, "html": "<p>There is a recent review:</p>\n<p>Computational analysis of tRNA identity\nFEBS Letters, Volume 584, Issue 2, Pages 325-333</p>\n<p>D. Ardell</p>\n<p>http://dx.doi.org/10.1016/j.febslet.2009.11.084</p>\n<p>You may check if COVE is your only option. </p>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 1, "parent": 271, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 277, "model": "server.post", "fields": {"rght": 28, "author": 52, "answer_accepted": true, "tag_string": "blast gff format", "creation_date": "2010-03-12 17:04:23", "lft": 1, "post_type": 164033, "score": 8, "title": "How to convert BLAST results to GFF", "unanswered": false, "content": "I'd like to visualise the results of a BLAST search in a genome browser. Is there a simple way to get the results in GFF format without having to write a parser myself?", "comment_count": 0, "html": "<p>I'd like to visualise the results of a BLAST search in a genome browser. Is there a simple way to get the results in GFF format without having to write a parser myself?</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 1, "parent": null, "views": 2558, "deleted": false, "answer_count": 8, "touch_date": "2011-11-24 14:49:31", "slug": "how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [3, 43, 53], "lastedit_user": 52}}, {"pk": 278, "model": "server.post", "fields": {"rght": 17, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 17:07:53", "lft": 10, "post_type": 109787, "score": 6, "title": "A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "I like [The Changelog][1]. It highlights interesting and useful open source software with a slight ruby slant.\n\n\n  [1]: http://thechangelog.com/", "comment_count": 3, "html": "<p>I like <a href=\"http://thechangelog.com/\">The Changelog</a>. It highlights interesting and useful open source software with a slight ruby slant.</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 1, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 279, "model": "server.post", "fields": {"rght": 17, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 17:18:08", "lft": 2, "post_type": 109787, "score": 3, "title": "A: How to convert BLAST results to GFF", "unanswered": false, "content": "I found this via google: http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl\n\nelse I would save my blast result as **XML** and transform it to GFF with with a (should be) simple **XSLT** stylesheet. As an example, you can have a look at my 'old' stylesheet blast2svg: http://code.google.com/p/lindenb/source/browse/trunk/src/xsl/blast2svg.xsl\nPierre\n\n", "comment_count": 7, "html": "<p>I found this via google: http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl</p>\n<p>else I would save my blast result as <strong>XML</strong> and transform it to GFF with with a (should be) simple <strong>XSLT</strong> stylesheet. As an example, you can have a look at my 'old' stylesheet blast2svg: http://code.google.com/p/lindenb/source/browse/trunk/src/xsl/blast2svg.xsl\nPierre</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 4, "parent": 277, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 280, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 17:29:05", "lft": 4, "post_type": 109787, "score": 1, "title": "A: How to convert BLAST results to GFF", "unanswered": false, "content": "Have you tried these scripts: http://gmod.org/wiki/Load_BLAST_Into_Chado, http://www.bioperl.org/pipermail/bioperl-l/2002-November/010223.html ??\n\nmaybe the [PSL][1] format is better to represent an alignment. You can also look at the [BED][2] format so later you can play with [BedTools][3]\n\n\n  [1]: http://genome.ucsc.edu/FAQ/FAQformat.html#format2\n  [2]: http://genome.ucsc.edu/FAQ/FAQformat.html#format1\n  [3]: http://code.google.com/p/bedtools/", "comment_count": 1, "html": "<p>Have you tried these scripts: http://gmod.org/wiki/Load_BLAST_Into_Chado, http://www.bioperl.org/pipermail/bioperl-l/2002-November/010223.html ??</p>\n<p>maybe the <a href=\"http://genome.ucsc.edu/FAQ/FAQformat.html#format2\">PSL</a> format is better to represent an alignment. You can also look at the <a href=\"http://genome.ucsc.edu/FAQ/FAQformat.html#format1\">BED</a> format so later you can play with <a href=\"http://code.google.com/p/bedtools/\">BedTools</a></p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 1, "parent": 277, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 281, "model": "server.post", "fields": {"rght": 9, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 18:12:04", "lft": 6, "post_type": 109787, "score": 3, "title": "A: How to convert BLAST results to GFF", "unanswered": false, "content": "Start with tabulated blast output myfile.blast.out. Then check two-liners from:\n\nhttp://bergman-lab.blogspot.com/2009/12/ncbi-blast-tabular-output-format-fields.html\n\nFew lines tooutput proper gff are missing, but you may either go for minimalistic gff or try to encode everything in column 9. Also you may try validating your gff3 here:\n\nhttp://modencode.oicr.on.ca/cgi-bin/validate_gff3_online\n\n**NOTE:** *The blog linked above does not seem to exist anymore, here is the content of it from the wayback machine:*\n\n**NCBI Blast Tabular output format fields**\n\nCertainly, with the new NCBI Blast+ tools, you won't need this anymore, but as long as we are sticking with the old blastall programm with its horrible documentation, I keep forgetting the format of the BLAST tabular reports. Tabular format is created when you specify \"`-m 8`\". This is the most useful format for parsing blast yourself without having to learn strange libraries like BioPerl, BioJava, BioPython or BioErlang (doesn't this exist yet, Mike?)\n\nSo here is the meaning of the fields:\n\n    queryId, subjectId, percIdentity, alnLength, mismatchCount, \n    gapOpenCount, queryStart, queryEnd, subjectStart, subjectEnd, eVal, bitScore\n\nParsing is then simple\n\nPython:\n\n    for line in open(\"myfile.blast\"):\n        (queryId, subjectId, percIdentity, alnLength, mismatchCount, \n        gapOpenCount, queryStart, queryEnd, subjectStart, \n        subjectEnd, eVal, bitScore) = line.split(\"\\t\")\n\nPerl:\n\n    while (<>) {\n       ($queryId, $subjectId, $percIdentity, $alnLength, $mismatchCount, \n       $gapOpenCount, $queryStart, $queryEnd, $subjectStart, \n       $subjectEnd, $eVal, $bitScore) = split(/\\t/)\n    }\n", "comment_count": 1, "html": "<p>Start with tabulated blast output myfile.blast.out. Then check two-liners from:</p>\n<p>http://bergman-lab.blogspot.com/2009/12/ncbi-blast-tabular-output-format-fields.html</p>\n<p>Few lines tooutput proper gff are missing, but you may either go for minimalistic gff or try to encode everything in column 9. Also you may try validating your gff3 here:</p>\n<p>http://modencode.oicr.on.ca/cgi-bin/validate_gff3_online</p>\n<p><strong>NOTE:</strong> <em>The blog linked above does not seem to exist anymore, here is the content of it from the wayback machine:</em></p>\n<p><strong>NCBI Blast Tabular output format fields</strong></p>\n<p>Certainly, with the new NCBI Blast+ tools, you won't need this anymore, but as long as we are sticking with the old blastall programm with its horrible documentation, I keep forgetting the format of the BLAST tabular reports. Tabular format is created when you specify \"<code>-m 8</code>\". This is the most useful format for parsing blast yourself without having to learn strange libraries like BioPerl, BioJava, BioPython or BioErlang (doesn't this exist yet, Mike?)</p>\n<p>So here is the meaning of the fields:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">queryId</span><span class=\"p\">,</span> <span class=\"n\">subjectId</span><span class=\"p\">,</span> <span class=\"n\">percIdentity</span><span class=\"p\">,</span> <span class=\"n\">alnLength</span><span class=\"p\">,</span> <span class=\"n\">mismatchCount</span><span class=\"p\">,</span> \n    <span class=\"n\">gapOpenCount</span><span class=\"p\">,</span> <span class=\"n\">queryStart</span><span class=\"p\">,</span> <span class=\"n\">queryEnd</span><span class=\"p\">,</span> <span class=\"n\">subjectStart</span><span class=\"p\">,</span> <span class=\"n\">subjectEnd</span><span class=\"p\">,</span> <span class=\"n\">eVal</span><span class=\"p\">,</span> <span class=\"n\">bitScore</span>\n</pre></div>\n</p>\n<p>Parsing is then simple</p>\n<p>Python:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"k\">for</span> <span class=\"n\">line</span> <span class=\"n\">in</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s\">&quot;myfile.blast&quot;</span><span class=\"p\">):</span>\n        <span class=\"p\">(</span><span class=\"n\">queryId</span><span class=\"p\">,</span> <span class=\"n\">subjectId</span><span class=\"p\">,</span> <span class=\"n\">percIdentity</span><span class=\"p\">,</span> <span class=\"n\">alnLength</span><span class=\"p\">,</span> <span class=\"n\">mismatchCount</span><span class=\"p\">,</span> \n        <span class=\"n\">gapOpenCount</span><span class=\"p\">,</span> <span class=\"n\">queryStart</span><span class=\"p\">,</span> <span class=\"n\">queryEnd</span><span class=\"p\">,</span> <span class=\"n\">subjectStart</span><span class=\"p\">,</span> \n        <span class=\"n\">subjectEnd</span><span class=\"p\">,</span> <span class=\"n\">eVal</span><span class=\"p\">,</span> <span class=\"n\">bitScore</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">line</span><span class=\"o\">.</span><span class=\"nb\">split</span><span class=\"p\">(</span><span class=\"s\">&quot;\\t&quot;</span><span class=\"p\">)</span>\n</pre></div>\n</p>\n<p>Perl:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"o\">&lt;&gt;</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n       <span class=\"p\">(</span><span class=\"nv\">$queryId</span><span class=\"p\">,</span> <span class=\"nv\">$subjectId</span><span class=\"p\">,</span> <span class=\"nv\">$percIdentity</span><span class=\"p\">,</span> <span class=\"nv\">$alnLength</span><span class=\"p\">,</span> <span class=\"nv\">$mismatchCount</span><span class=\"p\">,</span> \n       <span class=\"nv\">$gapOpenCount</span><span class=\"p\">,</span> <span class=\"nv\">$queryStart</span><span class=\"p\">,</span> <span class=\"nv\">$queryEnd</span><span class=\"p\">,</span> <span class=\"nv\">$subjectStart</span><span class=\"p\">,</span> \n       <span class=\"nv\">$subjectEnd</span><span class=\"p\">,</span> <span class=\"nv\">$eVal</span><span class=\"p\">,</span> <span class=\"nv\">$bitScore</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"nb\">split</span><span class=\"p\">(</span><span class=\"sr\">/\\t/</span><span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 2, "parent": 277, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 1}}, {"pk": 282, "model": "server.post", "fields": {"rght": 7, "author": 121, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 04:51:33", "lft": 6, "post_type": 109787, "score": 2, "title": "A: Programatic technique for gene-name/id conversion", "unanswered": false, "content": "In case anyone comes by this later I've made a simple python module for doing this sort of converting.  You can find it on GitHub: http://github.com/JudoWill/IDConverter\n\nFeel free make comments and provide suggestions.", "comment_count": 0, "html": "<p>In case anyone comes by this later I've made a simple python module for doing this sort of converting.  You can find it on GitHub: http://github.com/JudoWill/IDConverter</p>\n<p>Feel free make comments and provide suggestions.</p>", "child_count": 0, "closed": false, "tree_id": 64, "revision_count": 1, "parent": 258, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-programatic-technique-for-gene-nameid-conversion", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 121}}, {"pk": 283, "model": "server.post", "fields": {"rght": 78, "author": 30, "answer_accepted": false, "tag_string": "career subjective", "creation_date": "2010-03-13 15:46:57", "lft": 1, "post_type": 164033, "score": 5, "title": "What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "To clarify, I am a biochemist, trained in molecular evolution since undergrad and I changed my particular field of work to large scale phylogenetic analysis in the grad school. \n\nSo, to me, building and interpreting a phylogenetic tree from a family of genes can be considered a trivial task in my subfield (actually, this should be be trivial to any people with a background in biology), but to integrate functional data and increase the scale of the analysis to whole genomes and dozen/hundreds of species would be a little more challenging. \n\nI am really curious since bioinformatics and computational biology has had a fast growing in the last years, many paradigms have changed in what is trivial and what is challenging in his many subfields. ", "comment_count": 0, "html": "<p>To clarify, I am a biochemist, trained in molecular evolution since undergrad and I changed my particular field of work to large scale phylogenetic analysis in the grad school. </p>\n<p>So, to me, building and interpreting a phylogenetic tree from a family of genes can be considered a trivial task in my subfield (actually, this should be be trivial to any people with a background in biology), but to integrate functional data and increase the scale of the analysis to whole genomes and dozen/hundreds of species would be a little more challenging. </p>\n<p>I am really curious since bioinformatics and computational biology has had a fast growing in the last years, many paradigms have changed in what is trivial and what is challenging in his many subfields. </p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 1, "parent": null, "views": 489, "deleted": false, "answer_count": 16, "touch_date": "2011-11-24 14:49:29", "slug": "what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [32, 110], "lastedit_user": 30}}, {"pk": 284, "model": "server.post", "fields": {"rght": 5, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 16:41:18", "lft": 2, "post_type": 109787, "score": 4, "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "**Challenging**:\n\n - Using other's code\n - understanding why a technology/paper/language/db is worth looking/testing\n - understanding theoretical papers\n - making my code reusable\n - being my own learning mentor\n - working with 'big-data'\n - (...)\n\n**Trivial**:\n\n  - working with 'big-data' :-)\n  - Using SQL/C/C++/Java/etc... etc...\n  - using some common resources related to by field (dbsnp...)\n  - Parsing data\n  - sharing\n  - (...)", "comment_count": 1, "html": "<p><strong>Challenging</strong>:</p>\n<ul>\n<li>Using other's code</li>\n<li>understanding why a technology/paper/language/db is worth looking/testing</li>\n<li>understanding theoretical papers</li>\n<li>making my code reusable</li>\n<li>being my own learning mentor</li>\n<li>working with 'big-data'</li>\n<li>(...)</li>\n</ul>\n<p><strong>Trivial</strong>:</p>\n<ul>\n<li>working with 'big-data' :-)</li>\n<li>Using SQL/C/C++/Java/etc... etc...</li>\n<li>using some common resources related to by field (dbsnp...)</li>\n<li>Parsing data</li>\n<li>sharing</li>\n<li>(...)</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 1, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:21", "slug": "a-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 285, "model": "server.post", "fields": {"rght": 7, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 17:33:54", "lft": 4, "post_type": 109787, "score": 11, "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Off the top of my head:\n\n**Challenging and frustrating:**  \n\n - Sifting through the avalanche of new\n   papers and tools to find ones that\n   are immediately relevant  \n\n**Challenging and interesting:**  \n\n - Given whole-genome assays, deciding which\n   of the hundreds of mutations are\n   important and potentially causative\n -  Integrating results from assays that\n   provide different insights and\n   potentially conflicting information.\n - writing code using a parallel (or map/reduce) paradigm, so that it won't take years to run\n\n**Trivial, but tedious:**  \n\n - constantly munging data files from one poorly defined format to another\n", "comment_count": 1, "html": "<p>Off the top of my head:</p>\n<p><strong>Challenging and frustrating:</strong><br />\n</p>\n<ul>\n<li>Sifting through the avalanche of new\n   papers and tools to find ones that\n   are immediately relevant<br />\n</li>\n</ul>\n<p><strong>Challenging and interesting:</strong><br />\n</p>\n<ul>\n<li>Given whole-genome assays, deciding which\n   of the hundreds of mutations are\n   important and potentially causative</li>\n<li>Integrating results from assays that\n   provide different insights and\n   potentially conflicting information.</li>\n<li>writing code using a parallel (or map/reduce) paradigm, so that it won't take years to run</li>\n</ul>\n<p><strong>Trivial, but tedious:</strong><br />\n</p>\n<ul>\n<li>constantly munging data files from one poorly defined format to another</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 1, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 286, "model": "server.post", "fields": {"rght": 9, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 20:46:52", "lft": 8, "post_type": 109787, "score": 3, "title": "A: How to convert BLAST results to GFF", "unanswered": false, "content": ">  http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl\n\nYou can use the script Pierre found swith a slight modification, actually it is a bit crude and does no real error checking but it works. The error is it does not work if the blast file has a header like this:\n\n    # BLASTN 2.2.21 [Jun-14-2009]\n    # Query: 16383 sequences\n    # Database: genomedata/GenomeOfDeath.fas\n    # Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score\n    GeneOfDeath  GenomeOfDeath  100.00  295     0       0       1       295     152626  152920  4e-168   585\n\n\nSo, one should filter out lines beginning with \"#\" and it does no harm to skip lines which \nare empty or contain only white spaces.\n\nSo edit the file Blast2Gff.pl: in line 149 add:\n\n     next if (/^\\#/ || /^\\s*$/); # filter comments and empty lines\n\nSuch that this part looks like below, then try again.\n\n    while (<BLASTIN>)\n    {\n\n      next if (/^\\#/ || /^\\s*$/); # filter comments and empty lines\n\n\t$HitNum++;\n   \n\tmy ($QryId, $SubId, $PID, $Len, \n\t    $MisMatch, $GapOpen, \n\t    $QStart,$QEnd, $SStart, $SEnd,\n\t    $EVal, $BitScore) = split(/\\t/);\n\n\n\n\n", "comment_count": 0, "html": "<blockquote>\n<p>http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl</p>\n</blockquote>\n<p>You can use the script Pierre found swith a slight modification, actually it is a bit crude and does no real error checking but it works. The error is it does not work if the blast file has a header like this:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"c1\"># BLASTN 2.2.21 [Jun-14-2009]</span>\n    <span class=\"c1\"># Query: 16383 sequences</span>\n    <span class=\"c1\"># Database: genomedata/GenomeOfDeath.fas</span>\n    <span class=\"c1\"># Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score</span>\n    <span class=\"n\">GeneOfDeath</span>  <span class=\"n\">GenomeOfDeath</span>  <span class=\"mf\">100.00</span>  <span class=\"mi\">295</span>     <span class=\"mi\">0</span>       <span class=\"mi\">0</span>       <span class=\"mi\">1</span>       <span class=\"mi\">295</span>     <span class=\"mi\">152626</span>  <span class=\"mi\">152920</span>  <span class=\"mf\">4e-168</span>   <span class=\"mi\">585</span>\n</pre></div>\n</p>\n<p>So, one should filter out lines beginning with \"#\" and it does no harm to skip lines which \nare empty or contain only white spaces.</p>\n<p>So edit the file Blast2Gff.pl: in line 149 add:</p>\n<p><div class=\"highlight\"><pre>     <span class=\"k\">next</span> <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"sr\">/^\\#/</span> <span class=\"o\">||</span> <span class=\"sr\">/^\\s*$/</span><span class=\"p\">);</span> <span class=\"c1\"># filter comments and empty lines</span>\n</pre></div>\n</p>\n<p>Such that this part looks like below, then try again.</p>\n<p><div class=\"highlight\"><pre>    <span class=\"k\">while</span> <span class=\"p\">(</span><span class=\"sr\">&lt;BLASTIN&gt;</span><span class=\"p\">)</span>\n    <span class=\"p\">{</span>\n\n      <span class=\"k\">next</span> <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"sr\">/^\\#/</span> <span class=\"o\">||</span> <span class=\"sr\">/^\\s*$/</span><span class=\"p\">);</span> <span class=\"c1\"># filter comments and empty lines</span>\n\n\t<span class=\"nv\">$HitNum</span><span class=\"o\">++</span><span class=\"p\">;</span>\n</pre></div>\n</p>\n<p><div class=\"highlight\"><pre>\t<span class=\"k\">my</span> <span class=\"p\">(</span><span class=\"nv\">$QryId</span><span class=\"p\">,</span> <span class=\"nv\">$SubId</span><span class=\"p\">,</span> <span class=\"nv\">$PID</span><span class=\"p\">,</span> <span class=\"nv\">$Len</span><span class=\"p\">,</span> \n\t    <span class=\"nv\">$MisMatch</span><span class=\"p\">,</span> <span class=\"nv\">$GapOpen</span><span class=\"p\">,</span> \n\t    <span class=\"nv\">$QStart</span><span class=\"p\">,</span><span class=\"nv\">$QEnd</span><span class=\"p\">,</span> <span class=\"nv\">$SStart</span><span class=\"p\">,</span> <span class=\"nv\">$SEnd</span><span class=\"p\">,</span>\n\t    <span class=\"nv\">$EVal</span><span class=\"p\">,</span> <span class=\"nv\">$BitScore</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"nb\">split</span><span class=\"p\">(</span><span class=\"sr\">/\\t/</span><span class=\"p\">);</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 2, "parent": 277, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 287, "model": "server.post", "fields": {"rght": 14, "author": 130, "answer_accepted": true, "tag_string": "gene function database redundancy", "creation_date": "2010-03-14 16:26:35", "lft": 1, "post_type": 164033, "score": 3, "title": "A resource to identify functionally redundant genes", "unanswered": false, "content": "Can anybody point me to a resource that provides information on functionally redundant genes? I have been pointed towards the use of GOA (http://www.ebi.ac.uk/GOA/) as one approach. Would this provide sufficient 'resolution' to identify functionally equivalent genes? My thinking is that if two genes share the same GO term and the GO term is a leaf node, that might be useful. \n\nAny pointers would be appreciated", "comment_count": 0, "html": "<p>Can anybody point me to a resource that provides information on functionally redundant genes? I have been pointed towards the use of GOA (http://www.ebi.ac.uk/GOA/) as one approach. Would this provide sufficient 'resolution' to identify functionally equivalent genes? My thinking is that if two genes share the same GO term and the GO term is a leaf node, that might be useful. </p>\n<p>Any pointers would be appreciated</p>", "child_count": 0, "closed": false, "tree_id": 69, "revision_count": 1, "parent": null, "views": 368, "deleted": false, "answer_count": 8, "touch_date": "2011-11-24 14:49:29", "slug": "a-resource-to-identify-functionally-redundant-genes", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [36, 37, 69, 123], "lastedit_user": 130}}, {"pk": 288, "model": "server.post", "fields": {"rght": 7, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-14 16:38:32", "lft": 2, "post_type": 109787, "score": 6, "title": "A: A resource to identify functionally redundant genes", "unanswered": false, "content": "What exactly do you mean by functional redundancy? \n\n- Two proteins may both metabolize some sugar, but send different products down different pathways. Are they redundant?\n- Two different pathways can be used to produce the same end product from some metabolite.  Are all of the genes in these two pathways redundant? \n- What about proteins that have multiple functions? How do you handle _partial_ redundancy?\n\nMy take:  \nThere are no solid and complete answers to these questions at this point, but I think you could justify using GO terms of a certain depth, as you suggest. Just justify your assumptions, acknowledge that any such attempt is going to be full of errors and omissions, and be careful about  drawing too many hard conclusions from the results.", "comment_count": 2, "html": "<p>What exactly do you mean by functional redundancy? </p>\n<ul>\n<li>Two proteins may both metabolize some sugar, but send different products down different pathways. Are they redundant?</li>\n<li>Two different pathways can be used to produce the same end product from some metabolite.  Are all of the genes in these two pathways redundant? </li>\n<li>What about proteins that have multiple functions? How do you handle <em>partial</em> redundancy?</li>\n</ul>\n<p>My take:<br />\nThere are no solid and complete answers to these questions at this point, but I think you could justify using GO terms of a certain depth, as you suggest. Just justify your assumptions, acknowledge that any such attempt is going to be full of errors and omissions, and be careful about  drawing too many hard conclusions from the results.</p>", "child_count": 0, "closed": false, "tree_id": 69, "revision_count": 1, "parent": 287, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-a-resource-to-identify-functionally-redundant-genes", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 116}}, {"pk": 289, "model": "server.post", "fields": {"rght": 13, "author": 134, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 00:32:45", "lft": 12, "post_type": 109787, "score": 4, "title": "A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "From the same people as Futures in Biotech: [Floss weekly][1]. About free & open software, they had an [episode][2] on Bioperl a while ago.\n\n\n  [1]: http://twit.tv/FLOSS\n  [2]: http://twit.tv/floss96", "comment_count": 0, "html": "<p>From the same people as Futures in Biotech: <a href=\"http://twit.tv/FLOSS\">Floss weekly</a>. About free &amp; open software, they had an <a href=\"http://twit.tv/floss96\">episode</a> on Bioperl a while ago.</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 1, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 134}}, {"pk": 290, "model": "server.post", "fields": {"rght": 6, "author": 135, "answer_accepted": true, "tag_string": "blast c mpi sequence", "creation_date": "2010-03-15 07:11:09", "lft": 1, "post_type": 164033, "score": 2, "title": "Performing BLAST/SmithWaterman searches directly from my application", "unanswered": false, "content": "*Bringing in my questions from [stackoverflow][1]:*\n\n\n\nI'm working on a small application and thinking about integrating BLAST or other local alignment searches into my application. My searching has only brought up programs, which need to be installed and called as an external program.\n\nIs there a way short of me implementing it from scratch? Any pre-made library perhaps?\n\n\n  [1]: http://stackoverflow.com/questions/1432467/performing-blast-smithwaterman-searches-directly-from-my-application", "comment_count": 0, "html": "<p><em>Bringing in my questions from <a href=\"http://stackoverflow.com/questions/1432467/performing-blast-smithwaterman-searches-directly-from-my-application\">stackoverflow</a>:</em></p>\n<p>I'm working on a small application and thinking about integrating BLAST or other local alignment searches into my application. My searching has only brought up programs, which need to be installed and called as an external program.</p>\n<p>Is there a way short of me implementing it from scratch? Any pre-made library perhaps?</p>", "child_count": 0, "closed": false, "tree_id": 70, "revision_count": 1, "parent": null, "views": 155, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:31", "slug": "performing-blastsmithwaterman-searches-directly-from-my-application", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [40, 43, 124, 125], "lastedit_user": 135}}, {"pk": 291, "model": "server.post", "fields": {"rght": 3, "author": 135, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 07:12:01", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Performing BLAST/SmithWaterman searches directly from my application", "unanswered": false, "content": "I found the [NCBI C++ Toolkit][1] to be quite useful.\n\n\n  [1]: http://www.ncbi.nlm.nih.gov/IEB/ToolBox/CPP_DOC/", "comment_count": 0, "html": "<p>I found the <a href=\"http://www.ncbi.nlm.nih.gov/IEB/ToolBox/CPP_DOC/\">NCBI C++ Toolkit</a> to be quite useful.</p>", "child_count": 0, "closed": false, "tree_id": 70, "revision_count": 1, "parent": 290, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:21", "slug": "a-performing-blastsmithwaterman-searches-directly-from-my-application", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 135}}, {"pk": 292, "model": "server.post", "fields": {"rght": 5, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 12:12:24", "lft": 4, "post_type": 109787, "score": 4, "title": "A: Performing BLAST/SmithWaterman searches directly from my application", "unanswered": false, "content": "Also the [SeqAn][1] C++ library may be useful to some.\n\n\n  [1]: http://www.seqan.de/ ", "comment_count": 0, "html": "<p>Also the <a href=\"http://www.seqan.de/\">SeqAn</a> C++ library may be useful to some.</p>", "child_count": 0, "closed": false, "tree_id": 70, "revision_count": 1, "parent": 290, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-performing-blastsmithwaterman-searches-directly-from-my-application", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 118}}, {"pk": 293, "model": "server.post", "fields": {"rght": 7, "author": 137, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 15:02:35", "lft": 6, "post_type": 109787, "score": 4, "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "These are the big challenge(s) for me:\n \n 1. Ask the relevant questions and find/develop the proper/satisfactory solutions to obtain meaningful results.\n 2. Determine what is relevant (what really matters).\n 3. Understand what and why is proper, merely sufficient or unsatisfactory.\n 4. Interpret the results without bias and preconceptions.\n \n\n \n\n\n", "comment_count": 0, "html": "<p>These are the big challenge(s) for me:</p>\n<ol>\n<li>Ask the relevant questions and find/develop the proper/satisfactory solutions to obtain meaningful results.</li>\n<li>Determine what is relevant (what really matters).</li>\n<li>Understand what and why is proper, merely sufficient or unsatisfactory.</li>\n<li>Interpret the results without bias and preconceptions.</li>\n</ol>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 1, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 137}}, {"pk": 294, "model": "server.post", "fields": {"rght": 9, "author": 34, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 16:56:44", "lft": 8, "post_type": 109787, "score": 5, "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "**Trivial**\n\n - Creating lists of genes that might be of interest in a given system\n - Integrating several experiments with one kind of data\n - Talking with people in my own sub-disciplines of biology\n - Thinking of cool experiments to do\n\n**Challenging**\n\n - Determining which genes in a list are important for a process and integrating those genes in to current domain-specific understanding in a meaningful way\n - Integrating several experiments across totally different kinds of data\n - Talking with people in other sub-disciplines of biology and actually understanding each other well enough to collaborate effectively\n - Thinking of the most important and useful questions to ask\n - Getting funding", "comment_count": 0, "html": "<p><strong>Trivial</strong></p>\n<ul>\n<li>Creating lists of genes that might be of interest in a given system</li>\n<li>Integrating several experiments with one kind of data</li>\n<li>Talking with people in my own sub-disciplines of biology</li>\n<li>Thinking of cool experiments to do</li>\n</ul>\n<p><strong>Challenging</strong></p>\n<ul>\n<li>Determining which genes in a list are important for a process and integrating those genes in to current domain-specific understanding in a meaningful way</li>\n<li>Integrating several experiments across totally different kinds of data</li>\n<li>Talking with people in other sub-disciplines of biology and actually understanding each other well enough to collaborate effectively</li>\n<li>Thinking of the most important and useful questions to ask</li>\n<li>Getting funding</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 1, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 34}}, {"pk": 295, "model": "server.post", "fields": {"rght": 11, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 18:45:16", "lft": 10, "post_type": 109787, "score": 2, "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "\n\nMost challenging: processing contradictory information and identifying the credible evidence.\n", "comment_count": 0, "html": "<p>Most challenging: processing contradictory information and identifying the credible evidence.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 1, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:21", "slug": "a-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 296, "model": "server.post", "fields": {"rght": 32, "author": 1, "answer_accepted": false, "tag_string": "job career", "creation_date": "2010-03-15 18:57:44", "lft": 1, "post_type": 164033, "score": 19, "title": "Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "What do you recommend as the most appropriate site to advertise (or look for) bioinformatics related job openings.", "comment_count": 0, "html": "<p>What do you recommend as the most appropriate site to advertise (or look for) bioinformatics related job openings.</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 1, "parent": null, "views": 2064, "deleted": false, "answer_count": 22, "touch_date": "2011-11-24 14:49:31", "slug": "where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [110, 126], "lastedit_user": 1}}, {"pk": 297, "model": "server.post", "fields": {"rght": 3, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 19:27:51", "lft": 2, "post_type": 109787, "score": 3, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "I think it is easier to look at the home pages of the laboratories that work in a topic of your interest and ask; however, there are a few generic places:\n\n - [Nature Jobs][1], for example [these][2]\n - [Linked In][3], in particular groups like [Bioinformatics Geeks][4] or [Bioinformatics Computing][5]\n\n\n  [1]: http://www.nature.com/naturejobs/index.html\n  [2]: http://www.nature.com/naturejobs/science/searches/13075465-all-bioinformatics-jobs#search-results\n  [3]: http://www.linkedin.com/\n  [4]: http://www.linkedin.com/groups?gid=65325&trk=anetsrch_name&goback=%2Egdr_1268681143545_1\n  [5]: http://www.linkedin.com/groups?gid=96837&trk=anetsrch_name&goback=%2Egdr_1268681143545_1", "comment_count": 0, "html": "<p>I think it is easier to look at the home pages of the laboratories that work in a topic of your interest and ask; however, there are a few generic places:</p>\n<ul>\n<li><a href=\"http://www.nature.com/naturejobs/index.html\">Nature Jobs</a>, for example <a href=\"http://www.nature.com/naturejobs/science/searches/13075465-all-bioinformatics-jobs#search-results\">these</a></li>\n<li><a href=\"http://www.linkedin.com/\">Linked In</a>, in particular groups like <a href=\"http://www.linkedin.com/groups?gid=65325&amp;trk=anetsrch_name&amp;goback=%2Egdr_1268681143545_1\">Bioinformatics Geeks</a> or <a href=\"http://www.linkedin.com/groups?gid=96837&amp;trk=anetsrch_name&amp;goback=%2Egdr_1268681143545_1\">Bioinformatics Computing</a></li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 1, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 298, "model": "server.post", "fields": {"rght": 5, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 19:52:48", "lft": 4, "post_type": 109787, "score": 9, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": " * Biojobs on FriendFeed: http://friendfeed.com/biojobs\n * The (French) Bioinfo mailing list (but many international positions) http://listes.sfbi.fr/wws/info/bioinfo\n * http://www.nature.com/naturejobs/index.html (nature jobs)\n * some yahoo pipes .e.g. http://pipes.yahoo.com/pipes/search?q=bioinformatics+job&x=0&y=0\n * (...)", "comment_count": 0, "html": "<ul>\n<li>Biojobs on FriendFeed: http://friendfeed.com/biojobs</li>\n<li>The (French) Bioinfo mailing list (but many international positions) http://listes.sfbi.fr/wws/info/bioinfo</li>\n<li>http://www.nature.com/naturejobs/index.html (nature jobs)</li>\n<li>some yahoo pipes .e.g. http://pipes.yahoo.com/pipes/search?q=bioinformatics+job&amp;x=0&amp;y=0</li>\n<li>(...)</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 1, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 299, "model": "server.post", "fields": {"rght": 9, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 20:20:37", "lft": 6, "post_type": 109787, "score": 4, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": " 1. Some companies do not longer publish\n    their vacancies in newspapers but\n    instead use their own vacancy\n    web-site. This is helpful and\n    up-to-date (well, should be), but\n    the counterside is that there's no\n    longer a central place where you can\n    find all actual vacant jobs. So if\n    you are searching for a job you have\n    to check out a score of websites on\n    a regular base. To make this\n    somewhat easier the [Geneyous\n    JobReport][1] has been set up.\n    \n    The  JobReport checks the vacancy\n    pages of several (mostly Dutch)\n    companies and institutes on a\n    regular base on keywords like\n    genomics, bio-informatician,\n    genetics, scientific programmer and\n    more, including Dutch translations.\n    \n    The results are placed in a grid and\n    arrows indicate if the number of\n    keywords has\n    increased/decreased/remained stable\n    the last month.\n\n 2. [AcademicTransfer][2] is the joint job board of Dutch universities, university medical centers and research institutions. Use this website to search jobs, career opportunities and trends in the Dutch and international academic job market.\n\n 3. The [Bioinformatics Organization Career Center][3]\n\n\n\n  [1]: http://www.geneyous.nl/jobreport/\n  [2]: http://www.academictransfer.com/search_results/?q=bioinformatics&find=Search&phd_position=\n  [3]: http://www.bioinformatics.org/jobs/\n  [4]: http://www.bioinformatics.fr/jobs.php", "comment_count": 1, "html": "<ol>\n<li>\n<p>Some companies do not longer publish\n<div class=\"highlight\"><pre>    <span class=\"n\">their</span> <span class=\"n\">vacancies</span> <span class=\"n\">in</span> <span class=\"n\">newspapers</span> <span class=\"n\">but</span>\n    <span class=\"n\">instead</span> <span class=\"k\">use</span> <span class=\"n\">their</span> <span class=\"n\">own</span> <span class=\"n\">vacancy</span>\n    <span class=\"n\">web</span><span class=\"o\">-</span><span class=\"n\">site</span><span class=\"o\">.</span> <span class=\"n\">This</span> <span class=\"n\">is</span> <span class=\"n\">helpful</span> <span class=\"ow\">and</span>\n    <span class=\"n\">up</span><span class=\"o\">-</span><span class=\"n\">to</span><span class=\"o\">-</span><span class=\"n\">date</span> <span class=\"p\">(</span><span class=\"n\">well</span><span class=\"p\">,</span> <span class=\"n\">should</span> <span class=\"n\">be</span><span class=\"p\">),</span> <span class=\"n\">but</span>\n    <span class=\"n\">the</span> <span class=\"n\">counterside</span> <span class=\"n\">is</span> <span class=\"n\">that</span> <span class=\"n\">there</span><span class=\"err\">&#39;</span><span class=\"n\">s</span> <span class=\"nb\">no</span>\n    <span class=\"n\">longer</span> <span class=\"n\">a</span> <span class=\"n\">central</span> <span class=\"n\">place</span> <span class=\"n\">where</span> <span class=\"n\">you</span> <span class=\"n\">can</span>\n    <span class=\"n\">find</span> <span class=\"n\">all</span> <span class=\"n\">actual</span> <span class=\"n\">vacant</span> <span class=\"n\">jobs</span><span class=\"o\">.</span> <span class=\"n\">So</span> <span class=\"k\">if</span>\n    <span class=\"n\">you</span> <span class=\"n\">are</span> <span class=\"n\">searching</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"n\">job</span> <span class=\"n\">you</span> <span class=\"n\">have</span>\n    <span class=\"n\">to</span> <span class=\"n\">check</span> <span class=\"n\">out</span> <span class=\"n\">a</span> <span class=\"n\">score</span> <span class=\"n\">of</span> <span class=\"n\">websites</span> <span class=\"n\">on</span>\n    <span class=\"n\">a</span> <span class=\"n\">regular</span> <span class=\"n\">base</span><span class=\"o\">.</span> <span class=\"n\">To</span> <span class=\"n\">make</span> <span class=\"n\">this</span>\n    <span class=\"n\">somewhat</span> <span class=\"n\">easier</span> <span class=\"n\">the</span> <span class=\"p\">[</span><span class=\"n\">Geneyous</span>\n    <span class=\"n\">JobReport</span><span class=\"p\">][</span><span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"n\">has</span> <span class=\"n\">been</span> <span class=\"n\">set</span> <span class=\"n\">up</span><span class=\"o\">.</span>\n    \n    <span class=\"n\">The</span>  <span class=\"n\">JobReport</span> <span class=\"n\">checks</span> <span class=\"n\">the</span> <span class=\"n\">vacancy</span>\n    <span class=\"n\">pages</span> <span class=\"n\">of</span> <span class=\"n\">several</span> <span class=\"p\">(</span><span class=\"n\">mostly</span> <span class=\"n\">Dutch</span><span class=\"p\">)</span>\n    <span class=\"n\">companies</span> <span class=\"ow\">and</span> <span class=\"n\">institutes</span> <span class=\"n\">on</span> <span class=\"n\">a</span>\n    <span class=\"n\">regular</span> <span class=\"n\">base</span> <span class=\"n\">on</span> <span class=\"n\">keywords</span> <span class=\"n\">like</span>\n    <span class=\"n\">genomics</span><span class=\"p\">,</span> <span class=\"n\">bio</span><span class=\"o\">-</span><span class=\"n\">informatician</span><span class=\"p\">,</span>\n    <span class=\"n\">genetics</span><span class=\"p\">,</span> <span class=\"n\">scientific</span> <span class=\"n\">programmer</span> <span class=\"ow\">and</span>\n    <span class=\"n\">more</span><span class=\"p\">,</span> <span class=\"n\">including</span> <span class=\"n\">Dutch</span> <span class=\"n\">translations</span><span class=\"o\">.</span>\n    \n    <span class=\"n\">The</span> <span class=\"n\">results</span> <span class=\"n\">are</span> <span class=\"n\">placed</span> <span class=\"n\">in</span> <span class=\"n\">a</span> <span class=\"n\">grid</span> <span class=\"ow\">and</span>\n    <span class=\"n\">arrows</span> <span class=\"n\">indicate</span> <span class=\"k\">if</span> <span class=\"n\">the</span> <span class=\"n\">number</span> <span class=\"n\">of</span>\n    <span class=\"n\">keywords</span> <span class=\"n\">has</span>\n    <span class=\"n\">increased</span><span class=\"sr\">/decreased/</span><span class=\"n\">remained</span> <span class=\"n\">stable</span>\n    <span class=\"n\">the</span> <span class=\"k\">last</span> <span class=\"n\">month</span><span class=\"o\">.</span>\n</pre></div>\n</p>\n</li>\n<li>\n<p><a href=\"http://www.academictransfer.com/search_results/?q=bioinformatics&amp;find=Search&amp;phd_position=\">AcademicTransfer</a> is the joint job board of Dutch universities, university medical centers and research institutions. Use this website to search jobs, career opportunities and trends in the Dutch and international academic job market.</p>\n</li>\n<li>\n<p>The <a href=\"http://www.bioinformatics.org/jobs/\">Bioinformatics Organization Career Center</a></p>\n</li>\n</ol>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 2, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 300, "model": "server.post", "fields": {"rght": 9, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 21:50:36", "lft": 8, "post_type": 109787, "score": 4, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "You can also checked [http://www.bioinformatics.fr/jobs.php][1] with a dedicated RSS feed.</p>\n<p>When I have the time I also try to compile jobs from other sources like :</p>\n\n - [jobs.ac.uk][2] \n - [bioinformatics.org][3]\n - [listbioinfo][4] (see Pierre post)\n - [iscb.org][5] \n - [biospace.com][6]\n\n\n  [1]: http://www.bioinformatics.fr/jobs.php\n  [2]: http://www.jobs.ac.uk/cgi-bin/search.cgi?keywords=bioinformatics&x=0&y=0\n  [3]: http://www.bioinformatics.org/jobs/\n  [4]: http://listes.sfbi.fr/wws/info/bioinfo\n  [5]: http://www.iscb.org/iscb-careers\n  [6]: http://www.biospace.com/search_results_jobs.aspx?SearchWord=%25%25&TheLocation=%25%25", "comment_count": 0, "html": "<p>You can also checked <a href=\"http://www.bioinformatics.fr/jobs.php\">http://www.bioinformatics.fr/jobs.php</a> with a dedicated RSS feed.[HTML_REMOVED]\n[HTML_REMOVED]When I have the time I also try to compile jobs from other sources like :[HTML_REMOVED]</p>\n<ul>\n<li><a href=\"http://www.jobs.ac.uk/cgi-bin/search.cgi?keywords=bioinformatics&amp;x=0&amp;y=0\">jobs.ac.uk</a> </li>\n<li><a href=\"http://www.bioinformatics.org/jobs/\">bioinformatics.org</a></li>\n<li><a href=\"http://listes.sfbi.fr/wws/info/bioinfo\">listbioinfo</a> (see Pierre post)</li>\n<li><a href=\"http://www.iscb.org/iscb-careers\">iscb.org</a> </li>\n<li><a href=\"http://www.biospace.com/search_results_jobs.aspx?SearchWord=%25%25&amp;TheLocation=%25%25\">biospace.com</a></li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 3, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 301, "model": "server.post", "fields": {"rght": 9, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 22:14:03", "lft": 8, "post_type": 109787, "score": 3, "title": "A: Mapping SNPs to Pathways", "unanswered": false, "content": "Pierre,\n\nAs soon as you get the Entrez gene Id related to your SNPs you can query KEGG or WikiPathways that should provide Entrez gene Ids related to a given pathway.\nThe good think with this two websites is that with some SVG you can customized the graphic view of the pathways in order to highlight genes that have the SNPs.\nHope this helps.\n\nFred", "comment_count": 0, "html": "<p>Pierre,</p>\n<p>As soon as you get the Entrez gene Id related to your SNPs you can query KEGG or WikiPathways that should provide Entrez gene Ids related to a given pathway.\nThe good think with this two websites is that with some SVG you can customized the graphic view of the pathways in order to highlight genes that have the SNPs.\nHope this helps.</p>\n<p>Fred</p>", "child_count": 0, "closed": false, "tree_id": 41, "revision_count": 1, "parent": 142, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-mapping-snps-to-pathways", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 302, "model": "server.post", "fields": {"rght": 30, "author": 142, "answer_accepted": true, "tag_string": "biopython blast", "creation_date": "2010-03-15 23:24:58", "lft": 1, "post_type": 164033, "score": 4, "title": "Compare two protein sequences using local BLAST", "unanswered": false, "content": "Hi,\n\nI have been given a task to compare the all the protein sequences of a strain of campylobacter with a strain of E.coli. I would like to do this locally using Biopython and the inbuilt Blast tools. However, I'm stuck on how to program this and what tools I should be using. If anybody could point me in the right direction, I would be thankful!\n\nCheers", "comment_count": 0, "html": "<p>Hi,</p>\n<p>I have been given a task to compare the all the protein sequences of a strain of campylobacter with a strain of E.coli. I would like to do this locally using Biopython and the inbuilt Blast tools. However, I'm stuck on how to program this and what tools I should be using. If anybody could point me in the right direction, I would be thankful!</p>\n<p>Cheers</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 2, "parent": null, "views": 1086, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:29", "slug": "compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [43, 60], "lastedit_user": 142}}, {"pk": 303, "model": "server.post", "fields": {"rght": 11, "author": 34, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 00:07:51", "lft": 10, "post_type": 109787, "score": 3, "title": "A: Mapping SNPs to Pathways", "unanswered": false, "content": "I haven't used it myself, but [GRAIL][1] was built for this sort of problem in GWAS. It looks pretty impressive from what I've seen.\n\n\n  [1]: http://www.broadinstitute.org/mpg/grail/", "comment_count": 0, "html": "<p>I haven't used it myself, but <a href=\"http://www.broadinstitute.org/mpg/grail/\">GRAIL</a> was built for this sort of problem in GWAS. It looks pretty impressive from what I've seen.</p>", "child_count": 0, "closed": false, "tree_id": 41, "revision_count": 1, "parent": 142, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-mapping-snps-to-pathways", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 34}}, {"pk": 304, "model": "server.post", "fields": {"rght": 3, "author": 121, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 04:34:58", "lft": 2, "post_type": 109787, "score": 7, "title": "A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "The BLAST section of the BioPython module is not terribly well documented.  The relevant section is [here][1].  Before starting you'll need to create a local BLAST database ... To my knowledge there is no way to do this directly through BioPython (but you could use the Subprocess module to automate the commandline if you really wanted too) ... The documentation for the BLAST tool is on the NCBI website [here][2].  You'll obviously need to download the whole genome sequences ... I suggest using the NCBI FTP site, I can never seem to find the right link in the normal webportal.\n\nOnce you have all of the relevant downloads and databases created you'll simply need to run the BLAST query in a loop that processes all of the data.  Something like this should work (I don't have the required data to test this but it should get you 95% of the way there.)\n\n    from Bio.Blast.Applications import NcbiblastxCommandline\n    from Bio.Blast import NCBIXML\n    from Bio import SeqIO\n    import subprocess\n    \n    SOURCE_FASTA = '/path/to/source/seq.fasta'\n    DATABASE = 'databsename' #should be in the path but YMMV\n    \n    with open(SOURCE_FASTA) as inhandle:\n    \tfor seq in SeqIO.parse(handle, 'fasta'):\n    \t\twith open('scratch.fasta', 'w') as outhandle:\n    \t\t\t#write a scratch file\n    \t\t\tSeqIO.write(seq, outhandle, 'fasta')\n    \t\t\n    \t\t#create the commandline string\n    \t\tcline = NcbiblastxCommandline(query='scratch.fasta', \n                        db=DATABASE, evalue=0.001, outfmt=5, out=\"scratch.xml\")\n    \t\t\n    \t\t#actually run BLAST\n    \t\treturn_code = subprocess.call(str(cline))\n    \t\t\n    \t\tif return_code == 0:\n    \t\t\t#if it was successful then process it\n    \t\t\twith open('scratch.xml') as xmlhandle:\n    \t\t\t\tblast_record = NCBIXML.read(xmlhandle)\n    \t\t\t\t\n    \t\t\t\tdo_something_with_results(blast_record)\n\t\t\t\t\n\t\t\nHope that helps.\n\n  [1]: http://www.biopython.org/DIST/docs/tutorial/Tutorial.html#htoc77\n  [2]: ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/user_manual.pdf", "comment_count": 0, "html": "<p>The BLAST section of the BioPython module is not terribly well documented.  The relevant section is <a href=\"http://www.biopython.org/DIST/docs/tutorial/Tutorial.html#htoc77\">here</a>.  Before starting you'll need to create a local BLAST database ... To my knowledge there is no way to do this directly through BioPython (but you could use the Subprocess module to automate the commandline if you really wanted too) ... The documentation for the BLAST tool is on the NCBI website <a href=\"ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/user_manual.pdf\">here</a>.  You'll obviously need to download the whole genome sequences ... I suggest using the NCBI FTP site, I can never seem to find the right link in the normal webportal.</p>\n<p>Once you have all of the relevant downloads and databases created you'll simply need to run the BLAST query in a loop that processes all of the data.  Something like this should work (I don't have the required data to test this but it should get you 95% of the way there.)</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">from</span> <span class=\"n\">Bio</span><span class=\"o\">.</span><span class=\"n\">Blast</span><span class=\"o\">.</span><span class=\"n\">Applications</span> <span class=\"nb\">import</span> <span class=\"n\">NcbiblastxCommandline</span>\n    <span class=\"n\">from</span> <span class=\"n\">Bio</span><span class=\"o\">.</span><span class=\"n\">Blast</span> <span class=\"nb\">import</span> <span class=\"n\">NCBIXML</span>\n    <span class=\"n\">from</span> <span class=\"n\">Bio</span> <span class=\"nb\">import</span> <span class=\"n\">SeqIO</span>\n    <span class=\"nb\">import</span> <span class=\"n\">subprocess</span>\n    \n    <span class=\"n\">SOURCE_FASTA</span> <span class=\"o\">=</span> <span class=\"s\">&#39;/path/to/source/seq.fasta&#39;</span>\n    <span class=\"n\">DATABASE</span> <span class=\"o\">=</span> <span class=\"s\">&#39;databsename&#39;</span> <span class=\"c1\">#should be in the path but YMMV</span>\n    \n    <span class=\"n\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"n\">SOURCE_FASTA</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">inhandle:</span>\n    \t<span class=\"k\">for</span> <span class=\"n\">seq</span> <span class=\"n\">in</span> <span class=\"n\">SeqIO</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span><span class=\"n\">handle</span><span class=\"p\">,</span> <span class=\"s\">&#39;fasta&#39;</span><span class=\"p\">):</span>\n    \t\t<span class=\"n\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s\">&#39;scratch.fasta&#39;</span><span class=\"p\">,</span> <span class=\"s\">&#39;w&#39;</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">outhandle:</span>\n    \t\t\t<span class=\"c1\">#write a scratch file</span>\n    \t\t\t<span class=\"n\">SeqIO</span><span class=\"o\">.</span><span class=\"nb\">write</span><span class=\"p\">(</span><span class=\"n\">seq</span><span class=\"p\">,</span> <span class=\"n\">outhandle</span><span class=\"p\">,</span> <span class=\"s\">&#39;fasta&#39;</span><span class=\"p\">)</span>\n    \t\t\n    \t\t<span class=\"c1\">#create the commandline string</span>\n    \t\t<span class=\"n\">cline</span> <span class=\"o\">=</span> <span class=\"n\">NcbiblastxCommandline</span><span class=\"p\">(</span><span class=\"n\">query</span><span class=\"o\">=</span><span class=\"s\">&#39;scratch.fasta&#39;</span><span class=\"p\">,</span> \n                        <span class=\"n\">db</span><span class=\"o\">=</span><span class=\"n\">DATABASE</span><span class=\"p\">,</span> <span class=\"n\">evalue</span><span class=\"o\">=</span><span class=\"mf\">0.001</span><span class=\"p\">,</span> <span class=\"n\">outfmt</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"n\">out</span><span class=\"o\">=</span><span class=\"s\">&quot;scratch.xml&quot;</span><span class=\"p\">)</span>\n    \t\t\n    \t\t<span class=\"c1\">#actually run BLAST</span>\n    \t\t<span class=\"n\">return_code</span> <span class=\"o\">=</span> <span class=\"n\">subprocess</span><span class=\"o\">.</span><span class=\"n\">call</span><span class=\"p\">(</span><span class=\"n\">str</span><span class=\"p\">(</span><span class=\"n\">cline</span><span class=\"p\">))</span>\n    \t\t\n    \t\t<span class=\"k\">if</span> <span class=\"n\">return_code</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n    \t\t\t<span class=\"c1\">#if it was successful then process it</span>\n    \t\t\t<span class=\"n\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s\">&#39;scratch.xml&#39;</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">xmlhandle:</span>\n    \t\t\t\t<span class=\"n\">blast_record</span> <span class=\"o\">=</span> <span class=\"n\">NCBIXML</span><span class=\"o\">.</span><span class=\"nb\">read</span><span class=\"p\">(</span><span class=\"n\">xmlhandle</span><span class=\"p\">)</span>\n    \t\t\t\t\n    \t\t\t\t<span class=\"n\">do_something_with_results</span><span class=\"p\">(</span><span class=\"n\">blast_record</span><span class=\"p\">)</span>\n\t\t\t\t\n\t\t\n</pre></div>\n\nHope that helps.</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 1, "parent": 302, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 121}}, {"pk": 305, "model": "server.post", "fields": {"rght": 23, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 04:36:10", "lft": 4, "post_type": 109787, "score": 10, "title": "A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "hi, if you're having trouble, maybe it'd be wiser to do the simplest analysis--just do an all-vs-all blastp directly using the command-line-interface to blast. For example use E.coli as the subject and the other species as the query and a command like:\n\n    $ formatdb -p T -i ecoli.fa\n    $ blastall -d ecoli.fa -i other.fa -p blastn -m 8 -e 0.01 -o ecoli_other.blast\n\nUsing the -m 8 option, you can parse the tab-delimited blast file with few lines of code. This assumes you have the protein fasta files in hand--the are probably available from ncbi or your favorite bacteria genome repository.", "comment_count": 9, "html": "<p>hi, if you're having trouble, maybe it'd be wiser to do the simplest analysis--just do an all-vs-all blastp directly using the command-line-interface to blast. For example use E.coli as the subject and the other species as the query and a command like:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"nv\">$</span> <span class=\"nv\">formatdb</span> <span class=\"o\">-</span><span class=\"n\">p</span> <span class=\"n\">T</span> <span class=\"o\">-</span><span class=\"n\">i</span> <span class=\"n\">ecoli</span><span class=\"o\">.</span><span class=\"n\">fa</span>\n    <span class=\"nv\">$</span> <span class=\"nv\">blastall</span> <span class=\"o\">-</span><span class=\"n\">d</span> <span class=\"n\">ecoli</span><span class=\"o\">.</span><span class=\"n\">fa</span> <span class=\"o\">-</span><span class=\"n\">i</span> <span class=\"n\">other</span><span class=\"o\">.</span><span class=\"n\">fa</span> <span class=\"o\">-</span><span class=\"n\">p</span> <span class=\"n\">blastn</span> <span class=\"o\">-</span><span class=\"n\">m</span> <span class=\"mi\">8</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"mf\">0.01</span> <span class=\"o\">-</span><span class=\"n\">o</span> <span class=\"n\">ecoli_other</span><span class=\"o\">.</span><span class=\"n\">blast</span>\n</pre></div>\n</p>\n<p>Using the -m 8 option, you can parse the tab-delimited blast file with few lines of code. This assumes you have the protein fasta files in hand--the are probably available from ncbi or your favorite bacteria genome repository.</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 2, "parent": 302, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 35}}, {"pk": 306, "model": "server.post", "fields": {"rght": 11, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 06:21:11", "lft": 10, "post_type": 109787, "score": 5, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "BioPlanet is quite active, for both advertising and searching: http://www.bioplanet.com/planetforums/forumdisplay.php?fid=1.\n\nIn Australia I use the jobs portal Seek - http://www.seek.com.au/ - I'm sure other countries have a similar website.\n\nAdvertising?  Twitter, with the hash tags #bioinformatics #jobs.", "comment_count": 0, "html": "<p>BioPlanet is quite active, for both advertising and searching: http://www.bioplanet.com/planetforums/forumdisplay.php?fid=1.</p>\n<p>In Australia I use the jobs portal Seek - http://www.seek.com.au/ - I'm sure other countries have a similar website.</p>\n<p>Advertising?  Twitter, with the hash tags #bioinformatics #jobs.</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 1, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 307, "model": "server.post", "fields": {"rght": 7, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 07:07:24", "lft": 6, "post_type": 109787, "score": 4, "title": "A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "If the genomes are public, someone may have done this analysis for you, or there may be a web-based tool to do the job.\n\nFor example, here is a genome comparison tool at the JCVI/CMR - http://cmr.jcvi.org/cgi-bin/CMR/shared/MakeFrontPages.cgi?page=circular_display.\n\nThe JGI Integrated Microbial Genome system is also very good - http://img.jgi.doe.gov. It allows you to select multiple genomes for various comparative analyses.  I believe they may even have all versus all data buried away in their FTP archive somewhere.  However, take some time to get used to the site - it has quite a steep learning curve.", "comment_count": 0, "html": "<p>If the genomes are public, someone may have done this analysis for you, or there may be a web-based tool to do the job.</p>\n<p>For example, here is a genome comparison tool at the JCVI/CMR - http://cmr.jcvi.org/cgi-bin/CMR/shared/MakeFrontPages.cgi?page=circular_display.</p>\n<p>The JGI Integrated Microbial Genome system is also very good - http://img.jgi.doe.gov. It allows you to select multiple genomes for various comparative analyses.  I believe they may even have all versus all data buried away in their FTP archive somewhere.  However, take some time to get used to the site - it has quite a steep learning curve.</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 1, "parent": 302, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 308, "model": "server.post", "fields": {"rght": 28, "author": 141, "answer_accepted": false, "tag_string": "genome analysis integrated ngs", "creation_date": "2010-03-16 08:39:42", "lft": 1, "post_type": 164033, "score": 8, "title": "Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "Hello,\n\nI am looking for genome (from cell lines or patient samples) that have been fully characterized thanks to the Next Generation Sequencing (NGS) methods.\nI already know the following instances:\n\n - [NCI-H209 cell line][1]\n   \n  \n - [22 Human Glioblastoma Multiforme   \n   samples][2]\n\n   \n  \n\n - [a first Acute Myeloid Leukaemia with minimal maturation \n   (AML-M1) sample][3]\n\n   \n   \n\n - [a second Acute Myeloid Leukaemia with minimal maturation\n   (AML-M1) sample][4]\n\nSo if you know other papers/ressources I would be glad if you could share it with others.\n\nThanks in advance,\n\nFred\n\n  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08629.html\n  [2]: http://www.sciencemag.org/cgi/content/full/321/5897/1807\n  [3]: http://www.nature.com/nature/journal/v456/n7218/full/nature07485.html\n  [4]: http://content.nejm.org/cgi/content/full/361/11/1058", "comment_count": 2, "html": "<p>Hello,</p>\n<p>I am looking for genome (from cell lines or patient samples) that have been fully characterized thanks to the Next Generation Sequencing (NGS) methods.\nI already know the following instances:</p>\n<ul>\n<li>\n<p><a href=\"http://www.nature.com/nature/journal/v463/n7278/full/nature08629.html\">NCI-H209 cell line</a></p>\n</li>\n<li>\n<p><a href=\"http://www.sciencemag.org/cgi/content/full/321/5897/1807\">22 Human Glioblastoma Multiforme <br />\n   samples</a></p>\n</li>\n<li>\n<p><a href=\"http://www.nature.com/nature/journal/v456/n7218/full/nature07485.html\">a first Acute Myeloid Leukaemia with minimal maturation \n   (AML-M1) sample</a></p>\n</li>\n<li>\n<p><a href=\"http://content.nejm.org/cgi/content/full/361/11/1058\">a second Acute Myeloid Leukaemia with minimal maturation\n   (AML-M1) sample</a></p>\n</li>\n</ul>\n<p>So if you know other papers/ressources I would be glad if you could share it with others.</p>\n<p>Thanks in advance,</p>\n<p>Fred</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 4, "parent": null, "views": 360, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:28", "slug": "which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [67, 213, 214, 215], "lastedit_user": 141}}, {"pk": 309, "model": "server.post", "fields": {"rght": 13, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 08:52:17", "lft": 12, "post_type": 109787, "score": 4, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "In the UK, pretty much every academic job is listed on http://www.jobs.ac.uk/ - they have good mechanisms for filtering the stream.\n\nThe New Scientist is a good place to find openings too - http://www.newscientistjobs.com/jobs/default.aspx\n\nAs for advertising... I agree with Neil - Twitter + hash tags.\n\n", "comment_count": 0, "html": "<p>In the UK, pretty much every academic job is listed on http://www.jobs.ac.uk/ - they have good mechanisms for filtering the stream.</p>\n<p>The New Scientist is a good place to find openings too - http://www.newscientistjobs.com/jobs/default.aspx</p>\n<p>As for advertising... I agree with Neil - Twitter + hash tags.</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 1, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 310, "model": "server.post", "fields": {"rght": 32, "author": 22, "answer_accepted": true, "tag_string": "subjective agile sturdy team development", "creation_date": "2010-03-16 10:09:33", "lft": 1, "post_type": 164033, "score": 3, "title": "Which software development technique is used in your lab? ", "unanswered": false, "content": "On this page of the [software carpentry manual][1] you can find a brief introduction to different software development techniques, including agile and sturdy ones. \n\nWhich of these development model is closer to the one you use on your lab? How do you work together with your teammates?\n\nnote: If you are interested, I can provide you with more documents to describe the different development techniques.\n\n\n  [1]: http://software-carpentry.org/lifecycle.html", "comment_count": 0, "html": "<p>On this page of the <a href=\"http://software-carpentry.org/lifecycle.html\">software carpentry manual</a> you can find a brief introduction to different software development techniques, including agile and sturdy ones. </p>\n<p>Which of these development model is closer to the one you use on your lab? How do you work together with your teammates?</p>\n<p>note: If you are interested, I can provide you with more documents to describe the different development techniques.</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 1, "parent": null, "views": 352, "deleted": false, "answer_count": 16, "touch_date": "2011-11-24 14:49:26", "slug": "which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [32, 57, 59, 127, 128], "lastedit_user": 22}}, {"pk": 311, "model": "server.post", "fields": {"rght": 36, "author": 144, "answer_accepted": true, "tag_string": "recommendations books blog", "creation_date": "2010-03-16 10:47:33", "lft": 1, "post_type": 164033, "score": 4, "title": "How to get started in bioinformatics?", "unanswered": false, "content": "I am a Software Engineering student (with decent background in biology) and would like to explore the field of bioinformatics. I am completely new to the field and would like some pointers on where and how to get started.\n\n - Is there any book I should read?  \n - Any interesting online resources?\n - Any interesting blogs / online communities (apart from this one)?\n - What are some of the interesting problems bioinformatics is trying to solve?\n\nAny advice or insight about this industry would be appreciated.", "comment_count": 0, "html": "<p>I am a Software Engineering student (with decent background in biology) and would like to explore the field of bioinformatics. I am completely new to the field and would like some pointers on where and how to get started.</p>\n<ul>\n<li>Is there any book I should read?<br />\n</li>\n<li>Any interesting online resources?</li>\n<li>Any interesting blogs / online communities (apart from this one)?</li>\n<li>What are some of the interesting problems bioinformatics is trying to solve?</li>\n</ul>\n<p>Any advice or insight about this industry would be appreciated.</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 3, "parent": null, "views": 1138, "deleted": false, "answer_count": 8, "touch_date": "2011-11-24 14:49:27", "slug": "how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [71, 90, 120], "lastedit_user": 37}}, {"pk": 312, "model": "server.post", "fields": {"rght": 13, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 11:02:00", "lft": 2, "post_type": 109787, "score": 3, "title": "A: How to get started in bioinformatics?", "unanswered": false, "content": "*Note: the below answer is meant to be constructive.* The best way to start in any field is just to listen, learn, and do something. By actually doing something, you best show your intentions, and you get more people listening to your questions.\n\nI am pretty sure Google can help you with getting started, and otherwise have a look around at this forum for topics you like. I have seen questions like yours many times, like so many others before you, you have no idea where to start.\n\nHowever, like all those before you, you make a classical mistake: you forget to formulate what you really like to do. Never ask others what you should do (with your life). Instead, use Google to read up on topic, look around at (Open Source) bioinformatics tools, possibly get additional non-IT education, and decide for yourself what domain question you have. Only then you should start asking around how to proceed.\n\nThe reason underlying this, is that those reading your question, like me, have no clue about your background, your interested, while at the same time, there is so many interesting things to do. You basically ask us what is the answer to the world, but I am pretty sure 42 is not the answer you are looking for.\n\nSo, first do some research yourself, pick a topic yourself, formulate questions you have on that topic that Google, Wikipedia, your university courses do not tell you, and then pose those questions.", "comment_count": 5, "html": "<p><em>Note: the below answer is meant to be constructive.</em> The best way to start in any field is just to listen, learn, and do something. By actually doing something, you best show your intentions, and you get more people listening to your questions.</p>\n<p>I am pretty sure Google can help you with getting started, and otherwise have a look around at this forum for topics you like. I have seen questions like yours many times, like so many others before you, you have no idea where to start.</p>\n<p>However, like all those before you, you make a classical mistake: you forget to formulate what you really like to do. Never ask others what you should do (with your life). Instead, use Google to read up on topic, look around at (Open Source) bioinformatics tools, possibly get additional non-IT education, and decide for yourself what domain question you have. Only then you should start asking around how to proceed.</p>\n<p>The reason underlying this, is that those reading your question, like me, have no clue about your background, your interested, while at the same time, there is so many interesting things to do. You basically ask us what is the answer to the world, but I am pretty sure 42 is not the answer you are looking for.</p>\n<p>So, first do some research yourself, pick a topic yourself, formulate questions you have on that topic that Google, Wikipedia, your university courses do not tell you, and then pose those questions.</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 2, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 313, "model": "server.post", "fields": {"rght": 5, "author": 135, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 11:28:50", "lft": 4, "post_type": 109787, "score": 1, "title": "A: How to get started in bioinformatics?", "unanswered": false, "content": "Does your university offer bioinformatics courses? It might be a better place to start asking there...\n\nBooks: can't really recommend any. There are too many different sub-fields in bioinformatics\n\nOnline: depends what you're interested in, again.\n\nBlogs: not really, I think. If you find any good ones, let me know.\n\nThere seem to be two opposing sides to bioinformatics currently:\n\n - those who studied microbiology and use bioinformatics as a tool (maybe even cobble some scripts together)\n - those who come from the software engineering side and build tools according to these standards.\n\nProblems in bioinformatics:\n\n - sequence analysis, including sequence matching/searching (BLAST et al.), also databases\n - image processing (electron microscopy analysis, microarrays)\n - structure prediction (protein structure, see Folding@Home and others)\n\nMany of these include high performance computing, so you might want to learn stuff about that.\n\nYour question is rather broad. How did you find out about bioinformatics? What made you interested in this field?\n", "comment_count": 0, "html": "<p>Does your university offer bioinformatics courses? It might be a better place to start asking there...</p>\n<p>Books: can't really recommend any. There are too many different sub-fields in bioinformatics</p>\n<p>Online: depends what you're interested in, again.</p>\n<p>Blogs: not really, I think. If you find any good ones, let me know.</p>\n<p>There seem to be two opposing sides to bioinformatics currently:</p>\n<ul>\n<li>those who studied microbiology and use bioinformatics as a tool (maybe even cobble some scripts together)</li>\n<li>those who come from the software engineering side and build tools according to these standards.</li>\n</ul>\n<p>Problems in bioinformatics:</p>\n<ul>\n<li>sequence analysis, including sequence matching/searching (BLAST et al.), also databases</li>\n<li>image processing (electron microscopy analysis, microarrays)</li>\n<li>structure prediction (protein structure, see Folding@Home and others)</li>\n</ul>\n<p>Many of these include high performance computing, so you might want to learn stuff about that.</p>\n<p>Your question is rather broad. How did you find out about bioinformatics? What made you interested in this field?</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 1, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:21", "slug": "a-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 135}}, {"pk": 314, "model": "server.post", "fields": {"rght": 27, "author": 145, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 11:34:46", "lft": 26, "post_type": 109787, "score": 0, "title": "A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "And Will, your example seems overly complicated. Why not just give the multiple query input FASTA file directly to BLAST?\n\nAlso, satsurae - do you have to use BLAST? If the data set is not too big, you could use EMBOSS needleall to do a full Needleman-Wunsch alignment - although this may not offer the statistics you may want.\nhttp://emboss.sourceforge.net/apps/release/6.2/emboss/apps/needleall.html\n\n", "comment_count": 0, "html": "<p>And Will, your example seems overly complicated. Why not just give the multiple query input FASTA file directly to BLAST?</p>\n<p>Also, satsurae - do you have to use BLAST? If the data set is not too big, you could use EMBOSS needleall to do a full Needleman-Wunsch alignment - although this may not offer the statistics you may want.\nhttp://emboss.sourceforge.net/apps/release/6.2/emboss/apps/needleall.html</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 2, "parent": 302, "views": 0, "deleted": true, "answer_count": 0, "touch_date": "2011-11-24 14:48:57", "slug": "a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 145}}, {"pk": 315, "model": "server.post", "fields": {"rght": 7, "author": 145, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 11:39:30", "lft": 6, "post_type": 109787, "score": 1, "title": "A: Computing the reverse and complement of a sequence with Biopython", "unanswered": false, "content": "If you want to reverse a string in Python, you can use a slice with a step of minus one -1,\n\n    rev_str = str[::-1]\n\nIt should not surprise you that you can do the same with a Biopython Seq object:\n\n    rev_seq = seq[::-1]\n\nI guess the Biopython Tutorial you be more explicit but it does cover reversing a sequence like this.\n", "comment_count": 0, "html": "<p>If you want to reverse a string in Python, you can use a slice with a step of minus one -1,</p>\n<p><div class=\"highlight\"><pre>    <span class=\"s-Atom\">rev_str</span> <span class=\"o\">=</span> <span class=\"s-Atom\">str</span><span class=\"p\">[</span><span class=\"s-Atom\">::-</span><span class=\"m\">1</span><span class=\"p\">]</span>\n</pre></div>\n</p>\n<p>It should not surprise you that you can do the same with a Biopython Seq object:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"s-Atom\">rev_seq</span> <span class=\"o\">=</span> <span class=\"s-Atom\">seq</span><span class=\"p\">[</span><span class=\"s-Atom\">::-</span><span class=\"m\">1</span><span class=\"p\">]</span>\n</pre></div>\n</p>\n<p>I guess the Biopython Tutorial you be more explicit but it does cover reversing a sequence like this.</p>", "child_count": 0, "closed": false, "tree_id": 28, "revision_count": 1, "parent": 90, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-computing-the-reverse-and-complement-of-a-sequence-with-biopython", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 145}}, {"pk": 316, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 12:01:15", "lft": 6, "post_type": 109787, "score": 7, "title": "A: How to get started in bioinformatics?", "unanswered": false, "content": "Well, I will answer by redirecting you to other topics :-) :\n\n**Is there any book I should read?**\n\n - Biostar - [recommend your favorite bioinformatics books][1]\n\n**Any interesting online resources?**\n\n - Biostar - [appropriate podcasts for a bioinformatician][2]\n\n**Any interesting blogs / online communities (apart from this one)?**\n\n - Biostar - [your favorite bioinformatics blog][3]\n\n**What are some of the interesting problems bioinformatics is trying to solve?**\n\n - Biostar - [How far does bioinformatics go][4]\n\n\n  [1]: http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books\n  [2]: http://biostar.stackexchange.com/questions/268/appropriate-podcasts-for-a-bioinformatician\n  [3]: http://biostar.stackexchange.com/questions/112/your-favorite-bioinformatics-blog\n  [4]: http://biostar.stackexchange.com/questions/149/how-far-does-bioinformatics-go", "comment_count": 0, "html": "<p>Well, I will answer by redirecting you to other topics :-) :</p>\n<p><strong>Is there any book I should read?</strong></p>\n<ul>\n<li>Biostar - <a href=\"http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books\">recommend your favorite bioinformatics books</a></li>\n</ul>\n<p><strong>Any interesting online resources?</strong></p>\n<ul>\n<li>Biostar - <a href=\"http://biostar.stackexchange.com/questions/268/appropriate-podcasts-for-a-bioinformatician\">appropriate podcasts for a bioinformatician</a></li>\n</ul>\n<p><strong>Any interesting blogs / online communities (apart from this one)?</strong></p>\n<ul>\n<li>Biostar - <a href=\"http://biostar.stackexchange.com/questions/112/your-favorite-bioinformatics-blog\">your favorite bioinformatics blog</a></li>\n</ul>\n<p><strong>What are some of the interesting problems bioinformatics is trying to solve?</strong></p>\n<ul>\n<li>Biostar - <a href=\"http://biostar.stackexchange.com/questions/149/how-far-does-bioinformatics-go\">How far does bioinformatics go</a></li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 1, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 22}}, {"pk": 317, "model": "server.post", "fields": {"rght": 3, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 12:17:31", "lft": 2, "post_type": 109787, "score": 6, "title": "A: Which software development technique is used in your lab? ", "unanswered": false, "content": "As I've always worked alone on my sources, I've heavily used the [Cowboy Coding][1] and the [confessional debugging][2] techniques :-)\n\n\n  [1]: http://en.wikipedia.org/wiki/Cowboy_coding\n  [2]: http://en.wiktionary.org/wiki/confessional_debugging", "comment_count": 0, "html": "<p>As I've always worked alone on my sources, I've heavily used the <a href=\"http://en.wikipedia.org/wiki/Cowboy_coding\">Cowboy Coding</a> and the <a href=\"http://en.wiktionary.org/wiki/confessional_debugging\">confessional debugging</a> techniques :-)</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 1, "parent": 310, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 318, "model": "server.post", "fields": {"rght": 5, "author": 130, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 12:25:31", "lft": 4, "post_type": 109787, "score": 4, "title": "A: Which software development technique is used in your lab? ", "unanswered": false, "content": "think it, code it :)", "comment_count": 0, "html": "<p>think it, code it :)</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 1, "parent": 310, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 130}}, {"pk": 319, "model": "server.post", "fields": {"rght": 13, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 12:39:50", "lft": 12, "post_type": 109787, "score": 7, "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "I think the most trivial is also the most challenging:  fetching and pre-processing the data in the first place, before you even do any analysis with it.  I'd say 80% of my time is spent searching, fetching, parsing, munging and storing data, 20% is analysis and conclusions.", "comment_count": 0, "html": "<p>I think the most trivial is also the most challenging:  fetching and pre-processing the data in the first place, before you even do any analysis with it.  I'd say 80% of my time is spent searching, fetching, parsing, munging and storing data, 20% is analysis and conclusions.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 1, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 320, "model": "server.post", "fields": {"rght": 13, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 12:47:39", "lft": 10, "post_type": 109787, "score": 6, "title": "A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "I've been doing bioinformatics for 10 years or so and have never read a book on the subject. I learned (and still learn, every day) on the job, almost entirely from online resources.\n\nI think many bioinformaticians of a \"certain age\" learned in this way:  they are often former bench biologists who gave up lab work and taught themselves programming.  These days there are undergraduate courses (!), so I imagine more people use textbooks.  It's just that I don't know of any, nor have I ever needed to use one.", "comment_count": 1, "html": "<p>I've been doing bioinformatics for 10 years or so and have never read a book on the subject. I learned (and still learn, every day) on the job, almost entirely from online resources.</p>\n<p>I think many bioinformaticians of a \"certain age\" learned in this way:  they are often former bench biologists who gave up lab work and taught themselves programming.  These days there are undergraduate courses (!), so I imagine more people use textbooks.  It's just that I don't know of any, nor have I ever needed to use one.</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 1, "parent": 181, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 321, "model": "server.post", "fields": {"rght": 11, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 13:02:14", "lft": 10, "post_type": 109787, "score": 2, "title": "A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "The others have answered your question!\n\nI just want to make a suggestion, if you are interested in visually comparing the two genomes, I highly recommend the [Artemis][1] and [ACT (Artemis Comparison Tool)][2] from the Sanger institute.\n\nIf you have the full genome, then you can easily visualize all the reading frames. With ACT, you use the two genome sequences (or one genome and a fasta file of genes/proteins or even two gene/protein fasta files) as well as a \"comparison file\", which is a blast output file.\n\nIt is very useful for annotation and curation!\n\n\n  [1]: http://www.sanger.ac.uk/resources/software/artemis/\n  [2]: http://www.sanger.ac.uk/resources/software/act/", "comment_count": 0, "html": "<p>The others have answered your question!</p>\n<p>I just want to make a suggestion, if you are interested in visually comparing the two genomes, I highly recommend the <a href=\"http://www.sanger.ac.uk/resources/software/artemis/\">Artemis</a> and <a href=\"http://www.sanger.ac.uk/resources/software/act/\">ACT (Artemis Comparison Tool)</a> from the Sanger institute.</p>\n<p>If you have the full genome, then you can easily visualize all the reading frames. With ACT, you use the two genome sequences (or one genome and a fasta file of genes/proteins or even two gene/protein fasta files) as well as a \"comparison file\", which is a blast output file.</p>\n<p>It is very useful for annotation and curation!</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 1, "parent": 302, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 322, "model": "server.post", "fields": {"rght": 15, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 13:47:22", "lft": 14, "post_type": 109787, "score": 8, "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "From a support perspective, the biggest challenge of my day-to-day work (rather than grand scientific challenges) remains convincing wet-lab biologists of the inappropriateness of Excel and Word as data exchange formats.\n\nScientifically speaking, data integration is probably the biggest technical challenge. Making disparate experiments comparable, and databases compatible would make life significantly easier.", "comment_count": 0, "html": "<p>From a support perspective, the biggest challenge of my day-to-day work (rather than grand scientific challenges) remains convincing wet-lab biologists of the inappropriateness of Excel and Word as data exchange formats.</p>\n<p>Scientifically speaking, data integration is probably the biggest technical challenge. Making disparate experiments comparable, and databases compatible would make life significantly easier.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 2, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 323, "model": "server.post", "fields": {"rght": 7, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 14:26:13", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": " - [COLO-829 cell line][1]\n - [96 human glioblastoma samples][2]\n\n\n  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08658.html\n  [2]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2671642/?tool=pubmed", "comment_count": 2, "html": "<ul>\n<li><a href=\"http://www.nature.com/nature/journal/v463/n7278/full/nature08658.html\">COLO-829 cell line</a></li>\n<li><a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2671642/?tool=pubmed\">96 human glioblastoma samples</a></li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 2, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 324, "model": "server.post", "fields": {"rght": 17, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 15:31:11", "lft": 6, "post_type": 109787, "score": 3, "title": "A: Which software development technique is used in your lab? ", "unanswered": false, "content": "Question 1: With my collaborators, we use agile.\n\nQuestion 2: (if I've understood correctly the \"how do you work together with your teammates?\") Our team members have very different roles and it is mainly one person actually coding. So we don't need to share code etc. When it comes to the communication part, we rely on different tools:\n\n  * [Google Wave][1]\n  * Our personal Wiki\n  * We've been testing [Yammer][2]\n  * [SVN][3]\n  * Skype\n  * Email\n\nAnd most importantly, whenever we can, face to face brainstorming with a white board.\n\n\n  [1]: http://wave.google.com/\n  [2]: http://www.yammer.com/\n  [3]: http://subversion.tigris.org/", "comment_count": 5, "html": "<p>Question 1: With my collaborators, we use agile.</p>\n<p>Question 2: (if I've understood correctly the \"how do you work together with your teammates?\") Our team members have very different roles and it is mainly one person actually coding. So we don't need to share code etc. When it comes to the communication part, we rely on different tools:</p>\n<ul>\n<li><a href=\"http://wave.google.com/\">Google Wave</a></li>\n<li>Our personal Wiki</li>\n<li>We've been testing <a href=\"http://www.yammer.com/\">Yammer</a></li>\n<li><a href=\"http://subversion.tigris.org/\">SVN</a></li>\n<li>Skype</li>\n<li>Email</li>\n</ul>\n<p>And most importantly, whenever we can, face to face brainstorming with a white board.</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 1, "parent": 310, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 25}}, {"pk": 325, "model": "server.post", "fields": {"rght": 5, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 16:54:25", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "There were recently a paper from Nelson's lab at UCLA on full sequencing of U87 GBM cell line.\n\nClark et al, U87MG Decoded: The Genomic Sequence of a Cytogenetically Aberrant Human Cancer Cell Line, PLoS Genetics, 2010.\n\nhttp://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000832\n", "comment_count": 0, "html": "<p>There were recently a paper from Nelson's lab at UCLA on full sequencing of U87 GBM cell line.</p>\n<p>Clark et al, U87MG Decoded: The Genomic Sequence of a Cytogenetically Aberrant Human Cancer Cell Line, PLoS Genetics, 2010.</p>\n<p>http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000832</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 2, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 326, "model": "server.post", "fields": {"rght": 9, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 20:36:45", "lft": 8, "post_type": 109787, "score": 2, "title": "A: Which software development technique is used in your lab? ", "unanswered": false, "content": "We are using [37signals][1]' [Basecamp][2] and [Backpack][3] to exchange data, results, ideas and other staff. It's not free, but not so expensive. As for codes, we usually have individual projects. All techniques as in Pierre's answer. :)\n\n\n  [1]: http://37signals.com\n  [2]: http://basecamphq.com\n  [3]: http://backpackit.com", "comment_count": 0, "html": "<p>We are using <a href=\"http://37signals.com\">37signals</a>' <a href=\"http://basecamphq.com\">Basecamp</a> and <a href=\"http://backpackit.com\">Backpack</a> to exchange data, results, ideas and other staff. It's not free, but not so expensive. As for codes, we usually have individual projects. All techniques as in Pierre's answer. :)</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 1, "parent": 310, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 327, "model": "server.post", "fields": {"rght": 18, "author": 146, "answer_accepted": false, "tag_string": "microarray image", "creation_date": "2010-03-16 20:56:46", "lft": 1, "post_type": 164033, "score": -9, "title": "Convert microarray quantization in image", "unanswered": false, "content": "How can I convert the microarray quantization mathematically elaborated in the corresponding image? I need to see the image of the mathematic changes in the microarray quantization.  ", "comment_count": 8, "html": "<p>How can I convert the microarray quantization mathematically elaborated in the corresponding image? I need to see the image of the mathematic changes in the microarray quantization.<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 76, "revision_count": 2, "parent": null, "views": 77, "deleted": true, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "convert-microarray-quantization-in-image", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [7, 129], "lastedit_user": 146}}, {"pk": 328, "model": "server.post", "fields": {"rght": 20, "author": 147, "answer_accepted": false, "tag_string": "fpga hpc reconfigurable", "creation_date": "2010-03-16 22:46:17", "lft": 1, "post_type": 164033, "score": 9, "title": "Hardware resources for HPC in Bioinformatics", "unanswered": false, "content": "Greetings everybody,\n\nWe're planning to build a very powerful computing machine to serve bioinformatics application here at [HCFMUSP][7] (check my profile). I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions using FPGA cards like these ones:\n\n[CLCbio Cube][1]\n\n[TimeLogic DeCypher][2]\n\n[Pico Computing E-FPGA][3]\n\n\nFor the people who never heard of FPGA I do suggest to check out Wikipedia on these topics:\n\n[Field Programmable Gate Array][4]\n[Reconfigurable Computing][5]\n\nThere are several possible implementations of important algorithms in bioinformatics in those plataforms. This is  just one example:\n\n[160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)][6]\n\n\nDoes anybody have some experience with these cards? Do they scale well? Are they worth the trouble?\n\n\nCheers,\nDaniel\n\n-- Edit --\n\nFinally, my server is online!!! For now it's just some Xeons with lots of RAM. But, in a near future some Tesla/Fermi will be added. Happy !!!\n\n\n  [1]: http://www.clcbio.com/index.php?id=616\n  [2]: http://www.timelogic.com/decypher_intro.html\n  [3]: http://www.picocomputing.com/e_series.html\n  [4]: http://en.wikipedia.org/wiki/Fpga\n  [5]: http://en.wikipedia.org/wiki/Reconfigurable_computing\n  [6]: http://www.biomedcentral.com/1471-2105/8/185\n  [7]: http://www.hcnet.usp.br/", "comment_count": 0, "html": "<p>Greetings everybody,</p>\n<p>We're planning to build a very powerful computing machine to serve bioinformatics application here at <a href=\"http://www.hcnet.usp.br/\">HCFMUSP</a> (check my profile). I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions using FPGA cards like these ones:</p>\n<p><a href=\"http://www.clcbio.com/index.php?id=616\">CLCbio Cube</a></p>\n<p><a href=\"http://www.timelogic.com/decypher_intro.html\">TimeLogic DeCypher</a></p>\n<p><a href=\"http://www.picocomputing.com/e_series.html\">Pico Computing E-FPGA</a></p>\n<p>For the people who never heard of FPGA I do suggest to check out Wikipedia on these topics:</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Fpga\">Field Programmable Gate Array</a>\n<a href=\"http://en.wikipedia.org/wiki/Reconfigurable_computing\">Reconfigurable Computing</a></p>\n<p>There are several possible implementations of important algorithms in bioinformatics in those plataforms. This is  just one example:</p>\n<p><a href=\"http://www.biomedcentral.com/1471-2105/8/185\">160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)</a></p>\n<p>Does anybody have some experience with these cards? Do they scale well? Are they worth the trouble?</p>\n<p>Cheers,\nDaniel</p>\n<p>-- Edit --</p>\n<p>Finally, my server is online!!! For now it's just some Xeons with lots of RAM. But, in a near future some Tesla/Fermi will be added. Happy !!!</p>", "child_count": 0, "closed": false, "tree_id": 77, "revision_count": 6, "parent": null, "views": 608, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:24", "slug": "hardware-resources-for-hpc-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [130, 131, 217], "lastedit_user": 147}}, {"pk": 329, "model": "server.post", "fields": {"rght": 17, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 23:18:06", "lft": 16, "post_type": 109787, "score": 2, "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "My main work deals with simulations and modelling in population genetics (for several different purposes). Data are essential to validade both.\n\n**Trivial**:\n\n - Gathering HUGE amounts of data (I do\n   love NGS!); \n - Parsing/converting these\n   data to a usable condition;\n - Extracting the population genetics\n   parameters estimates from it;\n\n**Challenging**:\n\n - Knowing when to stop gathering HUGE\n   amounts of data (I still love NGS!);\n - Curating data <-- The real challenge;\n\nFor a population geneticist these are trully happy times. Finally we have (possibly) enough data to validate some fundamental models and theories. But, as a great philosopher said - \"With great power comes great responsibility\". So, carefully curated data is the great challenge from now on, IMHO.\n\nThat's all, dudes.", "comment_count": 0, "html": "<p>My main work deals with simulations and modelling in population genetics (for several different purposes). Data are essential to validade both.</p>\n<p><strong>Trivial</strong>:</p>\n<ul>\n<li>Gathering HUGE amounts of data (I do\n   love NGS!); </li>\n<li>Parsing/converting these\n   data to a usable condition;</li>\n<li>Extracting the population genetics\n   parameters estimates from it;</li>\n</ul>\n<p><strong>Challenging</strong>:</p>\n<ul>\n<li>Knowing when to stop gathering HUGE\n   amounts of data (I still love NGS!);</li>\n<li>Curating data &lt;-- The real challenge;</li>\n</ul>\n<p>For a population geneticist these are trully happy times. Finally we have (possibly) enough data to validate some fundamental models and theories. But, as a great philosopher said - \"With great power comes great responsibility\". So, carefully curated data is the great challenge from now on, IMHO.</p>\n<p>That's all, dudes.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 1, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 330, "model": "server.post", "fields": {"rght": 15, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 23:54:18", "lft": 12, "post_type": 109787, "score": 5, "title": "A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "Most of my sparse experience with bioinformatics came with the necessity to extract some statistics from sequence data. So, most books I can recommend deal with statistical and algorithmic approaches to biological data. \n\n- **An Introduction to Bioinformatics Algorithms** Neil C. Jones and Pavel A. Pevzner\n\n- **Statistical Methods in Bioinformatics** Warren J. Ewens, Gregory R. Grant\n\n- **Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison** David Sankoff, Joseph Kruskal\n\n- **Bioinformatics and Computational Biology Solutions Using R and Bioconductor** Robert Gentleman, Vincent Carey, Wolfgang Huber, Rafael Irizarry, Sandrine Dudoit\n\nJones and Pavel are accomplished mathematicians and bioinformaticians. Their work with repeats is a must have reference. Ewens's book will become a classic. He is already a foremost figure in population genetics, both in theory and experiment. Sankoff's book still is the most important reference in sequence aligment. Unfortunatelly, these books are somewhat mind bending. They rely heavily on mathematical concepts. But, as far as I know, bioinformatics theory is indeed mathematically and algorithmically challenging.\n\nAnd the last book is a very broad practical introduction to bioinformatics of array data.  Good for relaxing . . .\n\nCheers !\n", "comment_count": 1, "html": "<p>Most of my sparse experience with bioinformatics came with the necessity to extract some statistics from sequence data. So, most books I can recommend deal with statistical and algorithmic approaches to biological data. </p>\n<ul>\n<li>\n<p><strong>An Introduction to Bioinformatics Algorithms</strong> Neil C. Jones and Pavel A. Pevzner</p>\n</li>\n<li>\n<p><strong>Statistical Methods in Bioinformatics</strong> Warren J. Ewens, Gregory R. Grant</p>\n</li>\n<li>\n<p><strong>Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison</strong> David Sankoff, Joseph Kruskal</p>\n</li>\n<li>\n<p><strong>Bioinformatics and Computational Biology Solutions Using R and Bioconductor</strong> Robert Gentleman, Vincent Carey, Wolfgang Huber, Rafael Irizarry, Sandrine Dudoit</p>\n</li>\n</ul>\n<p>Jones and Pavel are accomplished mathematicians and bioinformaticians. Their work with repeats is a must have reference. Ewens's book will become a classic. He is already a foremost figure in population genetics, both in theory and experiment. Sankoff's book still is the most important reference in sequence aligment. Unfortunatelly, these books are somewhat mind bending. They rely heavily on mathematical concepts. But, as far as I know, bioinformatics theory is indeed mathematically and algorithmically challenging.</p>\n<p>And the last book is a very broad practical introduction to bioinformatics of array data.  Good for relaxing . . .</p>\n<p>Cheers !</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 1, "parent": 181, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 331, "model": "server.post", "fields": {"rght": 11, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 06:52:10", "lft": 10, "post_type": 109787, "score": 6, "title": "A: Which software development technique is used in your lab? ", "unanswered": false, "content": "As the number of good programmers in natural sciences is relatively low as compared to other programming projects, I think it is good to pick a model that suites the team. In these situations, I do not think coding style matters too much (write unit tests first or last, ...).\n\nI am involved in two large chem- and bioinformatics projects: [Bioclipse][1] and the [CDK][2]. There is a bit of overlap in developers, but still both projects use different development models. Both development teams are scattered around the internet.\n\nBut what does matter very much is communication. This makes the following components important:\n\n - choose a version control system: I would recommend Git; it does require some training, but there is plenty of information, and we all have good education to start with.\n - choose a bug track system and make this your main development communication channel: it works independent of individual developers' time lines.\n - have mailing lists to discuss issues in more detail, ask for advice, etc\n - choose coding standards: these can be small and large, and are aimed at removing getting annoyed to much about others coding styles\n - put persons in charge and have them take responsibility over the code\n\nThe CDK even adds to this that code is reviewed before it gets into the main version. Git makes it very easy to developed in such a distributed way (not just in location, but also in time). The person in charge is the gate keeper and decides how and when code gets incorporated into the main version, and ensures everyone lives up to coding and project standards.\n\nWikis, blogs, waves, etc are useful for documenting things. More important is to add proper documentation to the source code.\n\n  [1]: http://www.bioclipse.net\n  [2]: http://cdk.sf.net", "comment_count": 0, "html": "<p>As the number of good programmers in natural sciences is relatively low as compared to other programming projects, I think it is good to pick a model that suites the team. In these situations, I do not think coding style matters too much (write unit tests first or last, ...).</p>\n<p>I am involved in two large chem- and bioinformatics projects: <a href=\"http://www.bioclipse.net\">Bioclipse</a> and the <a href=\"http://cdk.sf.net\">CDK</a>. There is a bit of overlap in developers, but still both projects use different development models. Both development teams are scattered around the internet.</p>\n<p>But what does matter very much is communication. This makes the following components important:</p>\n<ul>\n<li>choose a version control system: I would recommend Git; it does require some training, but there is plenty of information, and we all have good education to start with.</li>\n<li>choose a bug track system and make this your main development communication channel: it works independent of individual developers' time lines.</li>\n<li>have mailing lists to discuss issues in more detail, ask for advice, etc</li>\n<li>choose coding standards: these can be small and large, and are aimed at removing getting annoyed to much about others coding styles</li>\n<li>put persons in charge and have them take responsibility over the code</li>\n</ul>\n<p>The CDK even adds to this that code is reviewed before it gets into the main version. Git makes it very easy to developed in such a distributed way (not just in location, but also in time). The person in charge is the gate keeper and decides how and when code gets incorporated into the main version, and ensures everyone lives up to coding and project standards.</p>\n<p>Wikis, blogs, waves, etc are useful for documenting things. More important is to add proper documentation to the source code.</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 1, "parent": 310, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 332, "model": "server.post", "fields": {"rght": 9, "author": 148, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 08:40:50", "lft": 6, "post_type": 109787, "score": 8, "title": "A: I was studying a gene but it disappeared in the latest ensembl release. What should I do now?", "unanswered": false, "content": "Do inform Ensembl via helpdesk@ensembl.org; if it is an error then the Havana curators can put this back in. Send them the ENSG number from the previous release, or the protein sequence, or a page from the archive site. If they think it should have been removed, they will give you a good reason.", "comment_count": 1, "html": "<p>Do inform Ensembl via helpdesk@ensembl.org; if it is an error then the Havana curators can put this back in. Send them the ENSG number from the previous release, or the protein sequence, or a page from the archive site. If they think it should have been removed, they will give you a good reason.</p>", "child_count": 0, "closed": false, "tree_id": 47, "revision_count": 1, "parent": 178, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-i-was-studying-a-gene-but-it-disappeared-in-the-latest-ensembl-release-what-should-i-do-now", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 148}}, {"pk": 333, "model": "server.post", "fields": {"rght": 5, "author": 135, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 12:15:03", "lft": 2, "post_type": 109787, "score": 4, "title": "A: Hardware resources for HPC in Bioinformatics", "unanswered": false, "content": "From what I've read, FPGAs are fine, but expensive. Have you looked into other, more readily available (and easier to program, mostly) architectures? I'm thinking of GPUs (CUDA, OpenCL), and Cell B.E. chips (in Playstation 3, programmable via C/C++ and also via OpenCL)?", "comment_count": 1, "html": "<p>From what I've read, FPGAs are fine, but expensive. Have you looked into other, more readily available (and easier to program, mostly) architectures? I'm thinking of GPUs (CUDA, OpenCL), and Cell B.E. chips (in Playstation 3, programmable via C/C++ and also via OpenCL)?</p>", "child_count": 0, "closed": false, "tree_id": 77, "revision_count": 1, "parent": 328, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-hardware-resources-for-hpc-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 135}}, {"pk": 334, "model": "server.post", "fields": {"rght": 24, "author": 86, "answer_accepted": true, "tag_string": "microarray annotation affymetrix probeset", "creation_date": "2010-03-17 16:51:43", "lft": 1, "post_type": 164033, "score": 4, "title": "Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "Is it possible for two different Affymetrix probe set IDs to have common annotations to a single gene ? I am looking for the concept behind Affy probe set IDs. Any literature or links ? ", "comment_count": 0, "html": "<p>Is it possible for two different Affymetrix probe set IDs to have common annotations to a single gene ? I am looking for the concept behind Affy probe set IDs. Any literature or links ? </p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 2, "parent": null, "views": 2563, "deleted": false, "answer_count": 8, "touch_date": "2011-11-24 14:49:25", "slug": "is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:48:33", "level": 0, "post_accepted": false, "tag_set": [7, 68, 132, 133], "lastedit_user": 58}}, {"pk": 335, "model": "server.post", "fields": {"rght": 15, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 16:55:23", "lft": 14, "post_type": 109787, "score": 3, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "I used to check Biojobs at FriendFeed,  [Bioinformatics.org][1]  and [Bioinformatics.fr][2] \n\nRecently found this [GenomeWeb careers section][3], interesting opportunities mostly from industry.  \n\n\n  [1]: http://www.bioinformatics.org/jobs/?show=archives\n  [2]: http://bioinformatics.fr/jobs.php\n  [3]: http://www.genomeweb.com/jobs", "comment_count": 0, "html": "<p>I used to check Biojobs at FriendFeed,  <a href=\"http://www.bioinformatics.org/jobs/?show=archives\">Bioinformatics.org</a>  and <a href=\"http://bioinformatics.fr/jobs.php\">Bioinformatics.fr</a> </p>\n<p>Recently found this <a href=\"http://www.genomeweb.com/jobs\">GenomeWeb careers section</a>, interesting opportunities mostly from industry.<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 2, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 336, "model": "server.post", "fields": {"rght": 5, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 17:00:00", "lft": 2, "post_type": 109787, "score": 7, "title": "A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "Different probesets are certainly capable of mapping to the same gene on the standard Affymetrix GeneChip platform.\n\nGroups of probes are combined into probesets and multiple probesets *MAY* exist for a gene\n\nNetAffx is the Affymetrix clearing house of Affymetrix probe ID info : [http://www.affymetrix.com/analysis/index.affx][1]\n\nYou might be interested in the BrainArray Custom CDFs which reannotate and regroup Affymetrix probes and probesets which are kept more up to date [http://brainarray.mbni.med.umich.edu/Brainarray/Database/CustomCDF/genomic_curated_CDF.asp][2] They also have tools for mapping probesets between chips/species [http://brainarray.mbni.med.umich.edu/Brainarray/Database/ProbeMatchDB/ncbi_probmatch_para_step1.asp][3]\n\nAnd interestingly a resource I have only just found called [ADAPT][4] which \"describes the many-to-many relationships between Affymetrix\u2122 probesets transcripts and genes, by directly mapping every probe against publicly available mRNAs/cDNA sequences from RefSeq and Ensembl.\"\n\n\n  [1]: http://www.affymetrix.com/analysis/index.affx\n  [2]: http://brainarray.mbni.med.umich.edu/Brainarray/Database/CustomCDF/genomic_curated_CDF.asp\n  [3]: http://brainarray.mbni.med.umich.edu/Brainarray/Database/ProbeMatchDB/ncbi_probmatch_para_step1.asp\n  [4]: http://bioinformatics.picr.man.ac.uk/adapt/Welcome.adapt", "comment_count": 1, "html": "<p>Different probesets are certainly capable of mapping to the same gene on the standard Affymetrix GeneChip platform.</p>\n<p>Groups of probes are combined into probesets and multiple probesets <em>MAY</em> exist for a gene</p>\n<p>NetAffx is the Affymetrix clearing house of Affymetrix probe ID info : <a href=\"http://www.affymetrix.com/analysis/index.affx\">http://www.affymetrix.com/analysis/index.affx</a></p>\n<p>You might be interested in the BrainArray Custom CDFs which reannotate and regroup Affymetrix probes and probesets which are kept more up to date <a href=\"http://brainarray.mbni.med.umich.edu/Brainarray/Database/CustomCDF/genomic_curated_CDF.asp\">http://brainarray.mbni.med.umich.edu/Brainarray/Database/CustomCDF/genomic_curated_CDF.asp</a> They also have tools for mapping probesets between chips/species <a href=\"http://brainarray.mbni.med.umich.edu/Brainarray/Database/ProbeMatchDB/ncbi_probmatch_para_step1.asp\">http://brainarray.mbni.med.umich.edu/Brainarray/Database/ProbeMatchDB/ncbi_probmatch_para_step1.asp</a></p>\n<p>And interestingly a resource I have only just found called <a href=\"http://bioinformatics.picr.man.ac.uk/adapt/Welcome.adapt\">ADAPT</a> which \"describes the many-to-many relationships between Affymetrix\u2122 probesets transcripts and genes, by directly mapping every probe against publicly available mRNAs/cDNA sequences from RefSeq and Ensembl.\"</p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 1, "parent": 334, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 58}}, {"pk": 337, "model": "server.post", "fields": {"rght": 5, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 17:02:19", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "Yes, many probe sets associated with the same gene.\n\nHere is the technical documentation from Affymetrix on probe set design:\n\n[Transcript Assignment for NetAffx\u2122 Annotations][1]\n\n\n  [1]: https://www.affymetrix.com/support/technical/whitepapers/Transcript_Assignment_whitepaper.pdf", "comment_count": 0, "html": "<p>Yes, many probe sets associated with the same gene.</p>\n<p>Here is the technical documentation from Affymetrix on probe set design:</p>\n<p><a href=\"https://www.affymetrix.com/support/technical/whitepapers/Transcript_Assignment_whitepaper.pdf\">Transcript Assignment for NetAffx\u2122 Annotations</a></p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 1, "parent": 334, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 338, "model": "server.post", "fields": {"rght": 9, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 18:00:23", "lft": 4, "post_type": 109787, "score": 2, "title": "A: Hardware resources for HPC in Bioinformatics", "unanswered": false, "content": "All depends how diverse will be the applications running on this beast. If the end users are from DNA sequencing, NMR, mass spec to crystallography and the total number o applications is say 50+ it is unlikely you will be able to support it not even on FPGAs but even with CUDAs. Either something installs / compiles (almost) out of the box or you may have to drop it. Software authors will be of no help when it comes to porting it (and possibly a bunch of libs they depend on) to a new platform they do not even have in house. \n\n\nOn the other hand whenever problem is restricted to one domain, FPGAs are great. I used SORCERER for protein mass spec and DeCypher for blast searches.   \n\nAnyway, have fun with new servers, whatever they will be :-)", "comment_count": 2, "html": "<p>All depends how diverse will be the applications running on this beast. If the end users are from DNA sequencing, NMR, mass spec to crystallography and the total number o applications is say 50+ it is unlikely you will be able to support it not even on FPGAs but even with CUDAs. Either something installs / compiles (almost) out of the box or you may have to drop it. Software authors will be of no help when it comes to porting it (and possibly a bunch of libs they depend on) to a new platform they do not even have in house. </p>\n<p>On the other hand whenever problem is restricted to one domain, FPGAs are great. I used SORCERER for protein mass spec and DeCypher for blast searches. <br />\n</p>\n<p>Anyway, have fun with new servers, whatever they will be :-)</p>", "child_count": 0, "closed": false, "tree_id": 77, "revision_count": 2, "parent": 328, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-hardware-resources-for-hpc-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 339, "model": "server.post", "fields": {"rght": 9, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 20:51:53", "lft": 8, "post_type": 109787, "score": 0, "title": "A: A resource to identify functionally redundant genes", "unanswered": false, "content": "Just want to clarify : Are you looking for Orthologs/Paralogs of knockdown genes ? If yes, I support Dave Bridges comments, you could try a bi-directional blast searches. If you are looking for large number of genes from a well annotated genome, you may look for database that reports orthologs. I have used orthologs from Inparanoid for fly genome.  ", "comment_count": 0, "html": "<p>Just want to clarify : Are you looking for Orthologs/Paralogs of knockdown genes ? If yes, I support Dave Bridges comments, you could try a bi-directional blast searches. If you are looking for large number of genes from a well annotated genome, you may look for database that reports orthologs. I have used orthologs from Inparanoid for fly genome.<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 69, "revision_count": 1, "parent": 287, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:51", "slug": "a-a-resource-to-identify-functionally-redundant-genes", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 340, "model": "server.post", "fields": {"rght": 7, "author": 115, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 21:03:20", "lft": 6, "post_type": 109787, "score": 2, "title": "A: A resource to identify functionally redundant genes", "unanswered": false, "content": "Have you looked at the COGS database at the NCBI? \nhttp://www.ncbi.nlm.nih.gov/COG/\n\nI'm not sure how current it is these days, and if the human coverage would be sufficient for your needs, but when I used to do structure-function work, I found it useful.\n\nGiven what you said in your response to Chris, I suspect you're going to be mostly looking at signaling proteins, so the EC numbers probably won't help you. But if you do find yourself looking at an enzyme that isn't a phosphatase or a kinase, EC numbers might help. In that case, MetaCyc might also be useful:\nhttp://metacyc.org/\n\nMy gut instinct on this one, though, is that you're going to get at best a 90% solution, and you'll have to do that last 10% by hand, using literature.", "comment_count": 0, "html": "<p>Have you looked at the COGS database at the NCBI? \nhttp://www.ncbi.nlm.nih.gov/COG/</p>\n<p>I'm not sure how current it is these days, and if the human coverage would be sufficient for your needs, but when I used to do structure-function work, I found it useful.</p>\n<p>Given what you said in your response to Chris, I suspect you're going to be mostly looking at signaling proteins, so the EC numbers probably won't help you. But if you do find yourself looking at an enzyme that isn't a phosphatase or a kinase, EC numbers might help. In that case, MetaCyc might also be useful:\nhttp://metacyc.org/</p>\n<p>My gut instinct on this one, though, is that you're going to get at best a 90% solution, and you'll have to do that last 10% by hand, using literature.</p>", "child_count": 0, "closed": false, "tree_id": 69, "revision_count": 1, "parent": 287, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-a-resource-to-identify-functionally-redundant-genes", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 115}}, {"pk": 341, "model": "server.post", "fields": {"rght": 9, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 21:22:29", "lft": 8, "post_type": 109787, "score": 2, "title": "A: A resource to identify functionally redundant genes", "unanswered": false, "content": "<p>If you are looking for genes that encode proteins that could play the same role in a pathway, then you can parse the XML files provided by KEGG Pathays Database.</p>\n\n<p>For instance let's take the mTOR signaling pathway. You can see that at some step of the pathway several proteins (genes) can be involved like it is the case for AKT1 in green : There is the number 3 because you can have either AKT1, AKT2 or AKT3.</p>\n\n![alt text][1]\n\n<p>So by parsing the related XML file (hsa04150.xml) you can easily get the related Entrez geneid 207, 2008, 1000 that are enclosed in the following XML part:</p>\n\n        <entry id=\"33\" name=\"hsa:10000 hsa:207 hsa:208\" type=\"gene\" link=\"http://www.genome.jp/dbget-bin/www_bget?hsa+10000+207+208\">\n        <graphics name=\"AKT3...\" fgcolor=\"#000000\" bgcolor=\"#BFFFBF\"\n             type=\"rectangle\" x=\"339\" y=\"291\" width=\"45\" height=\"17\"/>\n        </entry>\n\n<p>In this pathway there are other instances like this one. (when there is a number at the upper left side of the protein).</p>\n\n<p>So may be it could be a way to identify functionally redundant genes.</p>\n\nHope this helps.\n\nFred\n\n\n  [1]: http://www.bioinformatics.fr/images/tutorials/mTOR_KEGG.gif", "comment_count": 0, "html": "<p>[HTML_REMOVED]</p>\n<p>[HTML_REMOVED]</p>\n<p><img alt=\"alt text\" src=\"http://www.bioinformatics.fr/images/tutorials/mTOR_KEGG.gif\" /></p>\n<p>[HTML_REMOVED]</p>\n<p><div class=\"highlight\"><pre>        <span class=\"nt\">&lt;entry</span> <span class=\"na\">id=</span><span class=\"s\">&quot;33&quot;</span> <span class=\"na\">name=</span><span class=\"s\">&quot;hsa:10000 hsa:207 hsa:208&quot;</span> <span class=\"na\">type=</span><span class=\"s\">&quot;gene&quot;</span> <span class=\"na\">link=</span><span class=\"s\">&quot;http://www.genome.jp/dbget-bin/www_bget?hsa+10000+207+208&quot;</span><span class=\"nt\">&gt;</span>\n        <span class=\"nt\">&lt;graphics</span> <span class=\"na\">name=</span><span class=\"s\">&quot;AKT3...&quot;</span> <span class=\"na\">fgcolor=</span><span class=\"s\">&quot;#000000&quot;</span> <span class=\"na\">bgcolor=</span><span class=\"s\">&quot;#BFFFBF&quot;</span>\n             <span class=\"na\">type=</span><span class=\"s\">&quot;rectangle&quot;</span> <span class=\"na\">x=</span><span class=\"s\">&quot;339&quot;</span> <span class=\"na\">y=</span><span class=\"s\">&quot;291&quot;</span> <span class=\"na\">width=</span><span class=\"s\">&quot;45&quot;</span> <span class=\"na\">height=</span><span class=\"s\">&quot;17&quot;</span><span class=\"nt\">/&gt;</span>\n        <span class=\"nt\">&lt;/entry&gt;</span>\n</pre></div>\n</p>\n<p>[HTML_REMOVED]</p>\n<p>[HTML_REMOVED]</p>\n<p>Hope this helps.</p>\n<p>Fred</p>", "child_count": 0, "closed": false, "tree_id": 69, "revision_count": 1, "parent": 287, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-a-resource-to-identify-functionally-redundant-genes", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 342, "model": "server.post", "fields": {"rght": 17, "author": 115, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 21:52:53", "lft": 12, "post_type": 109787, "score": 2, "title": "A: Which software development technique is used in your lab? ", "unanswered": false, "content": "To put my answer in context: I work in industry. I've worked in both small biotechs and large pharmas. I am not the coder on the projects I work on- these days, I'm the project manager. Earlier in my career, I was the \"translator\" between the scientists and the programmers (that job has had many different titles, and was rarely my sole job function).\n\nI have found various permutations of agile programming to be the most successful. The one exception to this has been when I've worked on projects in the more heavily regulated drug development (vs. drug discovery) arena. In those cases, the internal processes have often required a waterfall-like process. For awhile, I specialized a bit in fitting the agile-like development approach favored by my programmers into the waterfall process required by corporate policy.", "comment_count": 2, "html": "<p>To put my answer in context: I work in industry. I've worked in both small biotechs and large pharmas. I am not the coder on the projects I work on- these days, I'm the project manager. Earlier in my career, I was the \"translator\" between the scientists and the programmers (that job has had many different titles, and was rarely my sole job function).</p>\n<p>I have found various permutations of agile programming to be the most successful. The one exception to this has been when I've worked on projects in the more heavily regulated drug development (vs. drug discovery) arena. In those cases, the internal processes have often required a waterfall-like process. For awhile, I specialized a bit in fitting the agile-like development approach favored by my programmers into the waterfall process required by corporate policy.</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 1, "parent": 310, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 115}}, {"pk": 343, "model": "server.post", "fields": {"rght": 9, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 21:55:59", "lft": 8, "post_type": 109787, "score": 1, "title": "A: How to get started in bioinformatics?", "unanswered": false, "content": "I think the best way is to get in to a lab for a rotation project / part-time project depending on your schedule and work on a live project. You may either help the group to code something, they can help you to get familiarize with some common bioinformatics tools and approaches. I think this will be the best way. \n\nIf you can work on your own, pick your language (Perl, Python, Java, Ruby) send a mail to respective bio* mailing list. You will definitely get a small project. You can help the open source community and also get to understand the field and its generic requirements. \n\nGo ahead, Future is Open, Bioinformatics is Open. All the best ! ", "comment_count": 0, "html": "<p>I think the best way is to get in to a lab for a rotation project / part-time project depending on your schedule and work on a live project. You may either help the group to code something, they can help you to get familiarize with some common bioinformatics tools and approaches. I think this will be the best way. </p>\n<p>If you can work on your own, pick your language (Perl, Python, Java, Ruby) send a mail to respective bio* mailing list. You will definitely get a small project. You can help the open source community and also get to understand the field and its generic requirements. </p>\n<p>Go ahead, Future is Open, Bioinformatics is Open. All the best ! </p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 1, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 344, "model": "server.post", "fields": {"rght": 21, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 00:24:55", "lft": 16, "post_type": 109787, "score": 4, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "A lot of universities and companies never post to national boards and their websites do not get spidered. When I was looking for my first bioinformatics job I collected a list of every job board of every major university I could find and checked each one daily.\n\nHere is my list (some of these might have moved by now)\n\nhttp://www.bioplanet.com/planetforums/viewthread.php?tid=2644", "comment_count": 2, "html": "<p>A lot of universities and companies never post to national boards and their websites do not get spidered. When I was looking for my first bioinformatics job I collected a list of every job board of every major university I could find and checked each one daily.</p>\n<p>Here is my list (some of these might have moved by now)</p>\n<p>http://www.bioplanet.com/planetforums/viewthread.php?tid=2644</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 1, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 345, "model": "server.post", "fields": {"rght": 19, "author": 71, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 01:54:11", "lft": 18, "post_type": 109787, "score": 5, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "Don't forget to network.  Many of my jobs have been found because I knew someone who pointed me to it or approached me about it.", "comment_count": 0, "html": "<p>Don't forget to network.  Many of my jobs have been found because I knew someone who pointed me to it or approached me about it.</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 1, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 71}}, {"pk": 346, "model": "server.post", "fields": {"rght": 15, "author": 71, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 02:03:54", "lft": 14, "post_type": 109787, "score": 1, "title": "A: Which software development technique is used in your lab? ", "unanswered": false, "content": "Like Melanie, I've worked in industry as a programmer, as a product manager, etc.  In my experience, an iterative, \"agile\" (without getting dogmatic about what agile means) works way better than the waterfall models.  In a research driven environment with constant change, incomplete requirements and needs, I would argue it's the only good way. \n\nThe other key point, don't go for all the features you can, since chances are you will need to re-implement parts anyway.\n\n(Disclaimer - I don't work in science these days)", "comment_count": 0, "html": "<p>Like Melanie, I've worked in industry as a programmer, as a product manager, etc.  In my experience, an iterative, \"agile\" (without getting dogmatic about what agile means) works way better than the waterfall models.  In a research driven environment with constant change, incomplete requirements and needs, I would argue it's the only good way. </p>\n<p>The other key point, don't go for all the features you can, since chances are you will need to re-implement parts anyway.</p>\n<p>(Disclaimer - I don't work in science these days)</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 1, "parent": 310, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:22", "slug": "a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 71}}, {"pk": 347, "model": "server.post", "fields": {"rght": 7, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 07:58:22", "lft": 6, "post_type": 109787, "score": 2, "title": "A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "<p>Yes of course it is possible. For instance you have the probeset 203074_at from HG-U133 Plus 2 that is associated to ANXA8, ANXA8L1 and ANXA8L2.</p>\n\n<p>In our team, for all the probe sets of the HG-U133 Plus 2 we are performing Blast sequence alignment between the 11 probes of a probset against all mRNAs from Ensembl and Refseq in order to associate them to the right transcript(s).</p>\n\n<p>And for additional information, please find below some interesting reading suggestions  concerning the mapping between the affymetrix probe sets and the mRNAs</p>\n\n 1. [Alternative mapping of probes to genes for Affymetrix chips][1]\n 2. [A sequence-based identification of the genes detected by probesets on the Affymetrix U133 plus 2.0 array][2]\n 3. [Evolving gene/transcript definitions significantly alter the interpretation of GeneChip data][3]\n 4. [Detecting false expression signals\n    in    high-density oligonucleotide\n    arrays    by an in silico\n    approach][4]\n\n\n  \n\n\n  [1]: http://www.biomedcentral.com/1471-2105/5/111\n  [2]: http://www.ncbi.nlm.nih.gov/pubmed/15722477\n  [3]: http://www.ncbi.nlm.nih.gov/pubmed/16284200\n  [4]: http://www.ncbi.nlm.nih.gov/pubmed/15718097", "comment_count": 0, "html": "<p>[HTML_REMOVED]</p>\n<p>[HTML_REMOVED]</p>\n<p>[HTML_REMOVED]</p>\n<ol>\n<li><a href=\"http://www.biomedcentral.com/1471-2105/5/111\">Alternative mapping of probes to genes for Affymetrix chips</a></li>\n<li><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/15722477\">A sequence-based identification of the genes detected by probesets on the Affymetrix U133 plus 2.0 array</a></li>\n<li><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16284200\">Evolving gene/transcript definitions significantly alter the interpretation of GeneChip data</a></li>\n<li>[Detecting false expression signals\n<div class=\"highlight\"><pre>    <span class=\"n\">in</span>    <span class=\"n\">high</span><span class=\"o\">-</span><span class=\"n\">density</span> <span class=\"n\">oligonucleotide</span>\n    <span class=\"n\">arrays</span>    <span class=\"n\">by</span> <span class=\"n\">an</span> <span class=\"n\">in</span> <span class=\"n\">silico</span>\n    <span class=\"n\">approach</span><span class=\"p\">][</span><span class=\"mi\">4</span><span class=\"p\">]</span>\n</pre></div>\n</li>\n</ol>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 1, "parent": 334, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:48:33", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 348, "model": "server.post", "fields": {"rght": 10, "author": 98, "answer_accepted": false, "tag_string": "chip distance profiles", "creation_date": "2010-03-18 10:02:35", "lft": 1, "post_type": 164033, "score": 3, "title": "distance measure between chip-seq peak set profiles", "unanswered": false, "content": "Is there any tool that will tell me how different/similar two chip-seq peak sets are in two different parts of the genome? For example, if I have a ~10Kb region in the genome with a series of peaks and another ~10Kb region in the genome with another set of peaks from the same experiment, can I calculate a distance measure between these two peak set profiles with any available tool?", "comment_count": 0, "html": "<p>Is there any tool that will tell me how different/similar two chip-seq peak sets are in two different parts of the genome? For example, if I have a ~10Kb region in the genome with a series of peaks and another ~10Kb region in the genome with another set of peaks from the same experiment, can I calculate a distance measure between these two peak set profiles with any available tool?</p>", "child_count": 0, "closed": false, "tree_id": 79, "revision_count": 1, "parent": null, "views": 348, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:23", "slug": "distance-measure-between-chip-seq-peak-set-profiles", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [15, 95, 134], "lastedit_user": 98}}, {"pk": 349, "model": "server.post", "fields": {"rght": 34, "author": 37, "answer_accepted": true, "tag_string": "licensing general software subjective", "creation_date": "2010-03-18 10:06:47", "lft": 1, "post_type": 164033, "score": 13, "title": "What license do you use when you release code and data?", "unanswered": false, "content": "Do you aim to make your resources as widely available and reusable as possible? \n\nConversely, do you try to protect the investment of time and resources that went into producing the IP?\n\nThe choice of license can be a tricky thing, and getting it wrong can cause considerable problems for you, and for others attempting to build on your work.\n\nThings to consider:\n\n[ISCB Discussion report on software sharing][1]\n\n[Ontology licensing][2]\n\n[Attribution vs Citation][3]\n\n\n\n\n  [1]: http://iscb-discussion.blogspot.com/2008/03/iscb-member-feedback-sought-on-revised.html\n  [2]: http://themindwobbles.wordpress.com/2009/11/12/science-commons-provide-a-list-of-considerations-for-researchers-looking-to-license-their-ontology/\n  [3]: http://peanutbutter.wordpress.com/2009/07/10/attribution-vs-citation-do-you-know-the-difference/", "comment_count": 0, "html": "<p>Do you aim to make your resources as widely available and reusable as possible? </p>\n<p>Conversely, do you try to protect the investment of time and resources that went into producing the IP?</p>\n<p>The choice of license can be a tricky thing, and getting it wrong can cause considerable problems for you, and for others attempting to build on your work.</p>\n<p>Things to consider:</p>\n<p><a href=\"http://iscb-discussion.blogspot.com/2008/03/iscb-member-feedback-sought-on-revised.html\">ISCB Discussion report on software sharing</a></p>\n<p><a href=\"http://themindwobbles.wordpress.com/2009/11/12/science-commons-provide-a-list-of-considerations-for-researchers-looking-to-license-their-ontology/\">Ontology licensing</a></p>\n<p><a href=\"http://peanutbutter.wordpress.com/2009/07/10/attribution-vs-citation-do-you-know-the-difference/\">Attribution vs Citation</a></p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 2, "parent": null, "views": 563, "deleted": false, "answer_count": 16, "touch_date": "2011-11-24 14:49:30", "slug": "what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [31, 32, 135, 136], "lastedit_user": 233}}, {"pk": 350, "model": "server.post", "fields": {"rght": 7, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 10:59:10", "lft": 2, "post_type": 109787, "score": 16, "title": "A: What license do you use when you release code and data?", "unanswered": false, "content": "my code ( http://code.google.com/p/lindenb/ ) is released under **GNU General Public License v2** but frankly,  the characteristics of all the available licenses are just vague for me. I just want a license that would say: \n> use my code as much as you want but \n> tell me if you're doing something\n> interesting with it, cite my work if an article is published, and remember me if\n> you're getting millionaire.\n", "comment_count": 2, "html": "<p>my code ( http://code.google.com/p/lindenb/ ) is released under <strong>GNU General Public License v2</strong> but frankly,  the characteristics of all the available licenses are just vague for me. I just want a license that would say: </p>\n<blockquote>\n<p>use my code as much as you want but \ntell me if you're doing something\ninteresting with it, cite my work if an article is published, and remember me if\nyou're getting millionaire.</p>\n</blockquote>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 1, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 29}}, {"pk": 351, "model": "server.post", "fields": {"rght": 5, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 11:21:20", "lft": 4, "post_type": 109787, "score": 4, "title": "A: What license do you use when you release code and data?", "unanswered": false, "content": "Most of the times I don't care about the license, I just forget to include it in the files; however, I didn't publish anything important yet apart from some scripts on github.\n\nIf I want to use a license, I choose GNU GPL2, but just because it is the only one that I know more or less how it works. \n\nFor slides and written material I pay more attention, I always use a [Creative Commons][1] license, usually [commercial work/free to share][2] \n\n\n  [1]: http://creativecommons.org/\n  [2]: http://creativecommons.org/licenses/by/3.0/us/", "comment_count": 0, "html": "<p>Most of the times I don't care about the license, I just forget to include it in the files; however, I didn't publish anything important yet apart from some scripts on github.</p>\n<p>If I want to use a license, I choose GNU GPL2, but just because it is the only one that I know more or less how it works. </p>\n<p>For slides and written material I pay more attention, I always use a <a href=\"http://creativecommons.org/\">Creative Commons</a> license, usually <a href=\"http://creativecommons.org/licenses/by/3.0/us/\">commercial work/free to share</a> </p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 2, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 352, "model": "server.post", "fields": {"rght": 7, "author": 137, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 12:10:10", "lft": 6, "post_type": 109787, "score": 4, "title": "A: What license do you use when you release code and data?", "unanswered": false, "content": "I prefer BSD-style license over GPL because I am a bit aware of the problems of using GPLed code in corporate setting. For example a software project **might** catch wind because it is inside some corporate codebase (i.e. has users) even if they do not technically have to release the modified sources.", "comment_count": 0, "html": "<p>I prefer BSD-style license over GPL because I am a bit aware of the problems of using GPLed code in corporate setting. For example a software project <strong>might</strong> catch wind because it is inside some corporate codebase (i.e. has users) even if they do not technically have to release the modified sources.</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 2, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 137}}, {"pk": 353, "model": "server.post", "fields": {"rght": 9, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 13:26:46", "lft": 8, "post_type": 109787, "score": 8, "title": "A: What license do you use when you release code and data?", "unanswered": false, "content": "One important consideration is that of the support that made the software possible. When someone's work is supported by public grants (aka taxpayers) both ethical considerations and probably the law requires that the software be made available with few strings attached.\n \nThe fundamental differences between the Open Source licenses can be found in the conditions specifying the licensing of derived work based on the software. Some licenses do not impose any conditions: MIT, BSD; others strictly mandate that any type of derived work must be licensed the same conditions as the original work GPL. \n\nI have been on various sides of software licensing, but now I think that each situation is unique thus no general rule or recommendation applies to all situations.", "comment_count": 0, "html": "<p>One important consideration is that of the support that made the software possible. When someone's work is supported by public grants (aka taxpayers) both ethical considerations and probably the law requires that the software be made available with few strings attached.</p>\n<p>The fundamental differences between the Open Source licenses can be found in the conditions specifying the licensing of derived work based on the software. Some licenses do not impose any conditions: MIT, BSD; others strictly mandate that any type of derived work must be licensed the same conditions as the original work GPL. </p>\n<p>I have been on various sides of software licensing, but now I think that each situation is unique thus no general rule or recommendation applies to all situations.</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 1, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 354, "model": "server.post", "fields": {"rght": 11, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 14:28:46", "lft": 10, "post_type": 109787, "score": 9, "title": "A: What license do you use when you release code and data?", "unanswered": false, "content": "Without getting into a licensing discussion: I prefer to use the most permissive licenses like MIT/BSD instead of GPL. The bottom line is being I never want the license to be a reason for people *not* to use my code--though I can see the reasons why some libraries choose different licenses.", "comment_count": 0, "html": "<p>Without getting into a licensing discussion: I prefer to use the most permissive licenses like MIT/BSD instead of GPL. The bottom line is being I never want the license to be a reason for people <em>not</em> to use my code--though I can see the reasons why some libraries choose different licenses.</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 1, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 35}}, {"pk": 355, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 14:40:57", "lft": 2, "post_type": 109787, "score": 4, "title": "A: distance measure between chip-seq peak set profiles", "unanswered": false, "content": "Hi,\n\nthis is a problem that I am actively investigating. I have come up with a potential (homegrown) approach but it has has not been fully vetted, so keep that in mind. It builds on the following assumptions\n\n 1. We assume that the  position of each peak is defined independently of the rest\n 2. Within one peak the distribution of the reads is governed by a reasonably normal distribution\n\nThus if we could detect each peak, find the corresponding peak in the other dataset,  extract only the reads that correspond to both of the these peaks, then we can run a statistical test to detect differences between these distributions. \n\nThe results will characterize each peak individually rather than the entire shape. These differences may manifest themselves as a difference in the mean or variance of peaks. (the first indicating a shift of the peak, the other is a change in occupancy). For example below are the results from a script that I wrote that compares peaks around TSS for two experiments:\n\n![alt text][1]\n\nThe upper panel shows the original peaks, the lower panel shows the underlying read distributions, the little boxes below show the shift and p-values respectively.\nThe interpretation is that the last 2 peaks show a statistically significant shift in the mean value of 10bp and +20 bp respectively.\n\nI do have a tool that does this pretty automatically but since I am not yet convinced of the correctness of the approach as a whole it is not yet publicly available.\n\nNot so long ago I was advised that this is a problem can be thought of a time series analysis but have not yet looked into this possibility. That is something to also investigate.\n\n\n  [1]: http://atlas.bx.psu.edu/_images/genie-compare.png", "comment_count": 0, "html": "<p>Hi,</p>\n<p>this is a problem that I am actively investigating. I have come up with a potential (homegrown) approach but it has has not been fully vetted, so keep that in mind. It builds on the following assumptions</p>\n<ol>\n<li>We assume that the  position of each peak is defined independently of the rest</li>\n<li>Within one peak the distribution of the reads is governed by a reasonably normal distribution</li>\n</ol>\n<p>Thus if we could detect each peak, find the corresponding peak in the other dataset,  extract only the reads that correspond to both of the these peaks, then we can run a statistical test to detect differences between these distributions. </p>\n<p>The results will characterize each peak individually rather than the entire shape. These differences may manifest themselves as a difference in the mean or variance of peaks. (the first indicating a shift of the peak, the other is a change in occupancy). For example below are the results from a script that I wrote that compares peaks around TSS for two experiments:</p>\n<p><img alt=\"alt text\" src=\"http://atlas.bx.psu.edu/_images/genie-compare.png\" /></p>\n<p>The upper panel shows the original peaks, the lower panel shows the underlying read distributions, the little boxes below show the shift and p-values respectively.\nThe interpretation is that the last 2 peaks show a statistically significant shift in the mean value of 10bp and +20 bp respectively.</p>\n<p>I do have a tool that does this pretty automatically but since I am not yet convinced of the correctness of the approach as a whole it is not yet publicly available.</p>\n<p>Not so long ago I was advised that this is a problem can be thought of a time series analysis but have not yet looked into this possibility. That is something to also investigate.</p>", "child_count": 0, "closed": false, "tree_id": 79, "revision_count": 2, "parent": 348, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-distance-measure-between-chip-seq-peak-set-profiles", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 356, "model": "server.post", "fields": {"rght": 9, "author": 137, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 19:54:45", "lft": 4, "post_type": 109787, "score": 1, "title": "A: distance measure between chip-seq peak set profiles", "unanswered": false, "content": "Looking only at the beautiful plots and not knowing what they really mean it seems to me that the a homegrown approach is unnecessary because after normalization you end up with two probability mass functions. There are multiple distance measures on probability distributions, but the Jensen-Shannon divergence seems (to me) to be most useful here because it can be generalized to multiple reads and has a probabilistic interpretation (the probability that the two runs represent samples drawn from the same background distribution) \n\nsee: \n\nEl-Yaniv, R., Fine, S. & Tishby, N. Agnostic classification of Markovian sequences. In Advances in Neural Information Processing (NIPS-97  (1997).\n\n\n", "comment_count": 2, "html": "<p>Looking only at the beautiful plots and not knowing what they really mean it seems to me that the a homegrown approach is unnecessary because after normalization you end up with two probability mass functions. There are multiple distance measures on probability distributions, but the Jensen-Shannon divergence seems (to me) to be most useful here because it can be generalized to multiple reads and has a probabilistic interpretation (the probability that the two runs represent samples drawn from the same background distribution) </p>\n<p>see: </p>\n<p>El-Yaniv, R., Fine, S. &amp; Tishby, N. Agnostic classification of Markovian sequences. In Advances in Neural Information Processing (NIPS-97  (1997).</p>", "child_count": 0, "closed": false, "tree_id": 79, "revision_count": 1, "parent": 348, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-distance-measure-between-chip-seq-peak-set-profiles", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 137}}, {"pk": 357, "model": "server.post", "fields": {"rght": 20, "author": 120, "answer_accepted": true, "tag_string": "r gene symbol", "creation_date": "2010-03-18 20:33:35", "lft": 1, "post_type": 164033, "score": 4, "title": "How do I access and query entire genome sequences with R", "unanswered": false, "content": "Is there a package in R where I can load in a whole genome, and then say e.g. get.gene.sequence (input_genome, \"gene_symbol\"), or another tool that you'd use for this job?", "comment_count": 0, "html": "<p>Is there a package in R where I can load in a whole genome, and then say e.g. get.gene.sequence (input_genome, \"gene_symbol\"), or another tool that you'd use for this job?</p>", "child_count": 0, "closed": false, "tree_id": 81, "revision_count": 2, "parent": null, "views": 879, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:30", "slug": "how-do-i-access-and-query-entire-genome-sequences-with-r", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [36, 137, 138], "lastedit_user": 1}}, {"pk": 358, "model": "server.post", "fields": {"rght": 11, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 21:37:45", "lft": 2, "post_type": 109787, "score": 5, "title": "A: How do I access and query entire genome sequences with R", "unanswered": false, "content": "Fasta files are pretty easy to manipulate using the seqinR package, if you've got the memory to handle it.  (~4GB for chr1)\n\n    library(seqinr)\n    seq = read.fasta(\"chr1.fa\",seqtype=\"DNA\")\n    geneSeq = seq[[1]][geneStart:geneStop]\n    \nThere's probably a better way to do it, but this may get you started.", "comment_count": 4, "html": "<p>Fasta files are pretty easy to manipulate using the seqinR package, if you've got the memory to handle it.  (~4GB for chr1)</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">library</span><span class=\"p\">(</span><span class=\"n\">seqinr</span><span class=\"p\">)</span>\n    <span class=\"n\">seq</span> <span class=\"o\">=</span> <span class=\"nb\">read</span><span class=\"o\">.</span><span class=\"n\">fasta</span><span class=\"p\">(</span><span class=\"s\">&quot;chr1.fa&quot;</span><span class=\"p\">,</span><span class=\"n\">seqtype</span><span class=\"o\">=</span><span class=\"s\">&quot;DNA&quot;</span><span class=\"p\">)</span>\n    <span class=\"n\">geneSeq</span> <span class=\"o\">=</span> <span class=\"n\">seq</span><span class=\"p\">[[</span><span class=\"mi\">1</span><span class=\"p\">]][</span><span class=\"n\">geneStart:geneStop</span><span class=\"p\">]</span>\n    \n</pre></div>\n\nThere's probably a better way to do it, but this may get you started.</p>", "child_count": 0, "closed": false, "tree_id": 81, "revision_count": 1, "parent": 357, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-do-i-access-and-query-entire-genome-sequences-with-r", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 359, "model": "server.post", "fields": {"rght": 5, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 21:47:46", "lft": 4, "post_type": 109787, "score": 5, "title": "A: How do I access and query entire genome sequences with R", "unanswered": false, "content": "Ok, here is my java solution. It only uses some *remote* resources (the anonymous mysql server and the DAS server of the UCSC). My piece of code takes a list of refGene as its arguments and only prints the genes/geneomic-sequences to stdout but one could imagine it would store a pair(name,sequence) in memory.\n\n\n\n    import java.sql.Connection;\n    import java.sql.DriverManager;\n    import java.sql.PreparedStatement;\n    import java.sql.ResultSet;\n    \n    import javax.xml.parsers.SAXParser;\n    import javax.xml.parsers.SAXParserFactory;\n    \n    import org.xml.sax.Attributes;\n    import org.xml.sax.SAXException;\n    import org.xml.sax.helpers.DefaultHandler;\n    \n    public class Gene2Seq\n    \t{\n    \tprivate static class DASHandler\n    \t\textends DefaultHandler\n    \t\t{\n    \t\tprivate boolean inDNA=false;\n    \t\t@Override\n    \t\tpublic void startElement(String uri, String localName, String qName,\n    \t\t\t\tAttributes attributes) throws SAXException\n    \t\t\t{\n    \t\t\tinDNA=(qName.equals(\"DNA\"));\n    \t\t\t}\n    \t\t@Override\n    \t\tpublic void endElement(String uri, String localName, String qName)\n    \t\t\t\tthrows SAXException\n    \t\t\t{\n    \t\t\tinDNA=false;\n    \t\t\t}\n    \t\t@Override\n    \t\tpublic void characters(char[] ch, int start, int length)\n    \t\t\t\tthrows SAXException\n    \t\t\t{\n    \t\t\tif(inDNA) System.out.print(new String(ch, start, length).replace(\"\\n\", \"\"));\n    \t\t\t}\n    \t\t}\n    \t\n    \tpublic static void main(String[] args) throws Throwable\n    \t\t{\n    \t\t//put the JDBC driver for mysql in the $CLASSPATH\n    \t\tClass.forName(\"com.mysql.jdbc.Driver\");\n    \t\tConnection con = DriverManager.getConnection(\n    \t\t\t\t\"jdbc:mysql://genome-mysql.cse.ucsc.edu/hg19\",\n    \t\t\t\t\"genome\", \"\"\n    \t\t\t\t);\n    \t\tSAXParserFactory f=SAXParserFactory.newInstance();\n    \t\tSAXParser parser=f.newSAXParser();\n    \t\tPreparedStatement pstmt=con.prepareStatement(\n    \t\t\t\t\"select name,chrom,txStart,txEnd from refGene where name2=?\"\n    \t\t\t\t);\n    \t\tfor(String name: args)\n    \t\t\t{\n    \t\t\tpstmt.setString(1, name);\n    \t\t\tResultSet row=pstmt.executeQuery();\n    \t\t\twhile(row.next())\n    \t\t\t\t{\n    \t\t\t\tSystem.out.println(\">\"+row.getString(1)+\"|\"+row.getString(2)+\":\"+row.getInt(3)+\"-\"+row.getInt(4));\n    \t\t\t\tparser.parse(\n    \t\t\t\t\t\t\"http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=\"+row.getString(2)+\":\"+(row.getInt(3)+1)+\",\"+(row.getInt(4)+1),\n    \t\t\t\t\t\tnew DASHandler());\n    \t\t\t\tSystem.out.println();\n    \t\t\t\t}\n    \t\t\trow.close();\n    \t\t\t}\n    \t\t\n    \t\tpstmt.close();\n    \t\tcon.close();\n    \t\t}\n    \t}\n\n\noutput with **EIF4G1**:\n\n\n\n    >NM_004953|chr3:184038262-184053145\n    agatgggctgaaagtggaactcaaggggtttctggcacctacctacctgcttcccgctggggggtggggagttggcccag....\n    >NM_182917|chr3:184032970-184053145\n    tcctcgacggccgccgcccgcctggccttttagggcctgactcccgcccttcctggcctacactcctgggcggcggcagg....\n    >NM_198241|chr3:184032355-184053145\n    gaagcggtggccgccgagcgggatctgtgcggggagccggaaatggt....\n\n\n", "comment_count": 0, "html": "<p>Ok, here is my java solution. It only uses some <em>remote</em> resources (the anonymous mysql server and the DAS server of the UCSC). My piece of code takes a list of refGene as its arguments and only prints the genes/geneomic-sequences to stdout but one could imagine it would store a pair(name,sequence) in memory.</p>\n<p><div class=\"highlight\"><pre>    <span class=\"nb\">import</span> <span class=\"n\">java</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">Connection</span><span class=\"p\">;</span>\n    <span class=\"nb\">import</span> <span class=\"n\">java</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">DriverManager</span><span class=\"p\">;</span>\n    <span class=\"nb\">import</span> <span class=\"n\">java</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">PreparedStatement</span><span class=\"p\">;</span>\n    <span class=\"nb\">import</span> <span class=\"n\">java</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">ResultSet</span><span class=\"p\">;</span>\n    \n    <span class=\"nb\">import</span> <span class=\"n\">javax</span><span class=\"o\">.</span><span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">parsers</span><span class=\"o\">.</span><span class=\"n\">SAXParser</span><span class=\"p\">;</span>\n    <span class=\"nb\">import</span> <span class=\"n\">javax</span><span class=\"o\">.</span><span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">parsers</span><span class=\"o\">.</span><span class=\"n\">SAXParserFactory</span><span class=\"p\">;</span>\n    \n    <span class=\"nb\">import</span> <span class=\"n\">org</span><span class=\"o\">.</span><span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">sax</span><span class=\"o\">.</span><span class=\"n\">Attributes</span><span class=\"p\">;</span>\n    <span class=\"nb\">import</span> <span class=\"n\">org</span><span class=\"o\">.</span><span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">sax</span><span class=\"o\">.</span><span class=\"n\">SAXException</span><span class=\"p\">;</span>\n    <span class=\"nb\">import</span> <span class=\"n\">org</span><span class=\"o\">.</span><span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">sax</span><span class=\"o\">.</span><span class=\"n\">helpers</span><span class=\"o\">.</span><span class=\"n\">DefaultHandler</span><span class=\"p\">;</span>\n    \n    <span class=\"n\">public</span> <span class=\"n\">class</span> <span class=\"n\">Gene2Seq</span>\n    \t<span class=\"p\">{</span>\n    \t<span class=\"n\">private</span> <span class=\"n\">static</span> <span class=\"n\">class</span> <span class=\"n\">DASHandler</span>\n    \t\t<span class=\"n\">extends</span> <span class=\"n\">DefaultHandler</span>\n    \t\t<span class=\"p\">{</span>\n    \t\t<span class=\"n\">private</span> <span class=\"n\">boolean</span> <span class=\"n\">inDNA</span><span class=\"o\">=</span><span class=\"n\">false</span><span class=\"p\">;</span>\n    \t\t<span class=\"nv\">@Override</span>\n    \t\t<span class=\"n\">public</span> <span class=\"n\">void</span> <span class=\"n\">startElement</span><span class=\"p\">(</span><span class=\"n\">String</span> <span class=\"n\">uri</span><span class=\"p\">,</span> <span class=\"n\">String</span> <span class=\"n\">localName</span><span class=\"p\">,</span> <span class=\"n\">String</span> <span class=\"n\">qName</span><span class=\"p\">,</span>\n    \t\t\t\t<span class=\"n\">Attributes</span> <span class=\"n\">attributes</span><span class=\"p\">)</span> <span class=\"n\">throws</span> <span class=\"n\">SAXException</span>\n    \t\t\t<span class=\"p\">{</span>\n    \t\t\t<span class=\"n\">inDNA</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">qName</span><span class=\"o\">.</span><span class=\"n\">equals</span><span class=\"p\">(</span><span class=\"s\">&quot;DNA&quot;</span><span class=\"p\">));</span>\n    \t\t\t<span class=\"p\">}</span>\n    \t\t<span class=\"nv\">@Override</span>\n    \t\t<span class=\"n\">public</span> <span class=\"n\">void</span> <span class=\"n\">endElement</span><span class=\"p\">(</span><span class=\"n\">String</span> <span class=\"n\">uri</span><span class=\"p\">,</span> <span class=\"n\">String</span> <span class=\"n\">localName</span><span class=\"p\">,</span> <span class=\"n\">String</span> <span class=\"n\">qName</span><span class=\"p\">)</span>\n    \t\t\t\t<span class=\"n\">throws</span> <span class=\"n\">SAXException</span>\n    \t\t\t<span class=\"p\">{</span>\n    \t\t\t<span class=\"n\">inDNA</span><span class=\"o\">=</span><span class=\"n\">false</span><span class=\"p\">;</span>\n    \t\t\t<span class=\"p\">}</span>\n    \t\t<span class=\"nv\">@Override</span>\n    \t\t<span class=\"n\">public</span> <span class=\"n\">void</span> <span class=\"n\">characters</span><span class=\"p\">(</span><span class=\"n\">char</span><span class=\"o\">[]</span> <span class=\"n\">ch</span><span class=\"p\">,</span> <span class=\"nb\">int</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"nb\">int</span> <span class=\"nb\">length</span><span class=\"p\">)</span>\n    \t\t\t\t<span class=\"n\">throws</span> <span class=\"n\">SAXException</span>\n    \t\t\t<span class=\"p\">{</span>\n    \t\t\t<span class=\"k\">if</span><span class=\"p\">(</span><span class=\"n\">inDNA</span><span class=\"p\">)</span> <span class=\"n\">System</span><span class=\"o\">.</span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"k\">print</span><span class=\"p\">(</span><span class=\"k\">new</span> <span class=\"n\">String</span><span class=\"p\">(</span><span class=\"n\">ch</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"nb\">length</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s\">&quot;\\n&quot;</span><span class=\"p\">,</span> <span class=\"s\">&quot;&quot;</span><span class=\"p\">));</span>\n    \t\t\t<span class=\"p\">}</span>\n    \t\t<span class=\"p\">}</span>\n    \t\n    \t<span class=\"n\">public</span> <span class=\"n\">static</span> <span class=\"n\">void</span> <span class=\"n\">main</span><span class=\"p\">(</span><span class=\"n\">String</span><span class=\"o\">[]</span> <span class=\"n\">args</span><span class=\"p\">)</span> <span class=\"n\">throws</span> <span class=\"n\">Throwable</span>\n    \t\t<span class=\"p\">{</span>\n    \t\t<span class=\"sr\">//</span><span class=\"n\">put</span> <span class=\"n\">the</span> <span class=\"n\">JDBC</span> <span class=\"n\">driver</span> <span class=\"k\">for</span> <span class=\"n\">mysql</span> <span class=\"n\">in</span> <span class=\"n\">the</span> <span class=\"nv\">$CLASSPATH</span>\n    \t\t<span class=\"n\">Class</span><span class=\"o\">.</span><span class=\"n\">forName</span><span class=\"p\">(</span><span class=\"s\">&quot;com.mysql.jdbc.Driver&quot;</span><span class=\"p\">);</span>\n    \t\t<span class=\"n\">Connection</span> <span class=\"n\">con</span> <span class=\"o\">=</span> <span class=\"n\">DriverManager</span><span class=\"o\">.</span><span class=\"n\">getConnection</span><span class=\"p\">(</span>\n    \t\t\t\t<span class=\"s\">&quot;jdbc:mysql://genome-mysql.cse.ucsc.edu/hg19&quot;</span><span class=\"p\">,</span>\n    \t\t\t\t<span class=\"s\">&quot;genome&quot;</span><span class=\"p\">,</span> <span class=\"s\">&quot;&quot;</span>\n    \t\t\t\t<span class=\"p\">);</span>\n    \t\t<span class=\"n\">SAXParserFactory</span> <span class=\"n\">f</span><span class=\"o\">=</span><span class=\"n\">SAXParserFactory</span><span class=\"o\">.</span><span class=\"n\">newInstance</span><span class=\"p\">();</span>\n    \t\t<span class=\"n\">SAXParser</span> <span class=\"n\">parser</span><span class=\"o\">=</span><span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">newSAXParser</span><span class=\"p\">();</span>\n    \t\t<span class=\"n\">PreparedStatement</span> <span class=\"n\">pstmt</span><span class=\"o\">=</span><span class=\"n\">con</span><span class=\"o\">.</span><span class=\"n\">prepareStatement</span><span class=\"p\">(</span>\n    \t\t\t\t<span class=\"s\">&quot;select name,chrom,txStart,txEnd from refGene where name2=?&quot;</span>\n    \t\t\t\t<span class=\"p\">);</span>\n    \t\t<span class=\"k\">for</span><span class=\"p\">(</span><span class=\"n\">String</span> <span class=\"n\">name:</span> <span class=\"n\">args</span><span class=\"p\">)</span>\n    \t\t\t<span class=\"p\">{</span>\n    \t\t\t<span class=\"n\">pstmt</span><span class=\"o\">.</span><span class=\"n\">setString</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"p\">);</span>\n    \t\t\t<span class=\"n\">ResultSet</span> <span class=\"n\">row</span><span class=\"o\">=</span><span class=\"n\">pstmt</span><span class=\"o\">.</span><span class=\"n\">executeQuery</span><span class=\"p\">();</span>\n    \t\t\t<span class=\"k\">while</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"o\">.</span><span class=\"k\">next</span><span class=\"p\">())</span>\n    \t\t\t\t<span class=\"p\">{</span>\n    \t\t\t\t<span class=\"n\">System</span><span class=\"o\">.</span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">println</span><span class=\"p\">(</span><span class=\"s\">&quot;&gt;&quot;</span><span class=\"o\">+</span><span class=\"n\">row</span><span class=\"o\">.</span><span class=\"n\">getString</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"s\">&quot;|&quot;</span><span class=\"o\">+</span><span class=\"n\">row</span><span class=\"o\">.</span><span class=\"n\">getString</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"s\">&quot;:&quot;</span><span class=\"o\">+</span><span class=\"n\">row</span><span class=\"o\">.</span><span class=\"n\">getInt</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"s\">&quot;-&quot;</span><span class=\"o\">+</span><span class=\"n\">row</span><span class=\"o\">.</span><span class=\"n\">getInt</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">));</span>\n    \t\t\t\t<span class=\"n\">parser</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">(</span>\n    \t\t\t\t\t\t<span class=\"s\">&quot;http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=&quot;</span><span class=\"o\">+</span><span class=\"n\">row</span><span class=\"o\">.</span><span class=\"n\">getString</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"s\">&quot;:&quot;</span><span class=\"o\">+</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"o\">.</span><span class=\"n\">getInt</span><span class=\"p\">(</span><span class=\"mi\">3</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"s\">&quot;,&quot;</span><span class=\"o\">+</span><span class=\"p\">(</span><span class=\"n\">row</span><span class=\"o\">.</span><span class=\"n\">getInt</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">)</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">),</span>\n    \t\t\t\t\t\t<span class=\"k\">new</span> <span class=\"n\">DASHandler</span><span class=\"p\">());</span>\n    \t\t\t\t<span class=\"n\">System</span><span class=\"o\">.</span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">println</span><span class=\"p\">();</span>\n    \t\t\t\t<span class=\"p\">}</span>\n    \t\t\t<span class=\"n\">row</span><span class=\"o\">.</span><span class=\"nb\">close</span><span class=\"p\">();</span>\n    \t\t\t<span class=\"p\">}</span>\n    \t\t\n    \t\t<span class=\"n\">pstmt</span><span class=\"o\">.</span><span class=\"nb\">close</span><span class=\"p\">();</span>\n    \t\t<span class=\"n\">con</span><span class=\"o\">.</span><span class=\"nb\">close</span><span class=\"p\">();</span>\n    \t\t<span class=\"p\">}</span>\n    \t<span class=\"p\">}</span>\n</pre></div>\n</p>\n<p>output with <strong>EIF4G1</strong>:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"o\">&gt;</span><span class=\"n\">NM_004953</span><span class=\"o\">|</span><span class=\"n\">chr3:184038262</span><span class=\"o\">-</span><span class=\"mi\">184053145</span>\n    <span class=\"n\">agatgggctgaaagtggaactcaaggggtttctggcacctacctacctgcttcccgctggggggtggggagttggcccag</span><span class=\"o\">....</span>\n    <span class=\"o\">&gt;</span><span class=\"n\">NM_182917</span><span class=\"o\">|</span><span class=\"n\">chr3:184032970</span><span class=\"o\">-</span><span class=\"mi\">184053145</span>\n    <span class=\"n\">tcctcgacggccgccgcccgcctggccttttagggcctgactcccgcccttcctggcctacactcctgggcggcggcagg</span><span class=\"o\">....</span>\n    <span class=\"o\">&gt;</span><span class=\"n\">NM_198241</span><span class=\"o\">|</span><span class=\"n\">chr3:184032355</span><span class=\"o\">-</span><span class=\"mi\">184053145</span>\n    <span class=\"n\">gaagcggtggccgccgagcgggatctgtgcggggagccggaaatggt</span><span class=\"o\">....</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 81, "revision_count": 1, "parent": 357, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-how-do-i-access-and-query-entire-genome-sequences-with-r", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 360, "model": "server.post", "fields": {"rght": 7, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 22:33:25", "lft": 6, "post_type": 109787, "score": 12, "title": "A: How do I access and query entire genome sequences with R", "unanswered": false, "content": "\nseqinR ([http://cran.r-project.org/web/packages/seqinr/index.html][1]) is a good option for R.\n\nIf you don't need the whole genome locally, you can fetch sequences from Ensembl using biomaRt ([http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html][2]):\n\n    library(biomaRt)\n    ensembl <- useMart(\"ensembl\",dataset=\"hsapiens_gene_ensembl\")\n    seq     <- getSequence(id = \"A2M\", type=\"hgnc_symbol\", mart = ensembl, seqType = \"transcript_exon_intron\")\n\n\nI would also consider one of the Bio* libraries ([http://www.open-bio.org/wiki/Projects][3]) for sequence retrieval and manipulation.\n\n\n  [1]: http://cran.r-project.org/web/packages/seqinr/index.html\n  [2]: http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html\n  [3]: http://www.open-bio.org/wiki/Projects", "comment_count": 0, "html": "<p>seqinR (<a href=\"http://cran.r-project.org/web/packages/seqinr/index.html\">http://cran.r-project.org/web/packages/seqinr/index.html</a>) is a good option for R.</p>\n<p>If you don't need the whole genome locally, you can fetch sequences from Ensembl using biomaRt (<a href=\"http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html\">http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html</a>):</p>\n<p><div class=\"highlight\"><pre>    library<span class=\"p\">(</span>biomaRt<span class=\"p\">)</span>\n    ensembl <span class=\"o\">&lt;-</span> useMart<span class=\"p\">(</span><span class=\"s\">&quot;ensembl&quot;</span><span class=\"p\">,</span>dataset<span class=\"o\">=</span><span class=\"s\">&quot;hsapiens_gene_ensembl&quot;</span><span class=\"p\">)</span>\n    seq     <span class=\"o\">&lt;-</span> getSequence<span class=\"p\">(</span>id <span class=\"o\">=</span> <span class=\"s\">&quot;A2M&quot;</span><span class=\"p\">,</span> type<span class=\"o\">=</span><span class=\"s\">&quot;hgnc_symbol&quot;</span><span class=\"p\">,</span> mart <span class=\"o\">=</span> ensembl<span class=\"p\">,</span> seqType <span class=\"o\">=</span> <span class=\"s\">&quot;transcript_exon_intron&quot;</span><span class=\"p\">)</span>\n</pre></div>\n</p>\n<p>I would also consider one of the Bio* libraries (<a href=\"http://www.open-bio.org/wiki/Projects\">http://www.open-bio.org/wiki/Projects</a>) for sequence retrieval and manipulation.</p>", "child_count": 0, "closed": false, "tree_id": 81, "revision_count": 1, "parent": 357, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-how-do-i-access-and-query-entire-genome-sequences-with-r", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 65}}, {"pk": 361, "model": "server.post", "fields": {"rght": 9, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 09:19:43", "lft": 8, "post_type": 109787, "score": 4, "title": "A: How do I access and query entire genome sequences with R", "unanswered": false, "content": "R has gotten a lot of sequence handling and searching routines recently that make it a good choice also for sequence analysis in bioinformatics.\n\nHave a look at the [BSGenome package in BioConductor][1]. It is meant to hold the genome sequence and allow fast sequence searches in the genome sequence. It *does not* contain real genome annotations though. There are readymade packages for a bunch of eukaryote genomes you can download, but of course your organism has to be in the list. This can be used together with the [BioStrings][2] package that allows for fast sequence searches and manipulation. \n\nIt could be a good team with biomaRt (already mentioned, I really recommend this) if you want further local sequence processing or if you already have the gene start/end coordinates, or alternatively transfer the coordinates only and cut these out of the BSGenome.\n\n\n  [1]: http://www.bioconductor.org/packages/2.5/bioc/html/BSgenome.html\n  [2]: http://www.bioconductor.org/packages/2.5/bioc/html/Biostrings.html", "comment_count": 0, "html": "<p>R has gotten a lot of sequence handling and searching routines recently that make it a good choice also for sequence analysis in bioinformatics.</p>\n<p>Have a look at the <a href=\"http://www.bioconductor.org/packages/2.5/bioc/html/BSgenome.html\">BSGenome package in BioConductor</a>. It is meant to hold the genome sequence and allow fast sequence searches in the genome sequence. It <em>does not</em> contain real genome annotations though. There are readymade packages for a bunch of eukaryote genomes you can download, but of course your organism has to be in the list. This can be used together with the <a href=\"http://www.bioconductor.org/packages/2.5/bioc/html/Biostrings.html\">BioStrings</a> package that allows for fast sequence searches and manipulation. </p>\n<p>It could be a good team with biomaRt (already mentioned, I really recommend this) if you want further local sequence processing or if you already have the gene start/end coordinates, or alternatively transfer the coordinates only and cut these out of the BSGenome.</p>", "child_count": 0, "closed": false, "tree_id": 81, "revision_count": 1, "parent": 357, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-do-i-access-and-query-entire-genome-sequences-with-r", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 362, "model": "server.post", "fields": {"rght": 34, "author": 29, "answer_accepted": true, "tag_string": "biomart wsdl soap java webservice", "creation_date": "2010-03-19 13:49:39", "lft": 1, "post_type": 164033, "score": 7, "title": "Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "Hi all,\nThanks to [Neil][1], I've discovered that **Biomart** is not just a HTML front-end but it can also be invoked as a [web service][2].\n\nSo, I played with java and the following webservice: http://www.ensembl.org/biomart/martwsdl .\n\n${jAVA_HOME}/bin/**wsimport**  http://www.ensembl.org/biomart/martwsdl\n\nwas called to generate the java sources from the **WSDL** file and I also wrote the following client:\n\n    import org.ensembl._80.martservicesoap.*;\n    \n    public class BioMartClient\n     {\n     public static void  main(String args[]) throws Exception\n      {\n      BioMartSoapService service=new BioMartSoapService();\n      MartServiceSoap martsoap= service.getBioMartSoapPort();\n      for(Mart mart: martsoap.getRegistry())\n       {\n       System.out.println(mart.getName());\n       }\n      }\n     }\n\nbut the program throwed the following exception when it invokes **getRegistry**():\n\n    Exception in thread \"main\" com.sun.xml.internal.ws.server.UnsupportedMediaException: Unsupported Content-Type: text/html; charset=utf-8 Supported ones are: [text/xml]\n            at com.sun.xml.internal.ws.encoding.StreamSOAPCodec.decode(StreamSOAPCodec.java:284)\n    (...)\n            at $Proxy30.getRegistry(Unknown Source)\n            at BioMartClient.main(BioMartClient.java:9)\n\n\nI also tested a few more BioMart servers: Sometimes *getRegistry* just returns an empty list (http://www.biomart.org/biomart/martwsdl ), sometimes the path *martwsdl* does not exist ( http://www.wormbase.org/biomart/martwsdl ), etc...\n\nIn the end I didn't find any server containing some data that could be processed via the SOAP protocol.\n\nIs it a known issue ? Am I missing something ? Is there a functional BioMart+SOAP server anywhere ?\n\nThanks,\n\n\n\n  [1]: http://biostar.stackexchange.com/questions/357\n  [2]: http://www.biomart.org/martservice.html", "comment_count": 3, "html": "<p>Hi all,\nThanks to <a href=\"http://biostar.stackexchange.com/questions/357\">Neil</a>, I've discovered that <strong>Biomart</strong> is not just a HTML front-end but it can also be invoked as a <a href=\"http://www.biomart.org/martservice.html\">web service</a>.</p>\n<p>So, I played with java and the following webservice: http://www.ensembl.org/biomart/martwsdl .</p>\n<p>${jAVA_HOME}/bin/<strong>wsimport</strong>  http://www.ensembl.org/biomart/martwsdl</p>\n<p>was called to generate the java sources from the <strong>WSDL</strong> file and I also wrote the following client:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"nb\">import</span> <span class=\"n\">org</span><span class=\"o\">.</span><span class=\"n\">ensembl</span><span class=\"o\">.</span><span class=\"n\">_80</span><span class=\"o\">.</span><span class=\"n\">martservicesoap</span><span class=\"o\">.*</span><span class=\"p\">;</span>\n    \n    <span class=\"n\">public</span> <span class=\"n\">class</span> <span class=\"n\">BioMartClient</span>\n     <span class=\"p\">{</span>\n     <span class=\"n\">public</span> <span class=\"n\">static</span> <span class=\"n\">void</span>  <span class=\"n\">main</span><span class=\"p\">(</span><span class=\"n\">String</span> <span class=\"n\">args</span><span class=\"o\">[]</span><span class=\"p\">)</span> <span class=\"n\">throws</span> <span class=\"n\">Exception</span>\n      <span class=\"p\">{</span>\n      <span class=\"n\">BioMartSoapService</span> <span class=\"n\">service</span><span class=\"o\">=</span><span class=\"k\">new</span> <span class=\"n\">BioMartSoapService</span><span class=\"p\">();</span>\n      <span class=\"n\">MartServiceSoap</span> <span class=\"n\">martsoap</span><span class=\"o\">=</span> <span class=\"n\">service</span><span class=\"o\">.</span><span class=\"n\">getBioMartSoapPort</span><span class=\"p\">();</span>\n      <span class=\"k\">for</span><span class=\"p\">(</span><span class=\"n\">Mart</span> <span class=\"n\">mart:</span> <span class=\"n\">martsoap</span><span class=\"o\">.</span><span class=\"n\">getRegistry</span><span class=\"p\">())</span>\n       <span class=\"p\">{</span>\n       <span class=\"n\">System</span><span class=\"o\">.</span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">println</span><span class=\"p\">(</span><span class=\"n\">mart</span><span class=\"o\">.</span><span class=\"n\">getName</span><span class=\"p\">());</span>\n       <span class=\"p\">}</span>\n      <span class=\"p\">}</span>\n     <span class=\"p\">}</span>\n</pre></div>\n</p>\n<p>but the program throwed the following exception when it invokes <strong>getRegistry</strong>():</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">Exception</span> <span class=\"n\">in</span> <span class=\"n\">thread</span> <span class=\"s\">&quot;main&quot;</span> <span class=\"n\">com</span><span class=\"o\">.</span><span class=\"n\">sun</span><span class=\"o\">.</span><span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">internal</span><span class=\"o\">.</span><span class=\"n\">ws</span><span class=\"o\">.</span><span class=\"n\">server</span><span class=\"o\">.</span><span class=\"n\">UnsupportedMediaException:</span> <span class=\"n\">Unsupported</span> <span class=\"n\">Content</span><span class=\"o\">-</span><span class=\"n\">Type:</span> <span class=\"n\">text</span><span class=\"sr\">/html; charset=utf-8 Supported ones are: [text/xm</span><span class=\"n\">l</span><span class=\"p\">]</span>\n            <span class=\"n\">at</span> <span class=\"n\">com</span><span class=\"o\">.</span><span class=\"n\">sun</span><span class=\"o\">.</span><span class=\"n\">xml</span><span class=\"o\">.</span><span class=\"n\">internal</span><span class=\"o\">.</span><span class=\"n\">ws</span><span class=\"o\">.</span><span class=\"n\">encoding</span><span class=\"o\">.</span><span class=\"n\">StreamSOAPCodec</span><span class=\"o\">.</span><span class=\"n\">decode</span><span class=\"p\">(</span><span class=\"n\">StreamSOAPCodec</span><span class=\"o\">.</span><span class=\"n\">java:284</span><span class=\"p\">)</span>\n    <span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n            <span class=\"n\">at</span> <span class=\"nv\">$Proxy30</span><span class=\"o\">.</span><span class=\"n\">getRegistry</span><span class=\"p\">(</span><span class=\"n\">Unknown</span> <span class=\"n\">Source</span><span class=\"p\">)</span>\n            <span class=\"n\">at</span> <span class=\"n\">BioMartClient</span><span class=\"o\">.</span><span class=\"n\">main</span><span class=\"p\">(</span><span class=\"n\">BioMartClient</span><span class=\"o\">.</span><span class=\"n\">java:9</span><span class=\"p\">)</span>\n</pre></div>\n</p>\n<p>I also tested a few more BioMart servers: Sometimes <em>getRegistry</em> just returns an empty list (http://www.biomart.org/biomart/martwsdl ), sometimes the path <em>martwsdl</em> does not exist ( http://www.wormbase.org/biomart/martwsdl ), etc...</p>\n<p>In the end I didn't find any server containing some data that could be processed via the SOAP protocol.</p>\n<p>Is it a known issue ? Am I missing something ? Is there a functional BioMart+SOAP server anywhere ?</p>\n<p>Thanks,</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 1, "parent": null, "views": 821, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:31", "slug": "anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [114, 139, 140, 141, 142], "lastedit_user": 29}}, {"pk": 363, "model": "server.post", "fields": {"rght": 20, "author": 35, "answer_accepted": false, "tag_string": "visualization genome plotting", "creation_date": "2010-03-19 15:14:27", "lft": 1, "post_type": 164033, "score": 25, "title": "What tools/libraries do you use to visualize genomic feature data?", "unanswered": false, "content": "Given some genomic data in a well-known format (e.g. GFF) with gene models, what tool(s) do you use to visualize that data. \nWhat tools allow you to add your own tracks of data easily? \nI'm interested in both desktop and web-based tools--with preference to those that are customizable via some kind of API.", "comment_count": 0, "html": "<p>Given some genomic data in a well-known format (e.g. GFF) with gene models, what tool(s) do you use to visualize that data. \nWhat tools allow you to add your own tracks of data easily? \nI'm interested in both desktop and web-based tools--with preference to those that are customizable via some kind of API.</p>", "child_count": 0, "closed": false, "tree_id": 83, "revision_count": 1, "parent": null, "views": 2780, "deleted": false, "answer_count": 16, "touch_date": "2011-11-24 14:49:31", "slug": "what-toolslibraries-do-you-use-to-visualize-genomic-feature-data", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [67, 143, 218], "lastedit_user": 35}}, {"pk": 364, "model": "server.post", "fields": {"rght": 5, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 15:24:07", "lft": 2, "post_type": 109787, "score": 10, "title": "A: What tools/libraries do you use to visualize genomic feature data?", "unanswered": false, "content": "I'm using the well-known UCSC Genome Browser http://genome.ucsc.edu/goldenPath/help/customTrack.html\n\nI also wrote an experimental implementation of [Jan Aerts' LocusTree][1] based on BerkeleyDB (see http://plindenbaum.blogspot.com/2009/11/java-implementation-of-jan-aerts.html )\n\n![LocusTree][2]\n\n\n  [1]: http://saaientist.blogspot.com/2009/04/locustree-searching-genomic-loci.html\n  [2]: http://4.media.tumblr.com/tumblr_kt8yz0W4AP1qznaooo1_400.jpg", "comment_count": 1, "html": "<p>I'm using the well-known UCSC Genome Browser http://genome.ucsc.edu/goldenPath/help/customTrack.html</p>\n<p>I also wrote an experimental implementation of <a href=\"http://saaientist.blogspot.com/2009/04/locustree-searching-genomic-loci.html\">Jan Aerts' LocusTree</a> based on BerkeleyDB (see http://plindenbaum.blogspot.com/2009/11/java-implementation-of-jan-aerts.html )</p>\n<p><img alt=\"LocusTree\" src=\"http://4.media.tumblr.com/tumblr_kt8yz0W4AP1qznaooo1_400.jpg\" /></p>", "child_count": 0, "closed": false, "tree_id": 83, "revision_count": 1, "parent": 363, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-what-toolslibraries-do-you-use-to-visualize-genomic-feature-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 365, "model": "server.post", "fields": {"rght": 21, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 15:46:08", "lft": 2, "post_type": 109787, "score": 3, "title": "A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "Edit:\n**Conclusion: It does not work and is unlikely to work without changing the service.**\n\n**In the meantime, I would like to ask everyone who has similar experiences with non-functional SOAP/REST web-services, non-parsable WSDLS, non-validating XML-messages or other problems with service interoperability not to give up, but to report to the providers, to challenge them to improve the interoperability!**\n\nThose experiencing similar problems with  BioMart can for example report to: mart-dev@ebi.ac.uk\n\nTesting bioinformatics web-services can sometimes be a frustrating experience. It looks as if all the specs of interoperability are not worth the (white-) papers they are printed on.\nI actually have had very little success in connecting to perl, SOAP-lite based web-services like BioMart, Kegg, etc.  \n\nActually, I tried to use a generated Axis2 client and got an exception.\nThen, I tried to validate the response message in SoapUI from BioMart, and it does not validate!\n\n    line 4: Expected element 'mart' instead of 'mart@http://www.biomart.org:80/MartServiceSoap' here in element getRegistryResponse@http://www.biomart.org:80/MartServiceSoap\n\nSo it's very unlikely that this is going to work at all, except with perl and SOAP::Lite. There are too many tiny glitches involved. To clean up this mess I intend to contact the Bimart developers and ask them to change their interface. In fact, it seems that nobody has tested that yet with Java, otherwise somebody would have noticed that it does not work. \n\nMaybe, you wish to join me in this effort?\n\n\n----------\n\n\nHi Pierre,\n\nactually it would surprise me if there were no problems. This reminds me of some experiences I encountered when I tried to use the highly appraised standardized SOAP web-services world (actually I wanted to ask a question about user's experiences with bioinfo services but didn't get that far). So, it is a bit like the famous [radio yerevan][1], \"In principle it's standardized, but everyone has different standards.\"\n\nHowever, and not to just bash the providers, I can remember that we had successfully accessed biomart SOAP web-services with [SoapUI][2]. That tool is great for testing and building messages. Alternatively try a different SOAP stack like Axis2 to generate the binding.\n\nI might give it a try and generate a simple Axis2 client, then I will edit and provide the \njava code. So long there could be something wrong with the way you are trying to use the library. Also, Biomart is sensitive to the exact workflow of service calls.\n\nThis is what I just tried in soapui:\nwith SoapUI load the wsdl at: http://www.biomart.org/biomart/martwsdl\nWith other tools (eg curl, see comments), send the xml-message below to the \nservice endpoint address: http://www.biomart.org/biomart/martsoap\n\nthen call \"getRegistry\" as you did with the following message:\n  \n      <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:mar=\"http://www.biomart.org:80/MartServiceSoap\">\n    \n       <soapenv:Header/>\n    \n       <soapenv:Body>\n    \n          <mar:getRegistry/>\n       </soapenv:Body>\n    </soapenv:Envelope>\n\nThen you will get this response, which looks very much ok.\n\n    <soap:Envelope soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <getRegistryResponse xmlns=\"http://www.biomart.org:80/MartServiceSoap\">\n             <mart>\n                <name xsi:type=\"xsd:string\">ensembl</name>\n                <displayName xsi:type=\"xsd:string\">ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database xsi:type=\"xsd:string\">ensembl_mart_57</database>\n                <host xsi:type=\"xsd:string\">www.biomart.org</host>\n                <path xsi:type=\"xsd:string\">/biomart/martservice</path>\n                <port xsi:type=\"xsd:string\">80</port>\n                <visible xsi:type=\"xsd:int\">1</visible>\n                <default xsi:type=\"xsd:int\">1</default>\n                <serverVirtualSchema xsi:type=\"xsd:string\">default</serverVirtualSchema>\n                <includeDatasets xsi:type=\"xsd:string\"/>\n                <martUser xsi:type=\"xsd:string\"/>\n                <redirect xsi:nil=\"true\" xsi:type=\"xsd:int\"/>\n             </mart>\n\n\n\n\n\n\n  [1]: http://en.wikipedia.org/wiki/Radio_Yerevan\n  [2]: http://www.soapui.org/\n\n\n\n\n\n\n\n\n\n", "comment_count": 9, "html": "<p>Edit:\n<strong>Conclusion: It does not work and is unlikely to work without changing the service.</strong></p>\n<p><strong>In the meantime, I would like to ask everyone who has similar experiences with non-functional SOAP/REST web-services, non-parsable WSDLS, non-validating XML-messages or other problems with service interoperability not to give up, but to report to the providers, to challenge them to improve the interoperability!</strong></p>\n<p>Those experiencing similar problems with  BioMart can for example report to: mart-dev@ebi.ac.uk</p>\n<p>Testing bioinformatics web-services can sometimes be a frustrating experience. It looks as if all the specs of interoperability are not worth the (white-) papers they are printed on.\nI actually have had very little success in connecting to perl, SOAP-lite based web-services like BioMart, Kegg, etc.<br />\n</p>\n<p>Actually, I tried to use a generated Axis2 client and got an exception.\nThen, I tried to validate the response message in SoapUI from BioMart, and it does not validate!</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">line</span> <span class=\"mi\">4</span><span class=\"p\">:</span> <span class=\"n\">Expected</span> <span class=\"n\">element</span> <span class=\"s\">&#39;mart&#39;</span> <span class=\"n\">instead</span> <span class=\"n\">of</span> <span class=\"s\">&#39;mart@http://www.biomart.org:80/MartServiceSoap&#39;</span> <span class=\"n\">here</span> <span class=\"n\">in</span> <span class=\"n\">element</span> <span class=\"n\">getRegistryResponse</span><span class=\"nv\">@http:</span><span class=\"sr\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">biomart</span><span class=\"o\">.</span><span class=\"n\">org:80</span><span class=\"o\">/</span><span class=\"n\">MartServiceSoap</span>\n</pre></div>\n</p>\n<p>So it's very unlikely that this is going to work at all, except with perl and SOAP::Lite. There are too many tiny glitches involved. To clean up this mess I intend to contact the Bimart developers and ask them to change their interface. In fact, it seems that nobody has tested that yet with Java, otherwise somebody would have noticed that it does not work. </p>\n<p>Maybe, you wish to join me in this effort?</p>\n<hr />\n<p>Hi Pierre,</p>\n<p>actually it would surprise me if there were no problems. This reminds me of some experiences I encountered when I tried to use the highly appraised standardized SOAP web-services world (actually I wanted to ask a question about user's experiences with bioinfo services but didn't get that far). So, it is a bit like the famous <a href=\"http://en.wikipedia.org/wiki/Radio_Yerevan\">radio yerevan</a>, \"In principle it's standardized, but everyone has different standards.\"</p>\n<p>However, and not to just bash the providers, I can remember that we had successfully accessed biomart SOAP web-services with <a href=\"http://www.soapui.org/\">SoapUI</a>. That tool is great for testing and building messages. Alternatively try a different SOAP stack like Axis2 to generate the binding.</p>\n<p>I might give it a try and generate a simple Axis2 client, then I will edit and provide the \njava code. So long there could be something wrong with the way you are trying to use the library. Also, Biomart is sensitive to the exact workflow of service calls.</p>\n<p>This is what I just tried in soapui:\nwith SoapUI load the wsdl at: http://www.biomart.org/biomart/martwsdl\nWith other tools (eg curl, see comments), send the xml-message below to the \nservice endpoint address: http://www.biomart.org/biomart/martsoap</p>\n<p>then call \"getRegistry\" as you did with the following message:</p>\n<p><div class=\"highlight\"><pre>      <span class=\"nt\">&lt;soapenv:Envelope</span> <span class=\"na\">xmlns:soapenv=</span><span class=\"s\">&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;</span> <span class=\"na\">xmlns:mar=</span><span class=\"s\">&quot;http://www.biomart.org:80/MartServiceSoap&quot;</span><span class=\"nt\">&gt;</span>\n    \n       <span class=\"nt\">&lt;soapenv:Header/&gt;</span>\n    \n       <span class=\"nt\">&lt;soapenv:Body&gt;</span>\n    \n          <span class=\"nt\">&lt;mar:getRegistry/&gt;</span>\n       <span class=\"nt\">&lt;/soapenv:Body&gt;</span>\n    <span class=\"nt\">&lt;/soapenv:Envelope&gt;</span>\n</pre></div>\n</p>\n<p>Then you will get this response, which looks very much ok.</p>\n<p><div class=\"highlight\"><pre>    <span class=\"nt\">&lt;soap:Envelope</span> <span class=\"na\">soap:encodingStyle=</span><span class=\"s\">&quot;http://schemas.xmlsoap.org/soap/encoding/&quot;</span> <span class=\"na\">xmlns:xsi=</span><span class=\"s\">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span> <span class=\"na\">xmlns:soapenc=</span><span class=\"s\">&quot;http://schemas.xmlsoap.org/soap/encoding/&quot;</span> <span class=\"na\">xmlns:xsd=</span><span class=\"s\">&quot;http://www.w3.org/2001/XMLSchema&quot;</span> <span class=\"na\">xmlns:soap=</span><span class=\"s\">&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;</span><span class=\"nt\">&gt;</span>\n       <span class=\"nt\">&lt;soap:Body&gt;</span>\n          <span class=\"nt\">&lt;getRegistryResponse</span> <span class=\"na\">xmlns=</span><span class=\"s\">&quot;http://www.biomart.org:80/MartServiceSoap&quot;</span><span class=\"nt\">&gt;</span>\n             <span class=\"nt\">&lt;mart&gt;</span>\n                <span class=\"nt\">&lt;name</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>ensembl<span class=\"nt\">&lt;/name&gt;</span>\n                <span class=\"nt\">&lt;displayName</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>ENSEMBL GENES 57 (SANGER UK)<span class=\"nt\">&lt;/displayName&gt;</span>\n                <span class=\"nt\">&lt;database</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>ensembl_mart_57<span class=\"nt\">&lt;/database&gt;</span>\n                <span class=\"nt\">&lt;host</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>www.biomart.org<span class=\"nt\">&lt;/host&gt;</span>\n                <span class=\"nt\">&lt;path</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>/biomart/martservice<span class=\"nt\">&lt;/path&gt;</span>\n                <span class=\"nt\">&lt;port</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>80<span class=\"nt\">&lt;/port&gt;</span>\n                <span class=\"nt\">&lt;visible</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:int&quot;</span><span class=\"nt\">&gt;</span>1<span class=\"nt\">&lt;/visible&gt;</span>\n                <span class=\"nt\">&lt;default</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:int&quot;</span><span class=\"nt\">&gt;</span>1<span class=\"nt\">&lt;/default&gt;</span>\n                <span class=\"nt\">&lt;serverVirtualSchema</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>default<span class=\"nt\">&lt;/serverVirtualSchema&gt;</span>\n                <span class=\"nt\">&lt;includeDatasets</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">/&gt;</span>\n                <span class=\"nt\">&lt;martUser</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">/&gt;</span>\n                <span class=\"nt\">&lt;redirect</span> <span class=\"na\">xsi:nil=</span><span class=\"s\">&quot;true&quot;</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:int&quot;</span><span class=\"nt\">/&gt;</span>\n             <span class=\"nt\">&lt;/mart&gt;</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 4, "parent": 362, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 54}}, {"pk": 366, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 16:08:53", "lft": 4, "post_type": 109787, "score": 7, "title": "A: What tools/libraries do you use to visualize genomic feature data?", "unanswered": false, "content": "For desktop level genome visualization the [Integrated Genome Browser][1] is a very nice tool.\n\n  [1]: http://www.bioviz.org/igb/", "comment_count": 0, "html": "<p>For desktop level genome visualization the <a href=\"http://www.bioviz.org/igb/\">Integrated Genome Browser</a> is a very nice tool.</p>", "child_count": 0, "closed": false, "tree_id": 83, "revision_count": 2, "parent": 363, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-toolslibraries-do-you-use-to-visualize-genomic-feature-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 367, "model": "server.post", "fields": {"rght": 7, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 16:44:35", "lft": 6, "post_type": 109787, "score": 6, "title": "A: What tools/libraries do you use to visualize genomic feature data?", "unanswered": false, "content": "I'll put in a plug for  [Genboree](http://genboree.org/java-bin/login.jsp), which my lab develops.  It's essentially a genome browser with personalized databases/wikis, access control, and integration with Galaxy.  It can import UCSC tracks and you can add any data that maps to genomic coordinates. It also has a [REST API](http://genboree.org/java-bin/showHelp.jsp?topic=restAPIOverview) that's fairly new.\n\nSince I do a lot of copy-number work, I also do quite a bit of sanity-check visualization with R, often just using simple tweaks of the plot command, but sometimes pulling in packages to help.", "comment_count": 0, "html": "<p>I'll put in a plug for  <a href=\"http://genboree.org/java-bin/login.jsp\">Genboree</a>, which my lab develops.  It's essentially a genome browser with personalized databases/wikis, access control, and integration with Galaxy.  It can import UCSC tracks and you can add any data that maps to genomic coordinates. It also has a <a href=\"http://genboree.org/java-bin/showHelp.jsp?topic=restAPIOverview\">REST API</a> that's fairly new.</p>\n<p>Since I do a lot of copy-number work, I also do quite a bit of sanity-check visualization with R, often just using simple tweaks of the plot command, but sometimes pulling in packages to help.</p>", "child_count": 0, "closed": false, "tree_id": 83, "revision_count": 2, "parent": 363, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-what-toolslibraries-do-you-use-to-visualize-genomic-feature-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 368, "model": "server.post", "fields": {"rght": 9, "author": 119, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 17:51:58", "lft": 8, "post_type": 109787, "score": 13, "title": "A: What tools/libraries do you use to visualize genomic feature data?", "unanswered": false, "content": "I like the Broad's IGV: [http://www.broadinstitute.org/igv/][1] for genome browsing. It handles lots of common data formats, including SAM/BAM files if you're dealing with NGS-scale datasets. Apparently you can talk to it it via http, but you can't say anything very complicated: [http://www.broadinstitute.org/igv/PortCommands][2]\n\n  [1]: http://www.broadinstitute.org/igv/\n  [2]: http://www.broadinstitute.org/igv/PortCommands\n", "comment_count": 0, "html": "<p>I like the Broad's IGV: <a href=\"http://www.broadinstitute.org/igv/\">http://www.broadinstitute.org/igv/</a> for genome browsing. It handles lots of common data formats, including SAM/BAM files if you're dealing with NGS-scale datasets. Apparently you can talk to it it via http, but you can't say anything very complicated: <a href=\"http://www.broadinstitute.org/igv/PortCommands\">http://www.broadinstitute.org/igv/PortCommands</a></p>", "child_count": 0, "closed": false, "tree_id": 83, "revision_count": 1, "parent": 363, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-toolslibraries-do-you-use-to-visualize-genomic-feature-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 119}}, {"pk": 369, "model": "server.post", "fields": {"rght": 5, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 18:25:34", "lft": 4, "post_type": 109787, "score": 1, "title": "A: Repeat subunit based multiple alignment of DNA", "unanswered": false, "content": "As tagged correctly, this is a multiple sequence alignment problem, so pairwise/database alignment tools (BLAST or maybe B/LASTZ as mentioned above) are not an option. \nSo well understood tools such as [ClustalW][1], or T-Coffe, or DIALIGN, might already do the job. Try low gap extension/opening costs. I would try a well-known algorithm and try the more 'esoteric' stuff later on, and only if that doesn't give good results.\n\nBetter than ClustalW maybe in your case\n[Dialign][2]: It uses no gap-costs. \n\n> This approach can be used for both global and local alignment, but it is particularly successful in situations where sequences share only local  homologies. (From the BiBiServ description)\n\nThis seems to fit your case quite well.\n\nAnother possibility would be to mask out the portions of each sequence that is a priori known to be less conserved. That requires to have knowledge about each sequence and to manually design a mask. Or even a vector of base-specific weights, but I don't know any MSA tool that takes such input. If you find one, please post it here :)\n\n\n\n\n  [1]: http://www.ebi.ac.uk/Tools/clustalw2/\n  [2]: http://bibiserv.techfak.uni-bielefeld.de/dialign/", "comment_count": 0, "html": "<p>As tagged correctly, this is a multiple sequence alignment problem, so pairwise/database alignment tools (BLAST or maybe B/LASTZ as mentioned above) are not an option. \nSo well understood tools such as <a href=\"http://www.ebi.ac.uk/Tools/clustalw2/\">ClustalW</a>, or T-Coffe, or DIALIGN, might already do the job. Try low gap extension/opening costs. I would try a well-known algorithm and try the more 'esoteric' stuff later on, and only if that doesn't give good results.</p>\n<p>Better than ClustalW maybe in your case\n<a href=\"http://bibiserv.techfak.uni-bielefeld.de/dialign/\">Dialign</a>: It uses no gap-costs. </p>\n<blockquote>\n<p>This approach can be used for both global and local alignment, but it is particularly successful in situations where sequences share only local  homologies. (From the BiBiServ description)</p>\n</blockquote>\n<p>This seems to fit your case quite well.</p>\n<p>Another possibility would be to mask out the portions of each sequence that is a priori known to be less conserved. That requires to have knowledge about each sequence and to manually design a mask. Or even a vector of base-specific weights, but I don't know any MSA tool that takes such input. If you find one, please post it here :)</p>", "child_count": 0, "closed": false, "tree_id": 44, "revision_count": 1, "parent": 162, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:23", "slug": "a-repeat-subunit-based-multiple-alignment-of-dna", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 370, "model": "server.post", "fields": {"rght": 11, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 20:51:09", "lft": 10, "post_type": 109787, "score": 5, "title": "A: What tools/libraries do you use to visualize genomic feature data?", "unanswered": false, "content": "I use [Artemis][1] and [ACT][2] from the Sanger Institute. The former is a genome viewer and annotation tool. The latter is used for comparing genomes.\n\nHowever, I'm not sure that there's an API for it...\n\n\n  [1]: http://www.sanger.ac.uk/resources/software/artemis/\n  [2]: http://www.sanger.ac.uk/resources/software/act/", "comment_count": 0, "html": "<p>I use <a href=\"http://www.sanger.ac.uk/resources/software/artemis/\">Artemis</a> and <a href=\"http://www.sanger.ac.uk/resources/software/act/\">ACT</a> from the Sanger Institute. The former is a genome viewer and annotation tool. The latter is used for comparing genomes.</p>\n<p>However, I'm not sure that there's an API for it...</p>", "child_count": 0, "closed": false, "tree_id": 83, "revision_count": 1, "parent": 363, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-toolslibraries-do-you-use-to-visualize-genomic-feature-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 371, "model": "server.post", "fields": {"rght": 13, "author": 89, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 21:56:40", "lft": 12, "post_type": 109787, "score": 15, "title": "A: What tools/libraries do you use to visualize genomic feature data?", "unanswered": false, "content": "A bit different from the linear browsers listed above is the genome visualization tool [circos][1]. It can plot a wide range of different data types onto the radially displayed chromosomes. Everything can be customized and is quite easy to use. \n\n![alt text][2]\n\n\n  [1]: http://mkweb.bcgsc.ca/circos/\n  [2]: http://mkweb.bcgsc.ca/circos/tutorial_images/100px/tutorial-05-05.png", "comment_count": 0, "html": "<p>A bit different from the linear browsers listed above is the genome visualization tool <a href=\"http://mkweb.bcgsc.ca/circos/\">circos</a>. It can plot a wide range of different data types onto the radially displayed chromosomes. Everything can be customized and is quite easy to use. </p>\n<p><img alt=\"alt text\" src=\"http://mkweb.bcgsc.ca/circos/tutorial_images/100px/tutorial-05-05.png\" /></p>", "child_count": 0, "closed": false, "tree_id": 83, "revision_count": 1, "parent": 363, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-what-toolslibraries-do-you-use-to-visualize-genomic-feature-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 89}}, {"pk": 372, "model": "server.post", "fields": {"rght": 15, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 23:16:11", "lft": 14, "post_type": 109787, "score": 10, "title": "A: What tools/libraries do you use to visualize genomic feature data?", "unanswered": false, "content": "It's interesting to see votes for the IGV; I've looked at it only recently and it does look very promising as a desktop viewer.\n\nI'm a long-time user of the [Generic Genome Browser][1], a Bioperl-based web application. It is extremely customizable and can act as both DAS server and client. Be prepared to spend quite a bit of time \"munging\" your GFF files into shape and working on the config file to get the desired results.\n\nI also like Bioperl's [Bio::Graphics][2] as a way to take simple text files (including GFF) and quickly generate very attractive plots.  There's a similar, but less extensive [Ruby library][3] too.\n\nI've recently tried [GenomeGraphs][4], an R Bioconductor package. It fetches annotations from Ensembl and plots them as tracks. It's a good way to overlay quantitative data onto genomic features:  here is a [sample plot][5].\n\n\n  [1]: http://gmod.org/wiki/Gbrowse\n  [2]: http://bioperl.org/wiki/HOWTO:Graphics\n  [3]: http://bio-graphics.rubyforge.org/\n  [4]: http://www.bioconductor.org/packages/release/bioc/html/GenomeGraphs.html\n  [5]: http://twitpic.com/19350x", "comment_count": 0, "html": "<p>It's interesting to see votes for the IGV; I've looked at it only recently and it does look very promising as a desktop viewer.</p>\n<p>I'm a long-time user of the <a href=\"http://gmod.org/wiki/Gbrowse\">Generic Genome Browser</a>, a Bioperl-based web application. It is extremely customizable and can act as both DAS server and client. Be prepared to spend quite a bit of time \"munging\" your GFF files into shape and working on the config file to get the desired results.</p>\n<p>I also like Bioperl's <a href=\"\">Bio::Graphics</a> as a way to take simple text files (including GFF) and quickly generate very attractive plots.  There's a similar, but less extensive <a href=\"http://bio-graphics.rubyforge.org/\">Ruby library</a> too.</p>\n<p>I've recently tried <a href=\"http://www.bioconductor.org/packages/release/bioc/html/GenomeGraphs.html\">GenomeGraphs</a>, an R Bioconductor package. It fetches annotations from Ensembl and plots them as tracks. It's a good way to overlay quantitative data onto genomic features:  here is a <a href=\"http://twitpic.com/19350x\">sample plot</a>.</p>", "child_count": 0, "closed": false, "tree_id": 83, "revision_count": 1, "parent": 363, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-what-toolslibraries-do-you-use-to-visualize-genomic-feature-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 373, "model": "server.post", "fields": {"rght": 13, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 08:22:48", "lft": 12, "post_type": 109787, "score": 3, "title": "A: What license do you use when you release code and data?", "unanswered": false, "content": "Regarding Open Data, these require different licenses. I recommend reading the [Panton Principles][1].\n\n\n  [1]: http://pantonprinciples.org/", "comment_count": 0, "html": "<p>Regarding Open Data, these require different licenses. I recommend reading the <a href=\"http://pantonprinciples.org/\">Panton Principles</a>.</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 1, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 374, "model": "server.post", "fields": {"rght": 15, "author": 153, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 11:37:31", "lft": 14, "post_type": 109787, "score": 2, "title": "A: Where can I get the secondary structure of a protein?", "unanswered": false, "content": "If you want to obtain domains as well as the annotations that come along, you can do it locally with an RPS-BALST. Here for example to obtain Pfam annotations :\n> rpsblast -i \".$InputPath.\"/\".$item.\" -d ~/Bioinfo/cdd/Pfam -e 0.000000000001 -o \".$elemt[0].\"_Pfam.rpsblast -T T -m 7\n\n- i = the input path\n- d = the database path\n- e = the e-value cut-off value\n- o = the output name\n- T T and -m 7 = to have the output in XML format\n\nYou can download all the databases fromm CDD http://www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtml.\n You'll obtain external source databases like Pfam, SMART, COG, PRK, TIGRFAM. ", "comment_count": 0, "html": "<p>If you want to obtain domains as well as the annotations that come along, you can do it locally with an RPS-BALST. Here for example to obtain Pfam annotations :</p>\n<blockquote>\n<p>rpsblast -i \".$InputPath.\"/\".$item.\" -d ~/Bioinfo/cdd/Pfam -e 0.000000000001 -o \".$elemt[0].\"_Pfam.rpsblast -T T -m 7</p>\n</blockquote>\n<ul>\n<li>i = the input path</li>\n<li>d = the database path</li>\n<li>e = the e-value cut-off value</li>\n<li>o = the output name</li>\n<li>T T and -m 7 = to have the output in XML format</li>\n</ul>\n<p>You can download all the databases fromm CDD http://www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtml.\n You'll obtain external source databases like Pfam, SMART, COG, PRK, TIGRFAM. </p>", "child_count": 0, "closed": false, "tree_id": 18, "revision_count": 1, "parent": 48, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-where-can-i-get-the-secondary-structure-of-a-protein", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 153}}, {"pk": 375, "model": "server.post", "fields": {"rght": 10, "author": 153, "answer_accepted": false, "tag_string": "swissprot dna protein embl genbank", "creation_date": "2010-03-20 12:24:42", "lft": 1, "post_type": 164033, "score": 3, "title": "How to retrive the DNA sequence from a list of EMBL and GeneID", "unanswered": false, "content": "Hi everyone,\n\nAs input files, I use swissprot files. \nI have a perl script which parses all the `enter code here`files to retieve all the EMBL ids and GeneID from the DR features line for each protein.\nI would like to know if there's an automatic way to retrieve all the corresponding DNA squences for each protein on the list. Thanks for your help.\n\nBest,\n\nKirsley\n\n", "comment_count": 0, "html": "<p>Hi everyone,</p>\n<p>As input files, I use swissprot files. \nI have a perl script which parses all the <code>enter code here</code>files to retieve all the EMBL ids and GeneID from the DR features line for each protein.\nI would like to know if there's an automatic way to retrieve all the corresponding DNA squences for each protein on the list. Thanks for your help.</p>\n<p>Best,</p>\n<p>Kirsley</p>", "child_count": 0, "closed": false, "tree_id": 84, "revision_count": 1, "parent": null, "views": 485, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:24", "slug": "how-to-retrive-the-dna-sequence-from-a-list-of-embl-and-geneid", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [41, 65, 145, 146, 219], "lastedit_user": 153}}, {"pk": 376, "model": "server.post", "fields": {"rght": 3, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 12:51:20", "lft": 2, "post_type": 109787, "score": 5, "title": "A: How to retrive the DNA sequence from a list of EMBL and GeneID", "unanswered": false, "content": "from a geneid you can get the information as XML from the NCBI  with **EFetch**. e.g. for GeneId=2.\n\nhttp://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=gene&id=2&retmode=xml\n\nand you can then get the accession of each RNA sequence under: `(...)/Gene-commentary_products/Gene-commentary/Gene-commentary_type[@value='mRNA']/Gene-commentary_accession` (use XSLT/XPATH to extract this information)\n\nand for each accession you get the DNA sequence  with EFetch.\n\nhttp://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nucleotide&id=NM_000014&rettype=fasta&retmode=xml\n\n", "comment_count": 0, "html": "<p>from a geneid you can get the information as XML from the NCBI  with <strong>EFetch</strong>. e.g. for GeneId=2.</p>\n<p>http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=gene&amp;id=2&amp;retmode=xml</p>\n<p>and you can then get the accession of each RNA sequence under: <code>(...)/Gene-commentary_products/Gene-commentary/Gene-commentary_type[@value='mRNA']/Gene-commentary_accession</code> (use XSLT/XPATH to extract this information)</p>\n<p>and for each accession you get the DNA sequence  with EFetch.</p>\n<p>http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nucleotide&amp;id=NM_000014&amp;rettype=fasta&amp;retmode=xml</p>", "child_count": 0, "closed": false, "tree_id": 84, "revision_count": 1, "parent": 375, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-to-retrive-the-dna-sequence-from-a-list-of-embl-and-geneid", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 377, "model": "server.post", "fields": {"rght": 5, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 13:02:12", "lft": 4, "post_type": 109787, "score": 4, "title": "A: How to retrive the DNA sequence from a list of EMBL and GeneID", "unanswered": false, "content": "Yes there is if your organism is in Ensembl - [BioMart][1].  Here is how you'd use the web interface, assuming that you want human sequences:\n\n 1. Go to BioMart and click MARTVIEW\n 2. Select database = Ensembl Genes 57\n 3. Select dataset = Homo sapiens genes\n 4. Click \"Filters\" to the left and open the \"Gene\" selection\n 5. From the dropdown box, select the IDs that you want to use (e.g. UniProt/TrEMBL)\n 6. Either paste your list in the box or upload the file\n 7. Click \"Attributes\" to the left, select the \"Sequences\" radio button and open the \"Sequences\" tab\n 8. Select what type of sequence (e.g. unspliced transcript)\n 9. Click \"Results\" (in menu bar, top-left of page)\n\nThis will return the first 10 sequences. You can download the rest as a file. There is also programmatic access to Ensembl:  Perl API, biomaRt for R Bioconductor.\n\nIf this doesn't work for you, the [Bioperl][2] library should be able to retrieve sequences given IDs.\n\n\n  [1]: http://www.biomart.org\n  [2]: http://www.bioperl.org", "comment_count": 0, "html": "<p>Yes there is if your organism is in Ensembl - <a href=\"http://www.biomart.org\">BioMart</a>.  Here is how you'd use the web interface, assuming that you want human sequences:</p>\n<ol>\n<li>Go to BioMart and click MARTVIEW</li>\n<li>Select database = Ensembl Genes 57</li>\n<li>Select dataset = Homo sapiens genes</li>\n<li>Click \"Filters\" to the left and open the \"Gene\" selection</li>\n<li>From the dropdown box, select the IDs that you want to use (e.g. UniProt/TrEMBL)</li>\n<li>Either paste your list in the box or upload the file</li>\n<li>Click \"Attributes\" to the left, select the \"Sequences\" radio button and open the \"Sequences\" tab</li>\n<li>Select what type of sequence (e.g. unspliced transcript)</li>\n<li>Click \"Results\" (in menu bar, top-left of page)</li>\n</ol>\n<p>This will return the first 10 sequences. You can download the rest as a file. There is also programmatic access to Ensembl:  Perl API, biomaRt for R Bioconductor.</p>\n<p>If this doesn't work for you, the <a href=\"http://www.bioperl.org\">Bioperl</a> library should be able to retrieve sequences given IDs.</p>", "child_count": 0, "closed": false, "tree_id": 84, "revision_count": 1, "parent": 375, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-to-retrive-the-dna-sequence-from-a-list-of-embl-and-geneid", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 378, "model": "server.post", "fields": {"rght": 34, "author": 88, "answer_accepted": true, "tag_string": "chromosome ideogram plotting visualization", "creation_date": "2010-03-20 15:12:06", "lft": 1, "post_type": 164033, "score": 5, "title": "Drawing chromosome ideogams with data", "unanswered": false, "content": "What software do you use to draw chromosomes with G-banding pattern and plot data alongside each chromosome? I'm interested in different kind of plots - lines, points, bars, etc - and high customization.\n\nI have used [coloredChromosomes.pl][1] and [chromosomeplot][2] in MATLAB, but there are not enough features. What would you recommend to try?\n\n**UPDATE**:\nI need something like this:\n![chromosome plot example][3]\n\n\n  [1]: http://users.comcen.com.au/~journals/ojb/ojbideofreesample2003/ojbideofreesample2003.htm\n  [2]: http://www.mathworks.com/access/helpdesk/help/toolbox/bioinfo/ref/chromosomeplot.html\n  [3]: http://img233.imageshack.us/img233/6805/chrexample.jpg \"chromosome plot example\"", "comment_count": 0, "html": "<p>What software do you use to draw chromosomes with G-banding pattern and plot data alongside each chromosome? I'm interested in different kind of plots - lines, points, bars, etc - and high customization.</p>\n<p>I have used <a href=\"http://users.comcen.com.au/~journals/ojb/ojbideofreesample2003/ojbideofreesample2003.htm\">coloredChromosomes.pl</a> and <a href=\"http://www.mathworks.com/access/helpdesk/help/toolbox/bioinfo/ref/chromosomeplot.html\">chromosomeplot</a> in MATLAB, but there are not enough features. What would you recommend to try?</p>\n<p><strong>UPDATE</strong>:\nI need something like this:\n<img alt=\"chromosome plot example\" src=\"http://img233.imageshack.us/img233/6805/chrexample.jpg\" title=\"chromosome plot example\" /></p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 3, "parent": null, "views": 4680, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:31", "slug": "drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [143, 147, 148, 218], "lastedit_user": 86}}, {"pk": 379, "model": "server.post", "fields": {"rght": 5, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 15:35:11", "lft": 2, "post_type": 109787, "score": 2, "title": "A: Drawing chromosome ideogams with data", "unanswered": false, "content": "I found this bookmark in my del.icio.us \n\n> \"Idiographica: a general-purpose web\n> application to build idiograms\n> on-demand for human, mouse and rat\"\n\n doi:10.1093/bioinformatics/btm455 \n\nhttp://www.ncrna.org/idiographica/\n\n![idiographica][1]\n\nThere is also [gff2ps][2] \n\nOr you can use the **custom tracks** in the [UCSC genome Browser][3].\n\n\n  [1]: http://www.ncrna.org/idiographica/image/idiogram_sample1s\n  [2]: http://genome.crg.es/software/gfftools/GFF2PS.html\n  [3]: http://genome.ucsc.edu/goldenPath/help/customTrack.html", "comment_count": 1, "html": "<p>I found this bookmark in my del.icio.us </p>\n<blockquote>\n<p>\"Idiographica: a general-purpose web\napplication to build idiograms\non-demand for human, mouse and rat\"</p>\n</blockquote>\n<p>doi:10.1093/bioinformatics/btm455 </p>\n<p>http://www.ncrna.org/idiographica/</p>\n<p><img alt=\"idiographica\" src=\"http://www.ncrna.org/idiographica/image/idiogram_sample1s\" /></p>\n<p>There is also <a href=\"http://genome.crg.es/software/gfftools/GFF2PS.html\">gff2ps</a> </p>\n<p>Or you can use the <strong>custom tracks</strong> in the <a href=\"http://genome.ucsc.edu/goldenPath/help/customTrack.html\">UCSC genome Browser</a>.</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 1, "parent": 378, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 380, "model": "server.post", "fields": {"rght": 7, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 17:35:00", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Drawing chromosome ideogams with data", "unanswered": false, "content": "Circos is very popular these days\nhttp://mkweb.bcgsc.ca/circos/", "comment_count": 1, "html": "<p>Circos is very popular these days\nhttp://mkweb.bcgsc.ca/circos/</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 1, "parent": 378, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 381, "model": "server.post", "fields": {"rght": 9, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 23:07:51", "lft": 6, "post_type": 109787, "score": 1, "title": "A: Drawing chromosome ideogams with data", "unanswered": false, "content": "You can try [Flash GViewer][1].\n<p>I found it so nice that I tried to do a SVG version of it but not enough spare time to finish it.</p>\n\n\n  [1]: http://gmod.org/wiki/Flashgviewer/", "comment_count": 1, "html": "<p>You can try <a href=\"http://gmod.org/wiki/Flashgviewer/\">Flash GViewer</a>.\n[HTML_REMOVED]I found it so nice that I tried to do a SVG version of it but not enough spare time to finish it.[HTML_REMOVED]</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 1, "parent": 378, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 382, "model": "server.post", "fields": {"rght": 9, "author": 153, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-21 13:21:00", "lft": 6, "post_type": 109787, "score": 0, "title": "A: How to retrive the DNA sequence from a list of EMBL and GeneID", "unanswered": false, "content": "Thanks for your answers! I could not try with BioMart as my organism is not present on Ensembl. I forgot to precise that I am working on Chlamydiales.", "comment_count": 1, "html": "<p>Thanks for your answers! I could not try with BioMart as my organism is not present on Ensembl. I forgot to precise that I am working on Chlamydiales.</p>", "child_count": 0, "closed": false, "tree_id": 84, "revision_count": 1, "parent": 375, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "a-how-to-retrive-the-dna-sequence-from-a-list-of-embl-and-geneid", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 153}}, {"pk": 383, "model": "server.post", "fields": {"rght": 21, "author": 94, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-21 16:42:53", "lft": 20, "post_type": 109787, "score": 7, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "I guess a follow on to this question is \"What are the best sites to advertise informatics jobs when you are on a limited budget.\"  My system includes posting on:\n\n - **[LinkedIn][1]** - Free when you post via your status profile and groups.\n - **[Nature Jobs][2]** - Free\n - **[GenomeWeb][3]** - Free\n - **[Bioinformatics(dot)org][4]** - $75 / year professional membership needed\n - **[Craigslist][5]** - Free in most cities and a great way to find local candidates if you are in a bigger biotech city (DC, Boston, SD)\n - **[ISCB][6]** - Free if you are a member, which is like 100 bucks.\n - **[Dice.com][7]** - Expensive, but targeted. Geared more to technology professionals, have found several great SE and sys admin candidates here.\n\nThen, use sites like Twitter, FriendFeed, LinkedIn, Facebook, etc to spread thew word about the availability of these positions, and point candidates to your website.  I use [Wufoo][8] to generate applications, track candidates via the reports, etc.\n\nI find all of these are great ways to find entry-mid level candidates. \n\nThere is no substitute for trusted referrals or candidates from your existing network of professionals.\n\nOf course these are all great sites to search for a new job as well, that why I use them. ;-)\n\n\n  [1]: http://www.linkedin.com/\n  [2]: http://www.nature.com/naturejobs/index.html\n  [3]: http://www.genomeweb.com/jobs\n  [4]: http://www.genomeweb.com/jobs\n  [5]: http://washingtondc.craigslist.org/sci/\n  [6]: http://www.iscb.org/iscb-careers\n  [7]: http://www.dice.com/\n  [8]: http://Wufoo.com", "comment_count": 0, "html": "<p>I guess a follow on to this question is \"What are the best sites to advertise informatics jobs when you are on a limited budget.\"  My system includes posting on:</p>\n<ul>\n<li><strong><a href=\"http://www.linkedin.com/\">LinkedIn</a></strong> - Free when you post via your status profile and groups.</li>\n<li><strong><a href=\"http://www.nature.com/naturejobs/index.html\">Nature Jobs</a></strong> - Free</li>\n<li><strong><a href=\"http://www.genomeweb.com/jobs\">GenomeWeb</a></strong> - Free</li>\n<li><strong><a href=\"http://www.genomeweb.com/jobs\">Bioinformatics(dot)org</a></strong> - $75 / year professional membership needed</li>\n<li><strong><a href=\"http://washingtondc.craigslist.org/sci/\">Craigslist</a></strong> - Free in most cities and a great way to find local candidates if you are in a bigger biotech city (DC, Boston, SD)</li>\n<li><strong><a href=\"http://www.iscb.org/iscb-careers\">ISCB</a></strong> - Free if you are a member, which is like 100 bucks.</li>\n<li><strong><a href=\"http://www.dice.com/\">Dice.com</a></strong> - Expensive, but targeted. Geared more to technology professionals, have found several great SE and sys admin candidates here.</li>\n</ul>\n<p>Then, use sites like Twitter, FriendFeed, LinkedIn, Facebook, etc to spread thew word about the availability of these positions, and point candidates to your website.  I use <a href=\"http://Wufoo.com\">Wufoo</a> to generate applications, track candidates via the reports, etc.</p>\n<p>I find all of these are great ways to find entry-mid level candidates. </p>\n<p>There is no substitute for trusted referrals or candidates from your existing network of professionals.</p>\n<p>Of course these are all great sites to search for a new job as well, that why I use them. ;-)</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 1, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 94}}, {"pk": 384, "model": "server.post", "fields": {"rght": 7, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-21 21:00:25", "lft": 4, "post_type": 109787, "score": 1, "title": "A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "Hi again,\n\nI was finally able to edit the received message such that it can be validated. The biomart reponse semed to screw up namespace definitions and they use [XML-schema instance][1]. :o)\n\nThe schema instance definitions had no obvious use and did not validate. So I just removed them. \n\nIf you look at that w3c site you see that W3C says this should never be used.\nSo compare the valid edited reponse massage with the real (but shortened) output.\nThe next step is to make the maintainers have their service send valid XML\n\nHere is the edited and schema-valid response, only the first mart given:\n\n\n    <soap:Envelope \n    soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" \n    \n    xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" \n    xmlns:tns=\"http://www.biomart.org:80/MartServiceSoap\"\n    xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <tns:getRegistryResponse>\n             <mart>\n                <name>ensembl</name>\n                <displayName>ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database>ensembl_mart_57</database>\n                <host>www.biomart.org</host>\n                <path>/biomart/martservice</path>\n                <port>80</port>\n                <visible>1</visible>\n                <default>1</default>\n                <serverVirtualSchema>default</serverVirtualSchema>\n                <includeDatasets/>\n                <martUser/>\n                <redirect>1</redirect>\n             </mart>\n           \n          </tns:getRegistryResponse>\n       </soap:Body>\n    </soap:Envelope>\n\nAnd compare this with the original response:\n\n    <soap:Envelope soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"     \n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n    xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" \n    xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <getRegistryResponse xmlns=\"http://www.biomart.org:80/MartServiceSoap\">\n             <mart>\n                <name xsi:type=\"xsd:string\">ensembl</name>\n                <displayName xsi:type=\"xsd:string\">ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database xsi:type=\"xsd:string\">ensembl_mart_57</database>\n                <host xsi:type=\"xsd:string\">www.biomart.org</host>\n                <path xsi:type=\"xsd:string\">/biomart/martservice</path>\n                <port xsi:type=\"xsd:string\">80</port>\n                <visible xsi:type=\"xsd:int\">1</visible>\n                <default xsi:type=\"xsd:int\">1</default>\n                <serverVirtualSchema xsi:type=\"xsd:string\">default</serverVirtualSchema>\n                <includeDatasets xsi:type=\"xsd:string\"/>\n                <martUser xsi:type=\"xsd:string\"/>\n                <redirect xsi:nil=\"true\" xsi:type=\"xsd:int\"/>\n             </mart>\n          </getRegistryResponse>\n       </soap:Body>\n    </soap:Envelope>\n\n\n  [1]: http://www.w3.org/2001/XMLSchema-instance\n\n", "comment_count": 1, "html": "<p>Hi again,</p>\n<p>I was finally able to edit the received message such that it can be validated. The biomart reponse semed to screw up namespace definitions and they use <a href=\"http://www.w3.org/2001/XMLSchema-instance\">XML-schema instance</a>. :o)</p>\n<p>The schema instance definitions had no obvious use and did not validate. So I just removed them. </p>\n<p>If you look at that w3c site you see that W3C says this should never be used.\nSo compare the valid edited reponse massage with the real (but shortened) output.\nThe next step is to make the maintainers have their service send valid XML</p>\n<p>Here is the edited and schema-valid response, only the first mart given:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"nt\">&lt;soap:Envelope</span> \n    <span class=\"na\">soap:encodingStyle=</span><span class=\"s\">&quot;http://schemas.xmlsoap.org/soap/encoding/&quot;</span> \n    \n    <span class=\"na\">xmlns:soapenc=</span><span class=\"s\">&quot;http://schemas.xmlsoap.org/soap/encoding/&quot;</span> \n    <span class=\"na\">xmlns:xsd=</span><span class=\"s\">&quot;http://www.w3.org/2001/XMLSchema&quot;</span> \n    <span class=\"na\">xmlns:tns=</span><span class=\"s\">&quot;http://www.biomart.org:80/MartServiceSoap&quot;</span>\n    <span class=\"na\">xmlns:soap=</span><span class=\"s\">&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;</span><span class=\"nt\">&gt;</span>\n       <span class=\"nt\">&lt;soap:Body&gt;</span>\n          <span class=\"nt\">&lt;tns:getRegistryResponse&gt;</span>\n             <span class=\"nt\">&lt;mart&gt;</span>\n                <span class=\"nt\">&lt;name&gt;</span>ensembl<span class=\"nt\">&lt;/name&gt;</span>\n                <span class=\"nt\">&lt;displayName&gt;</span>ENSEMBL GENES 57 (SANGER UK)<span class=\"nt\">&lt;/displayName&gt;</span>\n                <span class=\"nt\">&lt;database&gt;</span>ensembl_mart_57<span class=\"nt\">&lt;/database&gt;</span>\n                <span class=\"nt\">&lt;host&gt;</span>www.biomart.org<span class=\"nt\">&lt;/host&gt;</span>\n                <span class=\"nt\">&lt;path&gt;</span>/biomart/martservice<span class=\"nt\">&lt;/path&gt;</span>\n                <span class=\"nt\">&lt;port&gt;</span>80<span class=\"nt\">&lt;/port&gt;</span>\n                <span class=\"nt\">&lt;visible&gt;</span>1<span class=\"nt\">&lt;/visible&gt;</span>\n                <span class=\"nt\">&lt;default&gt;</span>1<span class=\"nt\">&lt;/default&gt;</span>\n                <span class=\"nt\">&lt;serverVirtualSchema&gt;</span>default<span class=\"nt\">&lt;/serverVirtualSchema&gt;</span>\n                <span class=\"nt\">&lt;includeDatasets/&gt;</span>\n                <span class=\"nt\">&lt;martUser/&gt;</span>\n                <span class=\"nt\">&lt;redirect&gt;</span>1<span class=\"nt\">&lt;/redirect&gt;</span>\n             <span class=\"nt\">&lt;/mart&gt;</span>\n           \n          <span class=\"nt\">&lt;/tns:getRegistryResponse&gt;</span>\n       <span class=\"nt\">&lt;/soap:Body&gt;</span>\n    <span class=\"nt\">&lt;/soap:Envelope&gt;</span>\n</pre></div>\n</p>\n<p>And compare this with the original response:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"nt\">&lt;soap:Envelope</span> <span class=\"na\">soap:encodingStyle=</span><span class=\"s\">&quot;http://schemas.xmlsoap.org/soap/encoding/&quot;</span>     \n    <span class=\"na\">xmlns:xsi=</span><span class=\"s\">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span> \n    <span class=\"na\">xmlns:soapenc=</span><span class=\"s\">&quot;http://schemas.xmlsoap.org/soap/encoding/&quot;</span> \n    <span class=\"na\">xmlns:xsd=</span><span class=\"s\">&quot;http://www.w3.org/2001/XMLSchema&quot;</span> \n    <span class=\"na\">xmlns:soap=</span><span class=\"s\">&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;</span><span class=\"nt\">&gt;</span>\n       <span class=\"nt\">&lt;soap:Body&gt;</span>\n          <span class=\"nt\">&lt;getRegistryResponse</span> <span class=\"na\">xmlns=</span><span class=\"s\">&quot;http://www.biomart.org:80/MartServiceSoap&quot;</span><span class=\"nt\">&gt;</span>\n             <span class=\"nt\">&lt;mart&gt;</span>\n                <span class=\"nt\">&lt;name</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>ensembl<span class=\"nt\">&lt;/name&gt;</span>\n                <span class=\"nt\">&lt;displayName</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>ENSEMBL GENES 57 (SANGER UK)<span class=\"nt\">&lt;/displayName&gt;</span>\n                <span class=\"nt\">&lt;database</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>ensembl_mart_57<span class=\"nt\">&lt;/database&gt;</span>\n                <span class=\"nt\">&lt;host</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>www.biomart.org<span class=\"nt\">&lt;/host&gt;</span>\n                <span class=\"nt\">&lt;path</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>/biomart/martservice<span class=\"nt\">&lt;/path&gt;</span>\n                <span class=\"nt\">&lt;port</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>80<span class=\"nt\">&lt;/port&gt;</span>\n                <span class=\"nt\">&lt;visible</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:int&quot;</span><span class=\"nt\">&gt;</span>1<span class=\"nt\">&lt;/visible&gt;</span>\n                <span class=\"nt\">&lt;default</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:int&quot;</span><span class=\"nt\">&gt;</span>1<span class=\"nt\">&lt;/default&gt;</span>\n                <span class=\"nt\">&lt;serverVirtualSchema</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">&gt;</span>default<span class=\"nt\">&lt;/serverVirtualSchema&gt;</span>\n                <span class=\"nt\">&lt;includeDatasets</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">/&gt;</span>\n                <span class=\"nt\">&lt;martUser</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:string&quot;</span><span class=\"nt\">/&gt;</span>\n                <span class=\"nt\">&lt;redirect</span> <span class=\"na\">xsi:nil=</span><span class=\"s\">&quot;true&quot;</span> <span class=\"na\">xsi:type=</span><span class=\"s\">&quot;xsd:int&quot;</span><span class=\"nt\">/&gt;</span>\n             <span class=\"nt\">&lt;/mart&gt;</span>\n          <span class=\"nt\">&lt;/getRegistryResponse&gt;</span>\n       <span class=\"nt\">&lt;/soap:Body&gt;</span>\n    <span class=\"nt\">&lt;/soap:Envelope&gt;</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 2, "parent": 362, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 385, "model": "server.post", "fields": {"rght": 23, "author": 157, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 08:21:22", "lft": 22, "post_type": 109787, "score": -5, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "Hi, \n\nI like this thread: begins as a troll, ends with nice advices\n\n  ---jmf", "comment_count": 0, "html": "<p>Hi, </p>\n<p>I like this thread: begins as a troll, ends with nice advices</p>\n<p>---jmf</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 2, "parent": 34, "views": 0, "deleted": true, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 157}}, {"pk": 386, "model": "server.post", "fields": {"rght": 25, "author": 160, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 10:30:55", "lft": 24, "post_type": 109787, "score": 1, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "Hi !\nBriefly, I use R/Bioconductor, combined with PHP and MySQL. PHP can encapsulate programmes/scripts from other languages, such as Perl and Java, and can easly manage webapps by URL. Also nice for UI and run on Linux/MacOSX/Window$.\n", "comment_count": 0, "html": "<p>Hi !\nBriefly, I use R/Bioconductor, combined with PHP and MySQL. PHP can encapsulate programmes/scripts from other languages, such as Perl and Java, and can easly manage webapps by URL. Also nice for UI and run on Linux/MacOSX/Window$.</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 160}}, {"pk": 387, "model": "server.post", "fields": {"rght": 46, "author": 147, "answer_accepted": true, "tag_string": "microarray data methods models", "creation_date": "2010-03-22 11:34:06", "lft": 1, "post_type": 164033, "score": 2, "title": "What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "Hi people,\n\nI've just attended a seminar focused on microarray data, essentially given by experimentalists. It was somewhat shocking that they were unable to agree on what methods to use for data normalization (and why). So, you can imagine what happened in further steps . . .\n\nHence, I'm wondering about a list of the most reliable methods for data normalization. Not a plain list of methods/models. A list explaing why a given method/model is reliable (or why someone should use it). \n\nJust to avoid some confusions, in this context [reliability][1] acquires its statistical meaning.\n\nThis question is relevant just because the most popular normalization procedures depends on statistical models to address probe-level, background-level, etc., variation/correlation. For example, RMA and fRMA uses a linear model. \n\nSo, given the number of microarray plataforms and designs, reliability is of utmost importance. \n\n\n\n  [1]: http://en.wikipedia.org/wiki/Reliability_%28statistics%29", "comment_count": 3, "html": "<p>Hi people,</p>\n<p>I've just attended a seminar focused on microarray data, essentially given by experimentalists. It was somewhat shocking that they were unable to agree on what methods to use for data normalization (and why). So, you can imagine what happened in further steps . . .</p>\n<p>Hence, I'm wondering about a list of the most reliable methods for data normalization. Not a plain list of methods/models. A list explaing why a given method/model is reliable (or why someone should use it). </p>\n<p>Just to avoid some confusions, in this context <a href=\"http://en.wikipedia.org/wiki/Reliability_%28statistics%29\">reliability</a> acquires its statistical meaning.</p>\n<p>This question is relevant just because the most popular normalization procedures depends on statistical models to address probe-level, background-level, etc., variation/correlation. For example, RMA and fRMA uses a linear model. </p>\n<p>So, given the number of microarray plataforms and designs, reliability is of utmost importance. </p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 3, "parent": null, "views": 1184, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:27", "slug": "what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [7, 48, 149, 224], "lastedit_user": 147}}, {"pk": 388, "model": "server.post", "fields": {"rght": 30, "author": 159, "answer_accepted": true, "tag_string": "what bioinformatics not related", "creation_date": "2010-03-22 11:59:39", "lft": 1, "post_type": 164033, "score": 6, "title": "How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "Ok, I realise that some of you work on a genome campus or your mum may be a Nobel prize winner, but, given a socially average situation, how do you explain your work, and for a 50 point bonus, how do you feel as you do it?", "comment_count": 0, "html": "<p>Ok, I realise that some of you work on a genome campus or your mum may be a Nobel prize winner, but, given a socially average situation, how do you explain your work, and for a 50 point bonus, how do you feel as you do it?</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 2, "parent": null, "views": 570, "deleted": false, "answer_count": 12, "touch_date": "2011-11-24 14:49:31", "slug": "how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [151, 152, 221, 222], "lastedit_user": 29}}, {"pk": 389, "model": "server.post", "fields": {"rght": 5, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 12:04:48", "lft": 2, "post_type": 109787, "score": 3, "title": "A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "I tell them: \"there must [be a page on wikipedia][1] about it\".\n\n\n  [1]: http://en.wikipedia.org/wiki/Bioinformatics", "comment_count": 1, "html": "<p>I tell them: \"there must <a href=\"http://en.wikipedia.org/wiki/Bioinformatics\">be a page on wikipedia</a> about it\".</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 1, "parent": 388, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 390, "model": "server.post", "fields": {"rght": 9, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 12:20:32", "lft": 4, "post_type": 109787, "score": 2, "title": "A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "I go to the streets and stop all the people I encounter, and I explain them what I do in my lab, so I accumulate a lot of experience and become better at explaining things :-)\n\nSeriously, if you want to be able to explain your project to other people, you have to be able to explain it to your workmates first.. so I prepare a seminar every once in a while and I try to be active at group meetings. In my first year of phd I was able to prepare a seminar every month (as a mean), I also went to python meetings etc..\n\nNon peer-review journals like The Scientist or Scientific American can give you good examples on how to translate a complex scientific experiment in a language that is easy to understand for everybody.\n\nAnother way to improve comes from the fact that I use a lot of A7 papers to take notes, so I constantly have to reduce my tasks to short phrases. However, it would take too long to explain this system better here..\n\nI think that in general, if you want to improve your communications skills, you have to practice a lot, there is no other way to do it. ", "comment_count": 2, "html": "<p>I go to the streets and stop all the people I encounter, and I explain them what I do in my lab, so I accumulate a lot of experience and become better at explaining things :-)</p>\n<p>Seriously, if you want to be able to explain your project to other people, you have to be able to explain it to your workmates first.. so I prepare a seminar every once in a while and I try to be active at group meetings. In my first year of phd I was able to prepare a seminar every month (as a mean), I also went to python meetings etc..</p>\n<p>Non peer-review journals like The Scientist or Scientific American can give you good examples on how to translate a complex scientific experiment in a language that is easy to understand for everybody.</p>\n<p>Another way to improve comes from the fact that I use a lot of A7 papers to take notes, so I constantly have to reduce my tasks to short phrases. However, it would take too long to explain this system better here..</p>\n<p>I think that in general, if you want to improve your communications skills, you have to practice a lot, there is no other way to do it. </p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 1, "parent": 388, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 391, "model": "server.post", "fields": {"rght": 6, "author": 70, "answer_accepted": false, "tag_string": "torrent bioinformatics data", "creation_date": "2010-03-22 13:03:12", "lft": 1, "post_type": 164033, "score": 4, "title": "How do I import data from a torrent into a BioPerl, R, Bioclipse, or Taverna application?", "unanswered": false, "content": "While [BioTorrent][1] is still rather unpopulated, I quite like the idea of having such torrents seeded by university IT or library departments. Now, I want to analyze the data, so the question is, how can the data be used directly in my workflow system ([BioPerl][2] or [R][3] scripts, [Taverna][4] or [Bioclipse][5] workflows)?\n\nAre there libraries in a suitable programming language to download torrents automatically, without human interaction?\n\n  [1]: http://www.biotorrents.net/browse.php?page=1\n  [2]: http://www.bioperl.org/\n  [3]: http://www.r-project.org/\n  [4]: http://taverna.sf.net\n  [5]: http://bioclipse.net", "comment_count": 0, "html": "<p>While <a href=\"http://www.biotorrents.net/browse.php?page=1\">BioTorrent</a> is still rather unpopulated, I quite like the idea of having such torrents seeded by university IT or library departments. Now, I want to analyze the data, so the question is, how can the data be used directly in my workflow system (<a href=\"http://www.bioperl.org/\">BioPerl</a> or <a href=\"http://www.r-project.org/\">R</a> scripts, <a href=\"http://taverna.sf.net\">Taverna</a> or <a href=\"http://bioclipse.net\">Bioclipse</a> workflows)?</p>\n<p>Are there libraries in a suitable programming language to download torrents automatically, without human interaction?</p>", "child_count": 0, "closed": false, "tree_id": 88, "revision_count": 1, "parent": null, "views": 238, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:28", "slug": "how-do-i-import-data-from-a-torrent-into-a-bioperl-r-bioclipse-or-taverna-application", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [48, 152, 153], "lastedit_user": 70}}, {"pk": 392, "model": "server.post", "fields": {"rght": 9, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 13:18:01", "lft": 2, "post_type": 109787, "score": 5, "title": "A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "I recommend that you visit PubMed, enter \"microarray (normalisation OR normalization) as a query, select some of the review articles and have a good read. Then, armed with appropriate keywords (RMA, GCRMA, MAS), head to Google and obtain some more opinions.\n\nIt is not so surprising that people cannot agree on methods. A normalisation method is just a statistical model that tries to explain what happens when probes meet gene chips. Different models have different assumptions. Some of these are: how to distinguish within-array effects from between-array effects?  Are mismatch probes ever useful?  (RMA says no, because MM probes often, in fact, match).  How is \"background\" distributed across a chip?\n\nExperiments also vary. Which of your experiments are comparable? Should you even be comparing, say, samples prepared last week and frozen to samples freshly-prepared today? If you do want to compare, you can only hope that each set will show some characteristic (batch effect) for which you can correct. \n\nHow do you conclude that a method is \"right\", or \"better\"?  You might try to validate using another experimental method, such as real-time PCR. Or you might conduct \"spike-in\" experiments, where you know what the \"true positives\" should be, then see how well each method picks them out.  That's the approach taken in [this paper][1].  Or, you might try several methods on your own favourite dataset. Of course, someone else will then try them on their favourite dataset - and reach totally opposite conclusions!  Or you might just ask \"what do most people do?\"\n\nThat's the long answer. The short answer: RMA ;-)\n\n  [1]: http://nar.oxfordjournals.org/cgi/content/full/31/4/e15", "comment_count": 3, "html": "<p>I recommend that you visit PubMed, enter \"microarray (normalisation OR normalization) as a query, select some of the review articles and have a good read. Then, armed with appropriate keywords (RMA, GCRMA, MAS), head to Google and obtain some more opinions.</p>\n<p>It is not so surprising that people cannot agree on methods. A normalisation method is just a statistical model that tries to explain what happens when probes meet gene chips. Different models have different assumptions. Some of these are: how to distinguish within-array effects from between-array effects?  Are mismatch probes ever useful?  (RMA says no, because MM probes often, in fact, match).  How is \"background\" distributed across a chip?</p>\n<p>Experiments also vary. Which of your experiments are comparable? Should you even be comparing, say, samples prepared last week and frozen to samples freshly-prepared today? If you do want to compare, you can only hope that each set will show some characteristic (batch effect) for which you can correct. </p>\n<p>How do you conclude that a method is \"right\", or \"better\"?  You might try to validate using another experimental method, such as real-time PCR. Or you might conduct \"spike-in\" experiments, where you know what the \"true positives\" should be, then see how well each method picks them out.  That's the approach taken in <a href=\"http://nar.oxfordjournals.org/cgi/content/full/31/4/e15\">this paper</a>.  Or, you might try several methods on your own favourite dataset. Of course, someone else will then try them on their favourite dataset - and reach totally opposite conclusions!  Or you might just ask \"what do most people do?\"</p>\n<p>That's the long answer. The short answer: RMA ;-)</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 1, "parent": 387, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 393, "model": "server.post", "fields": {"rght": 21, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 13:19:59", "lft": 4, "post_type": 109787, "score": 3, "title": "A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "The lack of reproducibility in microarray methods is well known problem. In my opinion the reasons for this go way beyond the choice of normalization and are primarily caused by biological and experimental variability. Some are convinced that one method must be substantially better than the other, but I suspect that is because that particular method worked well for them under some specific circumstances. \n\nI read studies that demonstrated that the upper 50% percent (the strongest signals) were recovered identically across just about all methodologies, whereas the bottom half contained a different subset for each method. So maybe the best strategy is to be more strict with the results, beyond what the original estimate of the significance is - of course it could be that this approach removes the genes of interest.\n\n\nThat's the long answer. The short answer: the best normalization is the one you understand the best. \n\n;-)\n", "comment_count": 8, "html": "<p>The lack of reproducibility in microarray methods is well known problem. In my opinion the reasons for this go way beyond the choice of normalization and are primarily caused by biological and experimental variability. Some are convinced that one method must be substantially better than the other, but I suspect that is because that particular method worked well for them under some specific circumstances. </p>\n<p>I read studies that demonstrated that the upper 50% percent (the strongest signals) were recovered identically across just about all methodologies, whereas the bottom half contained a different subset for each method. So maybe the best strategy is to be more strict with the results, beyond what the original estimate of the significance is - of course it could be that this approach removes the genes of interest.</p>\n<p>That's the long answer. The short answer: the best normalization is the one you understand the best. </p>\n<p>;-)</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 1, "parent": 387, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 394, "model": "server.post", "fields": {"rght": 5, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 13:45:56", "lft": 2, "post_type": 109787, "score": 5, "title": "A: How do I import data from a torrent into a BioPerl, R, Bioclipse, or Taverna application?", "unanswered": false, "content": "I don't think there is an R library for torrents. I have tried searching [here][1] and on [CRAN][2], but there is nothing.\n\nPerl, on the other side, has [many libraries][3] for downloading torrents. Python [supports torrents][4] as well.\n\nOnce you have chosen a library, just write a script to download the torrent and to give a return signal when it is finished. \n\nHowever, I would object on the reproducibility of using data downloaded with a torrent: what would you do if the torrent disappears or is modified after you have used it? How do you take into account the version of the data?\nMoreover, consider that scientific databases have to release their data often, and every release would require a different torrent to be seed. That would make it more difficult to control and keep.\n\n\n\n  [1]: http://www.rseek.org/?cx=010923144343702598753%3Aboaz1reyxd4&q=torrent&sa=Search+functions%2C+lists%2C+and+more&cof=FORID%3A11&siteurl=www.rseek.org%2F%3Fq%3Dtorrent#467\n  [2]: http://cran.r-project.org/\n  [3]: http://search.cpan.org/search?query=torrent&mode=all\n  [4]: http://pypi.python.org/pypi?%3Aaction=search&term=torrent&submit=search", "comment_count": 1, "html": "<p>I don't think there is an R library for torrents. I have tried searching <a href=\"http://www.rseek.org/?cx=010923144343702598753%3Aboaz1reyxd4&amp;q=torrent&amp;sa=Search+functions%2C+lists%2C+and+more&amp;cof=FORID%3A11&amp;siteurl=www.rseek.org%2F%3Fq%3Dtorrent#467\">here</a> and on <a href=\"http://cran.r-project.org/\">CRAN</a>, but there is nothing.</p>\n<p>Perl, on the other side, has <a href=\"http://search.cpan.org/search?query=torrent&amp;mode=all\">many libraries</a> for downloading torrents. Python <a href=\"http://pypi.python.org/pypi?%3Aaction=search&amp;term=torrent&amp;submit=search\">supports torrents</a> as well.</p>\n<p>Once you have chosen a library, just write a script to download the torrent and to give a return signal when it is finished. </p>\n<p>However, I would object on the reproducibility of using data downloaded with a torrent: what would you do if the torrent disappears or is modified after you have used it? How do you take into account the version of the data?\nMoreover, consider that scientific databases have to release their data often, and every release would require a different torrent to be seed. That would make it more difficult to control and keep.</p>", "child_count": 0, "closed": false, "tree_id": 88, "revision_count": 1, "parent": 391, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-how-do-i-import-data-from-a-torrent-into-a-bioperl-r-bioclipse-or-taverna-application", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 395, "model": "server.post", "fields": {"rght": 9, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 14:28:56", "lft": 6, "post_type": 109787, "score": 10, "title": "A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "I totally think that science communication should be a required course in every PhD program, and that you should have to practice these explanations until you can do them in your sleep. Scientists are their own best advocates, and we need to start acting like it. \n\nYou need to be able to explain your work at several different depths. It's just as important to accurately gauge the interest and experience of your audience, so you can choose the appropriate spiel. That's the really tricky part.  Some of the tools you need are:\n\nFor non-scientists:\n\n- The layperson's 15-second elevator pitch: For the cocktail party or the new acquaintance who asks what you do. They should walk away understanding that you do science and that your work is trying to make the world a better place. (\"better cancer treatments\", \"new malaria drugs\")\n\n- The follow-up 2-minute overview if they ask for more details  Still very high level, abstract, focused on where you're trying to get with your research. (\"understanding XYZ part of disease ABC by looking at things through a microscope\", \"figuring out how the brain stores memories by sticking people in cool scanners\")\n\n- The full explanation. For the non-scientists who really want to wrap their head around what you do. Keep in mind that these people may not have taken a science course since high school.  Avoid jargon and acronyms, and make sure that at the end, you leave them with the big picture idea of what you're trying to accomplish and how that will advance humanity.\n\nFor scientists:\n\n- The scientists's elevator pitch. For people who you'll meet around your campus or at conferences. You may even need two or three of these, for use in different venues.  (At a focused conference, you'll be more specific and jargon-ythan at a departmental retreat)\n\n- The two-minute casual conversation.  This one is tricky, because you need to read the person you're talking to in a very short time.  Do they know what RMA is? What about ERBB2? What's their background, and how can I look at my problem from their angle, so as to best couch my answer in terms they'll understand?\n\n- The 5, 15, and 30 minute presentations, often with slides or a poster. You should get drilled in these during your graduate school career, and if you didn't, there's no time like the present to start practicing.\n\n\nOnce you get these down, practice the final element, which is being enthusiastic about your work. After all, you probably think that what you\u2019re researching is one of the coolest and most important things ever. If that comes across to your audience, they\u2019ll be engaged and interested too.\n\n", "comment_count": 1, "html": "<p>I totally think that science communication should be a required course in every PhD program, and that you should have to practice these explanations until you can do them in your sleep. Scientists are their own best advocates, and we need to start acting like it. </p>\n<p>You need to be able to explain your work at several different depths. It's just as important to accurately gauge the interest and experience of your audience, so you can choose the appropriate spiel. That's the really tricky part.  Some of the tools you need are:</p>\n<p>For non-scientists:</p>\n<ul>\n<li>\n<p>The layperson's 15-second elevator pitch: For the cocktail party or the new acquaintance who asks what you do. They should walk away understanding that you do science and that your work is trying to make the world a better place. (\"better cancer treatments\", \"new malaria drugs\")</p>\n</li>\n<li>\n<p>The follow-up 2-minute overview if they ask for more details  Still very high level, abstract, focused on where you're trying to get with your research. (\"understanding XYZ part of disease ABC by looking at things through a microscope\", \"figuring out how the brain stores memories by sticking people in cool scanners\")</p>\n</li>\n<li>\n<p>The full explanation. For the non-scientists who really want to wrap their head around what you do. Keep in mind that these people may not have taken a science course since high school.  Avoid jargon and acronyms, and make sure that at the end, you leave them with the big picture idea of what you're trying to accomplish and how that will advance humanity.</p>\n</li>\n</ul>\n<p>For scientists:</p>\n<ul>\n<li>\n<p>The scientists's elevator pitch. For people who you'll meet around your campus or at conferences. You may even need two or three of these, for use in different venues.  (At a focused conference, you'll be more specific and jargon-ythan at a departmental retreat)</p>\n</li>\n<li>\n<p>The two-minute casual conversation.  This one is tricky, because you need to read the person you're talking to in a very short time.  Do they know what RMA is? What about ERBB2? What's their background, and how can I look at my problem from their angle, so as to best couch my answer in terms they'll understand?</p>\n</li>\n<li>\n<p>The 5, 15, and 30 minute presentations, often with slides or a poster. You should get drilled in these during your graduate school career, and if you didn't, there's no time like the present to start practicing.</p>\n</li>\n</ul>\n<p>Once you get these down, practice the final element, which is being enthusiastic about your work. After all, you probably think that what you\u2019re researching is one of the coolest and most important things ever. If that comes across to your audience, they\u2019ll be engaged and interested too.</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 2, "parent": 388, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 116}}, {"pk": 396, "model": "server.post", "fields": {"rght": 17, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 15:16:13", "lft": 16, "post_type": 109787, "score": 11, "title": "A: What tools/libraries do you use to visualize genomic feature data?", "unanswered": false, "content": "thanks for all the replies so far. i just want to add a couple i've found:\nAnnoj with a nice demo here: http://neomorph.salk.edu/epigenome/epigenome.html\nseems to be a pretty nice web-interface and i've been able to get my own annotations drawn. it may be an abandoned project, and i wasn't able to find the javascript source (only the packed/minified version).\n\nalso [genometools][1] wraps cairo to allow simple drawing of regions: here's the image from their home page. ![alt text][2] And they have bindings to a variety of scripting languages.\n\n  [1]: http://genometools.org\n  [2]: http://genometools.org/images/annotation.png", "comment_count": 0, "html": "<p>thanks for all the replies so far. i just want to add a couple i've found:\nAnnoj with a nice demo here: http://neomorph.salk.edu/epigenome/epigenome.html\nseems to be a pretty nice web-interface and i've been able to get my own annotations drawn. it may be an abandoned project, and i wasn't able to find the javascript source (only the packed/minified version).</p>\n<p>also <a href=\"http://genometools.org\">genometools</a> wraps cairo to allow simple drawing of regions: here's the image from their home page. <img alt=\"alt text\" src=\"http://genometools.org/images/annotation.png\" /> And they have bindings to a variety of scripting languages.</p>", "child_count": 0, "closed": false, "tree_id": 83, "revision_count": 1, "parent": 363, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-what-toolslibraries-do-you-use-to-visualize-genomic-feature-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 35}}, {"pk": 397, "model": "server.post", "fields": {"rght": 11, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 15:43:48", "lft": 8, "post_type": 109787, "score": 4, "title": "A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "My opening line: \"I work at the intersection between computers and biology\". \n\nOften there is no need to say anything more. If the person looks for more detailed answer I talk about assembling a whole book from a huge pile of randomly torn out sentences (DNA assembly). \n\nThen one can go with finding \"interesting paragraphs\", \"repeated, mostly boring parts\", etc. Works for non-scientist (at least that my impression...).\n\nIn short: if possible, find analogy everyone can somehow relate to. \nYou get minus points for anything sounding too technical.  \n \n  \n ", "comment_count": 1, "html": "<p>My opening line: \"I work at the intersection between computers and biology\". </p>\n<p>Often there is no need to say anything more. If the person looks for more detailed answer I talk about assembling a whole book from a huge pile of randomly torn out sentences (DNA assembly). </p>\n<p>Then one can go with finding \"interesting paragraphs\", \"repeated, mostly boring parts\", etc. Works for non-scientist (at least that my impression...).</p>\n<p>In short: if possible, find analogy everyone can somehow relate to. \nYou get minus points for anything sounding too technical.<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 2, "parent": 388, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 398, "model": "server.post", "fields": {"rght": 14, "author": 88, "answer_accepted": true, "tag_string": "job career general not related", "creation_date": "2010-03-22 15:48:32", "lft": 1, "post_type": 164033, "score": 6, "title": "What do different bioinformatics positions mean?", "unanswered": false, "content": "I went to several sites to look for a new position (thanks to recent [question][1]). With not much experience in bioinformatics market I'm confused with a lot of different positions. Some positions I understand but not everything. Some looks like just called differently for companies, academy or government. I tried to put here all I could find. Can somebody approximately sort them let's say by salary or level of responsibility? Which positions requires Ph.D. degree? Any systematic description would be very useful.\n\n - Bioinformatics Internship\n - Bioinformatics Postdoc \n - Bioinformatics Analyst (I, II, III) \n - Senior Bioinformatics Analyst \n - Bioinformatics Analyst Programmer (I, II, III)\n - Bioinformatics Developer Senior\n - Bioinformatics Developer\n - Bioinformatician (I, II, III)\n - Bioinformatics Expert \n - Bioinformatics Systems Administrator \n - Bioinformatics Research Fellow \n - Bioinformatics Research Assistant \n - Bioinformatics Research Associate \n - Bioinformatics Scientist (Researcher) \n - Bioinformatics Senior (Staff) Scientist\n - Bioinformatics Project Manager\n - Director (Head) of Bioinformatics\n\n  [1]: http://biostar.stackexchange.com/questions/296/where-to-advertise-or-find-bioinformatics-jobs", "comment_count": 0, "html": "<p>I went to several sites to look for a new position (thanks to recent <a href=\"http://biostar.stackexchange.com/questions/296/where-to-advertise-or-find-bioinformatics-jobs\">question</a>). With not much experience in bioinformatics market I'm confused with a lot of different positions. Some positions I understand but not everything. Some looks like just called differently for companies, academy or government. I tried to put here all I could find. Can somebody approximately sort them let's say by salary or level of responsibility? Which positions requires Ph.D. degree? Any systematic description would be very useful.</p>\n<ul>\n<li>Bioinformatics Internship</li>\n<li>Bioinformatics Postdoc </li>\n<li>Bioinformatics Analyst (I, II, III) </li>\n<li>Senior Bioinformatics Analyst </li>\n<li>Bioinformatics Analyst Programmer (I, II, III)</li>\n<li>Bioinformatics Developer Senior</li>\n<li>Bioinformatics Developer</li>\n<li>Bioinformatician (I, II, III)</li>\n<li>Bioinformatics Expert </li>\n<li>Bioinformatics Systems Administrator </li>\n<li>Bioinformatics Research Fellow </li>\n<li>Bioinformatics Research Assistant </li>\n<li>Bioinformatics Research Associate </li>\n<li>Bioinformatics Scientist (Researcher) </li>\n<li>Bioinformatics Senior (Staff) Scientist</li>\n<li>Bioinformatics Project Manager</li>\n<li>Director (Head) of Bioinformatics</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 89, "revision_count": 3, "parent": null, "views": 1302, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:30", "slug": "what-do-different-bioinformatics-positions-mean", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [31, 110, 126, 221, 222], "lastedit_user": 54}}, {"pk": 399, "model": "server.post", "fields": {"rght": 13, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 16:48:47", "lft": 10, "post_type": 109787, "score": 2, "title": "A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "I use these simple facts : I work on data from human genome project, and explain that its one of the biggest scientific achievement ever. I use that data to analyze proteins involved in X diseases. We are trying to understand these proteins and its various aspects related to disease using computer programs, database, software etc. I will clarify that I won't do any wet lab experiments, instead I use computers for the experiments and we call it as dry lab. This used to work for me most of the time. \n", "comment_count": 1, "html": "<p>I use these simple facts : I work on data from human genome project, and explain that its one of the biggest scientific achievement ever. I use that data to analyze proteins involved in X diseases. We are trying to understand these proteins and its various aspects related to disease using computer programs, database, software etc. I will clarify that I won't do any wet lab experiments, instead I use computers for the experiments and we call it as dry lab. This used to work for me most of the time. </p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 1, "parent": 388, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 400, "model": "server.post", "fields": {"rght": 5, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 17:01:04", "lft": 2, "post_type": 109787, "score": 5, "title": "A: What do different bioinformatics positions mean?", "unanswered": false, "content": "I think most of positions will have a brief, yet concise description that will explain the necessary qualification required for a particular position. I think the requirement depends on the nature of positions and there is no specific /systematic rule applies for different category of positions. ", "comment_count": 1, "html": "<p>I think most of positions will have a brief, yet concise description that will explain the necessary qualification required for a particular position. I think the requirement depends on the nature of positions and there is no specific /systematic rule applies for different category of positions. </p>", "child_count": 0, "closed": false, "tree_id": 89, "revision_count": 1, "parent": 398, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-what-do-different-bioinformatics-positions-mean", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 401, "model": "server.post", "fields": {"rght": 5, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 17:34:19", "lft": 4, "post_type": 109787, "score": 1, "title": "A: Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "unanswered": false, "content": "sorry, I'm only speaking 'java' here.\n\nI would create an interface ScoreMatrix:\n\n    public interface ScoreMatrix\n         {\n         public int getScore(char aa1,char aa2);\n         }\n\nthat would be used by your AlignmentTool\n\n    public interface AlignmentTool\n         {\n         public void setScoreMatrix(ScoreMatrix m);\n         public ScoreMatrix getScoreMatrix();\n         public void align(String seq1,String seq);\n         (...)\n         }\n\nand Blosum62 would be an implementation of ScoreMatrix\n\n    public class Blosum62 implements ScoreMatrix\n        {\n        public int getScore(char aa1,char aa2) \n            {\n            switch(upper(aa1))\n              {\n              (...)\n               {\n               case 'A' :\n               switch(upper(aa2))\n                 {\n                 (...)\n                 case 'A': return 98;\n                 (...)\n                 }\n              }\n            }\n        }\n\n\n", "comment_count": 0, "html": "<p>sorry, I'm only speaking 'java' here.</p>\n<p>I would create an interface ScoreMatrix:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">public</span> <span class=\"n\">interface</span> <span class=\"n\">ScoreMatrix</span>\n         <span class=\"p\">{</span>\n         <span class=\"n\">public</span> <span class=\"nb\">int</span> <span class=\"n\">getScore</span><span class=\"p\">(</span><span class=\"n\">char</span> <span class=\"n\">aa1</span><span class=\"p\">,</span><span class=\"n\">char</span> <span class=\"n\">aa2</span><span class=\"p\">);</span>\n         <span class=\"p\">}</span>\n</pre></div>\n</p>\n<p>that would be used by your AlignmentTool</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">public</span> <span class=\"n\">interface</span> <span class=\"n\">AlignmentTool</span>\n         <span class=\"p\">{</span>\n         <span class=\"n\">public</span> <span class=\"n\">void</span> <span class=\"n\">setScoreMatrix</span><span class=\"p\">(</span><span class=\"n\">ScoreMatrix</span> <span class=\"n\">m</span><span class=\"p\">);</span>\n         <span class=\"n\">public</span> <span class=\"n\">ScoreMatrix</span> <span class=\"n\">getScoreMatrix</span><span class=\"p\">();</span>\n         <span class=\"n\">public</span> <span class=\"n\">void</span> <span class=\"n\">align</span><span class=\"p\">(</span><span class=\"n\">String</span> <span class=\"n\">seq1</span><span class=\"p\">,</span><span class=\"n\">String</span> <span class=\"n\">seq</span><span class=\"p\">);</span>\n         <span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n         <span class=\"p\">}</span>\n</pre></div>\n</p>\n<p>and Blosum62 would be an implementation of ScoreMatrix</p>\n<p><div class=\"highlight\"><pre>    <span class=\"n\">public</span> <span class=\"n\">class</span> <span class=\"n\">Blosum62</span> <span class=\"n\">implements</span> <span class=\"n\">ScoreMatrix</span>\n        <span class=\"p\">{</span>\n        <span class=\"n\">public</span> <span class=\"nb\">int</span> <span class=\"n\">getScore</span><span class=\"p\">(</span><span class=\"n\">char</span> <span class=\"n\">aa1</span><span class=\"p\">,</span><span class=\"n\">char</span> <span class=\"n\">aa2</span><span class=\"p\">)</span> \n            <span class=\"p\">{</span>\n            <span class=\"n\">switch</span><span class=\"p\">(</span><span class=\"n\">upper</span><span class=\"p\">(</span><span class=\"n\">aa1</span><span class=\"p\">))</span>\n              <span class=\"p\">{</span>\n              <span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n               <span class=\"p\">{</span>\n               <span class=\"k\">case</span> <span class=\"s\">&#39;A&#39;</span> <span class=\"p\">:</span>\n               <span class=\"n\">switch</span><span class=\"p\">(</span><span class=\"n\">upper</span><span class=\"p\">(</span><span class=\"n\">aa2</span><span class=\"p\">))</span>\n                 <span class=\"p\">{</span>\n                 <span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n                 <span class=\"k\">case</span> <span class=\"s\">&#39;A&#39;</span><span class=\"p\">:</span> <span class=\"k\">return</span> <span class=\"mi\">98</span><span class=\"p\">;</span>\n                 <span class=\"p\">(</span><span class=\"o\">...</span><span class=\"p\">)</span>\n                 <span class=\"p\">}</span>\n              <span class=\"p\">}</span>\n            <span class=\"p\">}</span>\n        <span class=\"p\">}</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 43, "revision_count": 1, "parent": 161, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-implementation-of-blosum62-in-the-source-code-of-global-pairwise-alignment-of-proteins", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 402, "model": "server.post", "fields": {"rght": 20, "author": 163, "answer_accepted": true, "tag_string": "phylogeny software visualization feedback", "creation_date": "2010-03-22 18:00:18", "lft": 1, "post_type": 164033, "score": 8, "title": "What phylogeny viewing software do you use?", "unanswered": false, "content": "There are numerous phylogeny viewing programs available, which ones do people use most often? Are there features (e.g., visualisations, data formats, size of tree that can be displayed, annotation) that people feel existing software lack?\n\nI'll declare an interest. I'm the author of http://taxonomy.zoology.gla.ac.uk/rod/treeview.html, which is beginning to show its age. There are some other great tools around, so I'm trying to gauge whether TreeView should be allowed to die gracefully, of whether I should invest time in developing it further (see http://darwin.zoology.gla.ac.uk/~rpage/treeviewx/ ).", "comment_count": 0, "html": "<p>There are numerous phylogeny viewing programs available, which ones do people use most often? Are there features (e.g., visualisations, data formats, size of tree that can be displayed, annotation) that people feel existing software lack?</p>\n<p>I'll declare an interest. I'm the author of http://taxonomy.zoology.gla.ac.uk/rod/treeview.html, which is beginning to show its age. There are some other great tools around, so I'm trying to gauge whether TreeView should be allowed to die gracefully, of whether I should invest time in developing it further (see http://darwin.zoology.gla.ac.uk/~rpage/treeviewx/ ).</p>", "child_count": 0, "closed": false, "tree_id": 90, "revision_count": 4, "parent": null, "views": 1213, "deleted": false, "answer_count": 12, "touch_date": "2011-11-24 14:49:29", "slug": "what-phylogeny-viewing-software-do-you-use", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [136, 143, 155, 223], "lastedit_user": 126}}, {"pk": 403, "model": "server.post", "fields": {"rght": 16, "author": 127, "answer_accepted": true, "tag_string": "literature bioinformatics python text", "creation_date": "2010-03-22 18:01:27", "lft": 1, "post_type": 164033, "score": 5, "title": "How difficult/reliable is it to programmatically (python) look up and download papers?", "unanswered": false, "content": "I know that it is possible to write a script that attempts to use the ezproxy that most universities use to download papers directly using some search query. I have seen a perl implementation of this but was looking for something a bit cleaner and hopefully in python.\n\nI don't mind having the script only be able to work within a university network, but it would have to be able to check if the paper is accessible via the current IP or such. Not sure how feasible this is, thus my question...", "comment_count": 0, "html": "<p>I know that it is possible to write a script that attempts to use the ezproxy that most universities use to download papers directly using some search query. I have seen a perl implementation of this but was looking for something a bit cleaner and hopefully in python.</p>\n<p>I don't mind having the script only be able to work within a university network, but it would have to be able to check if the paper is accessible via the current IP or such. Not sure how feasible this is, thus my question...</p>", "child_count": 0, "closed": false, "tree_id": 91, "revision_count": 2, "parent": null, "views": 323, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:31", "slug": "how-difficultreliable-is-it-to-programmatically-python-look-up-and-download-papers", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [11, 152, 156, 157], "lastedit_user": 313}}, {"pk": 404, "model": "server.post", "fields": {"rght": 3, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:11:29", "lft": 2, "post_type": 109787, "score": 0, "title": "A: How difficult/reliable is it to programmatically (python) look up and download papers?", "unanswered": false, "content": "Sorry Ricardo, not python but the following codes contain some snippets that might be useful to find  the PDF from a doi/pmid...\n\n - http://code.google.com/p/pdfetch/\n - http://bio-geeks.com/?p=749\n\nAnd my version using java...\n\n - http://plindenbaum.blogspot.com/2009/11/my-pdfs-anywhere.html\n", "comment_count": 0, "html": "<p>Sorry Ricardo, not python but the following codes contain some snippets that might be useful to find  the PDF from a doi/pmid...</p>\n<ul>\n<li>http://code.google.com/p/pdfetch/</li>\n<li>http://bio-geeks.com/?p=749</li>\n</ul>\n<p>And my version using java...</p>\n<ul>\n<li>http://plindenbaum.blogspot.com/2009/11/my-pdfs-anywhere.html</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 91, "revision_count": 2, "parent": 403, "views": 0, "deleted": true, "answer_count": 0, "touch_date": "2011-11-24 14:48:57", "slug": "a-how-difficultreliable-is-it-to-programmatically-python-look-up-and-download-papers", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 405, "model": "server.post", "fields": {"rght": 25, "author": 85, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:14:50", "lft": 22, "post_type": 109787, "score": 3, "title": "A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "oddly enough, craigslist has been successful for us in the past...", "comment_count": 1, "html": "<p>oddly enough, craigslist has been successful for us in the past...</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 1, "parent": 296, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 85}}, {"pk": 406, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:15:19", "lft": 4, "post_type": 109787, "score": 4, "title": "A: How difficult/reliable is it to programmatically (python) look up and download papers?", "unanswered": false, "content": "Have you tried this [py-ezproxy][1]?\n\nThe script that you have seen in perl may have been written with the Mechanize library. In case, you can look at [Mechanize][2] in python, which is the reimplementation in python of the same concept. Anyway, you can use mechanize to connect to the internet using a proxy and do waht you are asking for.\n\n\n  [1]: http://bitbucket.org/dgc/py-ezproxy/overview/\n  [2]: http://pypi.python.org/pypi/mechanize/0.1.11", "comment_count": 1, "html": "<p>Have you tried this <a href=\"http://bitbucket.org/dgc/py-ezproxy/overview/\">py-ezproxy</a>?</p>\n<p>The script that you have seen in perl may have been written with the Mechanize library. In case, you can look at <a href=\"http://pypi.python.org/pypi/mechanize/0.1.11\">Mechanize</a> in python, which is the reimplementation in python of the same concept. Anyway, you can use mechanize to connect to the internet using a proxy and do waht you are asking for.</p>", "child_count": 0, "closed": false, "tree_id": 91, "revision_count": 1, "parent": 403, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-difficultreliable-is-it-to-programmatically-python-look-up-and-download-papers", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 22}}, {"pk": 407, "model": "server.post", "fields": {"rght": 3, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:34:52", "lft": 2, "post_type": 109787, "score": 2, "title": "A: What phylogeny viewing software do you use?", "unanswered": false, "content": "I am not too much into this, but I have used: [jalview][1], [seaview][2], [mega][3] (on linux throught wine).\n\nAll of these are not specifically developed for visualizing trees, however they have the ability to do so and for my needs it is enough.\n\n\n  [1]: http://www.jalview.org/examples/examples4.html\n  [2]: http://pbil.univ-lyon1.fr/binaries/seaview-tree.png\n  [3]: http://www.megasoftware.net/overview.html", "comment_count": 0, "html": "<p>I am not too much into this, but I have used: <a href=\"http://www.jalview.org/examples/examples4.html\">jalview</a>, <a href=\"http://pbil.univ-lyon1.fr/binaries/seaview-tree.png\">seaview</a>, <a href=\"http://www.megasoftware.net/overview.html\">mega</a> (on linux throught wine).</p>\n<p>All of these are not specifically developed for visualizing trees, however they have the ability to do so and for my needs it is enough.</p>", "child_count": 0, "closed": false, "tree_id": 90, "revision_count": 1, "parent": 402, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-what-phylogeny-viewing-software-do-you-use", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 408, "model": "server.post", "fields": {"rght": 11, "author": 115, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:43:31", "lft": 4, "post_type": 109787, "score": 9, "title": "A: What do different bioinformatics positions mean?", "unanswered": false, "content": "In general, positions labeled as \"analyst\" will be applying tools other people have created. Positions labeled as \"developer\" will be writing new tools. However, you shouldn't count on that, as sometimes job titles are written by people with no idea about bioinformatics. I'd expect the Bioinformatics Systems Administrator to be responsible for keeping the tools and the computers the tools run on up and running.\n\nResearch assistants and associates are usually BS/MS level jobs. Scientist jobs usually require a PhD. But neither of these rules is absolute.\n\nA project manager is responsible for putting together the project schedule and keeping the project on track. Whether a PhD is required or not is quite variable, and will usually correlate with whether the project manager is also expected to be the technical lead on the project.\n\nThe Director/Head of Bioinformatics is a management job. In a larger company, this person probably has almost no time for direct involvement in projects. In a smaller company, he/she is probably still hands on at least some of the time.\n\nSalaries are all over the place. About all I'd hazard to guess there is that the Director is making the most money, but even that is not a sure bet.", "comment_count": 3, "html": "<p>In general, positions labeled as \"analyst\" will be applying tools other people have created. Positions labeled as \"developer\" will be writing new tools. However, you shouldn't count on that, as sometimes job titles are written by people with no idea about bioinformatics. I'd expect the Bioinformatics Systems Administrator to be responsible for keeping the tools and the computers the tools run on up and running.</p>\n<p>Research assistants and associates are usually BS/MS level jobs. Scientist jobs usually require a PhD. But neither of these rules is absolute.</p>\n<p>A project manager is responsible for putting together the project schedule and keeping the project on track. Whether a PhD is required or not is quite variable, and will usually correlate with whether the project manager is also expected to be the technical lead on the project.</p>\n<p>The Director/Head of Bioinformatics is a management job. In a larger company, this person probably has almost no time for direct involvement in projects. In a smaller company, he/she is probably still hands on at least some of the time.</p>\n<p>Salaries are all over the place. About all I'd hazard to guess there is that the Director is making the most money, but even that is not a sure bet.</p>", "child_count": 0, "closed": false, "tree_id": 89, "revision_count": 1, "parent": 398, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-what-do-different-bioinformatics-positions-mean", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 115}}, {"pk": 409, "model": "server.post", "fields": {"rght": 5, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:47:42", "lft": 4, "post_type": 109787, "score": 4, "title": "A: What phylogeny viewing software do you use?", "unanswered": false, "content": "I usually do use [TreeView][1]. While it may not be particularly new, I think it's stood the test of time well. I've also used [Mesquite][2] and some other tools, but I always find myself coming back to TreeView per default. \n\nAmong my colleagues, many also use TreeView, so I am sure that if you did put in the effort to update/enhance TreeView, there'd be many who would greatly appreciate it.\n\nLast, but not least: THANK YOU for having produced this gem!\n\n\n  [1]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html\n  [2]: http://mesquiteproject.org/mesquite/mesquite.html", "comment_count": 0, "html": "<p>I usually do use <a href=\"http://taxonomy.zoology.gla.ac.uk/rod/treeview.html\">TreeView</a>. While it may not be particularly new, I think it's stood the test of time well. I've also used <a href=\"http://mesquiteproject.org/mesquite/mesquite.html\">Mesquite</a> and some other tools, but I always find myself coming back to TreeView per default. </p>\n<p>Among my colleagues, many also use TreeView, so I am sure that if you did put in the effort to update/enhance TreeView, there'd be many who would greatly appreciate it.</p>\n<p>Last, but not least: THANK YOU for having produced this gem!</p>", "child_count": 0, "closed": false, "tree_id": 90, "revision_count": 2, "parent": 402, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-phylogeny-viewing-software-do-you-use", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 118}}, {"pk": 410, "model": "server.post", "fields": {"rght": 7, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 19:21:19", "lft": 6, "post_type": 109787, "score": 4, "title": "A: What phylogeny viewing software do you use?", "unanswered": false, "content": "Tried Phyfi][1] for quick trees or [iTOL][2] whenever I need that super cool phylogeny tree figure for a publication. I have used [TreeView][3] and [MEGA][4] earlier. Tried couple of programs from the list of The Phylogeny Tree Drawing / Plotting program from Phylip [page][5]. \n\n\n  [1]: http://cgi-www.daimi.au.dk/cgi-chili/phyfi/go\n  [2]: http://itol.embl.de/\n  [3]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html\n  [4]: http://www.megasoftware.net/\n  [5]: http://evolution.genetics.washington.edu/phylip/software.html#Plotting", "comment_count": 0, "html": "<p>Tried Phyfi]<a href=\"http://cgi-www.daimi.au.dk/cgi-chili/phyfi/go\">1</a> for quick trees or <a href=\"http://itol.embl.de/\">iTOL</a> whenever I need that super cool phylogeny tree figure for a publication. I have used <a href=\"http://taxonomy.zoology.gla.ac.uk/rod/treeview.html\">TreeView</a> and <a href=\"http://www.megasoftware.net/\">MEGA</a> earlier. Tried couple of programs from the list of The Phylogeny Tree Drawing / Plotting program from Phylip <a href=\"http://evolution.genetics.washington.edu/phylip/software.html#Plotting\">page</a>. </p>", "child_count": 0, "closed": false, "tree_id": 90, "revision_count": 3, "parent": 402, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-what-phylogeny-viewing-software-do-you-use", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 411, "model": "server.post", "fields": {"rght": 13, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 19:48:02", "lft": 8, "post_type": 109787, "score": 4, "title": "A: What phylogeny viewing software do you use?", "unanswered": false, "content": "I like [FigTree][1] because it allows me to play with the tree a little bit to mark-up the regions I'm interested in, unfortunately it's Mac OSX only though. [Scriptree][2] also seems quite good.\n\nWith the availability of larger sequencing data sets I'd like to see tree viewers be able to help distill a phylogenetic tree down to the points of interest. I'd like to be able to use colours and branch grouping to highlight to the reader what I think is relevent.\n\n[1]: http://tree.bio.ed.ac.uk/software/figtree/\n[2]: http://atgc.lirmm.fr/scriptree/\n", "comment_count": 2, "html": "<p>I like <a href=\"http://tree.bio.ed.ac.uk/software/figtree/\">FigTree</a> because it allows me to play with the tree a little bit to mark-up the regions I'm interested in, unfortunately it's Mac OSX only though. <a href=\"http://atgc.lirmm.fr/scriptree/\">Scriptree</a> also seems quite good.</p>\n<p>With the availability of larger sequencing data sets I'd like to see tree viewers be able to help distill a phylogenetic tree down to the points of interest. I'd like to be able to use colours and branch grouping to highlight to the reader what I think is relevent.</p>", "child_count": 0, "closed": false, "tree_id": 90, "revision_count": 1, "parent": 402, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-phylogeny-viewing-software-do-you-use", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 412, "model": "server.post", "fields": {"rght": 13, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 20:10:13", "lft": 10, "post_type": 109787, "score": 3, "title": "A: What phylogeny viewing software do you use?", "unanswered": false, "content": "I normally use FigTree for a quick and flexible look on phylogenetic data. For small datasets, PHYLIP DRAWTREE or TreeView are enough. But, for printing I really look for some adequate LaTeX package, commonly PSTricks. It's cumbersome but it works and is beautifull, fully customizable. For large trees, some scripting is necessary. But, now there is [E.T.E.][1] which is quite handy.\n\nI'm happy to see Rod Page in this forum. Your books on phylogenetics and molecular evolution are part of my everyday life. I do appreciate the effort !!!\n\n\n  [1]: http://ete.cgenomics.org/", "comment_count": 1, "html": "<p>I normally use FigTree for a quick and flexible look on phylogenetic data. For small datasets, PHYLIP DRAWTREE or TreeView are enough. But, for printing I really look for some adequate LaTeX package, commonly PSTricks. It's cumbersome but it works and is beautifull, fully customizable. For large trees, some scripting is necessary. But, now there is <a href=\"http://ete.cgenomics.org/\">E.T.E.</a> which is quite handy.</p>\n<p>I'm happy to see Rod Page in this forum. Your books on phylogenetics and molecular evolution are part of my everyday life. I do appreciate the effort !!!</p>", "child_count": 0, "closed": false, "tree_id": 90, "revision_count": 1, "parent": 402, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:24", "slug": "a-what-phylogeny-viewing-software-do-you-use", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 413, "model": "server.post", "fields": {"rght": 28, "author": 86, "answer_accepted": false, "tag_string": "snp data human annotation", "creation_date": "2010-03-22 20:42:28", "lft": 1, "post_type": 164033, "score": 2, "title": "How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "I am looking at a bunch of SNPs. Some of them are part of genes, but other are not. I am interested to look up +60KB or -60KB of those SNPs to get details about some nearby genes. Please share your experience in dealing with such a situation or thoughts on any methods that can do this. Thanks in advance. ", "comment_count": 0, "html": "<p>I am looking at a bunch of SNPs. Some of them are part of genes, but other are not. I am interested to look up +60KB or -60KB of those SNPs to get details about some nearby genes. Please share your experience in dealing with such a situation or thoughts on any methods that can do this. Thanks in advance. </p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 1, "parent": null, "views": 2087, "deleted": false, "answer_count": 8, "touch_date": "2011-11-24 14:49:24", "slug": "how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [48, 68, 78, 158], "lastedit_user": 86}}, {"pk": 414, "model": "server.post", "fields": {"rght": 21, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 20:53:49", "lft": 8, "post_type": 109787, "score": 5, "title": "A: Drawing chromosome ideogams with data", "unanswered": false, "content": "The [GenomeGraphs package in Bioconductor][1] allows to draw (human) chromosome ideograms with R. The package can be used to depict genome tracks of coverage, microarray measurements and genes together with the ideograms. \nSee the [user guide][2] for an overview of different types of graphics. For the ideogram, the example looks like this (also in the [GenomeGraphs paper][3]): \n\n![Example][4]\n\n\nHere is the code that makes something like this (from the user guide):\n\n    library(GenomeGraphs)\n    library(biomaRt)\n    data(\"exampleData\", package = \"GenomeGraphs\")\n    mart <- useMart(\"ensembl\", dataset = \"hsapiens_gene_ensembl\")\n    minbase <- 180292097\n    maxbase <- 180492096\n    genesplus <- makeGeneRegion(start = minbase,\n                                end = maxbase, strand = \"+\", chromosome = \"3\",\n                                biomart = mart)\n    genesmin <- makeGeneRegion(start = minbase,\n                               end = maxbase, strand = \"-\", chromosome = \"3\",\n                               biomart = mart)\n    seg <- makeSegmentation(segStart, segEnd,\n                            segments, dp = DisplayPars(color = \"black\",\n                                        lwd = 2, lty = \"solid\"))\n    cop <- makeGenericArray(intensity = cn,\n                            probeStart = probestart, segmentation = seg,\n                            dp = DisplayPars(size = 3, color = \"seagreen\",\n                              type = \"dot\"))\n    ideog <- makeIdeogram(chromosome = 3)\n    expres <- makeGenericArray(intensity = intensity,\n                               probeStart = exonProbePos,\n                               dp = DisplayPars(color = \"darkred\",\n                                 type = \"point\"))\n    genomeAxis <- makeGenomeAxis(add53 = TRUE,\n                                 add35 = TRUE)\n    gdPlot(list(a = ideog, b = expres, c = cop,\n                d = genesplus, e = genomeAxis, f = genesmin),\n           minBase = minbase, maxBase = maxbase,\n           labelCex = 2)\n\nEdit: It supports multiple ideograms in one plot like this:\n\n     ideog <- makeIdeogram(chromosome = 1)\n     ideog2 <- makeIdeogram(chromosome = 2)\n     ideog3 <- makeIdeogram(chromosome = 3)\n     ideog4 <- makeIdeogram(chromosome = 4)\n     gdPlot(list(\"1\"= ideog, \"2\" = ideog2, \"3\" =ideog3, \"4\"=ideog4 ), \n     minBase = minbase, maxBase = maxbase)\n\nIf you plot data below the chromosomes using a base track, \ntake care of the `minbase, maxbase` parameters because the chromosomes have different length!\n\n\n  [1]: http://bioconductor.org/packages/2.5/bioc/html/GenomeGraphs.html\n  [2]: http://bioconductor.org/packages/2.5/bioc/vignettes/GenomeGraphs/inst/doc/GenomeGraphs.pdf\n  [3]: http://www.biomedcentral.com/1471-2105/10/2/abstract/\n  [4]: http://www.bccs.uni.no/~mdo041/rplots/ideog.png\n  [5]: http://www.biomedcentral.com/content/download/figures/1471-2105-10-2-1.PDF", "comment_count": 6, "html": "<p>The <a href=\"http://bioconductor.org/packages/2.5/bioc/html/GenomeGraphs.html\">GenomeGraphs package in Bioconductor</a> allows to draw (human) chromosome ideograms with R. The package can be used to depict genome tracks of coverage, microarray measurements and genes together with the ideograms. \nSee the <a href=\"http://bioconductor.org/packages/2.5/bioc/vignettes/GenomeGraphs/inst/doc/GenomeGraphs.pdf\">user guide</a> for an overview of different types of graphics. For the ideogram, the example looks like this (also in the <a href=\"http://www.biomedcentral.com/1471-2105/10/2/abstract/\">GenomeGraphs paper</a>): </p>\n<p><img alt=\"Example\" src=\"http://www.bccs.uni.no/~mdo041/rplots/ideog.png\" /></p>\n<p>Here is the code that makes something like this (from the user guide):</p>\n<p><div class=\"highlight\"><pre>    library<span class=\"p\">(</span>GenomeGraphs<span class=\"p\">)</span>\n    library<span class=\"p\">(</span>biomaRt<span class=\"p\">)</span>\n    data<span class=\"p\">(</span><span class=\"s\">&quot;exampleData&quot;</span><span class=\"p\">,</span> package <span class=\"o\">=</span> <span class=\"s\">&quot;GenomeGraphs&quot;</span><span class=\"p\">)</span>\n    mart <span class=\"o\">&lt;-</span> useMart<span class=\"p\">(</span><span class=\"s\">&quot;ensembl&quot;</span><span class=\"p\">,</span> dataset <span class=\"o\">=</span> <span class=\"s\">&quot;hsapiens_gene_ensembl&quot;</span><span class=\"p\">)</span>\n    minbase <span class=\"o\">&lt;-</span> <span class=\"m\">180292097</span>\n    maxbase <span class=\"o\">&lt;-</span> <span class=\"m\">180492096</span>\n    genesplus <span class=\"o\">&lt;-</span> makeGeneRegion<span class=\"p\">(</span>start <span class=\"o\">=</span> minbase<span class=\"p\">,</span>\n                                end <span class=\"o\">=</span> maxbase<span class=\"p\">,</span> strand <span class=\"o\">=</span> <span class=\"s\">&quot;+&quot;</span><span class=\"p\">,</span> chromosome <span class=\"o\">=</span> <span class=\"s\">&quot;3&quot;</span><span class=\"p\">,</span>\n                                biomart <span class=\"o\">=</span> mart<span class=\"p\">)</span>\n    genesmin <span class=\"o\">&lt;-</span> makeGeneRegion<span class=\"p\">(</span>start <span class=\"o\">=</span> minbase<span class=\"p\">,</span>\n                               end <span class=\"o\">=</span> maxbase<span class=\"p\">,</span> strand <span class=\"o\">=</span> <span class=\"s\">&quot;-&quot;</span><span class=\"p\">,</span> chromosome <span class=\"o\">=</span> <span class=\"s\">&quot;3&quot;</span><span class=\"p\">,</span>\n                               biomart <span class=\"o\">=</span> mart<span class=\"p\">)</span>\n    seg <span class=\"o\">&lt;-</span> makeSegmentation<span class=\"p\">(</span>segStart<span class=\"p\">,</span> segEnd<span class=\"p\">,</span>\n                            segments<span class=\"p\">,</span> dp <span class=\"o\">=</span> DisplayPars<span class=\"p\">(</span>color <span class=\"o\">=</span> <span class=\"s\">&quot;black&quot;</span><span class=\"p\">,</span>\n                                        lwd <span class=\"o\">=</span> <span class=\"m\">2</span><span class=\"p\">,</span> lty <span class=\"o\">=</span> <span class=\"s\">&quot;solid&quot;</span><span class=\"p\">))</span>\n    cop <span class=\"o\">&lt;-</span> makeGenericArray<span class=\"p\">(</span>intensity <span class=\"o\">=</span> cn<span class=\"p\">,</span>\n                            probeStart <span class=\"o\">=</span> probestart<span class=\"p\">,</span> segmentation <span class=\"o\">=</span> seg<span class=\"p\">,</span>\n                            dp <span class=\"o\">=</span> DisplayPars<span class=\"p\">(</span>size <span class=\"o\">=</span> <span class=\"m\">3</span><span class=\"p\">,</span> color <span class=\"o\">=</span> <span class=\"s\">&quot;seagreen&quot;</span><span class=\"p\">,</span>\n                              type <span class=\"o\">=</span> <span class=\"s\">&quot;dot&quot;</span><span class=\"p\">))</span>\n    ideog <span class=\"o\">&lt;-</span> makeIdeogram<span class=\"p\">(</span>chromosome <span class=\"o\">=</span> <span class=\"m\">3</span><span class=\"p\">)</span>\n    expres <span class=\"o\">&lt;-</span> makeGenericArray<span class=\"p\">(</span>intensity <span class=\"o\">=</span> intensity<span class=\"p\">,</span>\n                               probeStart <span class=\"o\">=</span> exonProbePos<span class=\"p\">,</span>\n                               dp <span class=\"o\">=</span> DisplayPars<span class=\"p\">(</span>color <span class=\"o\">=</span> <span class=\"s\">&quot;darkred&quot;</span><span class=\"p\">,</span>\n                                 type <span class=\"o\">=</span> <span class=\"s\">&quot;point&quot;</span><span class=\"p\">))</span>\n    genomeAxis <span class=\"o\">&lt;-</span> makeGenomeAxis<span class=\"p\">(</span>add53 <span class=\"o\">=</span> <span class=\"kc\">TRUE</span><span class=\"p\">,</span>\n                                 add35 <span class=\"o\">=</span> <span class=\"kc\">TRUE</span><span class=\"p\">)</span>\n    gdPlot<span class=\"p\">(</span>list<span class=\"p\">(</span>a <span class=\"o\">=</span> ideog<span class=\"p\">,</span> b <span class=\"o\">=</span> expres<span class=\"p\">,</span> c <span class=\"o\">=</span> cop<span class=\"p\">,</span>\n                d <span class=\"o\">=</span> genesplus<span class=\"p\">,</span> e <span class=\"o\">=</span> genomeAxis<span class=\"p\">,</span> f <span class=\"o\">=</span> genesmin<span class=\"p\">),</span>\n           minBase <span class=\"o\">=</span> minbase<span class=\"p\">,</span> maxBase <span class=\"o\">=</span> maxbase<span class=\"p\">,</span>\n           labelCex <span class=\"o\">=</span> <span class=\"m\">2</span><span class=\"p\">)</span>\n</pre></div>\n</p>\n<p>Edit: It supports multiple ideograms in one plot like this:</p>\n<p><div class=\"highlight\"><pre>     ideog <span class=\"o\">&lt;-</span> makeIdeogram<span class=\"p\">(</span>chromosome <span class=\"o\">=</span> <span class=\"m\">1</span><span class=\"p\">)</span>\n     ideog2 <span class=\"o\">&lt;-</span> makeIdeogram<span class=\"p\">(</span>chromosome <span class=\"o\">=</span> <span class=\"m\">2</span><span class=\"p\">)</span>\n     ideog3 <span class=\"o\">&lt;-</span> makeIdeogram<span class=\"p\">(</span>chromosome <span class=\"o\">=</span> <span class=\"m\">3</span><span class=\"p\">)</span>\n     ideog4 <span class=\"o\">&lt;-</span> makeIdeogram<span class=\"p\">(</span>chromosome <span class=\"o\">=</span> <span class=\"m\">4</span><span class=\"p\">)</span>\n     gdPlot<span class=\"p\">(</span>list<span class=\"p\">(</span><span class=\"s\">&quot;1&quot;</span><span class=\"o\">=</span> ideog<span class=\"p\">,</span> <span class=\"s\">&quot;2&quot;</span> <span class=\"o\">=</span> ideog2<span class=\"p\">,</span> <span class=\"s\">&quot;3&quot;</span> <span class=\"o\">=</span>ideog3<span class=\"p\">,</span> <span class=\"s\">&quot;4&quot;</span><span class=\"o\">=</span>ideog4 <span class=\"p\">),</span> \n     minBase <span class=\"o\">=</span> minbase<span class=\"p\">,</span> maxBase <span class=\"o\">=</span> maxbase<span class=\"p\">)</span>\n</pre></div>\n</p>\n<p>If you plot data below the chromosomes using a base track, \ntake care of the <code>minbase, maxbase</code> parameters because the chromosomes have different length!</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 4, "parent": 378, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 54}}, {"pk": 415, "model": "server.post", "fields": {"rght": 27, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 20:53:55", "lft": 26, "post_type": 109787, "score": 2, "title": "A: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "Good to have a strong background in general programming concepts. Choice of languags depends on the nature of your projects. In general a mixed bag of programming skills in domains like scripting (take your pick : Perl, Python, Ruby), Web(Lot of JScript, CSS, Perl / PHP), Databases (MySQL, PgSQL), statistics(Mostly R / Matlab) with c / C++ / Java will be an excellent combination. \n\n", "comment_count": 0, "html": "<p>Good to have a strong background in general programming concepts. Choice of languags depends on the nature of your projects. In general a mixed bag of programming skills in domains like scripting (take your pick : Perl, Python, Ruby), Web(Lot of JScript, CSS, Perl / PHP), Databases (MySQL, PgSQL), statistics(Mostly R / Matlab) with c / C++ / Java will be an excellent combination. </p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 1, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 416, "model": "server.post", "fields": {"rght": 5, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 21:00:53", "lft": 2, "post_type": 109787, "score": 2, "title": "A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "I downloaded refFlat table from UCSC Genome Browser, which contains gene symbols and their genomic locations. Then mapped SNPs to genes. I did it in MATLAB, but can be done with any language.\n\nYou can also try a Perl script from [here][1].\n\n\n  [1]: http://www.medicine.tcd.ie/neuropsychiatric-genetics/bioinformatics-biostatistics/software/", "comment_count": 1, "html": "<p>I downloaded refFlat table from UCSC Genome Browser, which contains gene symbols and their genomic locations. Then mapped SNPs to genes. I did it in MATLAB, but can be done with any language.</p>\n<p>You can also try a Perl script from <a href=\"http://www.medicine.tcd.ie/neuropsychiatric-genetics/bioinformatics-biostatistics/software/\">here</a>.</p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 3, "parent": 413, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 417, "model": "server.post", "fields": {"rght": 11, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 21:28:48", "lft": 4, "post_type": 109787, "score": 3, "title": "A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "No need to program this. This can be done as a BioMart query in MartView:\n\n[rs8 with 60000 bases up/donw-flanks][1]\n\nI just checked it works with that size flanks. The result is a FASTA file. \n\nOn the other hand, if you have a SNP position it could be easier to simply search for the genes directly in the genome annotation. Get a genome annotation as a tab separated file from e.g. BioMart and search for the genes with start/stop positons within this range.\n\n\n\n  [1]: http://www.biomart.org/biomart/martview?VIRTUALSCHEMANAME=default&ATTRIBUTES=hsapiens_snp.default.sequences.chr_name|hsapiens_snp.default.sequences.chrom_start|hsapiens_snp.default.sequences.refsnp_id|hsapiens_snp.default.sequences.allele|hsapiens_snp.default.sequences.snp|hsapiens_snp.default.sequences.downstream_flank.\"60000\"|hsapiens_snp.default.sequences.upstream_flank.\"60000\"&FILTERS=hsapiens_snp.default.filters.refsnp.\"rs8\"&VISIBLEPANEL=resultspanel", "comment_count": 3, "html": "<p>No need to program this. This can be done as a BioMart query in MartView:</p>\n<p><a href=\"http://www.biomart.org/biomart/martview?VIRTUALSCHEMANAME=default&amp;ATTRIBUTES=hsapiens_snp.default.sequences.chr_name|hsapiens_snp.default.sequences.chrom_start|hsapiens_snp.default.sequences.refsnp_id|hsapiens_snp.default.sequences.allele|hsapiens_snp.default.sequences.snp|hsapiens_snp.default.sequences.downstream_flank.&quot;60000&quot;|hsapiens_snp.default.sequences.upstream_flank.&quot;60000&quot;&amp;FILTERS=hsapiens_snp.default.filters.refsnp.&quot;rs8&quot;&amp;VISIBLEPANEL=resultspanel\">rs8 with 60000 bases up/donw-flanks</a></p>\n<p>I just checked it works with that size flanks. The result is a FASTA file. </p>\n<p>On the other hand, if you have a SNP position it could be easier to simply search for the genes directly in the genome annotation. Get a genome annotation as a tab separated file from e.g. BioMart and search for the genes with start/stop positons within this range.</p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 1, "parent": 413, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 418, "model": "server.post", "fields": {"rght": 15, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 21:44:47", "lft": 6, "post_type": 109787, "score": 6, "title": "A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "Using the **UCSC mysql server**:\n\n    ~> mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -D hg19 -e '\n    select\n     K.proteinID,\n     K.name,\n     S.name,\n     S.avHet,\n     S.chrom,\n     S.chromStart,\n     K.txStart,\n     K.txEnd\n    from snp130 as S\n    left join knownGene as K on\n     (S.chrom=K.chrom and not(K.txEnd+60000<S.chromStart or S.chromEnd+60000<K.txStart))\n    where\n     S.name in (\"rs25\",\"rs100\",\"rs75\",\"rs9876\",\"rs101\")'\n\nresult:\n\n    +-----------+------------+--------+----------+-------+------------+----------+----------+\n    | proteinID | name       | name   | avHet    | chrom | chromStart | txStart  | txEnd    |\n    +-----------+------------+--------+----------+-------+------------+----------+----------+\n    | NULL      | NULL       | rs100  |        0 | chr7  |   24438348 |     NULL |     NULL |\n    | NULL      | NULL       | rs101  |        0 | chr7  |   24438147 |     NULL |     NULL |\n    | NP_056019 | uc003ssf.3 | rs25   | 0.499586 | chr7  |   11584141 | 11414172 | 11871824 |\n    | NP_056019 | uc003ssf.3 | rs75   | 0.241967 | chr7  |   11613691 | 11414172 | 11871824 |\n    | B2RNV1    | uc003tnv.2 | rs9876 | 0.426096 | chr7  |   47315290 | 47314752 | 47579199 |\n    | B2RNV1    | uc003tnw.2 | rs9876 | 0.426096 | chr7  |   47315290 | 47314752 | 47621742 |\n    +-----------+------------+--------+----------+-------+------------+----------+----------+", "comment_count": 4, "html": "<p>Using the <strong>UCSC mysql server</strong>:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"o\">~&gt;</span> <span class=\"n\">mysql</span> <span class=\"o\">--</span><span class=\"n\">user</span><span class=\"o\">=</span><span class=\"n\">genome</span> <span class=\"o\">--</span><span class=\"n\">host</span><span class=\"o\">=</span><span class=\"n\">genome</span><span class=\"o\">-</span><span class=\"n\">mysql</span><span class=\"o\">.</span><span class=\"n\">cse</span><span class=\"o\">.</span><span class=\"n\">ucsc</span><span class=\"o\">.</span><span class=\"n\">edu</span> <span class=\"o\">-</span><span class=\"n\">A</span> <span class=\"o\">-</span><span class=\"n\">D</span> <span class=\"n\">hg19</span> <span class=\"o\">-</span><span class=\"n\">e</span> <span class=\"s\">&#39;</span>\n<span class=\"s\">    select</span>\n<span class=\"s\">     K.proteinID,</span>\n<span class=\"s\">     K.name,</span>\n<span class=\"s\">     S.name,</span>\n<span class=\"s\">     S.avHet,</span>\n<span class=\"s\">     S.chrom,</span>\n<span class=\"s\">     S.chromStart,</span>\n<span class=\"s\">     K.txStart,</span>\n<span class=\"s\">     K.txEnd</span>\n<span class=\"s\">    from snp130 as S</span>\n<span class=\"s\">    left join knownGene as K on</span>\n<span class=\"s\">     (S.chrom=K.chrom and not(K.txEnd+60000&lt;S.chromStart or S.chromEnd+60000&lt;K.txStart))</span>\n<span class=\"s\">    where</span>\n<span class=\"s\">     S.name in (&quot;rs25&quot;,&quot;rs100&quot;,&quot;rs75&quot;,&quot;rs9876&quot;,&quot;rs101&quot;)&#39;</span>\n</pre></div>\n</p>\n<p>result:</p>\n<p><div class=\"highlight\"><pre>    <span class=\"o\">+-----------+------------+--------+----------+-------+------------+----------+----------+</span>\n    <span class=\"o\">|</span> <span class=\"n\">proteinID</span> <span class=\"o\">|</span> <span class=\"n\">name</span>       <span class=\"o\">|</span> <span class=\"n\">name</span>   <span class=\"o\">|</span> <span class=\"n\">avHet</span>    <span class=\"o\">|</span> <span class=\"n\">chrom</span> <span class=\"o\">|</span> <span class=\"n\">chromStart</span> <span class=\"o\">|</span> <span class=\"n\">txStart</span>  <span class=\"o\">|</span> <span class=\"n\">txEnd</span>    <span class=\"o\">|</span>\n    <span class=\"o\">+-----------+------------+--------+----------+-------+------------+----------+----------+</span>\n    <span class=\"o\">|</span> <span class=\"n\">NULL</span>      <span class=\"o\">|</span> <span class=\"n\">NULL</span>       <span class=\"o\">|</span> <span class=\"n\">rs100</span>  <span class=\"o\">|</span>        <span class=\"mi\">0</span> <span class=\"o\">|</span> <span class=\"n\">chr7</span>  <span class=\"o\">|</span>   <span class=\"mi\">24438348</span> <span class=\"o\">|</span>     <span class=\"n\">NULL</span> <span class=\"o\">|</span>     <span class=\"n\">NULL</span> <span class=\"o\">|</span>\n    <span class=\"o\">|</span> <span class=\"n\">NULL</span>      <span class=\"o\">|</span> <span class=\"n\">NULL</span>       <span class=\"o\">|</span> <span class=\"n\">rs101</span>  <span class=\"o\">|</span>        <span class=\"mi\">0</span> <span class=\"o\">|</span> <span class=\"n\">chr7</span>  <span class=\"o\">|</span>   <span class=\"mi\">24438147</span> <span class=\"o\">|</span>     <span class=\"n\">NULL</span> <span class=\"o\">|</span>     <span class=\"n\">NULL</span> <span class=\"o\">|</span>\n    <span class=\"o\">|</span> <span class=\"n\">NP_056019</span> <span class=\"o\">|</span> <span class=\"n\">uc003ssf</span><span class=\"mf\">.3</span> <span class=\"o\">|</span> <span class=\"n\">rs25</span>   <span class=\"o\">|</span> <span class=\"mf\">0.499586</span> <span class=\"o\">|</span> <span class=\"n\">chr7</span>  <span class=\"o\">|</span>   <span class=\"mi\">11584141</span> <span class=\"o\">|</span> <span class=\"mi\">11414172</span> <span class=\"o\">|</span> <span class=\"mi\">11871824</span> <span class=\"o\">|</span>\n    <span class=\"o\">|</span> <span class=\"n\">NP_056019</span> <span class=\"o\">|</span> <span class=\"n\">uc003ssf</span><span class=\"mf\">.3</span> <span class=\"o\">|</span> <span class=\"n\">rs75</span>   <span class=\"o\">|</span> <span class=\"mf\">0.241967</span> <span class=\"o\">|</span> <span class=\"n\">chr7</span>  <span class=\"o\">|</span>   <span class=\"mi\">11613691</span> <span class=\"o\">|</span> <span class=\"mi\">11414172</span> <span class=\"o\">|</span> <span class=\"mi\">11871824</span> <span class=\"o\">|</span>\n    <span class=\"o\">|</span> <span class=\"n\">B2RNV1</span>    <span class=\"o\">|</span> <span class=\"n\">uc003tnv</span><span class=\"mf\">.2</span> <span class=\"o\">|</span> <span class=\"n\">rs9876</span> <span class=\"o\">|</span> <span class=\"mf\">0.426096</span> <span class=\"o\">|</span> <span class=\"n\">chr7</span>  <span class=\"o\">|</span>   <span class=\"mi\">47315290</span> <span class=\"o\">|</span> <span class=\"mi\">47314752</span> <span class=\"o\">|</span> <span class=\"mi\">47579199</span> <span class=\"o\">|</span>\n    <span class=\"o\">|</span> <span class=\"n\">B2RNV1</span>    <span class=\"o\">|</span> <span class=\"n\">uc003tnw</span><span class=\"mf\">.2</span> <span class=\"o\">|</span> <span class=\"n\">rs9876</span> <span class=\"o\">|</span> <span class=\"mf\">0.426096</span> <span class=\"o\">|</span> <span class=\"n\">chr7</span>  <span class=\"o\">|</span>   <span class=\"mi\">47315290</span> <span class=\"o\">|</span> <span class=\"mi\">47314752</span> <span class=\"o\">|</span> <span class=\"mi\">47621742</span> <span class=\"o\">|</span>\n    <span class=\"o\">+-----------+------------+--------+----------+-------+------------+----------+----------+</span>\n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 1, "parent": 413, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 29}}, {"pk": 419, "model": "server.post", "fields": {"rght": 11, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 23:18:20", "lft": 8, "post_type": 109787, "score": 2, "title": "A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "You can do it with UCSC or biomart as described in the other answers; however, if you are going to work a lot with snps, I suggest you to have a look at [plink][1].\n\nplink is a nice C program with many options to work with snps and genotypes, extract reports and even calculate basic statistics. To use it to check whether your snps are within 60Kb of a gene, follow the instructions [here][2].\n\n\n  [1]: http://pngu.mgh.harvard.edu/~purcell/plink\n  [2]: http://pngu.mgh.harvard.edu/~purcell/plink/grep.shtml", "comment_count": 1, "html": "<p>You can do it with UCSC or biomart as described in the other answers; however, if you are going to work a lot with snps, I suggest you to have a look at <a href=\"http://pngu.mgh.harvard.edu/~purcell/plink\">plink</a>.</p>\n<p>plink is a nice C program with many options to work with snps and genotypes, extract reports and even calculate basic statistics. To use it to check whether your snps are within 60Kb of a gene, follow the instructions <a href=\"http://pngu.mgh.harvard.edu/~purcell/plink/grep.shtml\">here</a>.</p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 1, "parent": 413, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:25", "slug": "a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 420, "model": "server.post", "fields": {"rght": 30, "author": 54, "answer_accepted": true, "tag_string": "webservice bioinformatics soap rest subjective", "creation_date": "2010-03-23 10:30:26", "lft": 1, "post_type": 164033, "score": 9, "title": "What is your experience with bioinformatics webservices?", "unanswered": false, "content": "[Web-services][1] using SOAP or REST style are becoming more and more popular in also bioinformatics. The [Embrace Registry][2] and [BioCatalogue][3] are registries which provide a good overview of publicly available bioinformatics services. They aim at making services easier to describe and find. It is also often heard that web-services provide a platform- and language-independent interface to databases and computation. Furthermore, web-services can be [composed into complex-workflows][4], [used for data-integration,][5] automated user-interface and API-generation, that's at least the theory. How does the reality look for you?\n\nDo you use  SOAP/REST/.NET services in bioinformatics,\nand what are your experiences with the different services and service providers?\n\nMain aspects I am interested in are motivated by my own recent (and very mixed) experiences:\n\n - Did you encounter interoperability or language-dependence problems?\n - How did the providers react?\n - What would make you replace local scripts and tools by web-services?\n\n------\nEdit: I will have difficulties to choose the right answer, because everything said so far is valid.  \n\nHere are some intermediate results. I am testing different SOAP services using Axis2/Java at the moment, using the wsdl2code to generate the Java trying adb and xmlbeans databindings. Maybe this list will grow:\n\n 1. KEGG: wsdl2code: only with xmlbeans , usable: no, couldn't set arrayOfString because use of soapenc:array\n 2. BRENDA: wsdl2code: Error message: Wsdl not WS-I compliant, usable: no\n 3. BioMart soap: wsdl2code: yes, usable: no, after few mods of wsdl-file and tweaking axis2 params could send a valid message, response message is not valid \n\n\n\n  [1]: http://en.wikipedia.org/wiki/Web_service\n  [2]: http://www.embraceregistry.net/\n  [3]: http://www.biocatalogue.org/\n  [4]: http://www.ncbi.nlm.nih.gov/pubmed/16845108\n  [5]: http://www.ncbi.nlm.nih.gov/pubmed/18056132", "comment_count": 0, "html": "<p><a href=\"http://en.wikipedia.org/wiki/Web_service\">Web-services</a> using SOAP or REST style are becoming more and more popular in also bioinformatics. The <a href=\"http://www.embraceregistry.net/\">Embrace Registry</a> and <a href=\"http://www.biocatalogue.org/\">BioCatalogue</a> are registries which provide a good overview of publicly available bioinformatics services. They aim at making services easier to describe and find. It is also often heard that web-services provide a platform- and language-independent interface to databases and computation. Furthermore, web-services can be <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16845108\">composed into complex-workflows</a>, <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/18056132\">used for data-integration,</a> automated user-interface and API-generation, that's at least the theory. How does the reality look for you?</p>\n<p>Do you use  SOAP/REST/.NET services in bioinformatics,\nand what are your experiences with the different services and service providers?</p>\n<p>Main aspects I am interested in are motivated by my own recent (and very mixed) experiences:</p>\n<ul>\n<li>Did you encounter interoperability or language-dependence problems?</li>\n<li>How did the providers react?</li>\n<li>What would make you replace local scripts and tools by web-services?</li>\n</ul>\n<hr />\n<p>Edit: I will have difficulties to choose the right answer, because everything said so far is valid.<br />\n</p>\n<p>Here are some intermediate results. I am testing different SOAP services using Axis2/Java at the moment, using the wsdl2code to generate the Java trying adb and xmlbeans databindings. Maybe this list will grow:</p>\n<ol>\n<li>KEGG: wsdl2code: only with xmlbeans , usable: no, couldn't set arrayOfString because use of soapenc:array</li>\n<li>BRENDA: wsdl2code: Error message: Wsdl not WS-I compliant, usable: no</li>\n<li>BioMart soap: wsdl2code: yes, usable: no, after few mods of wsdl-file and tweaking axis2 params could send a valid message, response message is not valid </li>\n</ol>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 2, "parent": null, "views": 976, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:28", "slug": "what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [32, 141, 142, 152, 159], "lastedit_user": 54}}, {"pk": 421, "model": "server.post", "fields": {"rght": 13, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 12:01:54", "lft": 6, "post_type": 109787, "score": 3, "title": "A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "Following this definition, all deterministic methods are 100% reliable, because they always reproduce the same result when repeated. Reliability is - of course - important for measurements, but data-transformations are not measurements. There are some statistics (not normalization methods I know of) for example those involving the\nEM-algorithms or k-means clustering.  \n\nSo, my advise: check if the methods are deterministic, then they are reliable by definition. This question of reliability is for sure relevant for the measurement techniques such as microarrays, qPCR, RNA-seq, but it is totally solved for normalization (say: ALL methods are deterministic/reliable). If you are looking for a problem to solve in normalization this is definitely not the right place.\n\nBTW.: one can easily assess the reliability. If you want to check RMA, loess-normalization, mean or quantile normalization, just run it on the same input data say 1000 times and look at the results.\nBTW2.: RMA  because mentioned (robust multichip average) is not (only) normalization, it comprizes background subtraction, quantile normalization (a totally deterministic method), and intensity sumarization. \n\nEdit: Just to restrict the above said again. There are some reliability issues with normalization. I just saw a message on bioconductor noticing differences in the analysis using GCRMA on windows/linux. As said, most normalization and summary methods are deterministic as long as data and methods stay the same. However, there can be variations on the probe level, even when using the same array design. The most common source of such events is that the array annotation and thereby the probe-level groups and their assignments to genes are changed. \n\nThis is sort of a \"pseudo-(un)reliabilty\" because if all parameters are the same, the results are the same. But the annotations are frequently changed and the annotation updates are mostly included automagically without the user noticing the difference. This is specifically true for the Affy platform.\n\n\n ", "comment_count": 3, "html": "<p>Following this definition, all deterministic methods are 100% reliable, because they always reproduce the same result when repeated. Reliability is - of course - important for measurements, but data-transformations are not measurements. There are some statistics (not normalization methods I know of) for example those involving the\nEM-algorithms or k-means clustering.<br />\n</p>\n<p>So, my advise: check if the methods are deterministic, then they are reliable by definition. This question of reliability is for sure relevant for the measurement techniques such as microarrays, qPCR, RNA-seq, but it is totally solved for normalization (say: ALL methods are deterministic/reliable). If you are looking for a problem to solve in normalization this is definitely not the right place.</p>\n<p>BTW.: one can easily assess the reliability. If you want to check RMA, loess-normalization, mean or quantile normalization, just run it on the same input data say 1000 times and look at the results.\nBTW2.: RMA  because mentioned (robust multichip average) is not (only) normalization, it comprizes background subtraction, quantile normalization (a totally deterministic method), and intensity sumarization. </p>\n<p>Edit: Just to restrict the above said again. There are some reliability issues with normalization. I just saw a message on bioconductor noticing differences in the analysis using GCRMA on windows/linux. As said, most normalization and summary methods are deterministic as long as data and methods stay the same. However, there can be variations on the probe level, even when using the same array design. The most common source of such events is that the array annotation and thereby the probe-level groups and their assignments to genes are changed. </p>\n<p>This is sort of a \"pseudo-(un)reliabilty\" because if all parameters are the same, the results are the same. But the annotations are frequently changed and the annotation updates are mostly included automagically without the user noticing the difference. This is specifically true for the Affy platform.</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 3, "parent": 387, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 54}}, {"pk": 422, "model": "server.post", "fields": {"rght": 5, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 12:20:21", "lft": 2, "post_type": 109787, "score": 4, "title": "A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": " - SOAP/WSDL is great for generating the code for reading/writing the structured information.\n - It is very easy to implement a SOAP server and its client with a few annotations with the Java API ( [my experience][1] )\n - I've tested a few SOAP services from the Biocatalogue. Many times it uses an old deprecated format. e.g.:\n\n     wsimport http://www.pdb.org/pdb/services/pdbws?wsdl\n\n    [WARNING] src-resolve: Cannot resolve the name 'soapenc:Array' to a(n) 'type definition' component.\n      line 10 of http://www.pdb.org/pdb/services/pdbws?wsdl#types?schema1\n\n    [ERROR] undefined simple or complex type 'soapenc:Array'\n      line 10 of http://www.pdb.org/pdb/services/pdbws?wsdl\n\n - the WSDL generated with JAVA are missing some documentation (what is this method? how should I use it ?)\n - I also played successfully with some WS at the EBI (  [my experience with intact][2] ) but here the message returned was 'just' a tab delimited line that had to be splitted/parsed again by the client :-)\n\n - (...)\n\n  [1]: http://plindenbaum.blogspot.com/2009/05/webservicesjaxws-for-snp-glassfish.html\n  [2]: http://plindenbaum.blogspot.com/2008/10/ebiintact-web-service-api-my-notebook.html", "comment_count": 1, "html": "<ul>\n<li>SOAP/WSDL is great for generating the code for reading/writing the structured information.</li>\n<li>It is very easy to implement a SOAP server and its client with a few annotations with the Java API ( <a href=\"http://plindenbaum.blogspot.com/2009/05/webservicesjaxws-for-snp-glassfish.html\">my experience</a> )</li>\n<li>I've tested a few SOAP services from the Biocatalogue. Many times it uses an old deprecated format. e.g.:</li>\n</ul>\n<p><div class=\"highlight\"><pre>     <span class=\"n\">wsimport</span> <span class=\"n\">http:</span><span class=\"sr\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">pdb</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"sr\">/pdb/s</span><span class=\"n\">ervices</span><span class=\"o\">/</span><span class=\"n\">pdbws</span><span class=\"p\">?</span><span class=\"n\">wsdl</span>\n\n    <span class=\"p\">[</span><span class=\"n\">WARNING</span><span class=\"p\">]</span> <span class=\"n\">src</span><span class=\"o\">-</span><span class=\"n\">resolve:</span> <span class=\"n\">Cannot</span> <span class=\"n\">resolve</span> <span class=\"n\">the</span> <span class=\"n\">name</span> <span class=\"s\">&#39;soapenc:Array&#39;</span> <span class=\"n\">to</span> <span class=\"n\">a</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"p\">)</span> <span class=\"s\">&#39;type definition&#39;</span> <span class=\"n\">component</span><span class=\"o\">.</span>\n      <span class=\"n\">line</span> <span class=\"mi\">10</span> <span class=\"n\">of</span> <span class=\"n\">http:</span><span class=\"sr\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">pdb</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"sr\">/pdb/s</span><span class=\"n\">ervices</span><span class=\"o\">/</span><span class=\"n\">pdbws</span><span class=\"p\">?</span><span class=\"n\">wsdl</span><span class=\"c1\">#types?schema1</span>\n\n    <span class=\"p\">[</span><span class=\"n\">ERROR</span><span class=\"p\">]</span> <span class=\"n\">undefined</span> <span class=\"n\">simple</span> <span class=\"ow\">or</span> <span class=\"n\">complex</span> <span class=\"n\">type</span> <span class=\"s\">&#39;soapenc:Array&#39;</span>\n      <span class=\"n\">line</span> <span class=\"mi\">10</span> <span class=\"n\">of</span> <span class=\"n\">http:</span><span class=\"sr\">//</span><span class=\"n\">www</span><span class=\"o\">.</span><span class=\"n\">pdb</span><span class=\"o\">.</span><span class=\"n\">org</span><span class=\"sr\">/pdb/s</span><span class=\"n\">ervices</span><span class=\"o\">/</span><span class=\"n\">pdbws</span><span class=\"p\">?</span><span class=\"n\">wsdl</span>\n</pre></div>\n</p>\n<ul>\n<li>the WSDL generated with JAVA are missing some documentation (what is this method? how should I use it ?)</li>\n<li>\n<p>I also played successfully with some WS at the EBI (  <a href=\"http://plindenbaum.blogspot.com/2008/10/ebiintact-web-service-api-my-notebook.html\">my experience with intact</a> ) but here the message returned was 'just' a tab delimited line that had to be splitted/parsed again by the client :-)</p>\n</li>\n<li>\n<p>(...)</p>\n</li>\n</ul>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 1, "parent": 420, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 29}}, {"pk": 423, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 13:23:52", "lft": 4, "post_type": 109787, "score": 1, "title": "A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "I feel somewhat embarrassed to admit that I know very little about these web-services. I knew that they existed but never saw examples of actual use cases performed with  them. When simply reading about a service they feel a little complicated, imposing a cognitive overhead that may not obviously pay off in long term.\n\nBut I have learned a number of neat tricks here on this site on how to access various resources, and I plan to put those to use. I find cookbook like approaches: *this is how we do X or Y with a bioservice* as being the most effective method of demonstrating their value.\n\nEdit (forgot to answer this):\n\n - What would make you replace local scripts and tools by web-services?\n\nFor me the first priority is that the simplicity of the overall solution. What is the added complexity of one approach versus the other, and weighing that against overall goals.\n ", "comment_count": 0, "html": "<p>I feel somewhat embarrassed to admit that I know very little about these web-services. I knew that they existed but never saw examples of actual use cases performed with  them. When simply reading about a service they feel a little complicated, imposing a cognitive overhead that may not obviously pay off in long term.</p>\n<p>But I have learned a number of neat tricks here on this site on how to access various resources, and I plan to put those to use. I find cookbook like approaches: <em>this is how we do X or Y with a bioservice</em> as being the most effective method of demonstrating their value.</p>\n<p>Edit (forgot to answer this):</p>\n<ul>\n<li>What would make you replace local scripts and tools by web-services?</li>\n</ul>\n<p>For me the first priority is that the simplicity of the overall solution. What is the added complexity of one approach versus the other, and weighing that against overall goals.</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 2, "parent": 420, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:25", "slug": "a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 424, "model": "server.post", "fields": {"rght": 15, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 14:04:31", "lft": 6, "post_type": 109787, "score": 6, "title": "A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "I have used the Stanford HIVdb web service, which is a fantastic tool for identifying drug resistant mutations in HIV sequences. Fortunately, they provide the entire client-side base code in both Perl and Java, otherwise it might have been too onerous to deal with. I think this is absolutely critical to getting any traction if you intend to roll out a web service like this.\n\nI believe our group was the first to submit pyrosequencing data to this service, which meant they received tens of thousands of hits from us instead of a just a few. Still, it was able to deal with the increased load over a weekend.\n\n* Did you encounter interoperability or language-dependence problems?\n * Yes their Perl client did not work after a certain version. Fortunately they provided a Java client which continued to work.\n\n\n* How did the providers react?\n     * Very well. They were very helpful.\n\n\n* What would make you replace local scripts and tools by web-services?\n\n   * Because I work in industry now it\n   would be difficult for me to get the\n   use of these services blessed by the\n   powers that be without a security\n   framework in place (https?). There also appears to be a lot more available on the human side than for plants.\n\nI would say SOAP is losing the popularity contest to REST, not because of a lack of merits, but because only Pierre Lindenbaum understands how to use SOAP. Seriously though, I think SOAP was/is too complex or intimidating for most end-users to wrap their head around even though it is a more powerful framework.\n\nAnother factor that I think will be in REST's favor is the proliferation of modern web frameworks like Rails and Grails that make it easy to develop RESTy interfaces which serve both human and robot clients with the flip of a switch.", "comment_count": 4, "html": "<p>I have used the Stanford HIVdb web service, which is a fantastic tool for identifying drug resistant mutations in HIV sequences. Fortunately, they provide the entire client-side base code in both Perl and Java, otherwise it might have been too onerous to deal with. I think this is absolutely critical to getting any traction if you intend to roll out a web service like this.</p>\n<p>I believe our group was the first to submit pyrosequencing data to this service, which meant they received tens of thousands of hits from us instead of a just a few. Still, it was able to deal with the increased load over a weekend.</p>\n<ul>\n<li>Did you encounter interoperability or language-dependence problems?</li>\n<li>\n<p>Yes their Perl client did not work after a certain version. Fortunately they provided a Java client which continued to work.</p>\n</li>\n<li>\n<p>How did the providers react?\n<div class=\"highlight\"><pre>     <span class=\"o\">*</span> <span class=\"n\">Very</span> <span class=\"n\">well</span><span class=\"o\">.</span> <span class=\"n\">They</span> <span class=\"n\">were</span> <span class=\"n\">very</span> <span class=\"n\">helpful</span><span class=\"o\">.</span>\n</pre></div>\n</p>\n</li>\n<li>\n<p>What would make you replace local scripts and tools by web-services?</p>\n</li>\n<li>\n<p>Because I work in industry now it\n   would be difficult for me to get the\n   use of these services blessed by the\n   powers that be without a security\n   framework in place (https?). There also appears to be a lot more available on the human side than for plants.</p>\n</li>\n</ul>\n<p>I would say SOAP is losing the popularity contest to REST, not because of a lack of merits, but because only Pierre Lindenbaum understands how to use SOAP. Seriously though, I think SOAP was/is too complex or intimidating for most end-users to wrap their head around even though it is a more powerful framework.</p>\n<p>Another factor that I think will be in REST's favor is the proliferation of modern web frameworks like Rails and Grails that make it easy to develop RESTy interfaces which serve both human and robot clients with the flip of a switch.</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 1, "parent": 420, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 425, "model": "server.post", "fields": {"rght": 14, "author": 165, "answer_accepted": false, "tag_string": "sequence submission ncbi public accession", "creation_date": "2010-03-23 14:37:58", "lft": 1, "post_type": 164033, "score": 6, "title": "When is the best time to submit sequences to public databases like NCBI?", "unanswered": false, "content": "I have always left the submission of sequences to NCBI to the very last minute, i.e. just before submitting a manuscript for review and on occasion, I have left it until I have known that the paper is accepted. In your opinion when is the best time to submit? As soon as you have quality checked the sequences? Once the manuscript is ready for submission? After the manuscript has been accepted?\nIt would be great to get a general feel of when people tend to submit there sequences.", "comment_count": 0, "html": "<p>I have always left the submission of sequences to NCBI to the very last minute, i.e. just before submitting a manuscript for review and on occasion, I have left it until I have known that the paper is accepted. In your opinion when is the best time to submit? As soon as you have quality checked the sequences? Once the manuscript is ready for submission? After the manuscript has been accepted?\nIt would be great to get a general feel of when people tend to submit there sequences.</p>", "child_count": 0, "closed": false, "tree_id": 94, "revision_count": 1, "parent": null, "views": 197, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:29", "slug": "when-is-the-best-time-to-submit-sequences-to-public-databases-like-ncbi", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [19, 40, 160, 161, 225], "lastedit_user": 165}}, {"pk": 426, "model": "server.post", "fields": {"rght": 3, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 16:06:48", "lft": 2, "post_type": 109787, "score": 5, "title": "A: When is the best time to submit sequences to public databases like NCBI?", "unanswered": false, "content": "In the past, I've mostly done it like you, but with the current wealth of sequence data, I guess the relative value of sequences is going down. Therefore, I don't see any reason per se to wait until the paper is submitted/accepted. *Unless* of course you have something that gives you an advantage over your competition (if applicable) that you don't want them to see before your publication is out. \n\nNote that you can also submit sequences and specify a release date, so it's not necessarily true that sequences become publically available as soon as they're submitted.\n\nIn my personal view, the advantage to submitting as early as possible is that you've got it out of the way sooner.\n\n", "comment_count": 0, "html": "<p>In the past, I've mostly done it like you, but with the current wealth of sequence data, I guess the relative value of sequences is going down. Therefore, I don't see any reason per se to wait until the paper is submitted/accepted. <em>Unless</em> of course you have something that gives you an advantage over your competition (if applicable) that you don't want them to see before your publication is out. </p>\n<p>Note that you can also submit sequences and specify a release date, so it's not necessarily true that sequences become publically available as soon as they're submitted.</p>\n<p>In my personal view, the advantage to submitting as early as possible is that you've got it out of the way sooner.</p>", "child_count": 0, "closed": false, "tree_id": 94, "revision_count": 1, "parent": 425, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-when-is-the-best-time-to-submit-sequences-to-public-databases-like-ncbi", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 118}}, {"pk": 427, "model": "server.post", "fields": {"rght": 12, "author": 85, "answer_accepted": false, "tag_string": "gwas gene genome", "creation_date": "2010-03-23 18:35:41", "lft": 1, "post_type": 164033, "score": 5, "title": "How to find all GWAS studies that a given gene has been implicated in?", "unanswered": false, "content": "dbGaP seems to be a primary data repository, but it doesn't store results on the level of genes (or as far as I can tell, even genomic regions).", "comment_count": 1, "html": "<p>dbGaP seems to be a primary data repository, but it doesn't store results on the level of genes (or as far as I can tell, even genomic regions).</p>", "child_count": 0, "closed": false, "tree_id": 95, "revision_count": 2, "parent": null, "views": 900, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:25", "slug": "how-to-find-all-gwas-studies-that-a-given-gene-has-been-implicated-in", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [36, 67, 162], "lastedit_user": 86}}, {"pk": 428, "model": "server.post", "fields": {"rght": 3, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 19:01:57", "lft": 2, "post_type": 109787, "score": 4, "title": "A: How to find all GWAS studies that a given gene has been implicated in?", "unanswered": false, "content": "AFAIK, [dbGAP][1] is one of the official resource for GWAS studies. A mere gene search may not fetch the exact details about the studies. Dataset from large scale GWAS studies are not available under public access due to sensitive genotype and phenotype data from patients. You have to write to individual investigators to get access to the data. Usually this data will be available only after the Embargo Release date. This is usually after 1year of the submission of the data. I think once you have access to the dataset, you will able to get the p-values of the SNPs genotyped in the whole study with the de-identified case/control and their phenotypes. These SNPs may need further mapping to get the details about the genes. \n\n[NHGRI website][2] provides A Catalog of Published Genome-Wide Association Studies: They provide a detailed table of GWAS and their details. As of 03/24/10, this table includes 517 publications and 2443 SNPs. You may map this SNPs to get the respective genes. \n\nAlso this [manuscript][3] provides results from various GWAS studies. \n\nI am looking forward for other comments to know if there is any public resource that provides GWAS data. \n\nEDIT : I have recently used [SCANDB][4], [GWASIntegrator][5] and [VARIETAS][6] for integrating GWAS studies around a gene. \n\n\n  [1]: http://www.ncbi.nlm.nih.gov/gap\n  [2]: http://www.genome.gov/26525384\n  [3]: http://www.biomedcentral.com/1471-2350/10/6\n  [4]: http://www.scandb.org/newinterface/about.html\n  [5]: http://hugenavigator.net/HuGENavigator/gWAHitStartPage.do\n  [6]: http://database.oxfordjournals.org/cgi/content/full/2010/0/baq016", "comment_count": 0, "html": "<p>AFAIK, <a href=\"http://www.ncbi.nlm.nih.gov/gap\">dbGAP</a> is one of the official resource for GWAS studies. A mere gene search may not fetch the exact details about the studies. Dataset from large scale GWAS studies are not available under public access due to sensitive genotype and phenotype data from patients. You have to write to individual investigators to get access to the data. Usually this data will be available only after the Embargo Release date. This is usually after 1year of the submission of the data. I think once you have access to the dataset, you will able to get the p-values of the SNPs genotyped in the whole study with the de-identified case/control and their phenotypes. These SNPs may need further mapping to get the details about the genes. </p>\n<p><a href=\"http://www.genome.gov/26525384\">NHGRI website</a> provides A Catalog of Published Genome-Wide Association Studies: They provide a detailed table of GWAS and their details. As of 03/24/10, this table includes 517 publications and 2443 SNPs. You may map this SNPs to get the respective genes. </p>\n<p>Also this <a href=\"http://www.biomedcentral.com/1471-2350/10/6\">manuscript</a> provides results from various GWAS studies. </p>\n<p>I am looking forward for other comments to know if there is any public resource that provides GWAS data. </p>\n<p>EDIT : I have recently used <a href=\"http://www.scandb.org/newinterface/about.html\">SCANDB</a>, <a href=\"http://hugenavigator.net/HuGENavigator/gWAHitStartPage.do\">GWASIntegrator</a> and <a href=\"http://database.oxfordjournals.org/cgi/content/full/2010/0/baq016\">VARIETAS</a> for integrating GWAS studies around a gene. </p>", "child_count": 0, "closed": false, "tree_id": 95, "revision_count": 4, "parent": 427, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-to-find-all-gwas-studies-that-a-given-gene-has-been-implicated-in", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 86}}, {"pk": 429, "model": "server.post", "fields": {"rght": 16, "author": 147, "answer_accepted": false, "tag_string": "taverna plone online workflow", "creation_date": "2010-03-23 20:02:14", "lft": 1, "post_type": 164033, "score": 4, "title": "Tips on how to set up a virtual online workbench for bioinformatics", "unanswered": false, "content": "Greetings again,\n\nI want to build a virtual workbench on a bunch of Linux servers (VM allowed) for a medical community. I'm thinking in a solution in the spirit of the Taverna project (server version). Every user shoud be able to construct its own online virtual workflow from a set of in-house tools, submit and retrive data, etc. \n\nThe data are somewhat sigilous. Applications will be critical in a near future. So, I can't use elsewhere servers/services.\n\nThe most important point is: the community is large and the bioinformaticians are very few. If we could set up a customizable online service for common tasks (alignment, phylogeny, GO annotation retrieval, etc.) our life would be so much happier (and we could focus on bioinformatics research again) !!! \n\nI aware only of Taverna and Plone4Bio. Is there other server-like virtual benches? Did someone already test them? Extensively?", "comment_count": 0, "html": "<p>Greetings again,</p>\n<p>I want to build a virtual workbench on a bunch of Linux servers (VM allowed) for a medical community. I'm thinking in a solution in the spirit of the Taverna project (server version). Every user shoud be able to construct its own online virtual workflow from a set of in-house tools, submit and retrive data, etc. </p>\n<p>The data are somewhat sigilous. Applications will be critical in a near future. So, I can't use elsewhere servers/services.</p>\n<p>The most important point is: the community is large and the bioinformaticians are very few. If we could set up a customizable online service for common tasks (alignment, phylogeny, GO annotation retrieval, etc.) our life would be so much happier (and we could focus on bioinformatics research again) !!! </p>\n<p>I aware only of Taverna and Plone4Bio. Is there other server-like virtual benches? Did someone already test them? Extensively?</p>", "child_count": 0, "closed": false, "tree_id": 96, "revision_count": 3, "parent": null, "views": 492, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:30", "slug": "tips-on-how-to-set-up-a-virtual-online-workbench-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [49, 52, 163, 164], "lastedit_user": 58}}, {"pk": 430, "model": "server.post", "fields": {"rght": 5, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 20:19:11", "lft": 2, "post_type": 109787, "score": 6, "title": "A: Tips on how to set up a virtual online workbench for bioinformatics", "unanswered": false, "content": "Some workflow engines. Some of them (like Mobyle or Galaxy) are hosted on a web server.\n\nMobyle: http://mobyle.pasteur.fr\n\nGalaxy: http://main.g2.bx.psu.edu/\n\nOrange: http://www.ailab.si/orange/\n\nKNime: http://knime.org/\n\nWildfire: http://wildfire.bii.a-star.edu.sg/index.php\n\nUgene: http://ugene.unipro.ru/index.html\n\nKepler: https://kepler-project.org/\n\n(...)", "comment_count": 1, "html": "<p>Some workflow engines. Some of them (like Mobyle or Galaxy) are hosted on a web server.</p>\n<p>Mobyle: http://mobyle.pasteur.fr</p>\n<p>Galaxy: http://main.g2.bx.psu.edu/</p>\n<p>Orange: http://www.ailab.si/orange/</p>\n<p>KNime: http://knime.org/</p>\n<p>Wildfire: http://wildfire.bii.a-star.edu.sg/index.php</p>\n<p>Ugene: http://ugene.unipro.ru/index.html</p>\n<p>Kepler: https://kepler-project.org/</p>\n<p>(...)</p>", "child_count": 0, "closed": false, "tree_id": 96, "revision_count": 1, "parent": 429, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-tips-on-how-to-set-up-a-virtual-online-workbench-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 431, "model": "server.post", "fields": {"rght": 13, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 21:15:24", "lft": 4, "post_type": 109787, "score": 5, "title": "A: Tips on how to set up a virtual online workbench for bioinformatics", "unanswered": false, "content": "Plenty of people have tried this before for other communities\n\nCARMEN for neuroinformatics: [http://carmen.org.uk][1]\n\nBIRN (Biomedical Informatics Reseatch Network) [http://www.birncommunity.org/][2]\n\nNUGO (via the NuGO Black Box or NBX) [http://www.nugo.org/nbx][3]\n\nThis is not a trivial problem and can be attacked with varying levels of complexity.  You would do well to look at how other people have attempted to solve the problem.  It's not just an issue of providing the services, or a workflow handler, but also opens up serious consideration of how you provide authentication and security for data and resources.\n\n\n  [1]: http://carmen.org.uk\n  [2]: http://www.birncommunity.org/\n  [3]: http://www.nugo.org/nbx", "comment_count": 4, "html": "<p>Plenty of people have tried this before for other communities</p>\n<p>CARMEN for neuroinformatics: <a href=\"http://carmen.org.uk\">http://carmen.org.uk</a></p>\n<p>BIRN (Biomedical Informatics Reseatch Network) <a href=\"http://www.birncommunity.org/\">http://www.birncommunity.org/</a></p>\n<p>NUGO (via the NuGO Black Box or NBX) <a href=\"http://www.nugo.org/nbx\">http://www.nugo.org/nbx</a></p>\n<p>This is not a trivial problem and can be attacked with varying levels of complexity.  You would do well to look at how other people have attempted to solve the problem.  It's not just an issue of providing the services, or a workflow handler, but also opens up serious consideration of how you provide authentication and security for data and resources.</p>", "child_count": 0, "closed": false, "tree_id": 96, "revision_count": 1, "parent": 429, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-tips-on-how-to-set-up-a-virtual-online-workbench-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 432, "model": "server.post", "fields": {"rght": 15, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 23:07:27", "lft": 14, "post_type": 109787, "score": 3, "title": "A: What license do you use when you release code and data?", "unanswered": false, "content": "Currently GPL, but if you are developing as part of your job you should probably check to see if your employer has a policy on it.", "comment_count": 0, "html": "<p>Currently GPL, but if you are developing as part of your job you should probably check to see if your employer has a policy on it.</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 1, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 433, "model": "server.post", "fields": {"rght": 21, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 23:32:24", "lft": 8, "post_type": 109787, "score": 2, "title": "A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "As previously stated in some of the excellent answers above it is not just possible, but common.\n\nWe have our own system for 'validating' the mappings between affy probesets and transcripts.\n\n 1. Align all of the probes to the genome sequence\n 2. Count the number of transcripts that each probe-set is associated with and how many probes hit for each.\n 3. Exclude probe-sets that map to more than one gene with a significant number of their probes (promiscuous).\n 4. Quality score the probe-sets against actual transcribed sequence (some probes do not actually hit exonic or UTR sequences) and exclude those that fall below a threshold.\n\nRecently I have worked most with the Affymetrix Drosophila 2.0 chip-set and we find about 5% of probe-sets to be unreliable. Most fail because they are promiscuous i.e. one probe-set maps to more than one gene/transcript.\n\n", "comment_count": 6, "html": "<p>As previously stated in some of the excellent answers above it is not just possible, but common.</p>\n<p>We have our own system for 'validating' the mappings between affy probesets and transcripts.</p>\n<ol>\n<li>Align all of the probes to the genome sequence</li>\n<li>Count the number of transcripts that each probe-set is associated with and how many probes hit for each.</li>\n<li>Exclude probe-sets that map to more than one gene with a significant number of their probes (promiscuous).</li>\n<li>Quality score the probe-sets against actual transcribed sequence (some probes do not actually hit exonic or UTR sequences) and exclude those that fall below a threshold.</li>\n</ol>\n<p>Recently I have worked most with the Affymetrix Drosophila 2.0 chip-set and we find about 5% of probe-sets to be unreliable. Most fail because they are promiscuous i.e. one probe-set maps to more than one gene/transcript.</p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 1, "parent": 334, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 434, "model": "server.post", "fields": {"rght": 9, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 07:17:10", "lft": 8, "post_type": 109787, "score": 2, "title": "A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "I always very much liked the idea of webservices, and the several standards have mixed goals and features. I quite like the idea of [SOAP][1]. The SOAP standard practically settled for XML, but there are alternatives, like SOAP over [XMPP][2].\n\nThe standard has been complex and large, resulting in many partial implementations. This makes the SOAP practically difficult to use, and resulting in best practices, effectively reducing the size of the standard, so that libraries can focus on that subset. [WSDL][3] is one additional standard required by most of those best practices.\n\nMoreover, those incomplete libraries are often mutually incompatible, which has prominently been the case for Axis1/Axis2. However, some SOAP services could be properly accessed by the first and not the latter and the other way around. Try setting up a client that supports services that require both versions.\n\nREST is much simpler, but does not offer the standardized discovery, and any service may use a different design.\n\n**Disclaimer**: we developed an XMPP alternative that supports asynchronous web services recently, doi:[10.1186/1471-2105-10-279][4].\n\n\n  [1]: http://www.w3.org/TR/soap/\n  [2]: http://xmpp.org/\n  [3]: http://www.w3.org/TR/wsdl\n  [4]: http://www.biomedcentral.com/1471-2105/10/279", "comment_count": 0, "html": "<p>I always very much liked the idea of webservices, and the several standards have mixed goals and features. I quite like the idea of <a href=\"http://www.w3.org/TR/soap/\">SOAP</a>. The SOAP standard practically settled for XML, but there are alternatives, like SOAP over <a href=\"http://xmpp.org/\">XMPP</a>.</p>\n<p>The standard has been complex and large, resulting in many partial implementations. This makes the SOAP practically difficult to use, and resulting in best practices, effectively reducing the size of the standard, so that libraries can focus on that subset. <a href=\"http://www.w3.org/TR/wsdl\">WSDL</a> is one additional standard required by most of those best practices.</p>\n<p>Moreover, those incomplete libraries are often mutually incompatible, which has prominently been the case for Axis1/Axis2. However, some SOAP services could be properly accessed by the first and not the latter and the other way around. Try setting up a client that supports services that require both versions.</p>\n<p>REST is much simpler, but does not offer the standardized discovery, and any service may use a different design.</p>\n<p><strong>Disclaimer</strong>: we developed an XMPP alternative that supports asynchronous web services recently, doi:<a href=\"http://www.biomedcentral.com/1471-2105/10/279\">10.1186/1471-2105-10-279</a>.</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 1, "parent": 420, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:25", "slug": "a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 435, "model": "server.post", "fields": {"rght": 22, "author": 135, "answer_accepted": true, "tag_string": "call papers conferences research not related", "creation_date": "2010-03-24 08:42:29", "lft": 1, "post_type": 164033, "score": 7, "title": "Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "Is there an easy way to find out about current calls for papers and conferences? I find it incredibly frustrating every time I find an interesting conference announcement and see that the call for papers deadline expired the day before, or is too soon to prepare a paper for submission. Is there a global collection of bioinformatics related conferences somewhere?", "comment_count": 0, "html": "<p>Is there an easy way to find out about current calls for papers and conferences? I find it incredibly frustrating every time I find an interesting conference announcement and see that the call for papers deadline expired the day before, or is too soon to prepare a paper for submission. Is there a global collection of bioinformatics related conferences somewhere?</p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 2, "parent": null, "views": 349, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:30", "slug": "is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [165, 166, 167, 221, 222, 227], "lastedit_user": 29}}, {"pk": 436, "model": "server.post", "fields": {"rght": 11, "author": 171, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 09:09:02", "lft": 10, "post_type": 109787, "score": 2, "title": "A: How do I access and query entire genome sequences with R", "unanswered": false, "content": "Hello,\nconcerning the seqinR package I would also consider the \"query\" function which allows you to \nquery various databases as  EMBL, GenBank, Uniprot, some Ensembl genomes and others databases structured under ACNUC ([http://pbil.univ-lyon1.fr/databases/acnuc/acnuc.html][1]) .\n\n>library(seqinr)\n\nTo check which databases are available, type:\n\n>choosebank(infobank=TRUE)\n\n\nFor example if you want to query the ensembl human genome for sequences in which the field hgnc is a2m :\n\n> choosebank(\"human\")\n\n> query(\"mylist\",\"k=hgnc:a2m\")\n\nNote that in the case of Ensembl, cross-references may be used as keywords:\n \nFor example in the selected sequence, the annotations are\n\n> S12_1.PE362                  \n> Location/Qualifiers    (length=4425\n> bp) FT   CDS            \n> join(complement(9268360..9268445),complement(9265956..9266139),\n> FT                  \n> complement(9264973..9265132),complement(9264755..9264807),\n> FT                  \n> complement(9262910..9262930),complement(9262463..9262631),\n> FT                  \n> complement(9261917..9262001),complement(9260120..9260240),\n> FT                  \n> complement(9259087..9259201),complement(9258832..9258941),\n> FT                  \n> complement(9256835..9256996),complement(9254043..9254270),\n> FT                  \n> complement(9253740..9253803),complement(9251977..9252119),\n> FT                  \n> complement(9251203..9251352),complement(9248135..9248296),\n> FT                  \n> complement(9247569..9247680),complement(9246061..9246175),\n> FT                  \n> complement(9243797..9244025),complement(9242952..9243078),\n> FT                  \n> complement(9242498..9242619),complement(9241796..9241847),\n> FT                  \n> complement(9232690..9232773),complement(9232235..9232411),\n> FT                  \n> complement(9231840..9231927),complement(9230297..9230453),\n> FT                  \n> complement(9229942..9230016),complement(9229352..9229532),\n> FT                  \n> complement(9227156..9227379),complement(9225249..9225467),\n> FT                  \n> complement(9224955..9225082),complement(9223084..9223174),\n> FT                  \n> complement(9222341..9222409),complement(9221336..9221438),\n> FT                  \n> complement(9220779..9220820),complement(9220419..9220435))\n> FT                  \n> /gene=\"ENSG00000175899\" FT            \n> /protein_id=\"ENSP00000323929\" FT      \n> /note=\"transcript_id=ENST00000318602\"\n> FT                  \n> /db_xref=\"HGNC:A2M\" FT                \n> /db_xref=\"UCSC:uc001qvk.1\" FT         \n> /db_xref=\"CCDS:CCDS44827.1\" FT        \n> /db_xref=\"HPA:CAB017621\" FT           \n> /db_xref=\"HPA:CAB017621\" FT           \n> /db_xref=\"HPA:HPA002265\" FT           \n> /db_xref=\"HPA:HPA002265\" FT           \n> /db_xref=\"WikiGene:A2M\" FT            \n> /db_xref=\"Uniprot/SWISSPROT:A2MG_HUMAN\"\n> FT                  \n> /db_xref=\"RefSeq_peptide:NP_000005.2\"\n> FT                  \n> /db_xref=\"RefSeq_dna:NM_000014.4\" FT  \n> /db_xref=\"Uniprot/SPTREMBL:C9J773_HUMAN\"\n> FT                  \n> /db_xref=\"Uniprot/SPTREMBL:Q9BQ22_HUMAN\"\n> FT                  \n> /db_xref=\"EntrezGene:A2M\" FT          \n> /db_xref=\"EMBL:AB209614\" FT           \n> /db_xref=\"EMBL:AC007436\" FT           \n> /db_xref=\"EMBL:AF109189\" FT           \n> /db_xref=\"EMBL:AF349032\" FT           \n> /db_xref=\"EMBL:AF349033\" FT           \n> /db_xref=\"EMBL:AY591530\" FT           \n> /db_xref=\"EMBL:BC026246\" FT           \n> /db_xref=\"EMBL:BC040071\" FT           \n> /db_xref=\"EMBL:CR749334\" FT           \n> /db_xref=\"EMBL:M11313\"\n\n \"HGNC:A2M\", \"UCSC:uc001qvk.1\",\"CCDS:CCDS44827.1\",\"HPA:CAB017621\",etc.\n are keywords which may be used to retrieve the sequence \n\nNow to check the sequence list ( in this case there is only 1 sequence in the list) :\n\n> mylist$req\n\n\n[[1]]\n          name         length          frame         ncbicg \n\"HS12_1.PE362\"         \"4425\"            \"0\"            \"1\" \n\n\nto get the sequence data:\n\n>seq<-sapply(mylist$req[1:1],getSequence, as.string = FALSE)  \n\n\nto save  data in fasta format:\n\n>write.fasta(sequences=seq,names=\"my_sequence\" , file.out = \"myseq.fasta\")\n\n\nYou can get as well  whole chromsome sequences, extract data in  several formats, extract fragments of sequences, translate into protein.\n\nYou may find more  information on  the seqinR page here  http://seqinr.r-forge.r-project.org/ \n\nI hope this may  help  you\n\n\nSimon\n\n\n  [1]: http://pbil.univ-lyon1.fr/databases/acnuc/acnuc.html", "comment_count": 0, "html": "<p>Hello,\nconcerning the seqinR package I would also consider the \"query\" function which allows you to \nquery various databases as  EMBL, GenBank, Uniprot, some Ensembl genomes and others databases structured under ACNUC (<a href=\"http://pbil.univ-lyon1.fr/databases/acnuc/acnuc.html\">http://pbil.univ-lyon1.fr/databases/acnuc/acnuc.html</a>) .</p>\n<blockquote>\n<p>library(seqinr)</p>\n</blockquote>\n<p>To check which databases are available, type:</p>\n<blockquote>\n<p>choosebank(infobank=TRUE)</p>\n</blockquote>\n<p>For example if you want to query the ensembl human genome for sequences in which the field hgnc is a2m :</p>\n<blockquote>\n<p>choosebank(\"human\")</p>\n<p>query(\"mylist\",\"k=hgnc:a2m\")</p>\n</blockquote>\n<p>Note that in the case of Ensembl, cross-references may be used as keywords:</p>\n<p>For example in the selected sequence, the annotations are</p>\n<blockquote>\n<p>S12_1.PE362                <br />\nLocation/Qualifiers    (length=4425\nbp) FT   CDS          <br />\njoin(complement(9268360..9268445),complement(9265956..9266139),\nFT                <br />\ncomplement(9264973..9265132),complement(9264755..9264807),\nFT                <br />\ncomplement(9262910..9262930),complement(9262463..9262631),\nFT                <br />\ncomplement(9261917..9262001),complement(9260120..9260240),\nFT                <br />\ncomplement(9259087..9259201),complement(9258832..9258941),\nFT                <br />\ncomplement(9256835..9256996),complement(9254043..9254270),\nFT                <br />\ncomplement(9253740..9253803),complement(9251977..9252119),\nFT                <br />\ncomplement(9251203..9251352),complement(9248135..9248296),\nFT                <br />\ncomplement(9247569..9247680),complement(9246061..9246175),\nFT                <br />\ncomplement(9243797..9244025),complement(9242952..9243078),\nFT                <br />\ncomplement(9242498..9242619),complement(9241796..9241847),\nFT                <br />\ncomplement(9232690..9232773),complement(9232235..9232411),\nFT                <br />\ncomplement(9231840..9231927),complement(9230297..9230453),\nFT                <br />\ncomplement(9229942..9230016),complement(9229352..9229532),\nFT                <br />\ncomplement(9227156..9227379),complement(9225249..9225467),\nFT                <br />\ncomplement(9224955..9225082),complement(9223084..9223174),\nFT                <br />\ncomplement(9222341..9222409),complement(9221336..9221438),\nFT                <br />\ncomplement(9220779..9220820),complement(9220419..9220435))\nFT                <br />\n/gene=\"ENSG00000175899\" FT          <br />\n/protein_id=\"ENSP00000323929\" FT    <br />\n/note=\"transcript_id=ENST00000318602\"\nFT                <br />\n/db_xref=\"HGNC:A2M\" FT              <br />\n/db_xref=\"UCSC:uc001qvk.1\" FT       <br />\n/db_xref=\"CCDS:CCDS44827.1\" FT      <br />\n/db_xref=\"HPA:CAB017621\" FT         <br />\n/db_xref=\"HPA:CAB017621\" FT         <br />\n/db_xref=\"HPA:HPA002265\" FT         <br />\n/db_xref=\"HPA:HPA002265\" FT         <br />\n/db_xref=\"WikiGene:A2M\" FT          <br />\n/db_xref=\"Uniprot/SWISSPROT:A2MG_HUMAN\"\nFT                <br />\n/db_xref=\"RefSeq_peptide:NP_000005.2\"\nFT                <br />\n/db_xref=\"RefSeq_dna:NM_000014.4\" FT<br />\n/db_xref=\"Uniprot/SPTREMBL:C9J773_HUMAN\"\nFT                <br />\n/db_xref=\"Uniprot/SPTREMBL:Q9BQ22_HUMAN\"\nFT                <br />\n/db_xref=\"EntrezGene:A2M\" FT        <br />\n/db_xref=\"EMBL:AB209614\" FT         <br />\n/db_xref=\"EMBL:AC007436\" FT         <br />\n/db_xref=\"EMBL:AF109189\" FT         <br />\n/db_xref=\"EMBL:AF349032\" FT         <br />\n/db_xref=\"EMBL:AF349033\" FT         <br />\n/db_xref=\"EMBL:AY591530\" FT         <br />\n/db_xref=\"EMBL:BC026246\" FT         <br />\n/db_xref=\"EMBL:BC040071\" FT         <br />\n/db_xref=\"EMBL:CR749334\" FT         <br />\n/db_xref=\"EMBL:M11313\"</p>\n</blockquote>\n<p>\"HGNC:A2M\", \"UCSC:uc001qvk.1\",\"CCDS:CCDS44827.1\",\"HPA:CAB017621\",etc.\n are keywords which may be used to retrieve the sequence </p>\n<p>Now to check the sequence list ( in this case there is only 1 sequence in the list) :</p>\n<blockquote>\n<p>mylist$req</p>\n</blockquote>\n<p>[[1]]\n<div class=\"highlight\"><pre>          <span class=\"n\">name</span>         <span class=\"nb\">length</span>          <span class=\"n\">frame</span>         <span class=\"n\">ncbicg</span> \n</pre></div>\n\n\"HS12_1.PE362\"         \"4425\"            \"0\"            \"1\" </p>\n<p>to get the sequence data:</p>\n<blockquote>\n<p>seq&lt;-sapply(mylist$req[1:1],getSequence, as.string = FALSE)<br />\n</p>\n</blockquote>\n<p>to save  data in fasta format:</p>\n<blockquote>\n<p>write.fasta(sequences=seq,names=\"my_sequence\" , file.out = \"myseq.fasta\")</p>\n</blockquote>\n<p>You can get as well  whole chromsome sequences, extract data in  several formats, extract fragments of sequences, translate into protein.</p>\n<p>You may find more  information on  the seqinR page here  http://seqinr.r-forge.r-project.org/ </p>\n<p>I hope this may  help  you</p>\n<p>Simon</p>", "child_count": 0, "closed": false, "tree_id": 81, "revision_count": 1, "parent": 357, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-how-do-i-access-and-query-entire-genome-sequences-with-r", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 171}}, {"pk": 437, "model": "server.post", "fields": {"rght": 15, "author": 170, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 09:53:57", "lft": 10, "post_type": 109787, "score": 7, "title": "A: Drawing chromosome ideogams with data", "unanswered": false, "content": "The quantsmooth Bioconductor package also has chromosome plotting functionality in the prepareGenomeplot(), paintCytobands() functions\n\nSome Examples\n![Digital Karyogram][1]\n\n\n![Copynumber plots][2]\n\n\nEDIT:\nThe code for these plots is quite involved, and depends a lot on the genomic data.\n\nThe supplementary data for Genome Res. 2007 17: 368-376, doi:10.1101/gr.5686107 contains the data and script to produce the figures for the paper, which also contain some of these ideograms\n\nA quick example leads to the following plot\n\n    # prepareGenomePlot example\n    library(quantsmooth)\n    # construct genomic positions\n    CHR<-sample(22,40,replace=TRUE)  # Chromosomes\n    MapInfo<-lengthChromosome(CHR,\"bases\")*runif(length(CHR)) # position on chromosome\n    chrompos<-prepareGenomePlot(data.frame(CHR,MapInfo),paintCytobands = TRUE, organism=\"hsa\")\n    # Chrompos returns a matrix with the positions of the elements on the plot\n    # You can use all kinds of base graphics functions to annotate the chromosomes\n    points(chrompos[,2],chrompos[,1]+0.1,pch=\"x\",col=\"red\")\n    # Show connection between 3rd and 4th element\n    segments(chrompos[3,2],chrompos[3,1],chrompos[4,2],chrompos[4,1],col=\"blue\",lwd=2)\n\n![PrepareGenomePlot Example][3]\n\n\n  [1]: http://imgur.com/8DsW5.png\n  [2]: http://imgur.com/a0AWz.png\n  [3]: http://imgur.com/RscFr.png", "comment_count": 2, "html": "<p>The quantsmooth Bioconductor package also has chromosome plotting functionality in the prepareGenomeplot(), paintCytobands() functions</p>\n<p>Some Examples\n<img alt=\"Digital Karyogram\" src=\"http://imgur.com/8DsW5.png\" /></p>\n<p><img alt=\"Copynumber plots\" src=\"http://imgur.com/a0AWz.png\" /></p>\n<p>EDIT:\nThe code for these plots is quite involved, and depends a lot on the genomic data.</p>\n<p>The supplementary data for Genome Res. 2007 17: 368-376, doi:10.1101/gr.5686107 contains the data and script to produce the figures for the paper, which also contain some of these ideograms</p>\n<p>A quick example leads to the following plot</p>\n<p><div class=\"highlight\"><pre>    <span class=\"c1\"># prepareGenomePlot example</span>\n    library<span class=\"p\">(</span>quantsmooth<span class=\"p\">)</span>\n    <span class=\"c1\"># construct genomic positions</span>\n    CHR<span class=\"o\">&lt;-</span>sample<span class=\"p\">(</span><span class=\"m\">22</span><span class=\"p\">,</span><span class=\"m\">40</span><span class=\"p\">,</span>replace<span class=\"o\">=</span><span class=\"kc\">TRUE</span><span class=\"p\">)</span>  <span class=\"c1\"># Chromosomes</span>\n    MapInfo<span class=\"o\">&lt;-</span>lengthChromosome<span class=\"p\">(</span>CHR<span class=\"p\">,</span><span class=\"s\">&quot;bases&quot;</span><span class=\"p\">)</span><span class=\"o\">*</span>runif<span class=\"p\">(</span>length<span class=\"p\">(</span>CHR<span class=\"p\">))</span> <span class=\"c1\"># position on chromosome</span>\n    chrompos<span class=\"o\">&lt;-</span>prepareGenomePlot<span class=\"p\">(</span>data.frame<span class=\"p\">(</span>CHR<span class=\"p\">,</span>MapInfo<span class=\"p\">),</span>paintCytobands <span class=\"o\">=</span> <span class=\"kc\">TRUE</span><span class=\"p\">,</span> organism<span class=\"o\">=</span><span class=\"s\">&quot;hsa&quot;</span><span class=\"p\">)</span>\n    <span class=\"c1\"># Chrompos returns a matrix with the positions of the elements on the plot</span>\n    <span class=\"c1\"># You can use all kinds of base graphics functions to annotate the chromosomes</span>\n    points<span class=\"p\">(</span>chrompos<span class=\"p\">[,</span><span class=\"m\">2</span><span class=\"p\">],</span>chrompos<span class=\"p\">[,</span><span class=\"m\">1</span><span class=\"p\">]</span><span class=\"o\">+</span><span class=\"m\">0.1</span><span class=\"p\">,</span>pch<span class=\"o\">=</span><span class=\"s\">&quot;x&quot;</span><span class=\"p\">,</span>col<span class=\"o\">=</span><span class=\"s\">&quot;red&quot;</span><span class=\"p\">)</span>\n    <span class=\"c1\"># Show connection between 3rd and 4th element</span>\n    segments<span class=\"p\">(</span>chrompos<span class=\"p\">[</span><span class=\"m\">3</span><span class=\"p\">,</span><span class=\"m\">2</span><span class=\"p\">],</span>chrompos<span class=\"p\">[</span><span class=\"m\">3</span><span class=\"p\">,</span><span class=\"m\">1</span><span class=\"p\">],</span>chrompos<span class=\"p\">[</span><span class=\"m\">4</span><span class=\"p\">,</span><span class=\"m\">2</span><span class=\"p\">],</span>chrompos<span class=\"p\">[</span><span class=\"m\">4</span><span class=\"p\">,</span><span class=\"m\">1</span><span class=\"p\">],</span>col<span class=\"o\">=</span><span class=\"s\">&quot;blue&quot;</span><span class=\"p\">,</span>lwd<span class=\"o\">=</span><span class=\"m\">2</span><span class=\"p\">)</span>\n</pre></div>\n</p>\n<p><img alt=\"PrepareGenomePlot Example\" src=\"http://imgur.com/RscFr.png\" /></p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 3, "parent": 378, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 170}}, {"pk": 438, "model": "server.post", "fields": {"rght": 5, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 11:35:32", "lft": 2, "post_type": 109787, "score": 4, "title": "A: Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "At the risk of sounding slightly daft - no, not that I know of.\n\nI personally get my information about upcoming conferences from the mailing lists I subscribe to where every upcoming barely relevant call for papers is spammed liberally across half a dozen of them at a time, ensuring that there is no way for me to not know about their existence!\n\n[http://www.bioinformatics.org/][1] however do seem to have lots of CfP's on their news front page.\n\n\n  [1]: http://www.bioinformatics.org/", "comment_count": 1, "html": "<p>At the risk of sounding slightly daft - no, not that I know of.</p>\n<p>I personally get my information about upcoming conferences from the mailing lists I subscribe to where every upcoming barely relevant call for papers is spammed liberally across half a dozen of them at a time, ensuring that there is no way for me to not know about their existence!</p>\n<p><a href=\"http://www.bioinformatics.org/\">http://www.bioinformatics.org/</a> however do seem to have lots of CfP's on their news front page.</p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 1, "parent": 435, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 439, "model": "server.post", "fields": {"rght": 11, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 11:45:01", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "There is no centralized place to this end. But, there are a few very important hubs, though. These are very important:\n\n[Genetics Society Meetings][1]\n[ISCB Meetings][2]\n\nIEEE has some interesting meetings too.\n\nTo avoid deadline frustation, I recommend you to follow this societies closely (use their RSS, Twitter or mail lists). Many conferences just spike out suddenly and have very short time windows (at least in South America). And always be prepared. Keep your preprints in good shape. Life will be much easier and a lot more funnier.\n\n\n  [1]: http://www.genetics.org.uk/page/3190/External-meetings.html\n  [2]: http://www.iscb.org/iscb-conferences", "comment_count": 3, "html": "<p>There is no centralized place to this end. But, there are a few very important hubs, though. These are very important:</p>\n<p><a href=\"http://www.genetics.org.uk/page/3190/External-meetings.html\">Genetics Society Meetings</a>\n<a href=\"http://www.iscb.org/iscb-conferences\">ISCB Meetings</a></p>\n<p>IEEE has some interesting meetings too.</p>\n<p>To avoid deadline frustation, I recommend you to follow this societies closely (use their RSS, Twitter or mail lists). Many conferences just spike out suddenly and have very short time windows (at least in South America). And always be prepared. Keep your preprints in good shape. Life will be much easier and a lot more funnier.</p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 1, "parent": 435, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 440, "model": "server.post", "fields": {"rght": 13, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 12:26:41", "lft": 6, "post_type": 109787, "score": 3, "title": "A: How difficult/reliable is it to programmatically (python) look up and download papers?", "unanswered": false, "content": "We have certainly written scripts using Mechanize for this in the past which picked up ~85-90% of articles for which PDFs were available. This trawled around looking for links, forwards etc.. to PDFs.\n\nSo you could go that way, but I wonder if you might want to take a look at Pubget http://pubget.com/. I haven't had a close look, but they have an API that you might be able to use to do the hard work for you. As I say I don't know how good the return rate is with this.", "comment_count": 3, "html": "<p>We have certainly written scripts using Mechanize for this in the past which picked up ~85-90% of articles for which PDFs were available. This trawled around looking for links, forwards etc.. to PDFs.</p>\n<p>So you could go that way, but I wonder if you might want to take a look at Pubget http://pubget.com/. I haven't had a close look, but they have an API that you might be able to use to do the hard work for you. As I say I don't know how good the return rate is with this.</p>", "child_count": 0, "closed": false, "tree_id": 91, "revision_count": 1, "parent": 403, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-difficultreliable-is-it-to-programmatically-python-look-up-and-download-papers", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 441, "model": "server.post", "fields": {"rght": 34, "author": 168, "answer_accepted": true, "tag_string": "hpc r parallel cran", "creation_date": "2010-03-24 12:39:46", "lft": 1, "post_type": 164033, "score": 10, "title": "Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "I have started running R jobs on a high performance compute cluster, but inevitably find that I am just performing array jobs which are ultimately not taking advantage of true parallelism, although they do speed up the experiment.\n\nI would like to start writing some parallel code in R where parallelized functions are available and wondered what people's experiences of this are and what packages you would recommend ?", "comment_count": 1, "html": "<p>I have started running R jobs on a high performance compute cluster, but inevitably find that I am just performing array jobs which are ultimately not taking advantage of true parallelism, although they do speed up the experiment.</p>\n<p>I would like to start writing some parallel code in R where parallelized functions are available and wondered what people's experiences of this are and what packages you would recommend ?</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 2, "parent": null, "views": 1205, "deleted": false, "answer_count": 12, "touch_date": "2011-11-24 14:49:29", "slug": "which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [29, 131, 137, 168], "lastedit_user": 1}}, {"pk": 442, "model": "server.post", "fields": {"rght": 9, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 12:49:25", "lft": 2, "post_type": 109787, "score": 5, "title": "A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "I know of two, but have not used either:\n\n 1. [R/parallel \u2013 speeding up bioinformatics analysis with R][1]\n 2. [The gputools package enables GPU computing in R][2]\n\nSee also [CRAN Task View: High-Performance and Parallel Computing with R][3].\n\n\n  [1]: http://www.biomedcentral.com/1471-2105/9/390\n  [2]: http://bioinformatics.oxfordjournals.org/cgi/content/abstract/26/1/134\n  [3]: http://cran.r-project.org/web/views/HighPerformanceComputing.html", "comment_count": 3, "html": "<p>I know of two, but have not used either:</p>\n<ol>\n<li><a href=\"http://www.biomedcentral.com/1471-2105/9/390\">R/parallel \u2013 speeding up bioinformatics analysis with R</a></li>\n<li><a href=\"http://bioinformatics.oxfordjournals.org/cgi/content/abstract/26/1/134\">The gputools package enables GPU computing in R</a></li>\n</ol>\n<p>See also <a href=\"http://cran.r-project.org/web/views/HighPerformanceComputing.html\">CRAN Task View: High-Performance and Parallel Computing with R</a>.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 1, "parent": 441, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 443, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 13:29:32", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "Maybe this question is best suited for stackoverflow.\nHave a look at [this discussion][1] and follow [this search][2].\n\n\n  [1]: http://stackoverflow.com/questions/1395309/how-to-make-r-use-all-processors\n  [2]: http://stackoverflow.com/search?q=[r]+parallel", "comment_count": 1, "html": "<p>Maybe this question is best suited for stackoverflow.\nHave a look at <a href=\"http://stackoverflow.com/questions/1395309/how-to-make-r-use-all-processors\">this discussion</a> and follow <a href=\"http://stackoverflow.com/search?q=[r]+parallel\">this search</a>.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 1, "parent": 441, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 444, "model": "server.post", "fields": {"rght": 11, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 13:33:26", "lft": 6, "post_type": 109787, "score": 6, "title": "A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "Have you looked at REvolution R?\n\n[http://www.revolution-computing.com/][1]\n\nsudo apt-get install revolution-r \n\nwill get you up and running in Ubuntu in no time.\n\n\"REvolution R runs many computationally-intensive programs faster, especially on multiprocessor systems. REvolution R is built with high-performance compilers and linked with computational libraries that take advantage of multiple processors simultaneously to reduce the time to complete many common mathematical operations. You do not need to modify your code to benefit from these optimizations. \"\n\n\n  [1]: http://www.revolution-computing.com/", "comment_count": 2, "html": "<p>Have you looked at REvolution R?</p>\n<p><a href=\"http://www.revolution-computing.com/\">http://www.revolution-computing.com/</a></p>\n<p>sudo apt-get install revolution-r </p>\n<p>will get you up and running in Ubuntu in no time.</p>\n<p>\"REvolution R runs many computationally-intensive programs faster, especially on multiprocessor systems. REvolution R is built with high-performance compilers and linked with computational libraries that take advantage of multiple processors simultaneously to reduce the time to complete many common mathematical operations. You do not need to modify your code to benefit from these optimizations. \"</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 1, "parent": 441, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 58}}, {"pk": 445, "model": "server.post", "fields": {"rght": 13, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 13:53:06", "lft": 8, "post_type": 109787, "score": 3, "title": "A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "Fundamentally the most important element of parallel computing revolves around requirement of *inter-process communication*. \n\nThere are many problems that require no such communication and thus can be simply be parallelized by splitting the input data into chunks and running multiple instances of the program in question. I don't personally consider this \"parallel\" computing but others call it as such. Many of the solutions you'll find for R are handy convenience functions for starting up R as new processes then collecting the results of their run. \n\nThe *true parallel* computing revolves around the ability to quickly exchange data across different parallel processes. These are necessary when one process needs some results computed in a different process. Most of the time this requires specialized libraries or computing models and is not something that I would recommend one to undertake as a side project. \n\nThere are some libraries written to take advantage of multiple cores. This is called *implicit parallelism*. In this case while the original may be a single threaded program, some internal functions are able to perform over multiple cores. \n\nYour primary course of action is to identify whether the problem that you wish to parallelize can be partitioned just by its input data and/or whether the functionality that you need is available via implicit parallelism. If so you have many straightforward solutions. If not then the solution will be a lot more complicated.\n", "comment_count": 2, "html": "<p>Fundamentally the most important element of parallel computing revolves around requirement of <em>inter-process communication</em>. </p>\n<p>There are many problems that require no such communication and thus can be simply be parallelized by splitting the input data into chunks and running multiple instances of the program in question. I don't personally consider this \"parallel\" computing but others call it as such. Many of the solutions you'll find for R are handy convenience functions for starting up R as new processes then collecting the results of their run. </p>\n<p>The <em>true parallel</em> computing revolves around the ability to quickly exchange data across different parallel processes. These are necessary when one process needs some results computed in a different process. Most of the time this requires specialized libraries or computing models and is not something that I would recommend one to undertake as a side project. </p>\n<p>There are some libraries written to take advantage of multiple cores. This is called <em>implicit parallelism</em>. In this case while the original may be a single threaded program, some internal functions are able to perform over multiple cores. </p>\n<p>Your primary course of action is to identify whether the problem that you wish to parallelize can be partitioned just by its input data and/or whether the functionality that you need is available via implicit parallelism. If so you have many straightforward solutions. If not then the solution will be a lot more complicated.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 1, "parent": 441, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:25", "slug": "a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 446, "model": "server.post", "fields": {"rght": 9, "author": 175, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 14:22:41", "lft": 4, "post_type": 109787, "score": 2, "title": "A: When is the best time to submit sequences to public databases like NCBI?", "unanswered": false, "content": "how about the issue of patenting after submitting the data? will there be any complications since these data are already in public domain", "comment_count": 2, "html": "<p>how about the issue of patenting after submitting the data? will there be any complications since these data are already in public domain</p>", "child_count": 0, "closed": false, "tree_id": 94, "revision_count": 1, "parent": 425, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-when-is-the-best-time-to-submit-sequences-to-public-databases-like-ncbi", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 175}}, {"pk": 447, "model": "server.post", "fields": {"rght": 13, "author": 73, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 14:37:13", "lft": 12, "post_type": 109787, "score": 1, "title": "A: Tools to find gene ontology term enrichment", "unanswered": false, "content": "[GOrilla][1] makes nice pictures.\n\n\n  [1]: http://cbl-gorilla.cs.technion.ac.il/", "comment_count": 0, "html": "<p><a href=\"http://cbl-gorilla.cs.technion.ac.il/\">GOrilla</a> makes nice pictures.</p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 1, "parent": 245, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 73}}, {"pk": 448, "model": "server.post", "fields": {"rght": 11, "author": 176, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 14:44:20", "lft": 10, "post_type": 109787, "score": 3, "title": "A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "If you know a little python or are interested in learning, you can use the mpi4py and rpy packages. The first one provides access to the MPI library for parallel computing very simply and the second allows you to use R from within your python program. With both you can do a lot ...", "comment_count": 0, "html": "<p>If you know a little python or are interested in learning, you can use the mpi4py and rpy packages. The first one provides access to the MPI library for parallel computing very simply and the second allows you to use R from within your python program. With both you can do a lot ...</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 1, "parent": 441, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 176}}, {"pk": 449, "model": "server.post", "fields": {"rght": 15, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 14:51:19", "lft": 14, "post_type": 109787, "score": 1, "title": "A: Tools to find gene ontology term enrichment", "unanswered": false, "content": "Like several of the others I also recommend DAVID to wet lab biologists. It is well maintained, but you should check the version on the particular species annotation(s) they are currently using as it it sometimes not the latest.\n\nThey use a variant of the Fisher exact statistic for their p-value calculations called the EASE score which they wrote up in a paper a few years back http://www.ncbi.nlm.nih.gov/pubmed/14519205 which is more conservative that the standard.", "comment_count": 0, "html": "<p>Like several of the others I also recommend DAVID to wet lab biologists. It is well maintained, but you should check the version on the particular species annotation(s) they are currently using as it it sometimes not the latest.</p>\n<p>They use a variant of the Fisher exact statistic for their p-value calculations called the EASE score which they wrote up in a paper a few years back http://www.ncbi.nlm.nih.gov/pubmed/14519205 which is more conservative that the standard.</p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 1, "parent": 245, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 450, "model": "server.post", "fields": {"rght": 9, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 15:45:11", "lft": 6, "post_type": 109787, "score": 5, "title": "A: Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "Just heard of [ResearchRaven][1] : A Place to Announce Upcoming Meetings and Calls for Papers. \n\n\n  [1]: http://www.researchraven.com/", "comment_count": 1, "html": "<p>Just heard of <a href=\"http://www.researchraven.com/\">ResearchRaven</a> : A Place to Announce Upcoming Meetings and Calls for Papers. </p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 1, "parent": 435, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 451, "model": "server.post", "fields": {"rght": 42, "author": 178, "answer_accepted": false, "tag_string": "college project education", "creation_date": "2010-03-24 16:00:03", "lft": 1, "post_type": 164033, "score": 4, "title": "Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "This is more of a general question as I am new to this site.  I teach at a community college and am trying to determine some projects that 1st year and 2nd year biology students could do.  Ideally, the project would be able to be continuous as 1. the turnover rate for the students would be pretty quick and 2. this couldn't be research done at universities.  \n\nOne thought I had involved the periodical cicadas.  These cicadas have life cycles where they are underground for either 13 or 17 years.  As a result, there are different populations of cicadas that are genetically isolated from each other.  One population will come out in 2011, another one in 2013 etc. etc.  When the populations emerge varies from state to state.  \n\nWould there be any value to sequencing these different populations?  What type of analysis would I do for each one?  There are a lot of details to be figured out and I would have to write a grant to get some equipment. I would also partner with a local university to see if I could use some of their equipment. Before I start trying to figure out the smaller details though, I just wanted some feedback to see if this would be worthwhile and what are some other details I may not have thought of.\n\nThe only other idea I had was sequencing some fungi as this area has not gotten a lot of attention.  Any ideas or comments are welcome.  Thank you!  ", "comment_count": 1, "html": "<p>This is more of a general question as I am new to this site.  I teach at a community college and am trying to determine some projects that 1st year and 2nd year biology students could do.  Ideally, the project would be able to be continuous as 1. the turnover rate for the students would be pretty quick and 2. this couldn't be research done at universities.<br />\n</p>\n<p>One thought I had involved the periodical cicadas.  These cicadas have life cycles where they are underground for either 13 or 17 years.  As a result, there are different populations of cicadas that are genetically isolated from each other.  One population will come out in 2011, another one in 2013 etc. etc.  When the populations emerge varies from state to state.<br />\n</p>\n<p>Would there be any value to sequencing these different populations?  What type of analysis would I do for each one?  There are a lot of details to be figured out and I would have to write a grant to get some equipment. I would also partner with a local university to see if I could use some of their equipment. Before I start trying to figure out the smaller details though, I just wanted some feedback to see if this would be worthwhile and what are some other details I may not have thought of.</p>\n<p>The only other idea I had was sequencing some fungi as this area has not gotten a lot of attention.  Any ideas or comments are welcome.  Thank you!<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 2, "parent": null, "views": 219, "deleted": false, "answer_count": 8, "touch_date": "2011-11-24 14:49:26", "slug": "is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [77, 169, 170], "lastedit_user": 168}}, {"pk": 452, "model": "server.post", "fields": {"rght": 15, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 16:07:09", "lft": 12, "post_type": 109787, "score": 2, "title": "A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "I'm dealing with some of the same problems right now - trying to adapt an R package to multi-core machines. I've had some luck using the [multicore/doMC](http://cran.r-project.org/web/packages/doMC/index.html) and [foreach](http://cran.r-project.org/web/packages/foreach/index.html) packages. They essentially take a for loop and parcel out the iterations to multiple cores. This is essentially splitting the input data, not the more implicit parallelism, but seems to work fairly well. This approach  doesn't solve the problem of splitting jobs among multiple cluster nodes, though.\n\nI also looked at R/parallel, but had major problems getting it to work. Lots of cryptic error messages and failure in simple cases that looked just like the vignettes.  I can't recommend it.", "comment_count": 1, "html": "<p>I'm dealing with some of the same problems right now - trying to adapt an R package to multi-core machines. I've had some luck using the <a href=\"http://cran.r-project.org/web/packages/doMC/index.html\">multicore/doMC</a> and <a href=\"http://cran.r-project.org/web/packages/foreach/index.html\">foreach</a> packages. They essentially take a for loop and parcel out the iterations to multiple cores. This is essentially splitting the input data, not the more implicit parallelism, but seems to work fairly well. This approach  doesn't solve the problem of splitting jobs among multiple cluster nodes, though.</p>\n<p>I also looked at R/parallel, but had major problems getting it to work. Lots of cryptic error messages and failure in simple cases that looked just like the vignettes.  I can't recommend it.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 1, "parent": 441, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 453, "model": "server.post", "fields": {"rght": 17, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 16:28:03", "lft": 2, "post_type": 109787, "score": 1, "title": "A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "You seem to be going at this a bit backwards. The first step in science is to make a hypothesis, then choose the appropriate tools to answer it.  That may include genome sequencing, it may not. It seems like you've got a hammer, and you're looking for a nail.\n\nIf you want to study cicadas, start reading up them. Look at the literature and see what other people are studying and what big unanswered cicada questions remain. If you lack access to subscription journals, try your local library, or other [online resources](http://friendfeed.com/references-wanted).  I suspect some of the questions relate to the different cycle lengths - have there been certain genes implicated? Do we know whether it's governed by differential gene expression, genomic factors, or even epigenomics? Has anyone sequenced them already? I'm sure some population geneticists would be interested in divergence patterns between the groups - might help you understand whether they're still the same species, or whether they're slowly splitting apart from each other because of the time differential in emergence.\n\nThe same applies for fungi. Find out what some of the big unanswered questions are, then try to figure out what approach you might take to answer some of them. Then narrow it down further to manageable size projects that a new biologist could handle.\n", "comment_count": 7, "html": "<p>You seem to be going at this a bit backwards. The first step in science is to make a hypothesis, then choose the appropriate tools to answer it.  That may include genome sequencing, it may not. It seems like you've got a hammer, and you're looking for a nail.</p>\n<p>If you want to study cicadas, start reading up them. Look at the literature and see what other people are studying and what big unanswered cicada questions remain. If you lack access to subscription journals, try your local library, or other <a href=\"http://friendfeed.com/references-wanted\">online resources</a>.  I suspect some of the questions relate to the different cycle lengths - have there been certain genes implicated? Do we know whether it's governed by differential gene expression, genomic factors, or even epigenomics? Has anyone sequenced them already? I'm sure some population geneticists would be interested in divergence patterns between the groups - might help you understand whether they're still the same species, or whether they're slowly splitting apart from each other because of the time differential in emergence.</p>\n<p>The same applies for fungi. Find out what some of the big unanswered questions are, then try to figure out what approach you might take to answer some of them. Then narrow it down further to manageable size projects that a new biologist could handle.</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 1, "parent": 451, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 454, "model": "server.post", "fields": {"rght": 5, "author": 121, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 16:53:56", "lft": 4, "post_type": 109787, "score": 1, "title": "A: How to find all GWAS studies that a given gene has been implicated in?", "unanswered": false, "content": "While I've looked for this sort of information I've never actually found a reasonable database of this sort of information.  OMIM is close to what you're looking for but its data is woefully sparse.  [SNPpedia][1] is a wikipedia-like website trying to annotate the SNPs implicated in diseases but it is also terribly sparse.\n\nGood luck.\n\n\n  [1]: http://www.snpedia.com", "comment_count": 0, "html": "<p>While I've looked for this sort of information I've never actually found a reasonable database of this sort of information.  OMIM is close to what you're looking for but its data is woefully sparse.  <a href=\"http://www.snpedia.com\">SNPpedia</a> is a wikipedia-like website trying to annotate the SNPs implicated in diseases but it is also terribly sparse.</p>\n<p>Good luck.</p>", "child_count": 0, "closed": false, "tree_id": 95, "revision_count": 1, "parent": 427, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-how-to-find-all-gwas-studies-that-a-given-gene-has-been-implicated-in", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 121}}, {"pk": 455, "model": "server.post", "fields": {"rght": 9, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:07:42", "lft": 4, "post_type": 109787, "score": 2, "title": "A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "It is a brainstorming question, so I will just give my 0.02$.\nThere are a number of fairly simple lab techniques producing useful but often not publishable results. \n\nIf you want to stick with Magicicada, quick look in Animal Genome Size Database http://www.genomesize.com/ reveals that there are no entries for Cicadidae.\nSo measuring of DNA content, counting chromosomes will be both new and useful for downstream DNA sequencing projects. \n\n\nYes, having genomic sequences for species with such life-cycles will be great for chronobiology. But it is a bit over the top as a student project. \n\nAt this point [NCBI][1] list just 19 nucleotide sequences for all Magicicada. So yes, you can contribute sequencing almost anything from any of these species, but if this is supposed to be more than an exercise in DNA extraction, subcloning and feeding sequencing machines then you will have to pick something interesting. \n\nLike sequencing as many as possible genes responsible for molecular clock. But then you are again on square one: complicated project requiring substantial funding.    \n  \n\n  [1]: http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=38085", "comment_count": 2, "html": "<p>It is a brainstorming question, so I will just give my 0.02$.\nThere are a number of fairly simple lab techniques producing useful but often not publishable results. </p>\n<p>If you want to stick with Magicicada, quick look in Animal Genome Size Database http://www.genomesize.com/ reveals that there are no entries for Cicadidae.\nSo measuring of DNA content, counting chromosomes will be both new and useful for downstream DNA sequencing projects. </p>\n<p>Yes, having genomic sequences for species with such life-cycles will be great for chronobiology. But it is a bit over the top as a student project. </p>\n<p>At this point <a href=\"http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=38085\">NCBI</a> list just 19 nucleotide sequences for all Magicicada. So yes, you can contribute sequencing almost anything from any of these species, but if this is supposed to be more than an exercise in DNA extraction, subcloning and feeding sequencing machines then you will have to pick something interesting. </p>\n<p>Like sequencing as many as possible genes responsible for molecular clock. But then you are again on square one: complicated project requiring substantial funding.  <br />\n</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 1, "parent": 451, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:25", "slug": "a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 456, "model": "server.post", "fields": {"rght": 32, "author": 72, "answer_accepted": false, "tag_string": "peer articles journals", "creation_date": "2010-03-24 17:25:03", "lft": 1, "post_type": 164033, "score": 6, "title": "Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "I am looking for something like Amazon User Reviews but for journal articles.", "comment_count": 0, "html": "<p>I am looking for something like Amazon User Reviews but for journal articles.</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 1, "parent": null, "views": 511, "deleted": false, "answer_count": 12, "touch_date": "2011-11-24 14:49:28", "slug": "are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [171, 172, 173], "lastedit_user": 72}}, {"pk": 457, "model": "server.post", "fields": {"rght": 7, "author": 178, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:29:36", "lft": 2, "post_type": 109787, "score": -1, "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "I don't know of any, but I am not as well versed in these areas as others here are - sounds like a great idea if there aren't any websites though!", "comment_count": 2, "html": "<p>I don't know of any, but I am not as well versed in these areas as others here are - sounds like a great idea if there aren't any websites though!</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 1, "parent": 456, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:25", "slug": "a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 178}}, {"pk": 458, "model": "server.post", "fields": {"rght": 9, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:38:37", "lft": 4, "post_type": 109787, "score": 8, "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "Well, http://www.connotea.org and http://www.citeulike.org both allow you to add a comment to any article/site .\nI also found http://acawiki.org/Home in my bookmarks: \n> AcaWiki is like a \"Wikipedia for\n> academic research\" designed to\n> increase the impact of scholars,\n> students, and bloggers by enabling\n> them to share summaries and discuss\n> academic papers online\n\nGoogle side wiki ? http://www.google.com/sidewiki/intl/en/index.html\n\nand the ooooooold Annotea http://www.w3.org/2001/Annotea (only works for GET urls...)\n", "comment_count": 2, "html": "<p>Well, http://www.connotea.org and http://www.citeulike.org both allow you to add a comment to any article/site .\nI also found http://acawiki.org/Home in my bookmarks: </p>\n<blockquote>\n<p>AcaWiki is like a \"Wikipedia for\nacademic research\" designed to\nincrease the impact of scholars,\nstudents, and bloggers by enabling\nthem to share summaries and discuss\nacademic papers online</p>\n</blockquote>\n<p>Google side wiki ? http://www.google.com/sidewiki/intl/en/index.html</p>\n<p>and the ooooooold Annotea http://www.w3.org/2001/Annotea (only works for GET urls...)</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 2, "parent": 456, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 459, "model": "server.post", "fields": {"rght": 11, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:40:43", "lft": 6, "post_type": 109787, "score": 5, "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "The [PLoS Journals](http://www.plos.org/) let you comment on the articles directly, which I suppose is like reviewing an amazon product on its page.", "comment_count": 2, "html": "<p>The <a href=\"http://www.plos.org/\">PLoS Journals</a> let you comment on the articles directly, which I suppose is like reviewing an amazon product on its page.</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 2, "parent": 456, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 460, "model": "server.post", "fields": {"rght": 7, "author": 163, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:40:47", "lft": 6, "post_type": 109787, "score": 3, "title": "A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "A good place for information on cicadas is [Chris Simon's web site](http://hydrodictyon.eeb.uconn.edu/projects/cicada/simon_lab/lab_pages/current.php). She maintains [Cicada Central](http://hydrodictyon.eeb.uconn.edu/projects/cicada/cc.php) which has loads of resources. You might also take a look at a recent PLoS ONE paper from her lab [doi:10.1371/journal.pone.0000892](http://dx.doi.org/10.1371/journal.pone.0000892). Chris might have some suggestions on possible projects.", "comment_count": 0, "html": "<p>A good place for information on cicadas is <a href=\"http://hydrodictyon.eeb.uconn.edu/projects/cicada/simon_lab/lab_pages/current.php\">Chris Simon's web site</a>. She maintains <a href=\"http://hydrodictyon.eeb.uconn.edu/projects/cicada/cc.php\">Cicada Central</a> which has loads of resources. You might also take a look at a recent PLoS ONE paper from her lab <a href=\"http://dx.doi.org/10.1371/journal.pone.0000892\">doi:10.1371/journal.pone.0000892</a>. Chris might have some suggestions on possible projects.</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 1, "parent": 451, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:25", "slug": "a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 163}}, {"pk": 461, "model": "server.post", "fields": {"rght": 13, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:40:58", "lft": 8, "post_type": 109787, "score": 3, "title": "A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "This question is somewhat fortuitous. I have a paper on Physica A with a automata model for *Magicicada*. Of course, to build the model we discussed a lot the underlying genetic architecture and possible ecological scenarios. It's a fair complicated problem. Despite plentiful cirscunstancial evidence, there are no sound ones for the underlying genetics. No clue about the biological clock, too. And aging and lifecycle are tipically governed by nontrivial QTL.\n<p>\nNevertheless, would be fantastic if you could track down the evolution of this two populations, phylogenetically speaking. This can be done at protein level and/or DNA level with just gels, PCR and Sanger sequencing. It's low resolution, but works.\n<p> This will be a great opportunity to teach evolutionary theory, ecology and scientific methodology. I can sure help with specific details.", "comment_count": 2, "html": "<p>This question is somewhat fortuitous. I have a paper on Physica A with a automata model for <em>Magicicada</em>. Of course, to build the model we discussed a lot the underlying genetic architecture and possible ecological scenarios. It's a fair complicated problem. Despite plentiful cirscunstancial evidence, there are no sound ones for the underlying genetics. No clue about the biological clock, too. And aging and lifecycle are tipically governed by nontrivial QTL.\n[HTML_REMOVED]\nNevertheless, would be fantastic if you could track down the evolution of this two populations, phylogenetically speaking. This can be done at protein level and/or DNA level with just gels, PCR and Sanger sequencing. It's low resolution, but works.\n[HTML_REMOVED] This will be a great opportunity to teach evolutionary theory, ecology and scientific methodology. I can sure help with specific details.</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 1, "parent": 451, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:25", "slug": "a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 462, "model": "server.post", "fields": {"rght": 17, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 18:18:41", "lft": 16, "post_type": 109787, "score": 2, "title": "A: Tools to find gene ontology term enrichment", "unanswered": false, "content": "I think most of the enrichment analysis tools deals with same class of statistics methods (p-value, FDR, Boneferroni etc). Defining background is a very important in such enrichment methods. To get real meaning of enrichment with respect to your experiments, you should be able to upload the background. For example, if you are looking at a set of a genes from a particular tissue, a background of that tissue give more meaningful results than a background of whole genome.", "comment_count": 0, "html": "<p>I think most of the enrichment analysis tools deals with same class of statistics methods (p-value, FDR, Boneferroni etc). Defining background is a very important in such enrichment methods. To get real meaning of enrichment with respect to your experiments, you should be able to upload the background. For example, if you are looking at a set of a genes from a particular tissue, a background of that tissue give more meaningful results than a background of whole genome.</p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 1, "parent": 245, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 463, "model": "server.post", "fields": {"rght": 17, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 18:48:27", "lft": 14, "post_type": 109787, "score": 7, "title": "A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "I've never found a good bioinformatics book.\n\nAll the books I've glanced  :\n\n  -  were too much theoretical\n  -  were too much trivial\n  -  don't have enough examples (code...)\n  -  only used perl\n  -  ...\n\nat the end, I learned much more at reading the blogs and the IT sites.\n", "comment_count": 1, "html": "<p>I've never found a good bioinformatics book.</p>\n<p>All the books I've glanced  :</p>\n<ul>\n<li>were too much theoretical</li>\n<li>were too much trivial</li>\n<li>don't have enough examples (code...)</li>\n<li>only used perl</li>\n<li>...</li>\n</ul>\n<p>at the end, I learned much more at reading the blogs and the IT sites.</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 1, "parent": 181, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 464, "model": "server.post", "fields": {"rght": 13, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 18:53:23", "lft": 8, "post_type": 109787, "score": 2, "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "[Bosco Ho][1]'s **ANNOTATR** :\n\nhttp://annotatr.appspot.com/\n\n\n  [1]: http://boscoh.com/", "comment_count": 2, "html": "<p><a href=\"http://boscoh.com/\">Bosco Ho</a>'s <strong>ANNOTATR</strong> :</p>\n<p>http://annotatr.appspot.com/</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 1, "parent": 456, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 465, "model": "server.post", "fields": {"rght": 20, "author": 147, "answer_accepted": false, "tag_string": "tips data practical data", "creation_date": "2010-03-24 19:07:25", "lft": 1, "post_type": 164033, "score": 11, "title": "Tips to build a data storage for bioinformatics", "unanswered": false, "content": "Storing large amounts of data will become a problem for the bioinformatics, sooner or later. I've faced this problem recently and a lot of questions that I've never thought before just surfaced. The most obvious are:\nHow to decide the filesystem? How to partition a large (TB range) HD? When is a cheap solution (e. g. a bunch of low-end HDs) inappropriate?\n<p>\nThese are pressing issues here at brazilian medical community. Everyone wants to buy a NGS machine, mass spec or microarray but no one perceives the forthcomming data flood. \n<p>\nIn practical terms, how do you store your data? A good reason for a given decision would be great too.\n\n\nEdit:\n\nI've asked this question not so long ago and thing got HOT here. They just finished to build a whole facility to deal with cancer. A lot of people aquired NGS machines and TB scale seems be a thing of the past. Now we are discussing what to keep and how to manage the process of data triage/filtering. So, I do really need new tips from the community. Is someone facing a similar problem (too many data)?", "comment_count": 0, "html": "<p>Storing large amounts of data will become a problem for the bioinformatics, sooner or later. I've faced this problem recently and a lot of questions that I've never thought before just surfaced. The most obvious are:\nHow to decide the filesystem? How to partition a large (TB range) HD? When is a cheap solution (e. g. a bunch of low-end HDs) inappropriate?\n[HTML_REMOVED]\nThese are pressing issues here at brazilian medical community. Everyone wants to buy a NGS machine, mass spec or microarray but no one perceives the forthcomming data flood. \n[HTML_REMOVED]\nIn practical terms, how do you store your data? A good reason for a given decision would be great too.</p>\n<p>Edit:</p>\n<p>I've asked this question not so long ago and thing got HOT here. They just finished to build a whole facility to deal with cancer. A lot of people aquired NGS machines and TB scale seems be a thing of the past. Now we are discussing what to keep and how to manage the process of data triage/filtering. So, I do really need new tips from the community. Is someone facing a similar problem (too many data)?</p>", "child_count": 0, "closed": false, "tree_id": 101, "revision_count": 2, "parent": null, "views": 915, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:30", "slug": "tips-to-build-a-data-storage-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [48, 174, 175], "lastedit_user": 147}}, {"pk": 466, "model": "server.post", "fields": {"rght": 13, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 19:53:31", "lft": 10, "post_type": 109787, "score": 7, "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "Alternatively, you can blog about the article. Websites like [ResearchBlogging][1], [Chemical blogspace][2] and [NatureBlogs][3], and the PLoS journals will index those blogs and link the comments to the papers. Using userscripts you can have those comments show up on the journal website when you use your [GreaseMonkey][4]-enabled browser (e.g. [Firefox][5] or [Chrome][6]) to look at the article website (see doi:[10.1186/1471-2105-8-487][7]).\n\nAn example screenshot of a journal ToC:\n![alt text][8]\n\n  [1]: http://researchblogging.org/\n  [2]: http://cb.openmolecules.net/papers.php\n  [3]: http://blogs.nature.com/\n  [4]: http://en.wikipedia.org/wiki/Greasemonkey\n  [5]: http://firefox.com\n  [6]: http://www.google.com/chrome\n  [7]: http://www.biomedcentral.com/1471-2105/8/487\n  [8]: http://blueobelisk.sourceforge.net/wiki/images/6/60/CBandPG.png", "comment_count": 1, "html": "<p>Alternatively, you can blog about the article. Websites like <a href=\"http://researchblogging.org/\">ResearchBlogging</a>, <a href=\"http://cb.openmolecules.net/papers.php\">Chemical blogspace</a> and <a href=\"http://blogs.nature.com/\">NatureBlogs</a>, and the PLoS journals will index those blogs and link the comments to the papers. Using userscripts you can have those comments show up on the journal website when you use your <a href=\"http://en.wikipedia.org/wiki/Greasemonkey\">GreaseMonkey</a>-enabled browser (e.g. <a href=\"http://firefox.com\">Firefox</a> or <a href=\"http://www.google.com/chrome\">Chrome</a>) to look at the article website (see doi:<a href=\"http://www.biomedcentral.com/1471-2105/8/487\">10.1186/1471-2105-8-487</a>).</p>\n<p>An example screenshot of a journal ToC:\n<img alt=\"alt text\" src=\"http://blueobelisk.sourceforge.net/wiki/images/6/60/CBandPG.png\" /></p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 1, "parent": 456, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 467, "model": "server.post", "fields": {"rght": 3, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 19:58:24", "lft": 2, "post_type": 109787, "score": 1, "title": "A: Tips to build a data storage for bioinformatics", "unanswered": false, "content": "I'm not an expert sysadmin, but here's something to consider: If you're connecting a file server to a cluster of compute nodes, don't forget to provide scratch space on each compute machine. This will allow users to do I/O intensive operations locally, rather than saturating the network and your disks with requests.", "comment_count": 0, "html": "<p>I'm not an expert sysadmin, but here's something to consider: If you're connecting a file server to a cluster of compute nodes, don't forget to provide scratch space on each compute machine. This will allow users to do I/O intensive operations locally, rather than saturating the network and your disks with requests.</p>", "child_count": 0, "closed": false, "tree_id": 101, "revision_count": 1, "parent": 465, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-tips-to-build-a-data-storage-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 468, "model": "server.post", "fields": {"rght": 9, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 20:04:44", "lft": 8, "post_type": 109787, "score": 2, "title": "A: Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "<p>You can find a listing at http://www.bioinformatics.fr/events.php.</p>\n<p>I try to update it during my spare time.</p>\n<p>There is an associated RSS Feed.</p>\n\n", "comment_count": 0, "html": "<p>[HTML_REMOVED]</p>\n<p>[HTML_REMOVED]</p>\n<p>[HTML_REMOVED]</p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 1, "parent": 435, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 469, "model": "server.post", "fields": {"rght": 8, "author": 91, "answer_accepted": true, "tag_string": "markov sequence protein random generation", "creation_date": "2010-03-24 20:05:25", "lft": 1, "post_type": 164033, "score": 3, "title": "Markov chain for generating random protein sequences", "unanswered": false, "content": "I have 1000+ protein sequences. I want to generate random sequences using a Markov model based on residue transitions found my sequences. I'm told Matlab will make a Markov chain based on multiple sequences, but I would like to use a free alternative to Matlab (python, ruby, R, etc). Can anyone provide me with a library or module?", "comment_count": 0, "html": "<p>I have 1000+ protein sequences. I want to generate random sequences using a Markov model based on residue transitions found my sequences. I'm told Matlab will make a Markov chain based on multiple sequences, but I would like to use a free alternative to Matlab (python, ruby, R, etc). Can anyone provide me with a library or module?</p>", "child_count": 0, "closed": false, "tree_id": 102, "revision_count": 3, "parent": null, "views": 245, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:27", "slug": "markov-chain-for-generating-random-protein-sequences", "lastedit_date": "2011-11-24 14:48:34", "level": 0, "post_accepted": false, "tag_set": [40, 41, 177, 178, 179], "lastedit_user": 58}}, {"pk": 470, "model": "server.post", "fields": {"rght": 5, "author": 85, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 20:25:11", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Tips to build a data storage for bioinformatics", "unanswered": false, "content": "You might check out this blog post about using Amazon Web Services for analysis of NGS data: http://defsci.blogspot.com/2010/01/ruby-aws-easy-map-reduce.html\n\nNot directly about data storage per se, but certainly your NGS analysis strategy affects your data storage needs...", "comment_count": 0, "html": "<p>You might check out this blog post about using Amazon Web Services for analysis of NGS data: http://defsci.blogspot.com/2010/01/ruby-aws-easy-map-reduce.html</p>\n<p>Not directly about data storage per se, but certainly your NGS analysis strategy affects your data storage needs...</p>", "child_count": 0, "closed": false, "tree_id": 101, "revision_count": 1, "parent": 465, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:28", "slug": "a-tips-to-build-a-data-storage-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 85}}, {"pk": 471, "model": "server.post", "fields": {"rght": 13, "author": 179, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 20:46:40", "lft": 12, "post_type": 109787, "score": 4, "title": "A: What phylogeny viewing software do you use?", "unanswered": false, "content": "I really have one main usage for TreeViewX, and that is to quickly visualize a tree from the clipboard when I'm coding. I used TreeView for that previously, but I think I can't run that any more on my new OSX version (10.7 Pussycat or whatever). I vaguely miss the ability to show unrooted trees, which TreeView used to have but the X version doesn't seem to. All in all I find either very handy for this one use case. Other programs (e.g. mesquite) just aren't lightweight and quick enough.", "comment_count": 0, "html": "<p>I really have one main usage for TreeViewX, and that is to quickly visualize a tree from the clipboard when I'm coding. I used TreeView for that previously, but I think I can't run that any more on my new OSX version (10.7 Pussycat or whatever). I vaguely miss the ability to show unrooted trees, which TreeView used to have but the X version doesn't seem to. All in all I find either very handy for this one use case. Other programs (e.g. mesquite) just aren't lightweight and quick enough.</p>", "child_count": 0, "closed": false, "tree_id": 90, "revision_count": 1, "parent": 402, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-phylogeny-viewing-software-do-you-use", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 179}}, {"pk": 472, "model": "server.post", "fields": {"rght": 15, "author": 73, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 20:47:16", "lft": 12, "post_type": 109787, "score": 3, "title": "A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "My person-on-the-street explanation would include where I work, the term Bioinformatics, and something like \"I use computers to analyze biological data so we can better understand how life works\". I tend to emphasize that I like my job, I find it interesting, and that the complexity of life continues to amaze me.\n\nAs I'm explaining, I feel, nervous, proud, and afraid they won't understand. \n\nI am also slightly afraid they might think I am evil and enjoy killing cuddly animals and/or babies.", "comment_count": 1, "html": "<p>My person-on-the-street explanation would include where I work, the term Bioinformatics, and something like \"I use computers to analyze biological data so we can better understand how life works\". I tend to emphasize that I like my job, I find it interesting, and that the complexity of life continues to amaze me.</p>\n<p>As I'm explaining, I feel, nervous, proud, and afraid they won't understand. </p>\n<p>I am also slightly afraid they might think I am evil and enjoy killing cuddly animals and/or babies.</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 1, "parent": 388, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 73}}, {"pk": 473, "model": "server.post", "fields": {"rght": 19, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 21:03:21", "lft": 6, "post_type": 109787, "score": 3, "title": "A: Tips to build a data storage for bioinformatics", "unanswered": false, "content": "You are very much right, and secure and reliable storage *is* already a problem. Im not a sysadmin person but got some insight from my work. Here is a little overview how it might [have looked in 2007 for a medium size setup][1] (this is a bit dated but I am sure it became just much bigger ;) ). \n\nBTW: I don't believe there much difference in requirements between bioinformatics storage and any other large scientific/business data. So, to get recommendations about top brands in storage better ask this on a sys-admin board, I guess there are some. \n\nMaybe most important about storage: \nStorage is nothing without a proper backup solution. And the backup systems are often much more expensive than the disks because you need some overhead for incremental backups. \nAnd that need to be taken care of by some admin.\n\nA tape archive system could also be used to store rarely used data.\n\nIf possible use an extensible solution and at that time that was some hotswappable RAID  (5?? or so) array disks. Why hot-swappable? Because disks fail and then it's nice to be able to replace them. \n\nFor data transfer of terabytes, fast connections are needed and that was fibre-channel. Redundant file servers are also nice to have. As you are working in a hospital, there\nmight be even sensitive person related data, so you might even have to think about cryptographic file systems.\n\nOf course this is sort of a maximum scenario and one can work with less. On my small  linux machines I am using Ext3 fs on some TB without many problems, also UFS worked very robust on FreeBSD and Mac.  \n\nbut as you say, your institute bought a/some highly expensive machines, the follow up costs must be considered. So if there is an application for research grants for a new -omics-machine (can call it ferrari too) then you have to be willing to pay the fuel, sorry the infrastructure and sysadmins.\n\n\n\n\n  [1]: http://www.cebitec.uni-bielefeld.de/brf/infrastructure/infrastructure.html", "comment_count": 6, "html": "<p>You are very much right, and secure and reliable storage <em>is</em> already a problem. Im not a sysadmin person but got some insight from my work. Here is a little overview how it might <a href=\"http://www.cebitec.uni-bielefeld.de/brf/infrastructure/infrastructure.html\">have looked in 2007 for a medium size setup</a> (this is a bit dated but I am sure it became just much bigger ;) ). </p>\n<p>BTW: I don't believe there much difference in requirements between bioinformatics storage and any other large scientific/business data. So, to get recommendations about top brands in storage better ask this on a sys-admin board, I guess there are some. </p>\n<p>Maybe most important about storage: \nStorage is nothing without a proper backup solution. And the backup systems are often much more expensive than the disks because you need some overhead for incremental backups. \nAnd that need to be taken care of by some admin.</p>\n<p>A tape archive system could also be used to store rarely used data.</p>\n<p>If possible use an extensible solution and at that time that was some hotswappable RAID  (5?? or so) array disks. Why hot-swappable? Because disks fail and then it's nice to be able to replace them. </p>\n<p>For data transfer of terabytes, fast connections are needed and that was fibre-channel. Redundant file servers are also nice to have. As you are working in a hospital, there\nmight be even sensitive person related data, so you might even have to think about cryptographic file systems.</p>\n<p>Of course this is sort of a maximum scenario and one can work with less. On my small  linux machines I am using Ext3 fs on some TB without many problems, also UFS worked very robust on FreeBSD and Mac.<br />\n</p>\n<p>but as you say, your institute bought a/some highly expensive machines, the follow up costs must be considered. So if there is an application for research grants for a new -omics-machine (can call it ferrari too) then you have to be willing to pay the fuel, sorry the infrastructure and sysadmins.</p>", "child_count": 0, "closed": false, "tree_id": 101, "revision_count": 1, "parent": 465, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-tips-to-build-a-data-storage-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:34", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 474, "model": "server.post", "fields": {"rght": 8, "author": 29, "answer_accepted": false, "tag_string": "sql bioinformatics server public resources", "creation_date": "2010-03-24 21:19:55", "lft": 1, "post_type": 164033, "score": 8, "title": "What are the public SQL servers for bioinformatics ?", "unanswered": false, "content": "Do you know any **public** scientific SQL server ?\n\nfor example, I would cite:\n\n - UCSC\thttp://genome.ucsc.edu/FAQ/FAQdownloads#download29\n - ENSEMBL\thttp://uswest.ensembl.org/info/data/mysql.html\n - GO\thttp://www.geneontology.org/GO.database.shtml#mirrors\n\n(I'll give a +1 to each correct answer)\n", "comment_count": 0, "html": "<p>Do you know any <strong>public</strong> scientific SQL server ?</p>\n<p>for example, I would cite:</p>\n<ul>\n<li>UCSC http://genome.ucsc.edu/FAQ/FAQdownloads#download29</li>\n<li>ENSEMBL  http://uswest.ensembl.org/info/data/mysql.html</li>\n<li>GO   http://www.geneontology.org/GO.database.shtml#mirrors</li>\n</ul>\n<p>(I'll give a +1 to each correct answer)</p>", "child_count": 0, "closed": false, "tree_id": 103, "revision_count": 1, "parent": null, "views": 807, "deleted": false, "answer_count": 6, "touch_date": "2011-11-24 14:49:29", "slug": "what-are-the-public-sql-servers-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:35", "level": 0, "post_accepted": false, "tag_set": [73, 88, 152, 180, 225], "lastedit_user": 29}}, {"pk": 475, "model": "server.post", "fields": {"rght": 19, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 21:25:18", "lft": 16, "post_type": 109787, "score": 1, "title": "A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "(Sorry, this is not an add, even if it sound like...)\n\nMy favourite bioinformatics book is a biology book [Lewin's Genes X][1]. Of course it's not a bioinformatics book, but is very good for getting a good understanding of the biology. Bio-informatics is an interdisciplinary field and for me, it is the fascination of the related genetics that motivates me to analyse it. I see computer science as a means to better understand genetics. This book can provide the necessary insight into genetics required for good bioinformatics. I cannot read this from cover to cover, it's just too much information, but it provides different levels of detail. Even when reading only the headlines, one could learn something new.\n\nMaybe not so well suited for absolute beginners in genetics, and some biologists say it is superficial sometimes. Might be, but that I cannot judge, I just found the parts I read well understandable. There are of course lots of references (rather many to \"Cell\").\n\n\n  [1]: http://www.jbpub.com/catalog/9780763766320/", "comment_count": 1, "html": "<p>(Sorry, this is not an add, even if it sound like...)</p>\n<p>My favourite bioinformatics book is a biology book <a href=\"http://www.jbpub.com/catalog/9780763766320/\">Lewin's Genes X</a>. Of course it's not a bioinformatics book, but is very good for getting a good understanding of the biology. Bio-informatics is an interdisciplinary field and for me, it is the fascination of the related genetics that motivates me to analyse it. I see computer science as a means to better understand genetics. This book can provide the necessary insight into genetics required for good bioinformatics. I cannot read this from cover to cover, it's just too much information, but it provides different levels of detail. Even when reading only the headlines, one could learn something new.</p>\n<p>Maybe not so well suited for absolute beginners in genetics, and some biologists say it is superficial sometimes. Might be, but that I cannot judge, I just found the parts I read well understandable. There are of course lots of references (rather many to \"Cell\").</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 2, "parent": 181, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 476, "model": "server.post", "fields": {"rght": 3, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 22:18:05", "lft": 2, "post_type": 109787, "score": 2, "title": "A: What are the public SQL servers for bioinformatics ?", "unanswered": false, "content": "Flybase has direct access to its postgres chado database.\n\nhttp://flybase.org/forums/viewtopic.php?f=14&t=114\n \nhostname: flybase.org\nport: 5432\nusername: flybase\npassword: no password\ndatabase name: flybase\n\ne.g.\npsql -h flybase.org -U flybase flybase", "comment_count": 0, "html": "<p>Flybase has direct access to its postgres chado database.</p>\n<p>http://flybase.org/forums/viewtopic.php?f=14&amp;t=114</p>\n<p>hostname: flybase.org\nport: 5432\nusername: flybase\npassword: no password\ndatabase name: flybase</p>\n<p>e.g.\npsql -h flybase.org -U flybase flybase</p>", "child_count": 0, "closed": false, "tree_id": 103, "revision_count": 1, "parent": 474, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-are-the-public-sql-servers-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 477, "model": "server.post", "fields": {"rght": 7, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 23:06:53", "lft": 2, "post_type": 109787, "score": 3, "title": "A: Markov chain for generating random protein sequences", "unanswered": false, "content": "It seems Python programmers like writing Markov generators.  I often see this topic pop up on Python blogs in the context of generating pseudo random text. A quick search shows a few hits:\n\n - [Markov chains][1]\n - [Pseudo random text generator][2]\n - [Markov chains in python][3]\n - [Markov chain algorithm][4]\n\nI guess you would only need to change to tokenizer to split on letters rather than words.\n\n  [1]: http://www.evanfosmark.com/2009/11/python-markov-chains-and-how-to-use-them/\n  [2]: http://uswaretech.com/blog/2009/06/pseudo-random-text-markov-chains-python/\n  [3]: http://justinbozonier.posterous.com/markov-chains-in-python\n  [4]: http://code.activestate.com/recipes/194364-the-markov-chain-algorithm/", "comment_count": 2, "html": "<p>It seems Python programmers like writing Markov generators.  I often see this topic pop up on Python blogs in the context of generating pseudo random text. A quick search shows a few hits:</p>\n<ul>\n<li><a href=\"http://www.evanfosmark.com/2009/11/python-markov-chains-and-how-to-use-them/\">Markov chains</a></li>\n<li><a href=\"http://uswaretech.com/blog/2009/06/pseudo-random-text-markov-chains-python/\">Pseudo random text generator</a></li>\n<li><a href=\"http://justinbozonier.posterous.com/markov-chains-in-python\">Markov chains in python</a></li>\n<li><a href=\"http://code.activestate.com/recipes/194364-the-markov-chain-algorithm/\">Markov chain algorithm</a></li>\n</ul>\n<p>I guess you would only need to change to tokenizer to split on letters rather than words.</p>", "child_count": 0, "closed": false, "tree_id": 102, "revision_count": 1, "parent": 469, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-markov-chain-for-generating-random-protein-sequences", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 1}}, {"pk": 478, "model": "server.post", "fields": {"rght": 5, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 00:44:54", "lft": 4, "post_type": 109787, "score": 2, "title": "A: What are the public SQL servers for bioinformatics ?", "unanswered": false, "content": "[PublicHouse][1] - uses the [BioWarehouse][2] system; requires user registration.\n\n\n  [1]: http://biowarehouse.ai.sri.com/PublicHouseOverview.html\n  [2]: http://biowarehouse.ai.sri.com/index.html", "comment_count": 0, "html": "<p><a href=\"http://biowarehouse.ai.sri.com/PublicHouseOverview.html\">PublicHouse</a> - uses the <a href=\"http://biowarehouse.ai.sri.com/index.html\">BioWarehouse</a> system; requires user registration.</p>", "child_count": 0, "closed": false, "tree_id": 103, "revision_count": 1, "parent": 474, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-are-the-public-sql-servers-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 479, "model": "server.post", "fields": {"rght": 6, "author": 184, "answer_accepted": false, "tag_string": "statistics sequence", "creation_date": "2010-03-25 07:34:14", "lft": 1, "post_type": 164033, "score": 6, "title": "amino acid content statistical test", "unanswered": false, "content": "I would like to compare the amino acid and the codon usage content between two organisms.\nWhat statistical test would be appropriate for this purpose? And what are the inputs needed?", "comment_count": 1, "html": "<p>I would like to compare the amino acid and the codon usage content between two organisms.\nWhat statistical test would be appropriate for this purpose? And what are the inputs needed?</p>", "child_count": 0, "closed": false, "tree_id": 104, "revision_count": 2, "parent": null, "views": 193, "deleted": false, "answer_count": 2, "touch_date": "2011-11-24 14:49:30", "slug": "amino-acid-content-statistical-test", "lastedit_date": "2011-11-24 14:48:35", "level": 0, "post_accepted": false, "tag_set": [40, 181], "lastedit_user": 65}}, {"pk": 480, "model": "server.post", "fields": {"rght": 3, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 07:57:13", "lft": 2, "post_type": 109787, "score": 5, "title": "A: amino acid content statistical test", "unanswered": false, "content": "I recommend that you study the work of Jean Lobry, who has done a lot of work in this area.\n\nSearch PubMed for \"Lobry JR[AU]\" or see his [partial list of publications][1].\n\nHe has also written an R package called [seqinR][2] which contains many methods for statistical analysis of sequences, including composition. Read the documentation, in particular chapter 9 on multivariate analysis.\n\n\n  [1]: http://pbil.univ-lyon1.fr/members/lobry/\n  [2]: http://seqinr.r-forge.r-project.org/", "comment_count": 0, "html": "<p>I recommend that you study the work of Jean Lobry, who has done a lot of work in this area.</p>\n<p>Search PubMed for \"Lobry JR[AU]\" or see his <a href=\"http://pbil.univ-lyon1.fr/members/lobry/\">partial list of publications</a>.</p>\n<p>He has also written an R package called <a href=\"http://seqinr.r-forge.r-project.org/\">seqinR</a> which contains many methods for statistical analysis of sequences, including composition. Read the documentation, in particular chapter 9 on multivariate analysis.</p>", "child_count": 0, "closed": false, "tree_id": 104, "revision_count": 1, "parent": 479, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-amino-acid-content-statistical-test", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 481, "model": "server.post", "fields": {"rght": 7, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 09:37:15", "lft": 6, "post_type": 109787, "score": 2, "title": "A: What are the public SQL servers for bioinformatics ?", "unanswered": false, "content": "This is quite an important one for people doing mouse work, though it is important to note that JAX offer Mart and Batch-Query functionality through the web site as well which may well suit many peoples needs.\n\n - Direct SQL Access to MGI\n - http://www.informatics.jax.org/software.shtml#sql\n\nNote that this is a public 'free' service, but that you do need to contact user support to get your login and password. They are also happy to provide some custom SQL scripts to get you started.", "comment_count": 0, "html": "<p>This is quite an important one for people doing mouse work, though it is important to note that JAX offer Mart and Batch-Query functionality through the web site as well which may well suit many peoples needs.</p>\n<ul>\n<li>Direct SQL Access to MGI</li>\n<li>http://www.informatics.jax.org/software.shtml#sql</li>\n</ul>\n<p>Note that this is a public 'free' service, but that you do need to contact user support to get your login and password. They are also happy to provide some custom SQL scripts to get you started.</p>", "child_count": 0, "closed": false, "tree_id": 103, "revision_count": 2, "parent": 474, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-are-the-public-sql-servers-for-bioinformatics", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 482, "model": "server.post", "fields": {"rght": 13, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 09:41:26", "lft": 12, "post_type": 109787, "score": 4, "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "All of the BioMed Central journals accept comments on journal articles, so that is currently 207 journals.\n\nThey have a policy on comments which you can access here :-\n\nhttp://www.biomedcentral.com/info/about/commentpolicy", "comment_count": 0, "html": "<p>All of the BioMed Central journals accept comments on journal articles, so that is currently 207 journals.</p>\n<p>They have a policy on comments which you can access here :-</p>\n<p>http://www.biomedcentral.com/info/about/commentpolicy</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 1, "parent": 456, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 483, "model": "server.post", "fields": {"rght": 12, "author": 22, "answer_accepted": false, "tag_string": "statistics testing r standard", "creation_date": "2010-03-25 11:31:01", "lft": 1, "post_type": 164033, "score": 3, "title": "test whether the variance in a group is lower than in another", "unanswered": false, "content": "I have two groups of data (not distributed under a normal distribution): I would like to test the hypothesis that the first group has a lower (or narrower) standard deviation than the other.\n\nAn alternative explanation to this is that I would like to tell whether the first group is less 'variable', 'heterogeneous', than the first. \n\nA [kruskal-wallis][1] won't do it because it compares the medians of two or more groups, and I am not interested in that.\n\nA [Levene][2] or a [Brown-Forsynth][3] test compare the variance between the two groups and tell whether they have the same variance. This is better, but I would also like to tell if the variance in the first group is lower than in the other(s) group(s).\n\nA simple [Chi-Square][4] test would tell me whether the standard deviation of a group is equal to a certain value, and the one-tailed version can tell me whether it is higher/lower.\n\nAn additional difficulty is that I would have to do this test as a two-way, because I have two grouping variables, but I would like to ask you if you can point me to any direction or give me some hint, I have not many ideas on where to search :-)\n\n\n  [1]: http://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_test\n  [2]: http://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm\n  [3]: http://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test\n  [4]: http://www.itl.nist.gov/div898/handbook/eda/section3/eda358.htm", "comment_count": 1, "html": "<p>I have two groups of data (not distributed under a normal distribution): I would like to test the hypothesis that the first group has a lower (or narrower) standard deviation than the other.</p>\n<p>An alternative explanation to this is that I would like to tell whether the first group is less 'variable', 'heterogeneous', than the first. </p>\n<p>A <a href=\"http://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_test\">kruskal-wallis</a> won't do it because it compares the medians of two or more groups, and I am not interested in that.</p>\n<p>A <a href=\"http://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm\">Levene</a> or a <a href=\"http://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test\">Brown-Forsynth</a> test compare the variance between the two groups and tell whether they have the same variance. This is better, but I would also like to tell if the variance in the first group is lower than in the other(s) group(s).</p>\n<p>A simple <a href=\"http://www.itl.nist.gov/div898/handbook/eda/section3/eda358.htm\">Chi-Square</a> test would tell me whether the standard deviation of a group is equal to a certain value, and the one-tailed version can tell me whether it is higher/lower.</p>\n<p>An additional difficulty is that I would have to do this test as a two-way, because I have two grouping variables, but I would like to ask you if you can point me to any direction or give me some hint, I have not many ideas on where to search :-)</p>", "child_count": 0, "closed": false, "tree_id": 105, "revision_count": 2, "parent": null, "views": 357, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:29", "slug": "test-whether-the-variance-in-a-group-is-lower-than-in-another", "lastedit_date": "2011-11-24 14:48:35", "level": 0, "post_accepted": false, "tag_set": [137, 181, 184, 185], "lastedit_user": 65}}, {"pk": 484, "model": "server.post", "fields": {"rght": 19, "author": 119, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 11:50:50", "lft": 18, "post_type": 109787, "score": 7, "title": "A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "I really like [Biological Sequence Analysis, Durbin et al.][1] and, although not really bioinformatics-specific, I found [Perl Medic, Peter J. Scott][2] made a big difference to my newbie Perl code. For biology text books, I mainly relied on [Lewin][3] and [Alberts][4] for background during my undergrad.\n\n\n  [1]: http://www.amazon.co.uk/Biological-Sequence-Analysis-Probabilistic-Proteins/dp/0521629713\n  [2]: http://www.amazon.co.uk/Perl-Medic-Maintaining-Inherited-Code/dp/0201795264\n  [3]: http://www.amazon.co.uk/Genes-IX-Benjamin-Lewin/dp/0763752223\n  [4]: http://www.amazon.co.uk/Molecular-Biology-Cell-Bruce-Alberts/dp/0815341067/ref=sr_1_1?ie=UTF8&s=books&qid=1269517727&sr=1-1", "comment_count": 0, "html": "<p>I really like <a href=\"http://www.amazon.co.uk/Biological-Sequence-Analysis-Probabilistic-Proteins/dp/0521629713\">Biological Sequence Analysis, Durbin et al.</a> and, although not really bioinformatics-specific, I found <a href=\"http://www.amazon.co.uk/Perl-Medic-Maintaining-Inherited-Code/dp/0201795264\">Perl Medic, Peter J. Scott</a> made a big difference to my newbie Perl code. For biology text books, I mainly relied on <a href=\"http://www.amazon.co.uk/Genes-IX-Benjamin-Lewin/dp/0763752223\">Lewin</a> and <a href=\"http://www.amazon.co.uk/Molecular-Biology-Cell-Bruce-Alberts/dp/0815341067/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1269517727&amp;sr=1-1\">Alberts</a> for background during my undergrad.</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 1, "parent": 181, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 119}}, {"pk": 485, "model": "server.post", "fields": {"rght": 7, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 11:54:05", "lft": 2, "post_type": 109787, "score": 2, "title": "A: test whether the variance in a group is lower than in another", "unanswered": false, "content": "Look for the F-test or [Bartlett's test][1]. As your data is non-normal you need something more robust against deviation from normality. [Leven's test is for example mentioned as an alternative][2]\n\n\n  [1]: http://en.wikipedia.org/wiki/Bartlett%27s_test\n  [2]: http://en.wikipedia.org/wiki/Levene_test", "comment_count": 2, "html": "<p>Look for the F-test or <a href=\"http://en.wikipedia.org/wiki/Bartlett%27s_test\">Bartlett's test</a>. As your data is non-normal you need something more robust against deviation from normality. <a href=\"http://en.wikipedia.org/wiki/Levene_test\">Leven's test is for example mentioned as an alternative</a></p>", "child_count": 0, "closed": false, "tree_id": 105, "revision_count": 1, "parent": 483, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-test-whether-the-variance-in-a-group-is-lower-than-in-another", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 486, "model": "server.post", "fields": {"rght": 14, "author": 72, "answer_accepted": false, "tag_string": "c fastq ngs", "creation_date": "2010-03-25 13:51:09", "lft": 1, "post_type": 164033, "score": 4, "title": "Which C++ libraries are best for dealing with fastq files?", "unanswered": false, "content": "I would like to rewrite some perl scripts into something faster. I haven't written C++ since the Clinton administration. Granted I am not married to C++ per se but I would need something that benchmarks well.\n\nWhich C++ libraries are people using to deal with NGS data?\n\n", "comment_count": 0, "html": "<p>I would like to rewrite some perl scripts into something faster. I haven't written C++ since the Clinton administration. Granted I am not married to C++ per se but I would need something that benchmarks well.</p>\n<p>Which C++ libraries are people using to deal with NGS data?</p>", "child_count": 0, "closed": false, "tree_id": 106, "revision_count": 4, "parent": null, "views": 518, "deleted": false, "answer_count": 4, "touch_date": "2011-11-24 14:49:28", "slug": "which-c-libraries-are-best-for-dealing-with-fastq-files", "lastedit_date": "2011-11-24 14:48:35", "level": 0, "post_accepted": false, "tag_set": [103, 124, 215], "lastedit_user": 58}}, {"pk": 487, "model": "server.post", "fields": {"rght": 5, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 13:59:26", "lft": 4, "post_type": 109787, "score": 1, "title": "A: test whether the variance in a group is lower than in another", "unanswered": false, "content": "You can try a Friedman test at first for each factor (assuming they're independent) and, given that really there is some difference, proceed an adequate multiple hypothesis testing using Bonferroni method, for example. Not a sequential hypothesis testing like we usually do with microarray data. You'll need to specifiy all concurrent hypothesis (variance =, <, >) and significance/power levels.\n\nI don't know much about your experimental/test design. You could furnish additional detais.", "comment_count": 0, "html": "<p>You can try a Friedman test at first for each factor (assuming they're independent) and, given that really there is some difference, proceed an adequate multiple hypothesis testing using Bonferroni method, for example. Not a sequential hypothesis testing like we usually do with microarray data. You'll need to specifiy all concurrent hypothesis (variance =, &lt;, &gt;) and significance/power levels.</p>\n<p>I don't know much about your experimental/test design. You could furnish additional detais.</p>", "child_count": 0, "closed": false, "tree_id": 105, "revision_count": 2, "parent": 483, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-test-whether-the-variance-in-a-group-is-lower-than-in-another", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 488, "model": "server.post", "fields": {"rght": 7, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 14:10:58", "lft": 2, "post_type": 109787, "score": 6, "title": "A: Which C++ libraries are best for dealing with fastq files?", "unanswered": false, "content": "I wouldn't dream of doing this I admit, I tend to handle fastq files with applications other people develop.\n\nHowever there is a FASTA/FASTQ c++ parser here:\n\n[http://lh3lh3.users.sourceforge.net/parsefastq.shtml][1] which might serve as a base for what you want to do.\n\nIt's from Heng Li who also works on SAMtools, BWA and MAQ\n\n\n  [1]: http://lh3lh3.users.sourceforge.net/parsefastq.shtml", "comment_count": 2, "html": "<p>I wouldn't dream of doing this I admit, I tend to handle fastq files with applications other people develop.</p>\n<p>However there is a FASTA/FASTQ c++ parser here:</p>\n<p><a href=\"http://lh3lh3.users.sourceforge.net/parsefastq.shtml\">http://lh3lh3.users.sourceforge.net/parsefastq.shtml</a> which might serve as a base for what you want to do.</p>\n<p>It's from Heng Li who also works on SAMtools, BWA and MAQ</p>", "child_count": 0, "closed": false, "tree_id": 106, "revision_count": 1, "parent": 486, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-which-c-libraries-are-best-for-dealing-with-fastq-files", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 489, "model": "server.post", "fields": {"rght": 5, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 14:44:17", "lft": 4, "post_type": 109787, "score": 4, "title": "A: Which C++ libraries are best for dealing with fastq files?", "unanswered": false, "content": "I saw a SeqAn poster at ISMB last year. No experience with the library (nor C++) myself but they support the fastq format and they made the impression that they are quite competent.\n\n[SeqAn file formats][1]\n\n\n  [1]: http://www.seqan.de/dddoc/html/TAG_File+_Format.html", "comment_count": 0, "html": "<p>I saw a SeqAn poster at ISMB last year. No experience with the library (nor C++) myself but they support the fastq format and they made the impression that they are quite competent.</p>\n<p><a href=\"http://www.seqan.de/dddoc/html/TAG_File+_Format.html\">SeqAn file formats</a></p>", "child_count": 0, "closed": false, "tree_id": 106, "revision_count": 1, "parent": 486, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-which-c-libraries-are-best-for-dealing-with-fastq-files", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 490, "model": "server.post", "fields": {"rght": 17, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 15:20:23", "lft": 10, "post_type": 109787, "score": 2, "title": "A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "We're currently gearing up to implement some of our fragmented analyses into Taverna workflows. The motivation for us is to provide web applications for both ourselves and other community members (for both dry and wet lab people) to get the most out of our high throughput data sources. There is no denying that part of this motivation is not purely philanthropic, but also to raise the impact of our work which makes our funders happy.\n\nFrom a technical point of view we are having to implement our own web services from quite a wide range of sources; mainly Perl, C, C++ and R. Some of these are quite easy to do fairly directly with SOAP/WDSL (especially for Perl). Others like R can take advantage of some recent tools such as RShell http://www.ncbi.nlm.nih.gov/pubmed/19607662. The hardest is implementing new algorithms in C or C++ into usable web services, which we really are feeling our way around at the moment.", "comment_count": 3, "html": "<p>We're currently gearing up to implement some of our fragmented analyses into Taverna workflows. The motivation for us is to provide web applications for both ourselves and other community members (for both dry and wet lab people) to get the most out of our high throughput data sources. There is no denying that part of this motivation is not purely philanthropic, but also to raise the impact of our work which makes our funders happy.</p>\n<p>From a technical point of view we are having to implement our own web services from quite a wide range of sources; mainly Perl, C, C++ and R. Some of these are quite easy to do fairly directly with SOAP/WDSL (especially for Perl). Others like R can take advantage of some recent tools such as RShell http://www.ncbi.nlm.nih.gov/pubmed/19607662. The hardest is implementing new algorithms in C or C++ into usable web services, which we really are feeling our way around at the moment.</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 1, "parent": 420, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 491, "model": "server.post", "fields": {"rght": 17, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 15:42:08", "lft": 16, "post_type": 109787, "score": 1, "title": "A: Which software development technique is used in your lab? ", "unanswered": false, "content": "We use an agile technique with SVN using the Eclipse development suite http://www.eclipse.org/, the SVN-Team plugin http://www.eclipse.org/subversive/ and either sourceforge or an internal SVN service.\n\nOur team work tends to be done face to face, though we do have a personal wiki and use google apps as well.", "comment_count": 0, "html": "<p>We use an agile technique with SVN using the Eclipse development suite http://www.eclipse.org/, the SVN-Team plugin http://www.eclipse.org/subversive/ and either sourceforge or an internal SVN service.</p>\n<p>Our team work tends to be done face to face, though we do have a personal wiki and use google apps as well.</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 1, "parent": 310, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:26", "slug": "a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 492, "model": "server.post", "fields": {"rght": 11, "author": 185, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 16:29:02", "lft": 10, "post_type": 109787, "score": 7, "title": "A: Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "I found this one few days ago : http://www.wikicfp.com/\nI found it ok, also you have to check 2 categories : bioinformatics and computational biology", "comment_count": 0, "html": "<p>I found this one few days ago : http://www.wikicfp.com/\nI found it ok, also you have to check 2 categories : bioinformatics and computational biology</p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 1, "parent": 435, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:27", "slug": "a-is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": true, "tag_set": [], "lastedit_user": 185}}, {"pk": 493, "model": "server.post", "fields": {"rght": 21, "author": 163, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 18:31:18", "lft": 20, "post_type": 109787, "score": 2, "title": "A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "I've learnt pretty much everything from doing, i.e. programming, and rely heavily on online resources. There have been occasional programming books that I've used to bootstrap learning about a language (especially if it was a major leap, say from procedural to object-oriented languages, or from standalone application programming to web scripting). Of the bioinformatics books mentioned so far, [Durbin et al., Biological Sequence Analysis](http://rads.stackoverflow.com/amzn/click/0521629713) was the book I got the most out of, especially the section on RNA secondary structure, which I was obsessed with for a time. Good description of the problem, algorithms clearly explained, and pseudocode. Great stuff.\n\nPerhaps off topic, but the books I find most fun and inspiring to read have been more general web-oriented books such as  [Ambient Findability: What We Find Changes Who We Become ](http://rads.stackoverflow.com/amzn/click/0596007655).", "comment_count": 0, "html": "<p>I've learnt pretty much everything from doing, i.e. programming, and rely heavily on online resources. There have been occasional programming books that I've used to bootstrap learning about a language (especially if it was a major leap, say from procedural to object-oriented languages, or from standalone application programming to web scripting). Of the bioinformatics books mentioned so far, <a href=\"http://rads.stackoverflow.com/amzn/click/0521629713\">Durbin et al., Biological Sequence Analysis</a> was the book I got the most out of, especially the section on RNA secondary structure, which I was obsessed with for a time. Good description of the problem, algorithms clearly explained, and pseudocode. Great stuff.</p>\n<p>Perhaps off topic, but the books I find most fun and inspiring to read have been more general web-oriented books such as  <a href=\"http://rads.stackoverflow.com/amzn/click/0596007655\">Ambient Findability: What We Find Changes Who We Become </a>.</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 1, "parent": 181, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 163}}, {"pk": 494, "model": "server.post", "fields": {"rght": 20, "author": 147, "answer_accepted": false, "tag_string": "subjective relief fun", "creation_date": "2010-03-25 19:42:11", "lft": 1, "post_type": 164033, "score": 4, "title": "Which application is truly missing in bioinformatics?", "unanswered": false, "content": "It's a simple & straight questions. Just think about an app that when you found it, you first thought would be - \"OMG!!! That's it\" - or smth like - \"I wish I could have found/written/idealized it before\". Don't need to be a bioinformatical swiss knife or a McGuyver paper clip. Just smth that would make your life much happier/easier.\n\nMy example is quite simple. I really wish that some sort of Monte Carlo Simulator of Generic Urn Models (population genetics rlz!) just appear in the net, with a nice, clean and well documented API (written in C) and bindings for my favorite scripting languages. That's what I really miss, right now. What's your story?\n\n-- Edit --\n\nI'm considering to start a bounty for this question. Maybe the first answer to get 10 up votes. Where are people's whishes? Don't be afraid, bionformaticians like me are lousy critics.", "comment_count": 1, "html": "<p>It's a simple &amp; straight questions. Just think about an app that when you found it, you first thought would be - \"OMG!!! That's it\" - or smth like - \"I wish I could have found/written/idealized it before\". Don't need to be a bioinformatical swiss knife or a McGuyver paper clip. Just smth that would make your life much happier/easier.</p>\n<p>My example is quite simple. I really wish that some sort of Monte Carlo Simulator of Generic Urn Models (population genetics rlz!) just appear in the net, with a nice, clean and well documented API (written in C) and bindings for my favorite scripting languages. That's what I really miss, right now. What's your story?</p>\n<p>-- Edit --</p>\n<p>I'm considering to start a bounty for this question. Maybe the first answer to get 10 up votes. Where are people's whishes? Don't be afraid, bionformaticians like me are lousy critics.</p>", "child_count": 0, "closed": false, "tree_id": 107, "revision_count": 3, "parent": null, "views": 953, "deleted": false, "answer_count": 10, "touch_date": "2011-11-24 14:49:30", "slug": "which-application-is-truly-missing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:35", "level": 0, "post_accepted": false, "tag_set": [32, 231, 232], "lastedit_user": 147}}, {"pk": 495, "model": "server.post", "fields": {"rght": 5, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 19:55:48", "lft": 2, "post_type": 109787, "score": 4, "title": "A: Which application is truly missing in bioinformatics?", "unanswered": false, "content": "    /irony on\nSomething like the following is missing for bioinformatics:\nhttp://pdos.csail.mit.edu/scigen/\n\n    /irony off\n\nSeriously, I think whatever it is, a *clean and well documented API* - as you say - is something it should provide.", "comment_count": 1, "html": "<p><div class=\"highlight\"><pre>    <span class=\"o\">/</span><span class=\"n\">irony</span> <span class=\"n\">on</span>\n</pre></div>\n\nSomething like the following is missing for bioinformatics:\nhttp://pdos.csail.mit.edu/scigen/</p>\n<p><div class=\"highlight\"><pre>    <span class=\"o\">/</span><span class=\"n\">irony</span> <span class=\"n\">off</span>\n</pre></div>\n</p>\n<p>Seriously, I think whatever it is, a <em>clean and well documented API</em> - as you say - is something it should provide.</p>", "child_count": 0, "closed": false, "tree_id": 107, "revision_count": 1, "parent": 494, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:31", "slug": "a-which-application-is-truly-missing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 118}}, {"pk": 496, "model": "server.post", "fields": {"rght": 5, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 20:03:16", "lft": 4, "post_type": 109787, "score": 3, "title": "A: Which application is truly missing in bioinformatics?", "unanswered": false, "content": "I wish R had an entire web application framework like Rails and that there was an easier way to go between genome browsers and analysis and back.\n\nThere are also not enough tools to properly organize individual genetic variation in humans much less poorly characterized species. I guess we'll have to see what 1000 genomes comes up with.\n\nI would also like a proper \"finishing tool\" to visualize and reconcile Velvet assemblies.", "comment_count": 0, "html": "<p>I wish R had an entire web application framework like Rails and that there was an easier way to go between genome browsers and analysis and back.</p>\n<p>There are also not enough tools to properly organize individual genetic variation in humans much less poorly characterized species. I guess we'll have to see what 1000 genomes comes up with.</p>\n<p>I would also like a proper \"finishing tool\" to visualize and reconcile Velvet assemblies.</p>", "child_count": 0, "closed": false, "tree_id": 107, "revision_count": 2, "parent": 494, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-which-application-is-truly-missing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 497, "model": "server.post", "fields": {"rght": 17, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 20:27:23", "lft": 16, "post_type": 109787, "score": 2, "title": "A: What license do you use when you release code and data?", "unanswered": false, "content": "I whole-heartedly agree with Pierre's answer w.r.t. what I'd like a licence to say. Be that as it may, I have sometimes used the [Artistic License 2.0][1].\n\n\n  [1]: http://www.opensource.org/licenses/artistic-license-2.0.php", "comment_count": 0, "html": "<p>I whole-heartedly agree with Pierre's answer w.r.t. what I'd like a licence to say. Be that as it may, I have sometimes used the <a href=\"http://www.opensource.org/licenses/artistic-license-2.0.php\">Artistic License 2.0</a>.</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 1, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:29", "slug": "a-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 118}}, {"pk": 498, "model": "server.post", "fields": {"rght": 9, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 20:39:53", "lft": 6, "post_type": 109787, "score": 4, "title": "A: Which application is truly missing in bioinformatics?", "unanswered": false, "content": "I want a [bio2rdf][1] for the whole scientific *corpus*.\n\n\n  [1]: http://bio2rdf.org/", "comment_count": 1, "html": "<p>I want a <a href=\"http://bio2rdf.org/\">bio2rdf</a> for the whole scientific <em>corpus</em>.</p>", "child_count": 0, "closed": false, "tree_id": 107, "revision_count": 1, "parent": 494, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-which-application-is-truly-missing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 499, "model": "server.post", "fields": {"rght": 11, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-26 00:25:36", "lft": 8, "post_type": 109787, "score": 9, "title": "A: Which application is truly missing in bioinformatics?", "unanswered": false, "content": "I think it would be incorrect to imagine that there is a single, \"killer app\" for bioinformatics.  I don't see bioinformatics as a field, discipline or topic.  For me it is about:  (1) inputs - many, diverse types of biological data, (2) processes - the code that we write to handle the data and (3) outputs - what the code produces and the subsequent biological interpretation.\n\nThat said, I'm sure there are tools we would all like to see when we handle whatever data type comes our way.  I'd like to see:\n\n 1. A RESTful API for every public, online database\n 2. Better web applications for data integration - so that when I search for, e.g. a gene, everything that's known about that gene and its products is presented to me in a way that enables effective data exploration\n\nThere are those who say that the \"linked data web\" is the answer to (2), which remains to be seen...", "comment_count": 1, "html": "<p>I think it would be incorrect to imagine that there is a single, \"killer app\" for bioinformatics.  I don't see bioinformatics as a field, discipline or topic.  For me it is about:  (1) inputs - many, diverse types of biological data, (2) processes - the code that we write to handle the data and (3) outputs - what the code produces and the subsequent biological interpretation.</p>\n<p>That said, I'm sure there are tools we would all like to see when we handle whatever data type comes our way.  I'd like to see:</p>\n<ol>\n<li>A RESTful API for every public, online database</li>\n<li>Better web applications for data integration - so that when I search for, e.g. a gene, everything that's known about that gene and its products is presented to me in a way that enables effective data exploration</li>\n</ol>\n<p>There are those who say that the \"linked data web\" is the answer to (2), which remains to be seen...</p>", "child_count": 0, "closed": false, "tree_id": 107, "revision_count": 1, "parent": 494, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:30", "slug": "a-which-application-is-truly-missing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 500, "model": "server.post", "fields": {"rght": 17, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-26 00:45:47", "lft": 16, "post_type": 109787, "score": 0, "title": "A: Which application is truly missing in bioinformatics?", "unanswered": false, "content": "I'd like Bioconductor-like repository would exist for MATLAB. Probably not gonna happen. :(", "comment_count": 0, "html": "<p>I'd like Bioconductor-like repository would exist for MATLAB. Probably not gonna happen. :(</p>", "child_count": 0, "closed": false, "tree_id": 107, "revision_count": 1, "parent": 494, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:55", "slug": "a-which-application-is-truly-missing-in-bioinformatics", "lastedit_date": "2011-11-24 14:48:35", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 501, "model": "server.post", "fields": {"rght": 9, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2009-09-30 14:56:48", "lft": 4, "post_type": 206247, "score": 0, "title": "C: How do I convert from BED format to GFF format?", "unanswered": false, "content": "I'll answer my own question here as it is a demo for now", "comment_count": 0, "html": "<p>I'll answer my own question here as it is a demo for now</p>", "child_count": 0, "closed": false, "tree_id": 2, "revision_count": 0, "parent": 2, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:59", "slug": "c-how-do-i-convert-from-bed-format-to-gff-format", "lastedit_date": "2011-11-24 14:48:59", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 502, "model": "server.post", "fields": {"rght": 8, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2009-09-30 19:43:58", "lft": 7, "post_type": 206247, "score": 1, "title": "C: A: Finding common motifs in sequences", "unanswered": false, "content": "post the python code as well (put it into pre tags then it will be shown nicely formatted, see help on the right)", "comment_count": 0, "html": "<p>post the python code as well (put it into pre tags then it will be shown nicely formatted, see help on the right)</p>", "child_count": 0, "closed": false, "tree_id": 3, "revision_count": 0, "parent": 9, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-finding-common-motifs-in-sequences", "lastedit_date": "2011-11-24 14:48:59", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 503, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-09 16:57:23", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Site use guidelines", "unanswered": false, "content": "I see, then I guess they will need to contribute first in some way to gain some reputation first. ", "comment_count": 0, "html": "<p>I see, then I guess they will need to contribute first in some way to gain some reputation first. </p>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 0, "parent": 18, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:59", "slug": "c-a-site-use-guidelines", "lastedit_date": "2011-11-24 14:48:59", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 504, "model": "server.post", "fields": {"rght": 4, "author": 15, "answer_accepted": false, "tag_string": "", "creation_date": "2009-10-28 16:38:40", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Gene ID conversion tool", "unanswered": false, "content": "Thanks! That's great! But I'm not student there...Can I access to that anyway? I am using Human whole genome Agilent array. Thank you so much. ", "comment_count": 0, "html": "<p>Thanks! That's great! But I'm not student there...Can I access to that anyway? I am using Human whole genome Agilent array. Thank you so much. </p>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 0, "parent": 23, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:59", "slug": "c-a-gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:48:59", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 15}}, {"pk": 505, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-22 15:14:58", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: How do I convert from BED format to GFF format?", "unanswered": false, "content": "Just a note: code above need bioperl", "comment_count": 0, "html": "<p>Just a note: code above need bioperl</p>", "child_count": 0, "closed": false, "tree_id": 2, "revision_count": 0, "parent": 30, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:59", "slug": "c-a-how-do-i-convert-from-bed-format-to-gff-format", "lastedit_date": "2011-11-24 14:48:59", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 506, "model": "server.post", "fields": {"rght": 4, "author": 3, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-23 23:29:53", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How do I map, align, and plot my SOLiD results?", "unanswered": false, "content": "Thanks, I think I'll try getting some help from the bioinformaticists here. In addition, I recently came across some other possibilities, have you or anyone here tried using CLC genomics workbench 3 (http://www.clcbio.com/index.php?id=1240) or SeqWeb GCG Wisconsin Sequence Analysis Package (http://www.hmc.psu.edu/core/computer/seqweb.htm)?  I know the SeqWeb is described in vague terms, but the CLC GW3 provides a means to do everything I need, in theory. ", "comment_count": 0, "html": "<p>Thanks, I think I'll try getting some help from the bioinformaticists here. In addition, I recently came across some other possibilities, have you or anyone here tried using CLC genomics workbench 3 (http://www.clcbio.com/index.php?id=1240) or SeqWeb GCG Wisconsin Sequence Analysis Package (http://www.hmc.psu.edu/core/computer/seqweb.htm)?  I know the SeqWeb is described in vague terms, but the CLC GW3 provides a means to do everything I need, in theory. </p>", "child_count": 0, "closed": false, "tree_id": 13, "revision_count": 0, "parent": 32, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:59", "slug": "c-a-how-do-i-map-align-and-plot-my-solid-results", "lastedit_date": "2011-11-24 14:48:59", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 3}}, {"pk": 507, "model": "server.post", "fields": {"rght": 8, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-26 20:39:39", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How do I map, align, and plot my SOLiD results?", "unanswered": false, "content": "you should ask questions separately not in the comments - those can get lost", "comment_count": 0, "html": "<p>you should ask questions separately not in the comments - those can get lost</p>", "child_count": 0, "closed": false, "tree_id": 13, "revision_count": 0, "parent": 32, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:48:59", "slug": "c-a-how-do-i-map-align-and-plot-my-solid-results", "lastedit_date": "2011-11-24 14:48:59", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 508, "model": "server.post", "fields": {"rght": 8, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-27 10:11:26", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "MacPorts seems to be a very useful tool, but I have the feeling that the ufficial repositories for the majority of linux distributions are bigger. Moreover, many programming languages have their own way to install new modules: easy_install for python, cpan for perl, cran for R...", "comment_count": 0, "html": "<p>MacPorts seems to be a very useful tool, but I have the feeling that the ufficial repositories for the majority of linux distributions are bigger. Moreover, many programming languages have their own way to install new modules: easy_install for python, cpan for perl, cran for R...</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 0, "parent": 37, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 509, "model": "server.post", "fields": {"rght": 14, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-27 14:18:52", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "macports is primarly for installing the necessary binary dependencies into OS X - its ability to install say python modules is just an *extra* feature.", "comment_count": 0, "html": "<p>macports is primarly for installing the necessary binary dependencies into OS X - its ability to install say python modules is just an <em>extra</em> feature.</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 0, "parent": 37, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 510, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-27 14:20:22", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Gene ID conversion tool", "unanswered": false, "content": "missed this comment, sorry about it!", "comment_count": 0, "html": "<p>missed this comment, sorry about it!</p>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 0, "parent": 23, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 511, "model": "server.post", "fields": {"rght": 8, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-28 21:42:41", "lft": 7, "post_type": 206247, "score": 1, "title": "C: A: Site use guidelines", "unanswered": false, "content": "for now we don't want to police questions too strictly, usually all questions are fine unless they are spam or obvious trolling", "comment_count": 0, "html": "<p>for now we don't want to police questions too strictly, usually all questions are fine unless they are spam or obvious trolling</p>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 0, "parent": 42, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-a-site-use-guidelines", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 512, "model": "server.post", "fields": {"rght": 8, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-01-29 16:17:44", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How do I convert from BED format to GFF format?", "unanswered": false, "content": "Hi Alex, one thing you could do it replace the case block with a hash map that remaps chromosomes. That way it is a lot easier to add other entries withouth make the code longer and longer...", "comment_count": 0, "html": "<p>Hi Alex, one thing you could do it replace the case block with a hash map that remaps chromosomes. That way it is a lot easier to add other entries withouth make the code longer and longer...</p>", "child_count": 0, "closed": false, "tree_id": 2, "revision_count": 0, "parent": 30, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-do-i-convert-from-bed-format-to-gff-format", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 513, "model": "server.post", "fields": {"rght": 4, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-22 16:30:04", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "I tought so, but I can't find the table for sequences, not even when I select 'All tracks' and 'AlLl tables'. Thanks anyway..", "comment_count": 0, "html": "<p>I tought so, but I can't find the table for sequences, not even when I select 'All tracks' and 'AlLl tables'. Thanks anyway..</p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 0, "parent": 57, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 514, "model": "server.post", "fields": {"rght": 14, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-22 18:37:59", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "I guess you are right, now that I tried myself and it seems that information is awfully hard to get - sometimes the seemingly getting the easiest thing is not possible. You could try your luck with the Ensemble API.", "comment_count": 0, "html": "<p>I guess you are right, now that I tried myself and it seems that information is awfully hard to get - sometimes the seemingly getting the easiest thing is not possible. You could try your luck with the Ensemble API.</p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 0, "parent": 57, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 515, "model": "server.post", "fields": {"rght": 16, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-22 18:38:52", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "I guess you are right, now that I tried myself and it seems that information is awfully hard to get - sometimes getting something seemingly easy end up as being not possible. You could try your luck with the Ensemble API.", "comment_count": 0, "html": "<p>I guess you are right, now that I tried myself and it seems that information is awfully hard to get - sometimes getting something seemingly easy end up as being not possible. You could try your luck with the Ensemble API.</p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 0, "parent": 57, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 516, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-25 18:26:02", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "that's really neat!", "comment_count": 0, "html": "<p>that's really neat!</p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 0, "parent": 59, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 517, "model": "server.post", "fields": {"rght": 4, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-25 23:54:17", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: What is the best way to share scripts between members of a lab?", "unanswered": false, "content": "Complementing this answer, a good option could be the Trac framework (http://trac.edgewall.org/) with the plug-in for Git (http://nanosleep.org/proj/trac-git-plugin). Default support is for Subversion AFAIK.", "comment_count": 0, "html": "<p>Complementing this answer, a good option could be the Trac framework (http://trac.edgewall.org/) with the plug-in for Git (http://nanosleep.org/proj/trac-git-plugin). Default support is for Subversion AFAIK.</p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 0, "parent": 61, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 518, "model": "server.post", "fields": {"rght": 8, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 09:51:42", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "Thanks!! I didn't know that, very cool!! :-)", "comment_count": 0, "html": "<p>Thanks!! I didn't know that, very cool!! :-)</p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 0, "parent": 59, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 519, "model": "server.post", "fields": {"rght": 8, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 09:58:51", "lft": 7, "post_type": 206247, "score": 1, "title": "C: A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "yep but with cygwin you lose all the fun of using Linux or an Unix system. Moreover, it is very complicated to install new programs (I think you have to click on the installer again) or to compile new ones. As an an alternative, you can also install a virtual machine on Windows if you really need to do that.", "comment_count": 0, "html": "<p>yep but with cygwin you lose all the fun of using Linux or an Unix system. Moreover, it is very complicated to install new programs (I think you have to click on the installer again) or to compile new ones. As an an alternative, you can also install a virtual machine on Windows if you really need to do that.</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 0, "parent": 65, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 520, "model": "server.post", "fields": {"rght": 4, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 13:57:38", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Using HDF5 to store  bio-data", "unanswered": false, "content": "Many thanks Fernando. As I said , I'm especially looking for some source code: e.g. I'd like to see a short program that would store/retrieve data just to see/understand why I should use this HDF instead of a classic RDBM or another engine (berkeleydb, couchdb...)", "comment_count": 0, "html": "<p>Many thanks Fernando. As I said , I'm especially looking for some source code: e.g. I'd like to see a short program that would store/retrieve data just to see/understand why I should use this HDF instead of a classic RDBM or another engine (berkeleydb, couchdb...)</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 0, "parent": 71, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 521, "model": "server.post", "fields": {"rght": 12, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 14:04:47", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Using HDF5 to store  bio-data", "unanswered": false, "content": "Still not the kind of source code I'm looking for but it is very interesting ! Your project reminds me Jan Aerts' Locus Tree : http://saaientist.blogspot.com/2009/04/locustree-searching-genomic-loci.html", "comment_count": 0, "html": "<p>Still not the kind of source code I'm looking for but it is very interesting ! Your project reminds me Jan Aerts' Locus Tree : http://saaientist.blogspot.com/2009/04/locustree-searching-genomic-loci.html</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 0, "parent": 73, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 522, "model": "server.post", "fields": {"rght": 10, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 14:08:54", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Site use guidelines", "unanswered": false, "content": "This site has been started by a Bionformatics group at Pennsylvania State University. See bottom of the page for a contact link. Thanks.", "comment_count": 0, "html": "<p>This site has been started by a Bionformatics group at Pennsylvania State University. See bottom of the page for a contact link. Thanks.</p>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 0, "parent": 66, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-site-use-guidelines", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 523, "model": "server.post", "fields": {"rght": 16, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 14:16:15", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Using HDF5 to store  bio-data", "unanswered": false, "content": "Interesting link. You might want to also check out the PyTables documentation. That may have some use cases that you might be interested in. You can safely ignore the python related features: http://www.pytables.org/docs/manual/", "comment_count": 0, "html": "<p>Interesting link. You might want to also check out the PyTables documentation. That may have some use cases that you might be interested in. You can safely ignore the python related features: http://www.pytables.org/docs/manual/</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 0, "parent": 73, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 524, "model": "server.post", "fields": {"rght": 14, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 14:34:38", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Using HDF5 to store  bio-data", "unanswered": false, "content": "Very interesting. I'll flag this answer as \"correct\", but please, if anybody knows some source code that would highlight the power of HDF5. Please, feel free to post it here. Thanks", "comment_count": 0, "html": "<p>Very interesting. I'll flag this answer as \"correct\", but please, if anybody knows some source code that would highlight the power of HDF5. Please, feel free to post it here. Thanks</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 0, "parent": 74, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 525, "model": "server.post", "fields": {"rght": 12, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 15:22:37", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Site use guidelines", "unanswered": false, "content": "Community building starts our very slowly but once it picks up steam it can really blossom. I do think that there bioinformatics is particularly well suited for this question-answer type format. I am very pleased to see an influx of new users to the system. This  motivates me to start promoting this site in a more visible manner. I have actually already learned a tremendous amount from the answers here. Users can help by posting questions and answers, and if you see an interesting question answered somewhere else you may want to post it here as well.\n", "comment_count": 0, "html": "<p>Community building starts our very slowly but once it picks up steam it can really blossom. I do think that there bioinformatics is particularly well suited for this question-answer type format. I am very pleased to see an influx of new users to the system. This  motivates me to start promoting this site in a more visible manner. I have actually already learned a tremendous amount from the answers here. Users can help by posting questions and answers, and if you see an interesting question answered somewhere else you may want to post it here as well.</p>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 0, "parent": 75, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-site-use-guidelines", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 526, "model": "server.post", "fields": {"rght": 14, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 15:23:03", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Site use guidelines", "unanswered": false, "content": "Community building starts our very slowly but once it picks up steam it can really blossom. I do think that bioinformatics is particularly well suited for this question-answer type format. I am very pleased to see an influx of new users to the system. This motivates me to start promoting this site in a more visible manner. I have actually already learned a tremendous amount from the answers here. Users can help by posting questions and answers, and if you see an interesting question answered somewhere else you may want to post it here as well", "comment_count": 0, "html": "<p>Community building starts our very slowly but once it picks up steam it can really blossom. I do think that bioinformatics is particularly well suited for this question-answer type format. I am very pleased to see an influx of new users to the system. This motivates me to start promoting this site in a more visible manner. I have actually already learned a tremendous amount from the answers here. Users can help by posting questions and answers, and if you see an interesting question answered somewhere else you may want to post it here as well</p>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 0, "parent": 75, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-site-use-guidelines", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 527, "model": "server.post", "fields": {"rght": 16, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 15:24:07", "lft": 15, "post_type": 206247, "score": 1, "title": "C: A: Site use guidelines", "unanswered": false, "content": "Community building starts our very slowly but once it picks up steam it can really blossom. I do think that bioinformatics is particularly well suited for this question-answer type format. I am very pleased to see an influx of new users to the system.  I have actually already learned a tremendous amount from the answers here. More than anything that motivates me to promote this site in a more visible manner. Users can help by posting questions and answers, and if you see an interesting question answered somewhere else you may want to post it here as well", "comment_count": 0, "html": "<p>Community building starts our very slowly but once it picks up steam it can really blossom. I do think that bioinformatics is particularly well suited for this question-answer type format. I am very pleased to see an influx of new users to the system.  I have actually already learned a tremendous amount from the answers here. More than anything that motivates me to promote this site in a more visible manner. Users can help by posting questions and answers, and if you see an interesting question answered somewhere else you may want to post it here as well</p>", "child_count": 0, "closed": false, "tree_id": 1, "revision_count": 0, "parent": 75, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-site-use-guidelines", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 528, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 16:12:29", "lft": 2, "post_type": 206247, "score": 0, "title": "C: How do I convert an Illumina export file to BED?", "unanswered": false, "content": "We can probably find/write you perl or python scripts that do this, what are you comfortable running?", "comment_count": 0, "html": "<p>We can probably find/write you perl or python scripts that do this, what are you comfortable running?</p>", "child_count": 0, "closed": false, "tree_id": 25, "revision_count": 0, "parent": 77, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-how-do-i-convert-an-illumina-export-file-to-bed", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 529, "model": "server.post", "fields": {"rght": 4, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 17:05:54", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "I have tried ruffus extensively, but in the end I decided I don't like its syntax. It complicates python's syntax and in the end, I recoded my pipeline as a simple python script, because I was getting errors that I couldn't understand well. What I am really looking for is something on the style of biomake/skam: http://skam.sourceforge.net/skam-intro.html", "comment_count": 0, "html": "<p>I have tried ruffus extensively, but in the end I decided I don't like its syntax. It complicates python's syntax and in the end, I recoded my pipeline as a simple python script, because I was getting errors that I couldn't understand well. What I am really looking for is something on the style of biomake/skam: http://skam.sourceforge.net/skam-intro.html</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 80, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 530, "model": "server.post", "fields": {"rght": 8, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 17:16:41", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "can you do 'loops' with (bio)make ?", "comment_count": 0, "html": "<p>can you do 'loops' with (bio)make ?</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 81, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 531, "model": "server.post", "fields": {"rght": 20, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 17:20:31", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "I know it but since I have starting use make, I can't do anything without some certain features. For example, if you write a 'glue' script, you don't have conditional execution of tasks, so you will always have to run all the pipeline at once, without the possibility of pausing it. Or again, with makefiles, if you change only one of the input files, the program will only run the steps that are necessary to obtain the results, while a batch script will re-run everything. Moreover, a Makefile script has a standard syntax and it is easier to understand what is happening.", "comment_count": 0, "html": "<p>I know it but since I have starting use make, I can't do anything without some certain features. For example, if you write a 'glue' script, you don't have conditional execution of tasks, so you will always have to run all the pipeline at once, without the possibility of pausing it. Or again, with makefiles, if you change only one of the input files, the program will only run the steps that are necessary to obtain the results, while a batch script will re-run everything. Moreover, a Makefile script has a standard syntax and it is easier to understand what is happening.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 82, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 532, "model": "server.post", "fields": {"rght": 10, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-02-26 17:22:56", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "no idea :-( Unfortunately I could never make it working. Anyway, since these are usually declarative-like syntax, you don't make loops, you just apply a function on an array of values (e.g. like in R with the apply function)", "comment_count": 0, "html": "<p>no idea :-( Unfortunately I could never make it working. Anyway, since these are usually declarative-like syntax, you don't make loops, you just apply a function on an array of values (e.g. like in R with the apply function)</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 81, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 533, "model": "server.post", "fields": {"rght": 12, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 09:03:58", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "well, a Makefile with phony rules is not much difficult to write. Even if you use a script only once, it is useful to write down the options and the files on which you have launched it. Moreover, sometimes you use binary files like the ones from emboss or blast, which have lot of options, and you need to annotate the options you have used to make your results reproducible.", "comment_count": 0, "html": "<p>well, a Makefile with phony rules is not much difficult to write. Even if you use a script only once, it is useful to write down the options and the files on which you have launched it. Moreover, sometimes you use binary files like the ones from emboss or blast, which have lot of options, and you need to annotate the options you have used to make your results reproducible.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 84, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 534, "model": "server.post", "fields": {"rght": 9, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 14:45:57", "lft": 2, "post_type": 206247, "score": 0, "title": "C: Computing the reverse and complement of a sequence with Biopython", "unanswered": false, "content": "Another tip: you can transform a Seq class instance into a string with the str() function.", "comment_count": 0, "html": "<p>Another tip: you can transform a Seq class instance into a string with the str() function.</p>", "child_count": 0, "closed": false, "tree_id": 28, "revision_count": 0, "parent": 90, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-computing-the-reverse-and-complement-of-a-sequence-with-biopython", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 535, "model": "server.post", "fields": {"rght": 4, "author": 9, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 16:10:23", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Computing the reverse and complement of a sequence with Biopython", "unanswered": false, "content": "good point but it seems like that would generate way too many small questions", "comment_count": 0, "html": "<p>good point but it seems like that would generate way too many small questions</p>", "child_count": 0, "closed": false, "tree_id": 28, "revision_count": 0, "parent": 94, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-computing-the-reverse-and-complement-of-a-sequence-with-biopython", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 9}}, {"pk": 536, "model": "server.post", "fields": {"rght": 14, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 16:46:23", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "interesting frameworks", "comment_count": 0, "html": "<p>interesting frameworks</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 95, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 537, "model": "server.post", "fields": {"rght": 14, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 16:56:27", "lft": 13, "post_type": 206247, "score": 1, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "Thanks. I think waf is too much oriented towards compiling programs, I have tried to use it but I don't think it is very useful for what we need to do. As for your third point, I use a lot of .Phony targets, which means that I just use a generic name (e.g. align_sequences, get_data, calculate_x) and the list of commands, with few dependencies. A bit like how I have shown in these slides: http://bioinfoblog.it/?p=29", "comment_count": 0, "html": "<p>Thanks. I think waf is too much oriented towards compiling programs, I have tried to use it but I don't think it is very useful for what we need to do. As for your third point, I use a lot of .Phony targets, which means that I just use a generic name (e.g. align_sequences, get_data, calculate_x) and the list of commands, with few dependencies. A bit like how I have shown in these slides: http://bioinfoblog.it/?p=29</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 95, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 538, "model": "server.post", "fields": {"rght": 6, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 16:58:00", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Agile programming for bioinformaticians - any suggestions?", "unanswered": false, "content": "scrum is interesting. I will probably collaborate to a colleague of mine who is using it to prepare a part of the talk on it. Thank you very much for answering.", "comment_count": 0, "html": "<p>scrum is interesting. I will probably collaborate to a colleague of mine who is using it to prepare a part of the talk on it. Thank you very much for answering.</p>", "child_count": 0, "closed": false, "tree_id": 27, "revision_count": 0, "parent": 91, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-agile-programming-for-bioinformaticians-any-suggestions", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 539, "model": "server.post", "fields": {"rght": 8, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-01 17:32:48", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Computing the reverse and complement of a sequence with Biopython", "unanswered": false, "content": "good observation will do that from now on", "comment_count": 0, "html": "<p>good observation will do that from now on</p>", "child_count": 0, "closed": false, "tree_id": 28, "revision_count": 0, "parent": 96, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-computing-the-reverse-and-complement-of-a-sequence-with-biopython", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 540, "model": "server.post", "fields": {"rght": 18, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 12:08:00", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "Yes, I have checked it on January 2009 and it was the same as it is now. I also wrote to the author and he confirmed that he is working on a different project now, and he doesn't plan to work on biomake soon.", "comment_count": 0, "html": "<p>Yes, I have checked it on January 2009 and it was the same as it is now. I also wrote to the author and he confirmed that he is working on a different project now, and he doesn't plan to work on biomake soon.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 107, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 541, "model": "server.post", "fields": {"rght": 16, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 14:35:32", "lft": 15, "post_type": 206247, "score": 1, "title": "C: A: Using HDF5 to store  bio-data", "unanswered": false, "content": "also pytables: http://www.pytables.org/moin", "comment_count": 0, "html": "<p>also pytables: http://www.pytables.org/moin</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 0, "parent": 110, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 542, "model": "server.post", "fields": {"rght": 5, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 14:56:06", "lft": 4, "post_type": 206247, "score": 0, "title": "C: Genome specific database (Gbrowse / Ensembl type)", "unanswered": false, "content": "now fixed, tagging rules have been relaxed please try again, thanks", "comment_count": 0, "html": "<p>now fixed, tagging rules have been relaxed please try again, thanks</p>", "child_count": 0, "closed": false, "tree_id": 32, "revision_count": 0, "parent": 108, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-genome-specific-database-gbrowse-ensembl-type", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 543, "model": "server.post", "fields": {"rght": 3, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 16:20:09", "lft": 2, "post_type": 206247, "score": 1, "title": "C: Taxonomy of blast hits", "unanswered": false, "content": "hum, not sure I understand what is your input... An example ?", "comment_count": 0, "html": "<p>hum, not sure I understand what is your input... An example ?</p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 0, "parent": 111, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 544, "model": "server.post", "fields": {"rght": 4, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 16:45:23", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: List all the tools or write a script to validate that a sequence only contains letters from a given alphabet", "unanswered": false, "content": "nice, but I would include the N in the dna set.", "comment_count": 0, "html": "<p>nice, but I would include the N in the dna set.</p>", "child_count": 0, "closed": false, "tree_id": 31, "revision_count": 0, "parent": 103, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-list-all-the-tools-or-write-a-script-to-validate-that-a-sequence-only-contains-letters-from-a-given-alphabet", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 545, "model": "server.post", "fields": {"rght": 21, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 17:06:24", "lft": 14, "post_type": 206247, "score": 0, "title": "C: Taxonomy of blast hits", "unanswered": false, "content": "Can you also show an example of the table output from blast? Anyway it is better to use the xml output as it is more stable over time. Also, are you doing this in any particular programming language or tool?", "comment_count": 0, "html": "<p>Can you also show an example of the table output from blast? Anyway it is better to use the xml output as it is more stable over time. Also, are you doing this in any particular programming language or tool?</p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 0, "parent": 111, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 546, "model": "server.post", "fields": {"rght": 4, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 17:48:38", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "eheh :-) this sounds familiar...", "comment_count": 0, "html": "<p>eheh :-) this sounds familiar...</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 0, "parent": 113, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 547, "model": "server.post", "fields": {"rght": 10, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 18:26:49", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "Second that. Good one for python\n", "comment_count": 0, "html": "<p>Second that. Good one for python</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 0, "parent": 117, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 548, "model": "server.post", "fields": {"rght": 20, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 18:40:29", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Taxonomy of blast hits", "unanswered": false, "content": "Thank you. These are genomic contigs. \"Metagenomics\" is accidental. Input DNA was from two sources, one of which contained bacterias. \nNo idea if these come from dirty root, lived between plant cells, within them(?) but it does not look like bacterial lab strain jumping to a new bottle.  \n Sequence produced by 454s, assembled by Newbler. My contigs are anywhere from 100bp to 1Mbp. So I am expecting one plant genome and at least one, possibly many bacterial species. Single, 1Mb  large bacterial contig can hit multiple species of bacteria (blastp using predicted genes, 40-70% similarity hits).", "comment_count": 0, "html": "<p>Thank you. These are genomic contigs. \"Metagenomics\" is accidental. Input DNA was from two sources, one of which contained bacterias. \nNo idea if these come from dirty root, lived between plant cells, within them(?) but it does not look like bacterial lab strain jumping to a new bottle.<br />\n Sequence produced by 454s, assembled by Newbler. My contigs are anywhere from 100bp to 1Mbp. So I am expecting one plant genome and at least one, possibly many bacterial species. Single, 1Mb  large bacterial contig can hit multiple species of bacteria (blastp using predicted genes, 40-70% similarity hits).</p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 0, "parent": 115, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 549, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 19:07:36", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "Hi everyone, slightly unrelated note. Remember to vote on posts, questions if you like them. That is the way to accumulate reputation that in the end allows the users to moderate content (see FAQ for more info). Also it is recommended to select the best answer for a question.", "comment_count": 0, "html": "<p>Hi everyone, slightly unrelated note. Remember to vote on posts, questions if you like them. That is the way to accumulate reputation that in the end allows the users to moderate content (see FAQ for more info). Also it is recommended to select the best answer for a question.</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 0, "parent": 113, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 550, "model": "server.post", "fields": {"rght": 4, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 19:12:53", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Taxonomy of blast hits", "unanswered": false, "content": "Dear Pierre, I just send you an email to your yahoo address. \nIn short I think it is a great idea. i will look into your code tomorrow. Thank you\n", "comment_count": 0, "html": "<p>Dear Pierre, I just send you an email to your yahoo address. \nIn short I think it is a great idea. i will look into your code tomorrow. Thank you</p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 0, "parent": 114, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 551, "model": "server.post", "fields": {"rght": 16, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 19:20:55", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Taxonomy of blast hits", "unanswered": false, "content": "Many plants undergo symbiotic interactions with soil-bacteria, e.g. legume palnts and nitrogen-fixing rhizobia, these form root nodules. If you sample from the wild, you have possibly discovered the plant and its symbiont(s) in between root cells, otherwise just dirt. Just speculation, depends on how you got the sample.\n\nAnyway, maybe then it's maybe best to sort out the individual reads on the domain level (bacteria vs. eukaryota) and assemble afterwards. At least if mainly interested in a pure assembly.\n\n ", "comment_count": 0, "html": "<p>Many plants undergo symbiotic interactions with soil-bacteria, e.g. legume palnts and nitrogen-fixing rhizobia, these form root nodules. If you sample from the wild, you have possibly discovered the plant and its symbiont(s) in between root cells, otherwise just dirt. Just speculation, depends on how you got the sample.</p>\n<p>Anyway, maybe then it's maybe best to sort out the individual reads on the domain level (bacteria vs. eukaryota) and assemble afterwards. At least if mainly interested in a pure assembly.</p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 0, "parent": 115, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 552, "model": "server.post", "fields": {"rght": 18, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 20:23:31", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Taxonomy of blast hits", "unanswered": false, "content": "re reassembly: indeed this is what we will do in the end. But since we already have draft assembly reducing the total sequence length I went for contig screen first. As a bonus one can confirm that 454 contigs contain our plant DNA by mapping (blast pre-screened) ESTs, GSS sequences and Illumina short reads from bacteria-free (so far...) leaves / mRNAs.    ", "comment_count": 0, "html": "<p>re reassembly: indeed this is what we will do in the end. But since we already have draft assembly reducing the total sequence length I went for contig screen first. As a bonus one can confirm that 454 contigs contain our plant DNA by mapping (blast pre-screened) ESTs, GSS sequences and Illumina short reads from bacteria-free (so far...) leaves / mRNAs.  <br />\n</p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 0, "parent": 115, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 553, "model": "server.post", "fields": {"rght": 14, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 21:08:44", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "Abhishek's is one of the bests :-)", "comment_count": 0, "html": "<p>Abhishek's is one of the bests :-)</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 0, "parent": 121, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 554, "model": "server.post", "fields": {"rght": 16, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-02 21:18:04", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "That is a good list\n", "comment_count": 0, "html": "<p>That is a good list</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 0, "parent": 121, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 555, "model": "server.post", "fields": {"rght": 6, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-03 11:33:21", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Taxonomy of blast hits", "unanswered": false, "content": "please don't be shy about continuing your discussion here... If you continue your discussion in private, then it is of no use for the other readers.", "comment_count": 0, "html": "<p>please don't be shy about continuing your discussion here... If you continue your discussion in private, then it is of no use for the other readers.</p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 0, "parent": 114, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 556, "model": "server.post", "fields": {"rght": 8, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-03 12:46:12", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Taxonomy of blast hits", "unanswered": false, "content": "put the source code I wrote on ghist: http://gist.github.com/320585", "comment_count": 0, "html": "<p>put the source code I wrote on ghist: http://gist.github.com/320585</p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 0, "parent": 114, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 557, "model": "server.post", "fields": {"rght": 10, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-03 12:49:28", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Taxonomy of blast hits", "unanswered": false, "content": "Sorry but the email was non-technical. All about what I possibly can do for Pierre for (in some way at least) doing my homework. Surely it may be interesting in the longer run how do we return the favors (authorship? $$$, invitation to give a talk?) but often person asking the question is not at the helm (can not promise much). Hope it explains a bit. \n\nAs for Pierre's program, once it stops running and I check the output I will write about it. ", "comment_count": 0, "html": "<p>Sorry but the email was non-technical. All about what I possibly can do for Pierre for (in some way at least) doing my homework. Surely it may be interesting in the longer run how do we return the favors (authorship? $$$, invitation to give a talk?) but often person asking the question is not at the helm (can not promise much). Hope it explains a bit. </p>\n<p>As for Pierre's program, once it stops running and I check the output I will write about it. </p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 0, "parent": 114, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 558, "model": "server.post", "fields": {"rght": 17, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-03 14:01:21", "lft": 16, "post_type": 206247, "score": 0, "title": "C: Gene ID conversion tool", "unanswered": false, "content": "How frequently do you need things updated?  DAVID does have yearly releases so far, but their latest release is this month (March 2010). See the release announcement here: http://david.abcc.ncifcrf.gov/forum/cgi-bin/ikonboard.cgi?act=ST;f=10;t=25 This does suggest the underlying mapping framework will be updated along with it in the 6.7 beta, and hence should include more recent information for the conversion tool", "comment_count": 0, "html": "<p>How frequently do you need things updated?  DAVID does have yearly releases so far, but their latest release is this month (March 2010). See the release announcement here: http://david.abcc.ncifcrf.gov/forum/cgi-bin/ikonboard.cgi?act=ST;f=10;t=25 This does suggest the underlying mapping framework will be updated along with it in the 6.7 beta, and hence should include more recent information for the conversion tool</p>", "child_count": 0, "closed": false, "tree_id": 10, "revision_count": 0, "parent": 22, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-gene-id-conversion-tool", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 559, "model": "server.post", "fields": {"rght": 6, "author": 60, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-03 16:09:37", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Using HDF5 to store  bio-data", "unanswered": false, "content": "There are Perl-based bindings to both HDF5 and BioHDF here, along with some docs: \n\nftp://ftp.hdfgroup.uiuc.edu/pub/outgoing/BioHDF/Perl/ ", "comment_count": 0, "html": "<p>There are Perl-based bindings to both HDF5 and BioHDF here, along with some docs: </p>\n<p>ftp://ftp.hdfgroup.uiuc.edu/pub/outgoing/BioHDF/Perl/ </p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 0, "parent": 71, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 60}}, {"pk": 560, "model": "server.post", "fields": {"rght": 12, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-03 17:23:28", "lft": 11, "post_type": 206247, "score": 1, "title": "C: A: Taxonomy of blast hits", "unanswered": false, "content": "Pierre's Java program did work as promised. For 6.6k accessions it took ca 6 hours. Thank you :-). \nNow it is my part to combine it with blast output /contig sizes etc. ", "comment_count": 0, "html": "<p>Pierre's Java program did work as promised. For 6.6k accessions it took ca 6 hours. Thank you :-). \nNow it is my part to combine it with blast output /contig sizes etc. </p>", "child_count": 0, "closed": false, "tree_id": 33, "revision_count": 0, "parent": 114, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-a-taxonomy-of-blast-hits", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 561, "model": "server.post", "fields": {"rght": 7, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 03:33:26", "lft": 2, "post_type": 206247, "score": 0, "title": "C: Pfam based functional annotaion", "unanswered": false, "content": "minor correction it was Giovanni who asked that question", "comment_count": 0, "html": "<p>minor correction it was Giovanni who asked that question</p>", "child_count": 0, "closed": false, "tree_id": 35, "revision_count": 0, "parent": 128, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-pfam-based-functional-annotaion", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 562, "model": "server.post", "fields": {"rght": 20, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 07:16:28", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Using HDF5 to store  bio-data", "unanswered": false, "content": "Thank you Abhishek !", "comment_count": 0, "html": "<p>Thank you Abhishek !</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 0, "parent": 127, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 563, "model": "server.post", "fields": {"rght": 5, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 09:44:21", "lft": 2, "post_type": 206247, "score": 0, "title": "C: Computing the reverse and complement of a sequence with Pygr", "unanswered": false, "content": "And what exactly is your question?", "comment_count": 0, "html": "<p>And what exactly is your question?</p>", "child_count": 0, "closed": false, "tree_id": 29, "revision_count": 0, "parent": 92, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-computing-the-reverse-and-complement-of-a-sequence-with-pygr", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 564, "model": "server.post", "fields": {"rght": 6, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 09:46:50", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Computing the reverse and complement of a sequence with Biopython", "unanswered": false, "content": "I concur with giovanni. ", "comment_count": 0, "html": "<p>I concur with giovanni. </p>", "child_count": 0, "closed": false, "tree_id": 28, "revision_count": 0, "parent": 94, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-computing-the-reverse-and-complement-of-a-sequence-with-biopython", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 565, "model": "server.post", "fields": {"rght": 4, "author": 6, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 14:07:30", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Pfam based functional annotaion", "unanswered": false, "content": "Hey Nicojo , \n\nThanks for your reply. I am trying to find out what percentage of peptides in my library share a same biological process or have same molecular function .These peptides have length between 17-22 residues and Pfam was giving the annotation for a test run which I carried out a few weeks before.\n\n", "comment_count": 0, "html": "<p>Hey Nicojo , </p>\n<p>Thanks for your reply. I am trying to find out what percentage of peptides in my library share a same biological process or have same molecular function .These peptides have length between 17-22 residues and Pfam was giving the annotation for a test run which I carried out a few weeks before.</p>", "child_count": 0, "closed": false, "tree_id": 35, "revision_count": 0, "parent": 129, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-pfam-based-functional-annotaion", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 6}}, {"pk": 566, "model": "server.post", "fields": {"rght": 15, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:03:56", "lft": 14, "post_type": 206247, "score": 0, "title": "C: Which are the best programming languages for a bioinformatician?", "unanswered": false, "content": "which answer should I choose? All of them are good.", "comment_count": 0, "html": "<p>which answer should I choose? All of them are good.</p>", "child_count": 0, "closed": false, "tree_id": 15, "revision_count": 0, "parent": 34, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-which-are-the-best-programming-languages-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 567, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:06:27", "lft": 2, "post_type": 206247, "score": 0, "title": "C: What is the best place in the world to do Bioinformatics?", "unanswered": false, "content": "you don't need to 'community wiki' all your questions: I suggest you to accumulate some points, unless you can at least vote, and then we will change to community wiki all the questions that deserve it here.", "comment_count": 0, "html": "<p>you don't need to 'community wiki' all your questions: I suggest you to accumulate some points, unless you can at least vote, and then we will change to community wiki all the questions that deserve it here.</p>", "child_count": 0, "closed": false, "tree_id": 39, "revision_count": 0, "parent": 138, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-what-is-the-best-place-in-the-world-to-do-bioinformatics", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 568, "model": "server.post", "fields": {"rght": 4, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:17:57", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: What methods do you use for short read mapping?", "unanswered": false, "content": "that's really neat Pierre!", "comment_count": 0, "html": "<p>that's really neat Pierre!</p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 0, "parent": 140, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 569, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:18:49", "lft": 5, "post_type": 206247, "score": 1, "title": "C: A: What methods do you use for short read mapping?", "unanswered": false, "content": "That's a really nice description of the problem and code, Pierre!", "comment_count": 0, "html": "<p>That's a really nice description of the problem and code, Pierre!</p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 0, "parent": 140, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 570, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:25:28", "lft": 6, "post_type": 206247, "score": 0, "title": "C: Mapping SNPs to Pathways", "unanswered": false, "content": "what does it means that a snp is related to a pathway?", "comment_count": 0, "html": "<p>what does it means that a snp is related to a pathway?</p>", "child_count": 0, "closed": false, "tree_id": 41, "revision_count": 0, "parent": 142, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-mapping-snps-to-pathways", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 571, "model": "server.post", "fields": {"rght": 4, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:28:39", "lft": 3, "post_type": 206247, "score": 1, "title": "C: A: What is the best place in the world to do Bioinformatics?", "unanswered": false, "content": "I'm even tempted to say that the EBI is one of the most interesting places from even a EU perspective. Particularly, if you value the ODOSOS ideas.", "comment_count": 0, "html": "<p>I'm even tempted to say that the EBI is one of the most interesting places from even a EU perspective. Particularly, if you value the ODOSOS ideas.</p>", "child_count": 0, "closed": false, "tree_id": 39, "revision_count": 0, "parent": 145, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-what-is-the-best-place-in-the-world-to-do-bioinformatics", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 572, "model": "server.post", "fields": {"rght": 4, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:33:47", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Mapping SNPs to Pathways", "unanswered": false, "content": "Thanks but your system just finds the genes in a given region ( To do this i would simply use the UCSC mysql anonymous server with 'select distinct G.name from knownGenes as G, snp130 as S where G.txtStart<= S.chromStart and G.txtEnd>=S.chromEnd and S.name in(\"rs1\",\"rs2\"...)'). Here I want to mine the pathways and/or the diseases. For example: \"this subset of SNPs is involved in the metabolism of XXXX\".", "comment_count": 0, "html": "<p>Thanks but your system just finds the genes in a given region ( To do this i would simply use the UCSC mysql anonymous server with 'select distinct G.name from knownGenes as G, snp130 as S where G.txtStart&lt;= S.chromStart and G.txtEnd&gt;=S.chromEnd and S.name in(\"rs1\",\"rs2\"...)'). Here I want to mine the pathways and/or the diseases. For example: \"this subset of SNPs is involved in the metabolism of XXXX\".</p>", "child_count": 0, "closed": false, "tree_id": 41, "revision_count": 0, "parent": 146, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-mapping-snps-to-pathways", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 573, "model": "server.post", "fields": {"rght": 9, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:35:58", "lft": 8, "post_type": 206247, "score": 0, "title": "C: Mapping SNPs to Pathways", "unanswered": false, "content": "@giovani e.g. \"this subset of snps (localized on gene G1,G2,...) have been described to be involved in the metabolism of 'X'\".  ", "comment_count": 0, "html": "<p>@giovani e.g. \"this subset of snps (localized on gene G1,G2,...) have been described to be involved in the metabolism of 'X'\".<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 41, "revision_count": 0, "parent": 142, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-mapping-snps-to-pathways", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 574, "model": "server.post", "fields": {"rght": 11, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:46:17", "lft": 10, "post_type": 206247, "score": 0, "title": "C: What is the best place in the world to do Bioinformatics?", "unanswered": false, "content": "yes, good point, community wiki will turn on automatically after some time.", "comment_count": 0, "html": "<p>yes, good point, community wiki will turn on automatically after some time.</p>", "child_count": 0, "closed": false, "tree_id": 39, "revision_count": 0, "parent": 138, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-what-is-the-best-place-in-the-world-to-do-bioinformatics", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 575, "model": "server.post", "fields": {"rght": 13, "author": 63, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 15:55:27", "lft": 12, "post_type": 206247, "score": 0, "title": "C: What is the best place in the world to do Bioinformatics?", "unanswered": false, "content": "thanks for your suggestions... Still learning.", "comment_count": 0, "html": "<p>thanks for your suggestions... Still learning.</p>", "child_count": 0, "closed": false, "tree_id": 39, "revision_count": 0, "parent": 138, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-what-is-the-best-place-in-the-world-to-do-bioinformatics", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 63}}, {"pk": 576, "model": "server.post", "fields": {"rght": 10, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 16:14:55", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "be careful: the DAS server uses an index of (+1) for the first base.", "comment_count": 0, "html": "<p>be careful: the DAS server uses an index of (+1) for the first base.</p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 0, "parent": 59, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 577, "model": "server.post", "fields": {"rght": 12, "author": 73, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 16:17:17", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: How to get the sequence of a genomic region from UCSC?", "unanswered": false, "content": "Wow, thanks. That's quite useful.", "comment_count": 0, "html": "<p>Wow, thanks. That's quite useful.</p>", "child_count": 0, "closed": false, "tree_id": 21, "revision_count": 0, "parent": 59, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-get-the-sequence-of-a-genomic-region-from-ucsc", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 73}}, {"pk": 578, "model": "server.post", "fields": {"rght": 24, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 16:43:22", "lft": 23, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "try makefiles, it basically the same as shell scripts but you can define more than a task in a file.", "comment_count": 0, "html": "<p>try makefiles, it basically the same as shell scripts but you can define more than a task in a file.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 153, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 579, "model": "server.post", "fields": {"rght": 4, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 19:14:01", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Experiences with cloud computing in bioinformatics", "unanswered": false, "content": "Agree with the point about small labs. I work at a small lab and there is no way that we could afford a large cluster. We can however afford to spin out EC2 when ever we need it.", "comment_count": 0, "html": "<p>Agree with the point about small labs. I work at a small lab and there is no way that we could afford a large cluster. We can however afford to spin out EC2 when ever we need it.</p>", "child_count": 0, "closed": false, "tree_id": 37, "revision_count": 0, "parent": 133, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-experiences-with-cloud-computing-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 580, "model": "server.post", "fields": {"rght": 6, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 20:14:32", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Looking for a 'Hello world\" plugin for Taverna.", "unanswered": false, "content": "I guess I should flag this anwser as correct :-) However, if someone has a method to build a simple plugin without maven, feel free to write it here. Thanks :-)", "comment_count": 0, "html": "<p>I guess I should flag this anwser as correct :-) However, if someone has a method to build a simple plugin without maven, feel free to write it here. Thanks :-)</p>", "child_count": 0, "closed": false, "tree_id": 24, "revision_count": 0, "parent": 156, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-looking-for-a-hello-world-plugin-for-taverna", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 581, "model": "server.post", "fields": {"rght": 6, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 21:20:26", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Pfam based functional annotaion", "unanswered": false, "content": "I'm still a bit confused: are these peptides experimentally shown to be present in the sample as such short peptides? Or are they fragments of large proteins that have been digested and sequenced?\nIn any case, you cannot predict the function of peptides just because that sequence is present in a full blown protein that has a function... I'd even say that it is not biologically relevant :(\n\nBut, if you have a bunch of peptides that are sequenced from a sample and you manage to map them back to a protein, then you can find out what Pfam domains that protein has and get an idea of its function.", "comment_count": 0, "html": "<p>I'm still a bit confused: are these peptides experimentally shown to be present in the sample as such short peptides? Or are they fragments of large proteins that have been digested and sequenced?\nIn any case, you cannot predict the function of peptides just because that sequence is present in a full blown protein that has a function... I'd even say that it is not biologically relevant :(</p>\n<p>But, if you have a bunch of peptides that are sequenced from a sample and you manage to map them back to a protein, then you can find out what Pfam domains that protein has and get an idea of its function.</p>", "child_count": 0, "closed": false, "tree_id": 35, "revision_count": 0, "parent": 129, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-pfam-based-functional-annotaion", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 582, "model": "server.post", "fields": {"rght": 7, "author": 6, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-04 23:05:24", "lft": 6, "post_type": 206247, "score": 0, "title": "C: State of computational genomics", "unanswered": false, "content": "Thanks for fixing the typo , was working on something else while posting this hence overlooked it.", "comment_count": 0, "html": "<p>Thanks for fixing the typo , was working on something else while posting this hence overlooked it.</p>", "child_count": 0, "closed": false, "tree_id": 40, "revision_count": 0, "parent": 139, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-state-of-computational-genomics", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 6}}, {"pk": 583, "model": "server.post", "fields": {"rght": 8, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 09:18:13", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: What is your experience with the STRING (interactions) database?", "unanswered": false, "content": "I looked at the genes in the pathway that I studied and I have found a lot of errors, including genes with similar names being merged as one, and many false positives due to genes being in the same pathway in some database. And my pathway is not exactly badly annotated, it was already described in the '80s...", "comment_count": 0, "html": "<p>I looked at the genes in the pathway that I studied and I have found a lot of errors, including genes with similar names being merged as one, and many false positives due to genes being in the same pathway in some database. And my pathway is not exactly badly annotated, it was already described in the '80s...</p>", "child_count": 0, "closed": false, "tree_id": 17, "revision_count": 0, "parent": 170, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-what-is-your-experience-with-the-string-interactions-database", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 584, "model": "server.post", "fields": {"rght": 13, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 12:03:10", "lft": 12, "post_type": 206247, "score": 0, "title": "C: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "Why preinstalled?  If you can maintain a Linux server to host bioinformatics apps, you can surely install CentOS as well.  Or are you after a mangaged solution?  Have you thought about just having a VM hosted somewhere?", "comment_count": 0, "html": "<p>Why preinstalled?  If you can maintain a Linux server to host bioinformatics apps, you can surely install CentOS as well.  Or are you after a mangaged solution?  Have you thought about just having a VM hosted somewhere?</p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 0, "parent": 168, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 585, "model": "server.post", "fields": {"rght": 4, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 12:45:23", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "I would argue that the installation of new and/or interdependent software packages is easiest on Linux, because the package management system takes care of resolving all dependencies.", "comment_count": 0, "html": "<p>I would argue that the installation of new and/or interdependent software packages is easiest on Linux, because the package management system takes care of resolving all dependencies.</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 0, "parent": 35, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 586, "model": "server.post", "fields": {"rght": 14, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 13:08:31", "lft": 13, "post_type": 206247, "score": 1, "title": "C: A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "thanks for the answer. I think there are at least two distributions called 'biolinux' and 'bio-linux', and they are different, one is based on rpm and the other on deb. I contributed a bit to debian-med in the past, but it is more aimed at medics (there is should be also a debian-science distro).", "comment_count": 0, "html": "<p>thanks for the answer. I think there are at least two distributions called 'biolinux' and 'bio-linux', and they are different, one is based on rpm and the other on deb. I contributed a bit to debian-med in the past, but it is more aimed at medics (there is should be also a debian-science distro).</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 0, "parent": 177, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 587, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 13:33:38", "lft": 2, "post_type": 206247, "score": 0, "title": "C: How to charecterize a residue in a protein based on it's ASA", "unanswered": false, "content": "It might probably help if you gave the full reference to the paper that you mention. ", "comment_count": 0, "html": "<p>It might probably help if you gave the full reference to the paper that you mention. </p>", "child_count": 0, "closed": false, "tree_id": 46, "revision_count": 0, "parent": 173, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-how-to-charecterize-a-residue-in-a-protein-based-on-its-asa", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 588, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 13:35:14", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: How far does bioinformatics go?", "unanswered": false, "content": "Wow. That's a pretty good history lesson! Thanks!", "comment_count": 0, "html": "<p>Wow. That's a pretty good history lesson! Thanks!</p>", "child_count": 0, "closed": false, "tree_id": 42, "revision_count": 0, "parent": 175, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-far-does-bioinformatics-go", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 589, "model": "server.post", "fields": {"rght": 10, "author": 55, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 15:18:37", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "I second the System76 recommendation. Bought a laptop from them and have been very happy.", "comment_count": 0, "html": "<p>I second the System76 recommendation. Bought a laptop from them and have been very happy.</p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 0, "parent": 174, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 55}}, {"pk": 590, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 15:34:20", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "What a great story! Thanks for sharing.", "comment_count": 0, "html": "<p>What a great story! Thanks for sharing.</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 0, "parent": 184, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 591, "model": "server.post", "fields": {"rght": 4, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 16:45:35", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: merging blastx hits from overlapping bacterial genome segments", "unanswered": false, "content": "Seems that I am missing hits to some fragments, therefore I will have to go down in fragment size and increase the proportion of the overlap. Average predicted gene size is 274 aa, so I will try 1kb fragments with 500bp overlaps next. ", "comment_count": 0, "html": "<p>Seems that I am missing hits to some fragments, therefore I will have to go down in fragment size and increase the proportion of the overlap. Average predicted gene size is 274 aa, so I will try 1kb fragments with 500bp overlaps next. </p>", "child_count": 0, "closed": false, "tree_id": 51, "revision_count": 0, "parent": 188, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-merging-blastx-hits-from-overlapping-bacterial-genome-segments", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 592, "model": "server.post", "fields": {"rght": 4, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 16:46:42", "lft": 3, "post_type": 206247, "score": 1, "title": "C: A: I was studying a gene but it disappeared in the latest ensembl release. What should I do now?", "unanswered": false, "content": "they merged it with another gene, with a similar name. Now, there is a gene in ensembl with three transcripts, two of which are localizated in the nucleus and are ribonucleoproteins, and the other is in the ER and catalyze a completely different reaction.", "comment_count": 0, "html": "<p>they merged it with another gene, with a similar name. Now, there is a gene in ensembl with three transcripts, two of which are localizated in the nucleus and are ribonucleoproteins, and the other is in the ER and catalyze a completely different reaction.</p>", "child_count": 0, "closed": false, "tree_id": 47, "revision_count": 0, "parent": 179, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-i-was-studying-a-gene-but-it-disappeared-in-the-latest-ensembl-release-what-should-i-do-now", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 593, "model": "server.post", "fields": {"rght": 17, "author": 81, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 16:53:56", "lft": 16, "post_type": 206247, "score": 0, "title": "C: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "Sometimes the powers that be like things such as service contracts, which tend to be hard to get if the OS isn't preinstalled.", "comment_count": 0, "html": "<p>Sometimes the powers that be like things such as service contracts, which tend to be hard to get if the OS isn't preinstalled.</p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 0, "parent": 168, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:49:00", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 81}}, {"pk": 594, "model": "server.post", "fields": {"rght": 4, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 17:07:53", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "unanswered": false, "content": "not including BioPython because it is not supported in Python 3 seems like a terrible decision", "comment_count": 0, "html": "<p>not including BioPython because it is not supported in Python 3 seems like a terrible decision</p>", "child_count": 0, "closed": false, "tree_id": 50, "revision_count": 0, "parent": 190, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-provide-a-book-review-for-bioinformatics-programming-using-python-by-mitchell-l-model", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 595, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 17:09:23", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "unanswered": false, "content": "Not including BioPython because it is not supported in Python 3 sounds like a bad decision.", "comment_count": 0, "html": "<p>Not including BioPython because it is not supported in Python 3 sounds like a bad decision.</p>", "child_count": 0, "closed": false, "tree_id": 50, "revision_count": 0, "parent": 190, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-provide-a-book-review-for-bioinformatics-programming-using-python-by-mitchell-l-model", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 596, "model": "server.post", "fields": {"rght": 10, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 20:00:17", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "Fixed your links - nice reviews!", "comment_count": 0, "html": "<p>Fixed your links - nice reviews!</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 0, "parent": 192, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 597, "model": "server.post", "fields": {"rght": 8, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 20:25:11", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How far does bioinformatics go?", "unanswered": false, "content": "So, according to this list Bioinfo is genome only, right?", "comment_count": 0, "html": "<p>So, according to this list Bioinfo is genome only, right?</p>", "child_count": 0, "closed": false, "tree_id": 42, "revision_count": 0, "parent": 175, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:00", "slug": "c-a-how-far-does-bioinformatics-go", "lastedit_date": "2011-11-24 14:49:00", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 598, "model": "server.post", "fields": {"rght": 10, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 21:44:13", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: What is your experience with the STRING (interactions) database?", "unanswered": false, "content": "Have you looked at their web site or downloadable files ? AFAIK, STRING basically use Ensembl IDs in their PPI files but provide another mapping file to map from other identitfiers. The problem of mapping a gene to a pathway is always not a direct approach, think of this scenario : 1 gene, n transcript and one of them could go in to pathway. 'n' transcripts code for n splice variants of same protein, so it is not wrong in merging the IDs of transcripts to one gene ID.", "comment_count": 0, "html": "<p>Have you looked at their web site or downloadable files ? AFAIK, STRING basically use Ensembl IDs in their PPI files but provide another mapping file to map from other identitfiers. The problem of mapping a gene to a pathway is always not a direct approach, think of this scenario : 1 gene, n transcript and one of them could go in to pathway. 'n' transcripts code for n splice variants of same protein, so it is not wrong in merging the IDs of transcripts to one gene ID.</p>", "child_count": 0, "closed": false, "tree_id": 17, "revision_count": 0, "parent": 170, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-what-is-your-experience-with-the-string-interactions-database", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 599, "model": "server.post", "fields": {"rght": 19, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 21:48:35", "lft": 18, "post_type": 206247, "score": 0, "title": "C: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "Daniel, True. Back in India, in my lab we used to get Systems engineers to help us with O/S or any critical systems issues. I can install and CentOS and get it up and running, but it need considerable amount to tweak things. I am looking for something like a pre-installed OS with a service contract. I already got some quotes. But, don't have any experience with the vendors in US. ", "comment_count": 0, "html": "<p>Daniel, True. Back in India, in my lab we used to get Systems engineers to help us with O/S or any critical systems issues. I can install and CentOS and get it up and running, but it need considerable amount to tweak things. I am looking for something like a pre-installed OS with a service contract. I already got some quotes. But, don't have any experience with the vendors in US. </p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 0, "parent": 168, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 600, "model": "server.post", "fields": {"rght": 21, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 21:49:03", "lft": 20, "post_type": 206247, "score": 0, "title": "C: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "Thanks for your point geoff ", "comment_count": 0, "html": "<p>Thanks for your point geoff </p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 0, "parent": 168, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 601, "model": "server.post", "fields": {"rght": 4, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 21:50:16", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "Egon thanks for the suggestion. I am afraid we are on a tight budget as of now. May be later we will try Ubuntu Amazon EC2. ", "comment_count": 0, "html": "<p>Egon thanks for the suggestion. I am afraid we are on a tight budget as of now. May be later we will try Ubuntu Amazon EC2. </p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 0, "parent": 172, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 602, "model": "server.post", "fields": {"rght": 8, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-05 22:22:07", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "Thanks Geoff. I will look the URL.", "comment_count": 0, "html": "<p>Thanks Geoff. I will look the URL.</p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 0, "parent": 189, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 603, "model": "server.post", "fields": {"rght": 4, "author": 26, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 16:34:42", "lft": 3, "post_type": 206247, "score": 1, "title": "C: A: How to do quality trimming of SoLid Reads in colour space?", "unanswered": false, "content": "Thanks a lot for your kind help, the number of dots in csfasta reads does become lower.", "comment_count": 0, "html": "<p>Thanks a lot for your kind help, the number of dots in csfasta reads does become lower.</p>", "child_count": 0, "closed": false, "tree_id": 20, "revision_count": 0, "parent": 55, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-how-to-do-quality-trimming-of-solid-reads-in-colour-space", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 26}}, {"pk": 604, "model": "server.post", "fields": {"rght": 22, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 18:18:25", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: Using HDF5 to store  bio-data", "unanswered": false, "content": "thanks, that's very useful too", "comment_count": 0, "html": "<p>thanks, that's very useful too</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 0, "parent": 213, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 605, "model": "server.post", "fields": {"rght": 4, "author": 78, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-06 22:07:35", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Score protein variants based on frequency of AA in multiple sequence alignment", "unanswered": false, "content": "I want to do this programmatically, so I can do this scoring thousands of times.. Manual wont do, and using curl for this seems hackish, unreliable & sensitive to change.", "comment_count": 0, "html": "<p>I want to do this programmatically, so I can do this scoring thousands of times.. Manual wont do, and using curl for this seems hackish, unreliable &amp; sensitive to change.</p>", "child_count": 0, "closed": false, "tree_id": 49, "revision_count": 0, "parent": 199, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-score-protein-variants-based-on-frequency-of-aa-in-multiple-sequence-alignment", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 78}}, {"pk": 606, "model": "server.post", "fields": {"rght": 36, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 03:34:53", "lft": 35, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "I guess it is hard to improve on a time tested approach such as make. Thanks for the review of ruffus.", "comment_count": 0, "html": "<p>I guess it is hard to improve on a time tested approach such as make. Thanks for the review of ruffus.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 220, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 607, "model": "server.post", "fields": {"rght": 26, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 04:15:14", "lft": 25, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "paver does look like a good option, falling somewhere between a makefile and ruffus. http://blog.doughellmann.com/2009/01/converting-from-make-to-paver.html", "comment_count": 0, "html": "<p>paver does look like a good option, falling somewhere between a makefile and ruffus. http://blog.doughellmann.com/2009/01/converting-from-make-to-paver.html</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 218, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 35}}, {"pk": 608, "model": "server.post", "fields": {"rght": 34, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 11:53:53", "lft": 33, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "Try argparse (http://code.google.com/p/argparse/) which is an extended argument parse library for python. I had a similar experience with ruffus, as I have tried it and then reverted to makefiles. I think the est is still biomake.", "comment_count": 0, "html": "<p>Try argparse (http://code.google.com/p/argparse/) which is an extended argument parse library for python. I had a similar experience with ruffus, as I have tried it and then reverted to makefiles. I think the est is still biomake.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 220, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 609, "model": "server.post", "fields": {"rght": 6, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 13:21:09", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Score protein variants based on frequency of AA in multiple sequence alignment", "unanswered": false, "content": "The form on the above page triggers http://strand.imb.ac.ru/PSIC-cgi/run.pl so that Perl script probably has the code you're looking for. Maybe mail the webmaster (vlasov@imb.imb.ac.ru) or the authors of the article for a copy of that code?", "comment_count": 0, "html": "<p>The form on the above page triggers http://strand.imb.ac.ru/PSIC-cgi/run.pl so that Perl script probably has the code you're looking for. Maybe mail the webmaster (vlasov@imb.imb.ac.ru) or the authors of the article for a copy of that code?</p>", "child_count": 0, "closed": false, "tree_id": 49, "revision_count": 0, "parent": 199, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-score-protein-variants-based-on-frequency-of-aa-in-multiple-sequence-alignment", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 610, "model": "server.post", "fields": {"rght": 3, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 13:21:19", "lft": 2, "post_type": 206247, "score": 0, "title": "C: How to find a 28bp 'primer' sequence in a genome?", "unanswered": false, "content": "do you need some random primers or do you know your 500 targets ?", "comment_count": 0, "html": "<p>do you need some random primers or do you know your 500 targets ?</p>", "child_count": 0, "closed": false, "tree_id": 56, "revision_count": 0, "parent": 222, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-how-to-find-a-28bp-primer-sequence-in-a-genome", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 611, "model": "server.post", "fields": {"rght": 6, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 14:29:45", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: What is the best place in the world to do Bioinformatics?", "unanswered": false, "content": "haha that's great. i think a quality physical work environment is underrated. i would also demand two monitors or one very large one.", "comment_count": 0, "html": "<p>haha that's great. i think a quality physical work environment is underrated. i would also demand two monitors or one very large one.</p>", "child_count": 0, "closed": false, "tree_id": 39, "revision_count": 0, "parent": 165, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-what-is-the-best-place-in-the-world-to-do-bioinformatics", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 612, "model": "server.post", "fields": {"rght": 9, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-07 18:55:34", "lft": 8, "post_type": 206247, "score": 1, "title": "C: How to find a 28bp 'primer' sequence in a genome?", "unanswered": false, "content": "I think you need to be more specific with your question: what are you trying to do? 500 pairs of \"primers\": are you targeting something in particular or just random? Will these sequences be used for wet lab experiments like PCR or qPCR? Etc.", "comment_count": 0, "html": "<p>I think you need to be more specific with your question: what are you trying to do? 500 pairs of \"primers\": are you targeting something in particular or just random? Will these sequences be used for wet lab experiments like PCR or qPCR? Etc.</p>", "child_count": 0, "closed": false, "tree_id": 56, "revision_count": 0, "parent": 222, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-how-to-find-a-28bp-primer-sequence-in-a-genome", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 613, "model": "server.post", "fields": {"rght": 8, "author": 107, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 08:42:58", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: What methods do you use for short read mapping?", "unanswered": false, "content": "So you're only interested in exact matches, did I get that right? If not, what is your strategy to find inexact matches?", "comment_count": 0, "html": "<p>So you're only interested in exact matches, did I get that right? If not, what is your strategy to find inexact matches?</p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 0, "parent": 140, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 107}}, {"pk": 614, "model": "server.post", "fields": {"rght": 10, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 13:05:55", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: What methods do you use for short read mapping?", "unanswered": false, "content": "yes, only extact matches", "comment_count": 0, "html": "<p>yes, only extact matches</p>", "child_count": 0, "closed": false, "tree_id": 38, "revision_count": 0, "parent": 140, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-what-methods-do-you-use-for-short-read-mapping", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 615, "model": "server.post", "fields": {"rght": 8, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 15:56:54", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How to find a 28bp 'primer' sequence in a genome?", "unanswered": false, "content": "thanks for the links, didn't know about that.", "comment_count": 0, "html": "<p>thanks for the links, didn't know about that.</p>", "child_count": 0, "closed": false, "tree_id": 56, "revision_count": 0, "parent": 231, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-find-a-28bp-primer-sequence-in-a-genome", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 35}}, {"pk": 616, "model": "server.post", "fields": {"rght": 4, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 17:11:47", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: k-mer based sequencing contamination detection", "unanswered": false, "content": "Thank you, that's a very useful tip. \n\nIt is quite fast to count all 4-mers in my draft sequence. I think I have to count them on a reverse strand and add it to forward counts (done). For implementing TETRA-measure I will start with RPy.   \n    ", "comment_count": 0, "html": "<p>Thank you, that's a very useful tip. </p>\n<p>It is quite fast to count all 4-mers in my draft sequence. I think I have to count them on a reverse strand and add it to forward counts (done). For implementing TETRA-measure I will start with RPy. <br />\n<div class=\"highlight\"><pre>    \n</pre></div>\n</p>", "child_count": 0, "closed": false, "tree_id": 36, "revision_count": 0, "parent": 197, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-k-mer-based-sequencing-contamination-detection", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 617, "model": "server.post", "fields": {"rght": 4, "author": 113, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 20:30:14", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Computing the reverse and complement of a sequence with Pygr", "unanswered": false, "content": "Please place the reason for closing a question in the question's comments, not as an answer, since it's a comment, not an answer.", "comment_count": 0, "html": "<p>Please place the reason for closing a question in the question's comments, not as an answer, since it's a comment, not an answer.</p>", "child_count": 0, "closed": false, "tree_id": 29, "revision_count": 0, "parent": 230, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-computing-the-reverse-and-complement-of-a-sequence-with-pygr", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 113}}, {"pk": 618, "model": "server.post", "fields": {"rght": 9, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 21:45:12", "lft": 8, "post_type": 206247, "score": 0, "title": "C: Computing the reverse and complement of a sequence with Pygr", "unanswered": false, "content": "This post was not formulated in a question/answer format therefore will be closed.", "comment_count": 0, "html": "<p>This post was not formulated in a question/answer format therefore will be closed.</p>", "child_count": 0, "closed": false, "tree_id": 29, "revision_count": 0, "parent": 92, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-computing-the-reverse-and-complement-of-a-sequence-with-pygr", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 619, "model": "server.post", "fields": {"rght": 6, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-08 23:12:16", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Compute genetic map", "unanswered": false, "content": "I doubt you can get better resolution since centimorgan is experimental unit for recombination frequency. It does not correlate well with base pairs, which depends on genomic position. In human it approximately 1 Mbp in average.", "comment_count": 0, "html": "<p>I doubt you can get better resolution since centimorgan is experimental unit for recombination frequency. It does not correlate well with base pairs, which depends on genomic position. In human it approximately 1 Mbp in average.</p>", "child_count": 0, "closed": false, "tree_id": 52, "revision_count": 0, "parent": 227, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-compute-genetic-map", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 620, "model": "server.post", "fields": {"rght": 17, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 04:51:35", "lft": 2, "post_type": 206247, "score": 0, "title": "C: How to determine if a gene is active from expression data", "unanswered": false, "content": "I think it would help to elaborate on what the \"produce enough protein to have an effect\" means. ", "comment_count": 0, "html": "<p>I think it would help to elaborate on what the \"produce enough protein to have an effect\" means. </p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 0, "parent": 238, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 621, "model": "server.post", "fields": {"rght": 21, "author": 89, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 06:20:49", "lft": 20, "post_type": 206247, "score": 0, "title": "C: How to determine if a gene is active from expression data", "unanswered": false, "content": "Sorry, I was to vague here. I am looking at the effects of a certain set of transcription factors in a certain tissue. There seem to be some interesting patterns of co-operation between them. Whether these TFs are able to interact in the first place depends on whether all of them are actually expressed in this tissue. That's what I want to find out with this exercise. -- Thanks for your help !", "comment_count": 0, "html": "<p>Sorry, I was to vague here. I am looking at the effects of a certain set of transcription factors in a certain tissue. There seem to be some interesting patterns of co-operation between them. Whether these TFs are able to interact in the first place depends on whether all of them are actually expressed in this tissue. That's what I want to find out with this exercise. -- Thanks for your help !</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 0, "parent": 238, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 89}}, {"pk": 622, "model": "server.post", "fields": {"rght": 10, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 12:15:08", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: How do I map, align, and plot my SOLiD results?", "unanswered": false, "content": "+1 for Bowtie, I find that very useful", "comment_count": 0, "html": "<p>+1 for Bowtie, I find that very useful</p>", "child_count": 0, "closed": false, "tree_id": 13, "revision_count": 0, "parent": 208, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-do-i-map-align-and-plot-my-solid-results", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 118}}, {"pk": 623, "model": "server.post", "fields": {"rght": 15, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 13:00:51", "lft": 14, "post_type": 206247, "score": 0, "title": "C: How to find a 28bp 'primer' sequence in a genome?", "unanswered": false, "content": "Yes, please be more clear.  Do you (1) have 500 forward and reverse 28 bp sequences that you wish to *align* to the genome sequence?  Or (2) want to *generate* 500 forward/reverse primers using the genome sequence?", "comment_count": 0, "html": "<p>Yes, please be more clear.  Do you (1) have 500 forward and reverse 28 bp sequences that you wish to <em>align</em> to the genome sequence?  Or (2) want to <em>generate</em> 500 forward/reverse primers using the genome sequence?</p>", "child_count": 0, "closed": false, "tree_id": 56, "revision_count": 0, "parent": 222, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-how-to-find-a-28bp-primer-sequence-in-a-genome", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 624, "model": "server.post", "fields": {"rght": 10, "author": 74, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 14:59:28", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Which operating system do you prefer for bioinformatics?", "unanswered": false, "content": "Porticus (http://porticus.alittledrop.com/) is a GUI for MacPorts that  makes the installation of unix software as simple as using the Synaptic Frontend on debian/ubuntu.", "comment_count": 0, "html": "<p>Porticus (http://porticus.alittledrop.com/) is a GUI for MacPorts that  makes the installation of unix software as simple as using the Synaptic Frontend on debian/ubuntu.</p>", "child_count": 0, "closed": false, "tree_id": 14, "revision_count": 0, "parent": 37, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-which-operating-system-do-you-prefer-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 74}}, {"pk": 625, "model": "server.post", "fields": {"rght": 4, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 15:33:24", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How to determine if a gene is active from expression data", "unanswered": false, "content": "I agree, using the background level as noise and using that as not-expressed at all sounds like a good approach", "comment_count": 0, "html": "<p>I agree, using the background level as noise and using that as not-expressed at all sounds like a good approach</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 0, "parent": 239, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 626, "model": "server.post", "fields": {"rght": 10, "author": 71, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 16:37:05", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: How Important is it to belong to a Professional Society in Computational Biology?", "unanswered": false, "content": "I have to agree with Neil.  I have gained a lot more from informal social networks.  In the end societies are about networking and certain, usually unimportant, membership benefits and there are better ways to network now.", "comment_count": 0, "html": "<p>I have to agree with Neil.  I have gained a lot more from informal social networks.  In the end societies are about networking and certain, usually unimportant, membership benefits and there are better ways to network now.</p>", "child_count": 0, "closed": false, "tree_id": 58, "revision_count": 0, "parent": 237, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-important-is-it-to-belong-to-a-professional-society-in-computational-biology", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 71}}, {"pk": 627, "model": "server.post", "fields": {"rght": 6, "author": 112, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 17:26:02", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: How do I map, align, and plot my SOLiD results?", "unanswered": false, "content": "Use the direct url, as it has been split from the MAQ project: http://bio-bwa.sourceforge.net/", "comment_count": 0, "html": "<p>Use the direct url, as it has been split from the MAQ project: http://bio-bwa.sourceforge.net/</p>", "child_count": 0, "closed": false, "tree_id": 13, "revision_count": 0, "parent": 54, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-do-i-map-align-and-plot-my-solid-results", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 112}}, {"pk": 628, "model": "server.post", "fields": {"rght": 4, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 19:50:51", "lft": 3, "post_type": 206247, "score": 1, "title": "C: A: Tools to find gene ontology term enrichment", "unanswered": false, "content": "I also like DAVID.\n\nIf you're ruby users, I wrote a very basic library that allows you to query DAVID from your scripts: http://github.com/chrisamiller/davidapi", "comment_count": 0, "html": "<p>I also like DAVID.</p>\n<p>If you're ruby users, I wrote a very basic library that allows you to query DAVID from your scripts: http://github.com/chrisamiller/davidapi</p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 0, "parent": 246, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 629, "model": "server.post", "fields": {"rght": 16, "author": 89, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 22:55:50", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: How to determine if a gene is active from expression data", "unanswered": false, "content": "Thanks for this detailed reply! Those are really great references you pointed me to !", "comment_count": 0, "html": "<p>Thanks for this detailed reply! Those are really great references you pointed me to !</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 0, "parent": 248, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 89}}, {"pk": 630, "model": "server.post", "fields": {"rght": 6, "author": 89, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 22:57:47", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: How to determine if a gene is active from expression data", "unanswered": false, "content": "That sounds like the approach I'm after. How would I determine the noise level thought?", "comment_count": 0, "html": "<p>That sounds like the approach I'm after. How would I determine the noise level thought?</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 0, "parent": 239, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 89}}, {"pk": 631, "model": "server.post", "fields": {"rght": 8, "author": 89, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 23:01:46", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How to determine if a gene is active from expression data", "unanswered": false, "content": "Thanks for this detailed reply! Those are really great references you pointed me to! However, determining how much proteins are actually produced from the transcribed mRNA is going into too much detail for this project.  ", "comment_count": 0, "html": "<p>Thanks for this detailed reply! Those are really great references you pointed me to! However, determining how much proteins are actually produced from the transcribed mRNA is going into too much detail for this project.<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 0, "parent": 248, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 89}}, {"pk": 632, "model": "server.post", "fields": {"rght": 10, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-09 23:18:48", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: How to determine if a gene is active from expression data", "unanswered": false, "content": "The point is that no amount of mRNA will tell you if the protein is present and in what amount... And even less if there is a biological impact by the proteins produced.", "comment_count": 0, "html": "<p>The point is that no amount of mRNA will tell you if the protein is present and in what amount... And even less if there is a biological impact by the proteins produced.</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 0, "parent": 248, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 633, "model": "server.post", "fields": {"rght": 8, "author": 109, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-10 00:56:10", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Hierarchical Clustering, Cluster Heat Maps in Java", "unanswered": false, "content": "Thank you for making me aware of this. I was interested in knowing if I could use any libraries in Java that have HC already implemented as a method which I could use with the clusters I get and plot them as a cluster heatmap.", "comment_count": 0, "html": "<p>Thank you for making me aware of this. I was interested in knowing if I could use any libraries in Java that have HC already implemented as a method which I could use with the clusters I get and plot them as a cluster heatmap.</p>", "child_count": 0, "closed": false, "tree_id": 57, "revision_count": 0, "parent": 249, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-hierarchical-clustering-cluster-heat-maps-in-java", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 109}}, {"pk": 634, "model": "server.post", "fields": {"rght": 10, "author": 109, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-10 00:58:45", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Hierarchical Clustering, Cluster Heat Maps in Java", "unanswered": false, "content": "Thank you, I didnt know about this. I was actually more interested in knowing if any libraries in Java already have this method of generating cluster heat maps implemented, which I could use with the clusters that I generate.", "comment_count": 0, "html": "<p>Thank you, I didnt know about this. I was actually more interested in knowing if any libraries in Java already have this method of generating cluster heat maps implemented, which I could use with the clusters that I generate.</p>", "child_count": 0, "closed": false, "tree_id": 57, "revision_count": 0, "parent": 249, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-hierarchical-clustering-cluster-heat-maps-in-java", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 109}}, {"pk": 635, "model": "server.post", "fields": {"rght": 4, "author": 109, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-10 00:59:08", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Hierarchical Clustering, Cluster Heat Maps in Java", "unanswered": false, "content": "Thanks Istvan. will look at this.", "comment_count": 0, "html": "<p>Thanks Istvan. will look at this.</p>", "child_count": 0, "closed": false, "tree_id": 57, "revision_count": 0, "parent": 229, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-hierarchical-clustering-cluster-heat-maps-in-java", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 109}}, {"pk": 636, "model": "server.post", "fields": {"rght": 12, "author": 89, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-10 02:37:20", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: How to determine if a gene is active from expression data", "unanswered": false, "content": "I agree, theis statement in my question was quite confusing. What I'm after is just a rough classification for the proteins in \"probably there\" or not. (I'm looking forward to reading the publication you hinted at)", "comment_count": 0, "html": "<p>I agree, theis statement in my question was quite confusing. What I'm after is just a rough classification for the proteins in \"probably there\" or not. (I'm looking forward to reading the publication you hinted at)</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 0, "parent": 248, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 89}}, {"pk": 637, "model": "server.post", "fields": {"rght": 14, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-10 08:25:14", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: How to determine if a gene is active from expression data", "unanswered": false, "content": "Ahh I'm struggling with quite a few things more urgent. I'm afraid it might stay on the shelf for a while (I hope not forever though)... Wet lab can be EXTREMELY frustrating :(", "comment_count": 0, "html": "<p>Ahh I'm struggling with quite a few things more urgent. I'm afraid it might stay on the shelf for a while (I hope not forever though)... Wet lab can be EXTREMELY frustrating :(</p>", "child_count": 0, "closed": false, "tree_id": 59, "revision_count": 0, "parent": 248, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-determine-if-a-gene-is-active-from-expression-data", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 638, "model": "server.post", "fields": {"rght": 8, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-10 15:33:59", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Using HDF5 to store  bio-data", "unanswered": false, "content": "In case you did not look at it yet:\nhttp://www.hdfgroup.org/HDF5/doc/H5.intro.html\nhttp://www.hdfgroup.org/HDF5/doc/Intro/IntroExamples.html\n", "comment_count": 0, "html": "<p>In case you did not look at it yet:\nhttp://www.hdfgroup.org/HDF5/doc/H5.intro.html\nhttp://www.hdfgroup.org/HDF5/doc/Intro/IntroExamples.html</p>", "child_count": 0, "closed": false, "tree_id": 23, "revision_count": 0, "parent": 71, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-using-hdf5-to-store-bio-data", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 639, "model": "server.post", "fields": {"rght": 5, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-10 23:54:06", "lft": 2, "post_type": 206247, "score": 0, "title": "C: How can a base-called position be \"unknown\" but have a non-minimal score?", "unanswered": false, "content": "Which platform is this data from?", "comment_count": 0, "html": "<p>Which platform is this data from?</p>", "child_count": 0, "closed": false, "tree_id": 62, "revision_count": 0, "parent": 255, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-how-can-a-base-called-position-be-unknown-but-have-a-non-minimal-score", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 640, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 03:41:43", "lft": 2, "post_type": 206247, "score": 0, "title": "C: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "unanswered": false, "content": "Just to clarify the situation: in each of your two sequencing runs you found a single base difference between the two strands, and that difference was in the same position in both cases?  ", "comment_count": 0, "html": "<p>Just to clarify the situation: in each of your two sequencing runs you found a single base difference between the two strands, and that difference was in the same position in both cases?<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 63, "revision_count": 0, "parent": 256, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-if-i-have-4-sequence-runs-2-in-each-direction-1-bp-is-different-on-each-should-i-resequence", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 641, "model": "server.post", "fields": {"rght": 13, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 11:36:52", "lft": 12, "post_type": 206247, "score": 0, "title": "C: Programatic technique for gene-name/id conversion", "unanswered": false, "content": "Which Ids do you want to convert, exactly? I think there is not a single service that can convert between all the most used ids for genes, even biomart and uniprot lack some databases. Look at this question: http://biostar.stackexchange.com/questions/22/gene-id-conversion-tool", "comment_count": 0, "html": "<p>Which Ids do you want to convert, exactly? I think there is not a single service that can convert between all the most used ids for genes, even biomart and uniprot lack some databases. Look at this question: http://biostar.stackexchange.com/questions/22/gene-id-conversion-tool</p>", "child_count": 0, "closed": false, "tree_id": 64, "revision_count": 0, "parent": 258, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-programatic-technique-for-gene-nameid-conversion", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 642, "model": "server.post", "fields": {"rght": 9, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 15:28:17", "lft": 8, "post_type": 206247, "score": 0, "title": "C: How can a base-called position be \"unknown\" but have a non-minimal score?", "unanswered": false, "content": "illumina - maybe v1.3", "comment_count": 0, "html": "<p>illumina - maybe v1.3</p>", "child_count": 0, "closed": false, "tree_id": 62, "revision_count": 0, "parent": 255, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-how-can-a-base-called-position-be-unknown-but-have-a-non-minimal-score", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 643, "model": "server.post", "fields": {"rght": 4, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-11 18:00:38", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How can a base-called position be \"unknown\" but have a non-minimal score?", "unanswered": false, "content": "I'll get on board with this answer. It's pretty easy to envision a scenario where the actual base call and the quality score get adjusted by separate processes at some point.", "comment_count": 0, "html": "<p>I'll get on board with this answer. It's pretty easy to envision a scenario where the actual base call and the quality score get adjusted by separate processes at some point.</p>", "child_count": 0, "closed": false, "tree_id": 62, "revision_count": 0, "parent": 261, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-can-a-base-called-position-be-unknown-but-have-a-non-minimal-score", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 644, "model": "server.post", "fields": {"rght": 6, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 09:18:42", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Tools to find gene ontology term enrichment", "unanswered": false, "content": "DAVID is the one I always recommend to our wet lab biologists too.  It's now been maintained well for several years, unlike many bioinformatics resources..", "comment_count": 0, "html": "<p>DAVID is the one I always recommend to our wet lab biologists too.  It's now been maintained well for several years, unlike many bioinformatics resources..</p>", "child_count": 0, "closed": false, "tree_id": 60, "revision_count": 0, "parent": 246, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-tools-to-find-gene-ontology-term-enrichment", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 645, "model": "server.post", "fields": {"rght": 11, "author": 120, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 09:19:38", "lft": 10, "post_type": 206247, "score": 0, "title": "C: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "unanswered": false, "content": "Thanks all, yes I had two good reads on each strand and the single bp on one of the colonies was different from that of the other colony (I'd picked 3 originally, but one was just an insert).  I went with picking another 2 colonies to be sure.  I'm sequencing ~100 markers though, so I was trying to weigh up the extra $$ / time in sequencing another colony with the extra information a C or T gives me over a Y.  This is only the 15th sequence or so and the first time this has happened, so I'll see how the others turn out before deciding on a general policy.", "comment_count": 0, "html": "<p>Thanks all, yes I had two good reads on each strand and the single bp on one of the colonies was different from that of the other colony (I'd picked 3 originally, but one was just an insert).  I went with picking another 2 colonies to be sure.  I'm sequencing ~100 markers though, so I was trying to weigh up the extra $$ / time in sequencing another colony with the extra information a C or T gives me over a Y.  This is only the 15th sequence or so and the first time this has happened, so I'll see how the others turn out before deciding on a general policy.</p>", "child_count": 0, "closed": false, "tree_id": 63, "revision_count": 0, "parent": 256, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-if-i-have-4-sequence-runs-2-in-each-direction-1-bp-is-different-on-each-should-i-resequence", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 120}}, {"pk": 646, "model": "server.post", "fields": {"rght": 13, "author": 120, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 09:21:49", "lft": 12, "post_type": 206247, "score": 0, "title": "C: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "unanswered": false, "content": "Actually, what I'd really like to know is when you go to publish a sequence like this, how much coverage should you have?  Is it acceptable to put a sequence with a Y into genbank, because you didn't go to the effort / cost of re-sequencing to resolve it?  Or does the Y represent natural variation... and how many would you need to sequence to answer that question... :)", "comment_count": 0, "html": "<p>Actually, what I'd really like to know is when you go to publish a sequence like this, how much coverage should you have?  Is it acceptable to put a sequence with a Y into genbank, because you didn't go to the effort / cost of re-sequencing to resolve it?  Or does the Y represent natural variation... and how many would you need to sequence to answer that question... :)</p>", "child_count": 0, "closed": false, "tree_id": 63, "revision_count": 0, "parent": 256, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-if-i-have-4-sequence-runs-2-in-each-direction-1-bp-is-different-on-each-should-i-resequence", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 120}}, {"pk": 647, "model": "server.post", "fields": {"rght": 24, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 12:15:14", "lft": 23, "post_type": 206247, "score": 0, "title": "C: A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "Yep Mpre or Less is great, and I nearly added it into the list above.  Statistical podcasts are even thinner on the ground than coding ones I suspect!", "comment_count": 0, "html": "<p>Yep Mpre or Less is great, and I nearly added it into the list above.  Statistical podcasts are even thinner on the ground than coding ones I suspect!</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 270, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 648, "model": "server.post", "fields": {"rght": 4, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 12:17:36", "lft": 3, "post_type": 206247, "score": 1, "title": "C: A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "I should also add that things like the MIT Courseware sites are excellent and similar resources: http://ocw.mit.edu/OcwWeb/web/home/home/index.htm\n\n", "comment_count": 0, "html": "<p>I should also add that things like the MIT Courseware sites are excellent and similar resources: http://ocw.mit.edu/OcwWeb/web/home/home/index.htm</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 269, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 649, "model": "server.post", "fields": {"rght": 8, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 14:21:43", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "Thanks Mikael, that's a new one on me - I will give it a whirl", "comment_count": 0, "html": "<p>Thanks Mikael, that's a new one on me - I will give it a whirl</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 272, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 650, "model": "server.post", "fields": {"rght": 9, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 14:56:53", "lft": 2, "post_type": 206247, "score": 0, "title": "C: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": "the program you linked is 14 years old and has the phrase 'old version' in its description. Are you sure you want to use it? ", "comment_count": 0, "html": "<p>the program you linked is 14 years old and has the phrase 'old version' in its description. Are you sure you want to use it? </p>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 0, "parent": 271, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 651, "model": "server.post", "fields": {"rght": 15, "author": 71, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 15:00:51", "lft": 14, "post_type": 206247, "score": 2, "title": "C: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "We should be back next week and given our absence from the airwaves lots to cover and some interviews lined up", "comment_count": 0, "html": "<p>We should be back next week and given our absence from the airwaves lots to cover and some interviews lined up</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 71}}, {"pk": 652, "model": "server.post", "fields": {"rght": 16, "author": 71, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 15:01:36", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "Agreed.  FIB can be pretty good.  There was a recent episode (poor audio) with David Haussler you could start with.", "comment_count": 0, "html": "<p>Agreed.  FIB can be pretty good.  There was a recent episode (poor audio) with David Haussler you could start with.</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 272, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 71}}, {"pk": 653, "model": "server.post", "fields": {"rght": 31, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 15:14:50", "lft": 30, "post_type": 206247, "score": 0, "title": "C: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "@mndoci - This is excellent news!", "comment_count": 0, "html": "<p>@mndoci - This is excellent news!</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 654, "model": "server.post", "fields": {"rght": 33, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 15:22:45", "lft": 32, "post_type": 206247, "score": 0, "title": "C: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "Deepak - that is good news, I think you should know the podcast is quite sorely missed between episodes!", "comment_count": 0, "html": "<p>Deepak - that is good news, I think you should know the podcast is quite sorely missed between episodes!</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 655, "model": "server.post", "fields": {"rght": 11, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 15:46:42", "lft": 10, "post_type": 206247, "score": 0, "title": "C: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": "Maybe, you should be more specific about what you really want to do? It looks a bit like you already have the solution in the web-site you linked. So, what do you really want to do with your tRNA sequences, what is the problem you are trying to solve?\nThis would really help people to provide a good answer.", "comment_count": 0, "html": "<p>Maybe, you should be more specific about what you really want to do? It looks a bit like you already have the solution in the web-site you linked. So, what do you really want to do with your tRNA sequences, what is the problem you are trying to solve?\nThis would really help people to provide a good answer.</p>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 0, "parent": 271, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 656, "model": "server.post", "fields": {"rght": 4, "author": 83, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 15:55:06", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "unanswered": false, "content": "Thanks Istvan for your suggestion. I will work on the same lines.", "comment_count": 0, "html": "<p>Thanks Istvan for your suggestion. I will work on the same lines.</p>", "child_count": 0, "closed": false, "tree_id": 43, "revision_count": 0, "parent": 163, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-implementation-of-blosum62-in-the-source-code-of-global-pairwise-alignment-of-proteins", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 83}}, {"pk": 657, "model": "server.post", "fields": {"rght": 6, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 16:05:52", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Programatic technique for gene-name/id conversion", "unanswered": false, "content": "I should note that DAVIS has an API: http://david.abcc.ncifcrf.gov/content.jsp?file=DAVID_API.html but it doesn't seem to cover their ID mapping service.", "comment_count": 0, "html": "<p>I should note that DAVIS has an API: http://david.abcc.ncifcrf.gov/content.jsp?file=DAVID_API.html but it doesn't seem to cover their ID mapping service.</p>", "child_count": 0, "closed": false, "tree_id": 64, "revision_count": 0, "parent": 266, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-programatic-technique-for-gene-nameid-conversion", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 658, "model": "server.post", "fields": {"rght": 8, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 16:06:27", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Programatic technique for gene-name/id conversion", "unanswered": false, "content": "Oh and also, Tim Yates has written a Groovy version of my code, above: http://gist.github.com/330312", "comment_count": 0, "html": "<p>Oh and also, Tim Yates has written a Groovy version of my code, above: http://gist.github.com/330312</p>", "child_count": 0, "closed": false, "tree_id": 64, "revision_count": 0, "parent": 266, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-programatic-technique-for-gene-nameid-conversion", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 659, "model": "server.post", "fields": {"rght": 10, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 16:07:17", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Programatic technique for gene-name/id conversion", "unanswered": false, "content": "I should note that DAVID has an API: http://david.abcc.ncifcrf.gov/content.jsp?file=DAVID_API.html but it doesn't seem to cover their ID mapping service. ", "comment_count": 0, "html": "<p>I should note that DAVID has an API: http://david.abcc.ncifcrf.gov/content.jsp?file=DAVID_API.html but it doesn't seem to cover their ID mapping service. </p>", "child_count": 0, "closed": false, "tree_id": 64, "revision_count": 0, "parent": 266, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-programatic-technique-for-gene-nameid-conversion", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 660, "model": "server.post", "fields": {"rght": 27, "author": 113, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 17:22:09", "lft": 26, "post_type": 206247, "score": 1, "title": "C: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "If there's such a concept here as Stack Overflow, this should probably be community wiki; helpful links should be curated and compiled in the question.", "comment_count": 0, "html": "<p>If there's such a concept here as Stack Overflow, this should probably be community wiki; helpful links should be curated and compiled in the question.</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 113}}, {"pk": 661, "model": "server.post", "fields": {"rght": 18, "author": 71, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 17:27:59", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "Oooh I need to add that to my list. Always looking for new Ruby-centric podcasts.", "comment_count": 0, "html": "<p>Oooh I need to add that to my list. Always looking for new Ruby-centric podcasts.</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 278, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 71}}, {"pk": 662, "model": "server.post", "fields": {"rght": 4, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 17:28:51", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How to convert BLAST results to GFF", "unanswered": false, "content": "Thanks I'll give it a go. I've never used perl before though. :S", "comment_count": 0, "html": "<p>Thanks I'll give it a go. I've never used perl before though. :S</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 0, "parent": 279, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 663, "model": "server.post", "fields": {"rght": 20, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 17:42:03", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: How to convert BLAST results to GFF", "unanswered": false, "content": "I don't have bioperl on my computer and the documentation states that installing bioperl is \"non-trivial\" which is not encouraging. Perhaps it would be simpler just to write a parser myself.", "comment_count": 0, "html": "<p>I don't have bioperl on my computer and the documentation states that installing bioperl is \"non-trivial\" which is not encouraging. Perhaps it would be simpler just to write a parser myself.</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 0, "parent": 280, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 664, "model": "server.post", "fields": {"rght": 6, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 17:43:11", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: How to convert BLAST results to GFF", "unanswered": false, "content": "I just got a bunch of errors with this. :(\n\n\"Use of uninitialized value $QEnd in numeric lt (<) at ./Blast2Gff.pl line 161, <BLASTIN> line 12.\"", "comment_count": 0, "html": "<p>I just got a bunch of errors with this. :(</p>\n<p>\"Use of uninitialized value $QEnd in numeric lt (&lt;) at ./Blast2Gff.pl line 161, [HTML_REMOVED] line 12.\"</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 0, "parent": 279, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 665, "model": "server.post", "fields": {"rght": 22, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 17:54:02", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "So up-vote me! ;)", "comment_count": 0, "html": "<p>So up-vote me! ;)</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 278, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 666, "model": "server.post", "fields": {"rght": 10, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 17:59:17", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: How to convert BLAST results to GFF", "unanswered": false, "content": "Sorry I'm not a perl guru too :-P", "comment_count": 0, "html": "<p>Sorry I'm not a perl guru too :-P</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 0, "parent": 279, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 667, "model": "server.post", "fields": {"rght": 41, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 18:29:55", "lft": 40, "post_type": 206247, "score": 0, "title": "C: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "Good observation, I turned the question into a community wiki", "comment_count": 0, "html": "<p>Good observation, I turned the question into a community wiki</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 268, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 668, "model": "server.post", "fields": {"rght": 18, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 18:59:33", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: How to convert BLAST results to GFF", "unanswered": false, "content": "The blast2Gff.pl looks as if it uses Blast tabular format, did you try this?", "comment_count": 0, "html": "<p>The blast2Gff.pl looks as if it uses Blast tabular format, did you try this?</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 0, "parent": 279, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 669, "model": "server.post", "fields": {"rght": 8, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 21:39:54", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How to convert BLAST results to GFF", "unanswered": false, "content": "Using the examples this was relatively simple to do. The GFF3 validator helped too.", "comment_count": 0, "html": "<p>Using the examples this was relatively simple to do. The GFF3 validator helped too.</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 0, "parent": 281, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 670, "model": "server.post", "fields": {"rght": 12, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 21:40:32", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: How to convert BLAST results to GFF", "unanswered": false, "content": "I was using the tab delimited output produced using the -m8 option but I was still getting the error unfortunately.", "comment_count": 0, "html": "<p>I was using the tab delimited output produced using the -m8 option but I was still getting the error unfortunately.</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 0, "parent": 279, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 671, "model": "server.post", "fields": {"rght": 14, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-12 21:41:21", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: How to convert BLAST results to GFF", "unanswered": false, "content": "Thanks for the XLST Pierre. I'm not used to XLST though so it was a bit over my head.", "comment_count": 0, "html": "<p>Thanks for the XLST Pierre. I'm not used to XLST though so it was a bit over my head.</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 0, "parent": 279, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 672, "model": "server.post", "fields": {"rght": 10, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 10:17:00", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "Looks interesting Chris, will certainly give that a try!", "comment_count": 0, "html": "<p>Looks interesting Chris, will certainly give that a try!</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 274, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 673, "model": "server.post", "fields": {"rght": 20, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 13:04:57", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "I second Changelog. I occasionally listen to FLOSS Weekly and IT Conversations too, for programming. Aside from c2cbio, I can't think of another podcast with a strong bioinformatics focus.", "comment_count": 0, "html": "<p>I second Changelog. I occasionally listen to FLOSS Weekly and IT Conversations too, for programming. Aside from c2cbio, I can't think of another podcast with a strong bioinformatics focus.</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 278, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 674, "model": "server.post", "fields": {"rght": 4, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 16:49:10", "lft": 3, "post_type": 206247, "score": 1, "title": "C: A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "+1; among other things I definitely agree on \"understanding theoretical papers\" ", "comment_count": 0, "html": "<p>+1; among other things I definitely agree on \"understanding theoretical papers\" </p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 284, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-a-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 118}}, {"pk": 675, "model": "server.post", "fields": {"rght": 11, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 18:18:54", "lft": 10, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "I can't agree with you when you say that building and interpreting a phylogenetic tree should be trivial to any person with a background in biology. Tell me, are you any good at Florescence activated cell sorting? It's a pretty \"basic\" technique in biology... I don't know anybody good at FACS who can do phylogeny and vis-versa.", "comment_count": 0, "html": "<p>I can't agree with you when you say that building and interpreting a phylogenetic tree should be trivial to any person with a background in biology. Tell me, are you any good at Florescence activated cell sorting? It's a pretty \"basic\" technique in biology... I don't know anybody good at FACS who can do phylogeny and vis-versa.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 676, "model": "server.post", "fields": {"rght": 13, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 19:00:35", "lft": 12, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "I say that because I firmly believe that this should be a skill that any biologist can have. Tools like www.Phylogeny.fr and Mega (megasoftware.net) greatly reduce the time and work need to build a phylogenetic tree. Since evolution is a core concept in biology, the foundation to  interpret a tree is already explored in most undergraduate courses I know.", "comment_count": 0, "html": "<p>I say that because I firmly believe that this should be a skill that any biologist can have. Tools like www.Phylogeny.fr and Mega (megasoftware.net) greatly reduce the time and work need to build a phylogenetic tree. Since evolution is a core concept in biology, the foundation to  interpret a tree is already explored in most undergraduate courses I know.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 677, "model": "server.post", "fields": {"rght": 13, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 19:06:05", "lft": 12, "post_type": 206247, "score": 1, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": " In true, for quickly build a tree, it is only a matter to run a BLAST search and from the results page click in the \"Distance tree of results\" link. Sure, this may not be a good tree built with the most sofisticated methods, but is a good start to a more complete analysis. I am not saying that philogenetics as a whole is trivial, just the specific task to build a simple tree and interpreting the branching pattern resulting from it. ", "comment_count": 0, "html": "<p>In true, for quickly build a tree, it is only a matter to run a BLAST search and from the results page click in the \"Distance tree of results\" link. Sure, this may not be a good tree built with the most sofisticated methods, but is a good start to a more complete analysis. I am not saying that philogenetics as a whole is trivial, just the specific task to build a simple tree and interpreting the branching pattern resulting from it. </p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 678, "model": "server.post", "fields": {"rght": 17, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 19:07:05", "lft": 16, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Without questioning the merit of FACS as an important technique (I know it is), we must agree with this famous Dobzhansky quote \"Nothing in Biology Makes Sense Except in the Light of Evolution\". ", "comment_count": 0, "html": "<p>Without questioning the merit of FACS as an important technique (I know it is), we must agree with this famous Dobzhansky quote \"Nothing in Biology Makes Sense Except in the Light of Evolution\". </p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 679, "model": "server.post", "fields": {"rght": 19, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 19:24:42", "lft": 18, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "I play around with phylogenetics. It's not simple. And yes, I understand the importance it has in biology. But, sorry, I still can't agree with you. You're view and experience seem limited if you think that every University teaching biology goes into the concept of phylogenetics. In particular there are a lot that focus on medical issues and they really don't care about it.\n\nTrust me, the really don't. And they do very good biology too!", "comment_count": 0, "html": "<p>I play around with phylogenetics. It's not simple. And yes, I understand the importance it has in biology. But, sorry, I still can't agree with you. You're view and experience seem limited if you think that every University teaching biology goes into the concept of phylogenetics. In particular there are a lot that focus on medical issues and they really don't care about it.</p>\n<p>Trust me, the really don't. And they do very good biology too!</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 680, "model": "server.post", "fields": {"rght": 21, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 19:50:30", "lft": 20, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "I think we are arguing about a different point of view. Maybe due to a particular bias. I am in Brasil and here all biology courses consider phylogenetics pretty seriously, undergraduates seeking to work in medical issues generally goes to medical school. Anyway, I think that even biomedical students can greatly benefit if they start to think about medical problems from an evolutionary perspective. This will be particularly important with the coming availability of a vast number of sequenced human genomes.", "comment_count": 0, "html": "<p>I think we are arguing about a different point of view. Maybe due to a particular bias. I am in Brasil and here all biology courses consider phylogenetics pretty seriously, undergraduates seeking to work in medical issues generally goes to medical school. Anyway, I think that even biomedical students can greatly benefit if they start to think about medical problems from an evolutionary perspective. This will be particularly important with the coming availability of a vast number of sequenced human genomes.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 681, "model": "server.post", "fields": {"rght": 16, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 20:01:59", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: How to convert BLAST results to GFF", "unanswered": false, "content": "The message \"Use of unitialized value\" is just a warning, not an error. It is not nice, it means that $QEnd has an empty value but is used in a comparison. However, if the result is ok you could tolerate this. Is the result ok?", "comment_count": 0, "html": "<p>The message \"Use of unitialized value\" is just a warning, not an error. It is not nice, it means that $QEnd has an empty value but is used in a comparison. However, if the result is ok you could tolerate this. Is the result ok?</p>", "child_count": 0, "closed": false, "tree_id": 67, "revision_count": 0, "parent": 279, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-convert-blast-results-to-gff", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 682, "model": "server.post", "fields": {"rght": 23, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 21:02:46", "lft": 22, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Dude, I'm not saying you are wrong in stating that it is important (you are totally right!!!).\nI'm saying that you're wrong if you think that every biologist in the world understands or cares about it.", "comment_count": 0, "html": "<p>Dude, I'm not saying you are wrong in stating that it is important (you are totally right!!!).\nI'm saying that you're wrong if you think that every biologist in the world understands or cares about it.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 683, "model": "server.post", "fields": {"rght": 25, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 21:18:37", "lft": 24, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Are you sure you can call someone a biologist if they don't understand a simple phylogenetic tree? (I am not telling everyone should care about, I would like that, but it is unreal.)", "comment_count": 0, "html": "<p>Are you sure you can call someone a biologist if they don't understand a simple phylogenetic tree? (I am not telling everyone should care about, I would like that, but it is unreal.)</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 684, "model": "server.post", "fields": {"rght": 25, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 21:19:45", "lft": 24, "post_type": 206247, "score": 1, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Are you sure you can call someone a biologist if they don't understand a simple phylogenetic tree? ", "comment_count": 0, "html": "<p>Are you sure you can call someone a biologist if they don't understand a simple phylogenetic tree? </p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 685, "model": "server.post", "fields": {"rght": 29, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 21:37:10", "lft": 28, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Yes. (This is all I have to say, but I have to add more characters ;)", "comment_count": 0, "html": "<p>Yes. (This is all I have to say, but I have to add more characters ;)</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 686, "model": "server.post", "fields": {"rght": 29, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 22:03:36", "lft": 28, "post_type": 206247, "score": 1, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Ok, so we have different views about what a biologist is, and that goes a long way. :--) Thanks for the discussion.", "comment_count": 0, "html": "<p>Ok, so we have different views about what a biologist is, and that goes a long way. :--) Thanks for the discussion.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 687, "model": "server.post", "fields": {"rght": 4, "author": 124, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 22:59:52", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": "Hi Istvan.\n\n1) I contacted - no reply yet.\n\n2) Thanks!", "comment_count": 0, "html": "<p>Hi Istvan.</p>\n<p>1) I contacted - no reply yet.</p>\n<p>2) Thanks!</p>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 0, "parent": 273, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 124}}, {"pk": 688, "model": "server.post", "fields": {"rght": 6, "author": 124, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 23:02:58", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": "Hi Michael,\n\nThanks for your opinion.  I see I will have to go deeper then.  Thanks again.", "comment_count": 0, "html": "<p>Hi Michael,</p>\n<p>Thanks for your opinion.  I see I will have to go deeper then.  Thanks again.</p>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 0, "parent": 275, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 124}}, {"pk": 689, "model": "server.post", "fields": {"rght": 33, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 23:03:12", "lft": 32, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "LOL, sorry I didn't want to add anything but I have to add: please, go tell all those people working on type III secretion systems or biofilms in microbiology and all those working on p53 or c-Myc and other cancer related topics! Trust me, they don't care one bit about phylogenetics ;)", "comment_count": 0, "html": "<p>LOL, sorry I didn't want to add anything but I have to add: please, go tell all those people working on type III secretion systems or biofilms in microbiology and all those working on p53 or c-Myc and other cancer related topics! Trust me, they don't care one bit about phylogenetics ;)</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 690, "model": "server.post", "fields": {"rght": 8, "author": 124, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 23:03:50", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": "Thanks darked.\nI am at home now and can't access the file.  I'll try it once I get to the University (I am not sure if they have access or not). Thanks!", "comment_count": 0, "html": "<p>Thanks darked.\nI am at home now and can't access the file.  I'll try it once I get to the University (I am not sure if they have access or not). Thanks!</p>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 0, "parent": 276, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 124}}, {"pk": 691, "model": "server.post", "fields": {"rght": 19, "author": 124, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 23:04:47", "lft": 18, "post_type": 206247, "score": 0, "title": "C: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": "Giovanni - if I where to find a newer better software I would gladly use it :)", "comment_count": 0, "html": "<p>Giovanni - if I where to find a newer better software I would gladly use it :)</p>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 0, "parent": 271, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 124}}, {"pk": 692, "model": "server.post", "fields": {"rght": 21, "author": 124, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-13 23:09:01", "lft": 20, "post_type": 206247, "score": 0, "title": "C: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "unanswered": false, "content": "Michael - what I really want is to compare (some areas of, for example, the D loop in) tRNA's from different species.\nIn order to do so, I need to know that I am looking at the D loop in all of them, but it is located in different numbering in different tRNA's from different species.  I could just copy paste the websites result (for an aligned sequence, based on the COVE model and the secondary folding of the tRNA) - but I had hoped for a more generic (and thus, scalable) solution for getting these aligned sequences (then using copy paste).", "comment_count": 0, "html": "<p>Michael - what I really want is to compare (some areas of, for example, the D loop in) tRNA's from different species.\nIn order to do so, I need to know that I am looking at the D loop in all of them, but it is located in different numbering in different tRNA's from different species.  I could just copy paste the websites result (for an aligned sequence, based on the COVE model and the secondary folding of the tRNA) - but I had hoped for a more generic (and thus, scalable) solution for getting these aligned sequences (then using copy paste).</p>", "child_count": 0, "closed": false, "tree_id": 66, "revision_count": 0, "parent": 271, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-how-to-perform-trna-sequence-alignment-against-a-domain-specific-trna-covariance-models-with-cove-or-infernal-on-windows", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 124}}, {"pk": 693, "model": "server.post", "fields": {"rght": 35, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-14 00:11:31", "lft": 34, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "ORLLY?? http://bit.ly/cZ7ssB", "comment_count": 0, "html": "<p>ORLLY?? http://bit.ly/cZ7ssB</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 694, "model": "server.post", "fields": {"rght": 37, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-14 00:36:03", "lft": 36, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "or...if you have access to Scopus: http://bit.ly/coSBWK", "comment_count": 0, "html": "<p>or...if you have access to Scopus: http://bit.ly/coSBWK</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 695, "model": "server.post", "fields": {"rght": 39, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-14 00:38:09", "lft": 38, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "...and broad results from Scirus: http://bit.ly/cB6eNu", "comment_count": 0, "html": "<p>...and broad results from Scirus: http://bit.ly/cB6eNu</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 696, "model": "server.post", "fields": {"rght": 6, "author": 13, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-14 04:56:14", "lft": 5, "post_type": 206247, "score": 1, "title": "C: A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "\"Trivial, but tedious:\nconstantly munging data files from one poorly defined format to another\"\n\nCan't agree with you more!", "comment_count": 0, "html": "<p>\"Trivial, but tedious:\nconstantly munging data files from one poorly defined format to another\"</p>\n<p>Can't agree with you more!</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 285, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-a-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 13}}, {"pk": 697, "model": "server.post", "fields": {"rght": 41, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-14 08:02:02", "lft": 40, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Look at the stats: pubmed \"p53 cancer\" and compare to \"p53 cancer phylogeny\" :) And YES, again, you do have some that do phylogeny! But seriously, are you calling the tens of thousands of other papers that don't care about it \"Not Biological\"?", "comment_count": 0, "html": "<p>Look at the stats: pubmed \"p53 cancer\" and compare to \"p53 cancer phylogeny\" :) And YES, again, you do have some that do phylogeny! But seriously, are you calling the tens of thousands of other papers that don't care about it \"Not Biological\"?</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 698, "model": "server.post", "fields": {"rght": 4, "author": 130, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-14 17:03:08", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: A resource to identify functionally redundant genes", "unanswered": false, "content": "Thanks Chris. I think what I was thinking of was more on the lines of functional redundancy arising from evolutionary convergence (rather than say gene duplication). As to what exactly is meant by \"redundant\", you point out interesting variations.\n\nMy question originates from RNAi screens. If knockdown of gene X does not result in a loss-of-function phenotype is it because X is not involved in that phenotype? Or is it because X is knocked down, but a functionally equivalent gene (or pathway) can take over the function?", "comment_count": 0, "html": "<p>Thanks Chris. I think what I was thinking of was more on the lines of functional redundancy arising from evolutionary convergence (rather than say gene duplication). As to what exactly is meant by \"redundant\", you point out interesting variations.</p>\n<p>My question originates from RNAi screens. If knockdown of gene X does not result in a loss-of-function phenotype is it because X is not involved in that phenotype? Or is it because X is knocked down, but a functionally equivalent gene (or pathway) can take over the function?</p>", "child_count": 0, "closed": false, "tree_id": 69, "revision_count": 0, "parent": 288, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-a-resource-to-identify-functionally-redundant-genes", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 130}}, {"pk": 699, "model": "server.post", "fields": {"rght": 6, "author": 57, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-14 18:19:18", "lft": 5, "post_type": 206247, "score": 1, "title": "C: A: A resource to identify functionally redundant genes", "unanswered": false, "content": "If thats all you are looking for, probably a simple blast search to see if there are reasonably well conserved isoforms might be sufficient", "comment_count": 0, "html": "<p>If thats all you are looking for, probably a simple blast search to see if there are reasonably well conserved isoforms might be sufficient</p>", "child_count": 0, "closed": false, "tree_id": 69, "revision_count": 0, "parent": 288, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-a-resource-to-identify-functionally-redundant-genes", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 57}}, {"pk": 700, "model": "server.post", "fields": {"rght": 43, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-14 19:10:29", "lft": 42, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "No, that is not the point.", "comment_count": 0, "html": "<p>No, that is not the point.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 701, "model": "server.post", "fields": {"rght": 24, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-14 19:28:22", "lft": 23, "post_type": 206247, "score": 0, "title": "C: A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "Since this was chosen as the top answer, I've added a link to BioStar in the sidebar of the bioinformatics subreddit.", "comment_count": 0, "html": "<p>Since this was chosen as the top answer, I've added a link to BioStar in the sidebar of the bioinformatics subreddit.</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 0, "parent": 131, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 702, "model": "server.post", "fields": {"rght": 45, "author": 137, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 12:48:19", "lft": 44, "post_type": 206247, "score": 1, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Sorry to interrupt this \"discussion\", but the statement that phylogenetics is easy is unjustified. But because it might be me who just cannot grasp the \"trivial trees\" could you Marcos explain me how I can relate/interpret posterior branch probabilities with bootstrapping values and what to do if they differ significantly? And which of the two approaches for consensus/super-tree reconstruction using majority-rule voting is more relevant evolutionarily i.e. closer to the real evolution.  ", "comment_count": 0, "html": "<p>Sorry to interrupt this \"discussion\", but the statement that phylogenetics is easy is unjustified. But because it might be me who just cannot grasp the \"trivial trees\" could you Marcos explain me how I can relate/interpret posterior branch probabilities with bootstrapping values and what to do if they differ significantly? And which of the two approaches for consensus/super-tree reconstruction using majority-rule voting is more relevant evolutionarily i.e. closer to the real evolution.<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 137}}, {"pk": 703, "model": "server.post", "fields": {"rght": 49, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 15:43:18", "lft": 48, "post_type": 206247, "score": 1, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Marcin, please consider my other comments. I didn't want to say that phylogenetics is easy. But, build a simple phylogenetic tree and interpret it can be. Please, point me where I told that phylogenetics is easy. Remember that not all problems are ultra-hard and need the most sophisticated inference methods or supertrees to be solved. I definitely wasn't trying to be pedant, pretty much the inverse. See my example about buiding a tree from BLAST results, what can be more simple? Yes, it may not be the most accurate, etc, but sometimes you only need that. That is what I am talking about.", "comment_count": 0, "html": "<p>Marcin, please consider my other comments. I didn't want to say that phylogenetics is easy. But, build a simple phylogenetic tree and interpret it can be. Please, point me where I told that phylogenetics is easy. Remember that not all problems are ultra-hard and need the most sophisticated inference methods or supertrees to be solved. I definitely wasn't trying to be pedant, pretty much the inverse. See my example about buiding a tree from BLAST results, what can be more simple? Yes, it may not be the most accurate, etc, but sometimes you only need that. That is what I am talking about.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 704, "model": "server.post", "fields": {"rght": 51, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 16:12:49", "lft": 50, "post_type": 206247, "score": 1, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Marcos +1: not everyone can understand the subtleties of a phylogenic tree. But *any* biologist (high school student ?) should understand ( I didn't say 'be interested') what is the underlying idea described in those trees. ", "comment_count": 0, "html": "<p>Marcos +1: not everyone can understand the subtleties of a phylogenic tree. But <em>any</em> biologist (high school student ?) should understand ( I didn't say 'be interested') what is the underlying idea described in those trees. </p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 705, "model": "server.post", "fields": {"rght": 57, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 20:25:25", "lft": 56, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Pierre and Marcos, I'll just emphasize the key word in your statement: SHOULD. And that is my point... You all seem to evolve in the world of bioinformatics and you understand phylogenetics. But, when it comes to their own work, many biologists (yes, I insist, they are biologists, even if they don't understand phylogenetics) in wet labs do not understand the meaning of phylogenetic relationships. Yes they understand that you can make a \"species tree\", but no, they don't relate it to what they do, i.e. they don't understand it and they do not value it.", "comment_count": 0, "html": "<p>Pierre and Marcos, I'll just emphasize the key word in your statement: SHOULD. And that is my point... You all seem to evolve in the world of bioinformatics and you understand phylogenetics. But, when it comes to their own work, many biologists (yes, I insist, they are biologists, even if they don't understand phylogenetics) in wet labs do not understand the meaning of phylogenetic relationships. Yes they understand that you can make a \"species tree\", but no, they don't relate it to what they do, i.e. they don't understand it and they do not value it.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 706, "model": "server.post", "fields": {"rght": 59, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 20:26:28", "lft": 58, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "And Pierre, I have been to high school in the french system. Please tell me when phylogenetics is covered?", "comment_count": 0, "html": "<p>And Pierre, I have been to high school in the french system. Please tell me when phylogenetics is covered?</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 707, "model": "server.post", "fields": {"rght": 61, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 21:24:55", "lft": 60, "post_type": 206247, "score": 1, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "I am sorry Nicojo, but what you are asking me for is that I admit that is ok for a biologist not understand a phylogenetic tree. This is like saying it is ok for a chemist not understand the acid/base concepts, as long as he works with nuclear chemistry. I can't agree. ", "comment_count": 0, "html": "<p>I am sorry Nicojo, but what you are asking me for is that I admit that is ok for a biologist not understand a phylogenetic tree. This is like saying it is ok for a chemist not understand the acid/base concepts, as long as he works with nuclear chemistry. I can't agree. </p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 708, "model": "server.post", "fields": {"rght": 63, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 22:01:02", "lft": 62, "post_type": 206247, "score": 1, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Marcos, would we have Rock music if all musicians had to go to the conservatory and learn Brahms first? I don't think so, but I'm probably wrong... I do agree that this is a very important and fundamental aspect of biology. I'm sorry I made all this fuss over this topic. I'm usually fighting with wet lab biologists to try and make them understand that bioinformaticians are also biologists! In any case, even if I disagree, still I respect your take on the matter, and I'll even use it next time I argue with the others ;). Thanks for your patience with my arguments!", "comment_count": 0, "html": "<p>Marcos, would we have Rock music if all musicians had to go to the conservatory and learn Brahms first? I don't think so, but I'm probably wrong... I do agree that this is a very important and fundamental aspect of biology. I'm sorry I made all this fuss over this topic. I'm usually fighting with wet lab biologists to try and make them understand that bioinformaticians are also biologists! In any case, even if I disagree, still I respect your take on the matter, and I'll even use it next time I argue with the others ;). Thanks for your patience with my arguments!</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:32", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 709, "model": "server.post", "fields": {"rght": 65, "author": 30, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 22:46:36", "lft": 64, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "No problem Nicojo, it was a good discussion. All the best.", "comment_count": 0, "html": "<p>No problem Nicojo, it was a good discussion. All the best.</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 30}}, {"pk": 710, "model": "server.post", "fields": {"rght": 67, "author": 137, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-15 23:37:59", "lft": 66, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "I'll quote \"building and interpreting a phylogenetic tree from a family of genes can be considered a trivial task in my subfield\". If your statement is true and indeed building a tree from a family of genes is a trivial task to anyone, then my PhD is a terrible mistake is a terrible mistake because I try to give answers to trivial questions like \"what is a family of genes\" or \"how to interpret a phylogenetic tree\". ", "comment_count": 0, "html": "<p>I'll quote \"building and interpreting a phylogenetic tree from a family of genes can be considered a trivial task in my subfield\". If your statement is true and indeed building a tree from a family of genes is a trivial task to anyone, then my PhD is a terrible mistake is a terrible mistake because I try to give answers to trivial questions like \"what is a family of genes\" or \"how to interpret a phylogenetic tree\". </p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:01", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 137}}, {"pk": 711, "model": "server.post", "fields": {"rght": 6, "author": 121, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 04:53:02", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "i didn't know BLAST had a blastall commandline argument ...I'll have to remember that for later.", "comment_count": 0, "html": "<p>i didn't know BLAST had a blastall commandline argument ...I'll have to remember that for later.</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 0, "parent": 305, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:01", "slug": "c-a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:49:01", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 121}}, {"pk": 712, "model": "server.post", "fields": {"rght": 8, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 06:24:01", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "This is an excellent solution - simple and effective.", "comment_count": 0, "html": "<p>This is an excellent solution - simple and effective.</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 0, "parent": 305, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 713, "model": "server.post", "fields": {"rght": 10, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 06:25:33", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "Except for the yeast genome part, since these are bacteria :-)", "comment_count": 0, "html": "<p>Except for the yeast genome part, since these are bacteria :-)</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 0, "parent": 305, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 714, "model": "server.post", "fields": {"rght": 12, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 09:02:36", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "I agree, this seems like the best way to accomplish your goal - don't overcomplicate with BioPython where it simply isn't necessary. By the way, you can grab the sequences you need from UniProt: search for \"organism:$tax_id AND keyword:\"Complete proteome\"\" where $tax_id is the taxonomy identifier of the strain you're interested in (so E. coli K12 is 83333 and C jejuni is 197). Though this method does rely on the curation levels of UniProt, which may not be so good for organisms a little off the beaten track.", "comment_count": 0, "html": "<p>I agree, this seems like the best way to accomplish your goal - don't overcomplicate with BioPython where it simply isn't necessary. By the way, you can grab the sequences you need from UniProt: search for \"organism:$tax_id AND keyword:\"Complete proteome\"\" where $tax_id is the taxonomy identifier of the strain you're interested in (so E. coli K12 is 83333 and C jejuni is 197). Though this method does rely on the curation levels of UniProt, which may not be so good for organisms a little off the beaten track.</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 0, "parent": 305, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 715, "model": "server.post", "fields": {"rght": 4, "author": 144, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 11:12:00", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How to get started in bioinformatics?", "unanswered": false, "content": "You're basically telling me to Google instead of asking here. I thought I'd get a more insightful answer here than from Google but apparently, you are not interested in helping out \"newbies\" which I can understand. ", "comment_count": 0, "html": "<p>You're basically telling me to Google instead of asking here. I thought I'd get a more insightful answer here than from Google but apparently, you are not interested in helping out \"newbies\" which I can understand. </p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 312, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 144}}, {"pk": 716, "model": "server.post", "fields": {"rght": 6, "author": 144, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 11:16:01", "lft": 5, "post_type": 206247, "score": 1, "title": "C: A: How to get started in bioinformatics?", "unanswered": false, "content": "\"you forget to formulate what you really like to do. Never ask others what you should do (with your life).\" was somewhat an overstatement. All I was asking for was book recommendation, not life advice. And I did formulate what I was interested in: bioinformatics.", "comment_count": 0, "html": "<p>\"you forget to formulate what you really like to do. Never ask others what you should do (with your life).\" was somewhat an overstatement. All I was asking for was book recommendation, not life advice. And I did formulate what I was interested in: bioinformatics.</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 312, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 144}}, {"pk": 717, "model": "server.post", "fields": {"rght": 8, "author": 144, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 11:18:58", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How to get started in bioinformatics?", "unanswered": false, "content": "I understand you get this kind of question a lot, but you could've simply ignored it or at least let me know it wasn't appropriate on this forum - in a non arrogant way.", "comment_count": 0, "html": "<p>I understand you get this kind of question a lot, but you could've simply ignored it or at least let me know it wasn't appropriate on this forum - in a non arrogant way.</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 312, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 144}}, {"pk": 718, "model": "server.post", "fields": {"rght": 17, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 11:56:31", "lft": 16, "post_type": 206247, "score": 0, "title": "C: How to get started in bioinformatics?", "unanswered": false, "content": "why the negative vote? It is true that the question is a bit too general (in fact, each question should go to a separate topic) but it is nothing so terrible..", "comment_count": 0, "html": "<p>why the negative vote? It is true that the question is a bit too general (in fact, each question should go to a separate topic) but it is nothing so terrible..</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 719, "model": "server.post", "fields": {"rght": 21, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 12:02:26", "lft": 20, "post_type": 206247, "score": 0, "title": "C: How to get started in bioinformatics?", "unanswered": false, "content": "ok, now I understand... maybe we should close this question and leave the links to the other discussions on biostar.", "comment_count": 0, "html": "<p>ok, now I understand... maybe we should close this question and leave the links to the other discussions on biostar.</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 720, "model": "server.post", "fields": {"rght": 10, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 12:30:03", "lft": 9, "post_type": 206247, "score": 1, "title": "C: A: How to get started in bioinformatics?", "unanswered": false, "content": "Oli, you are misreading my answer. Asking here is fine, but you are doing it the wrong way.", "comment_count": 0, "html": "<p>Oli, you are misreading my answer. Asking here is fine, but you are doing it the wrong way.</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 312, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 721, "model": "server.post", "fields": {"rght": 21, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 12:32:12", "lft": 20, "post_type": 206247, "score": 1, "title": "C: How to get started in bioinformatics?", "unanswered": false, "content": "Voted down because the question is IMHO way too general; see my answer.", "comment_count": 0, "html": "<p>Voted down because the question is IMHO way too general; see my answer.</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 722, "model": "server.post", "fields": {"rght": 12, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 12:34:18", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: How to get started in bioinformatics?", "unanswered": false, "content": "And for the record, you asked for online resources: Google *is* an online resource. Alternatively, you could have just split up things and asked \"What Bioinformatics blogs can I read to learn about Bioinformatics coding?\"... then you would have posed a reasonable answerable question.", "comment_count": 0, "html": "<p>And for the record, you asked for online resources: Google <em>is</em> an online resource. Alternatively, you could have just split up things and asked \"What Bioinformatics blogs can I read to learn about Bioinformatics coding?\"... then you would have posed a reasonable answerable question.</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 312, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 723, "model": "server.post", "fields": {"rght": 71, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 12:49:39", "lft": 70, "post_type": 206247, "score": 1, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Nicojo, I was introduced to genetics/phylogeny in my final year of Secondary School (~17 y.o.)", "comment_count": 0, "html": "<p>Nicojo, I was introduced to genetics/phylogeny in my final year of Secondary School (~17 y.o.)</p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 724, "model": "server.post", "fields": {"rght": 25, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 13:01:13", "lft": 24, "post_type": 206247, "score": 3, "title": "C: How to get started in bioinformatics?", "unanswered": false, "content": "that's ok, it is fine to ask questions, but it is better if we close this topic and leave the links to other discussions. Otherwise, people will start writing here about their favorite blogs, books, resources, etc... while they should to so in the specific topics.", "comment_count": 0, "html": "<p>that's ok, it is fine to ask questions, but it is better if we close this topic and leave the links to other discussions. Otherwise, people will start writing here about their favorite blogs, books, resources, etc... while they should to so in the specific topics.</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 725, "model": "server.post", "fields": {"rght": 14, "author": 142, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 13:04:24", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "Thanks very much for your help!", "comment_count": 0, "html": "<p>Thanks very much for your help!</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 0, "parent": 305, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 142}}, {"pk": 726, "model": "server.post", "fields": {"rght": 7, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 13:20:33", "lft": 2, "post_type": 206247, "score": 0, "title": "C: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "do you refer to human genomes only?", "comment_count": 0, "html": "<p>do you refer to human genomes only?</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 727, "model": "server.post", "fields": {"rght": 5, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 13:23:04", "lft": 4, "post_type": 206247, "score": 1, "title": "C: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "This question is very interesting, but maybe the title can be refined. what about something like 'Which human cell line genomes have been already sequenced completely?', if I understood the question correctly.", "comment_count": 0, "html": "<p>This question is very interesting, but maybe the title can be refined. what about something like 'Which human cell line genomes have been already sequenced completely?', if I understood the question correctly.</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 728, "model": "server.post", "fields": {"rght": 11, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 13:55:16", "lft": 10, "post_type": 206247, "score": 0, "title": "C: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "Question 1: Yes I refer to human geneomes.\nQuestion 2: You are right I will give it a try.", "comment_count": 0, "html": "<p>Question 1: Yes I refer to human geneomes.\nQuestion 2: You are right I will give it a try.</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 729, "model": "server.post", "fields": {"rght": 13, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 13:55:47", "lft": 12, "post_type": 206247, "score": 0, "title": "C: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "<p>Question 1: Yes I refer to human geneomes.</p>\n<p>Question 2: You are right I will give it a try.</p>", "comment_count": 0, "html": "<p>[HTML_REMOVED]</p>\n<p>[HTML_REMOVED]</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 730, "model": "server.post", "fields": {"rght": 15, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 13:56:31", "lft": 14, "post_type": 206247, "score": 0, "title": "C: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "Question 1: Yes I refer to human genomes only.", "comment_count": 0, "html": "<p>Question 1: Yes I refer to human genomes only.</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 731, "model": "server.post", "fields": {"rght": 17, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 13:56:43", "lft": 16, "post_type": 206247, "score": 0, "title": "C: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "Question 2: You are right I will give it a try.", "comment_count": 0, "html": "<p>Question 2: You are right I will give it a try.</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 732, "model": "server.post", "fields": {"rght": 75, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 14:06:21", "lft": 74, "post_type": 206247, "score": 0, "title": "C: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "unanswered": false, "content": "Pierre, je viens de chercher le programme officiel et effectivement il semblerait que c'est maintenant partie int\u00e9grante de l'enseignement de terminal S. Mais de votre r\u00e9ponse, j'en d\u00e9duis que vous \u00eates bien plus jeune que moi. Cela fait il de moi un \"non-biologist\"? Je trouve que vous avez une vision tr\u00e8s r\u00e9ductionniste si vous arrivez \u00e0 de telles conclusions. ", "comment_count": 0, "html": "<p>Pierre, je viens de chercher le programme officiel et effectivement il semblerait que c'est maintenant partie int\u00e9grante de l'enseignement de terminal S. Mais de votre r\u00e9ponse, j'en d\u00e9duis que vous \u00eates bien plus jeune que moi. Cela fait il de moi un \"non-biologist\"? Je trouve que vous avez une vision tr\u00e8s r\u00e9ductionniste si vous arrivez \u00e0 de telles conclusions. </p>", "child_count": 0, "closed": false, "tree_id": 68, "revision_count": 0, "parent": 283, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-what-do-you-consider-the-most-trivial-and-the-most-challenging-tasks-in-your-particular-field-of-work", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 733, "model": "server.post", "fields": {"rght": 27, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 14:28:38", "lft": 26, "post_type": 206247, "score": 0, "title": "C: How to get started in bioinformatics?", "unanswered": false, "content": "I do agree with your sentiment that this could be closed. On the other sometimes lettings things grow in their organic way my appear inefficient but leads to unexpected features that we did not foresee. Once multiple people have moderator then we can all vote on the right course of action. ", "comment_count": 0, "html": "<p>I do agree with your sentiment that this could be closed. On the other sometimes lettings things grow in their organic way my appear inefficient but leads to unexpected features that we did not foresee. Once multiple people have moderator then we can all vote on the right course of action. </p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 734, "model": "server.post", "fields": {"rght": 29, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 14:33:45", "lft": 28, "post_type": 206247, "score": 0, "title": "C: How to get started in bioinformatics?", "unanswered": false, "content": "I do agree with your sentiment that this could be closed. On the hand other sometimes lettings things grow in their organic way my appear inefficient but leads to unexpected features that one may not have foreseen. Once multiple people have moderator then we can all vote on the right course of action. My personal preference is for people to vote up questions that they like, that way the interesting stuff rises to the top, only down-vote sparingly ...", "comment_count": 0, "html": "<p>I do agree with your sentiment that this could be closed. On the hand other sometimes lettings things grow in their organic way my appear inefficient but leads to unexpected features that one may not have foreseen. Once multiple people have moderator then we can all vote on the right course of action. My personal preference is for people to vote up questions that they like, that way the interesting stuff rises to the top, only down-vote sparingly ...</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 735, "model": "server.post", "fields": {"rght": 31, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 14:39:44", "lft": 30, "post_type": 206247, "score": 0, "title": "C: How to get started in bioinformatics?", "unanswered": false, "content": "Sometimes lettings things grow in their organic way my appear inefficient but leads to unexpected features that we did not foresee. Once multiple people have moderator then we can all vote on the right course of action. ", "comment_count": 0, "html": "<p>Sometimes lettings things grow in their organic way my appear inefficient but leads to unexpected features that we did not foresee. Once multiple people have moderator then we can all vote on the right course of action. </p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 736, "model": "server.post", "fields": {"rght": 33, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 14:40:02", "lft": 32, "post_type": 206247, "score": 1, "title": "C: How to get started in bioinformatics?", "unanswered": false, "content": "Sometimes lettings things grow in their organic way my appear inefficient but leads to unexpected features that we did not foresee. Once multiple people have moderator rights then we can all vote on the right course of action", "comment_count": 0, "html": "<p>Sometimes lettings things grow in their organic way my appear inefficient but leads to unexpected features that we did not foresee. Once multiple people have moderator rights then we can all vote on the right course of action</p>", "child_count": 0, "closed": false, "tree_id": 75, "revision_count": 0, "parent": 311, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-how-to-get-started-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 737, "model": "server.post", "fields": {"rght": 16, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 15:29:38", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "neilfws, i changed \"yeast\" to \"bacteria\". thanks.", "comment_count": 0, "html": "<p>neilfws, i changed \"yeast\" to \"bacteria\". thanks.</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 0, "parent": 305, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 35}}, {"pk": 738, "model": "server.post", "fields": {"rght": 8, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 16:28:41", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Which software development technique is used in your lab? ", "unanswered": false, "content": "Thank you very much, this is very interesting. I will wait for other answers and eventually mark yours as the accepted one.", "comment_count": 0, "html": "<p>Thank you very much, this is very interesting. I will wait for other answers and eventually mark yours as the accepted one.</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 0, "parent": 324, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 739, "model": "server.post", "fields": {"rght": 10, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 16:35:56", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Which software development technique is used in your lab? ", "unanswered": false, "content": "I didn't know about yammer, but I will look at it. When we tried google/wave, it was too slow for being of use. It would be complicated to use a wiki because the other members will have to learn its syntax. A few of us use git, which doesn't require a central repo like svn, and github. We use skype and emails, as well as dropbox for sharing files :-)", "comment_count": 0, "html": "<p>I didn't know about yammer, but I will look at it. When we tried google/wave, it was too slow for being of use. It would be complicated to use a wiki because the other members will have to learn its syntax. A few of us use git, which doesn't require a central repo like svn, and github. We use skype and emails, as well as dropbox for sharing files :-)</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 0, "parent": 324, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 740, "model": "server.post", "fields": {"rght": 21, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 16:36:55", "lft": 20, "post_type": 206247, "score": 0, "title": "C: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "Are you referring only to deep coverage, whole-genome sequencing?  If not, many genomes and cell lines have been assayed for rearrangements using low-coverage with paired-end sequencing, and others have had whole-exome sequencing done.", "comment_count": 0, "html": "<p>Are you referring only to deep coverage, whole-genome sequencing?  If not, many genomes and cell lines have been assayed for rearrangements using low-coverage with paired-end sequencing, and others have had whole-exome sequencing done.</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 741, "model": "server.post", "fields": {"rght": 4, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 16:39:36", "lft": 3, "post_type": 206247, "score": 2, "title": "C: A: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "a) The TCGA (GBM) is up to something like 150 samples now, but they aren't doing whole genome resequencing at this point. The first draft resequenced 600 selected genes, and they're bumping that number up, but still using targeted capture.", "comment_count": 0, "html": "<p>a) The TCGA (GBM) is up to something like 150 samples now, but they aren't doing whole genome resequencing at this point. The first draft resequenced 600 selected genes, and they're bumping that number up, but still using targeted capture.</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 323, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 742, "model": "server.post", "fields": {"rght": 12, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 16:54:23", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Which software development technique is used in your lab? ", "unanswered": false, "content": "Well, Wave works well for us... most of the time. One of my collaborators had a problem recently where he couldn't update anything (unsynced). A change of browser fixed it though. The \"extentions\" list is growing, which is good too. Maybe you should give it another try!", "comment_count": 0, "html": "<p>Well, Wave works well for us... most of the time. One of my collaborators had a problem recently where he couldn't update anything (unsynced). A change of browser fixed it though. The \"extentions\" list is growing, which is good too. Maybe you should give it another try!</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 0, "parent": 324, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 743, "model": "server.post", "fields": {"rght": 18, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 16:55:19", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Which software development technique is used in your lab? ", "unanswered": false, "content": "I use Dropbox personally, but we haven't used it in our collaboration yet. Will probably come in handy soon though!", "comment_count": 0, "html": "<p>I use Dropbox personally, but we haven't used it in our collaboration yet. Will probably come in handy soon though!</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 0, "parent": 324, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 744, "model": "server.post", "fields": {"rght": 6, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 16:56:36", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "AFAIK, TCGA project does not do full sequencing yet, only genes of interest.", "comment_count": 0, "html": "<p>AFAIK, TCGA project does not do full sequencing yet, only genes of interest.</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 323, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 745, "model": "server.post", "fields": {"rght": 20, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 16:57:31", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Which software development technique is used in your lab? ", "unanswered": false, "content": "As for Yammer, in the end we like some aspect of it, but it's not as useful as Wave, so we'll probably slowly abandon it.", "comment_count": 0, "html": "<p>As for Yammer, in the end we like some aspect of it, but it's not as useful as Wave, so we'll probably slowly abandon it.</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 0, "parent": 324, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 746, "model": "server.post", "fields": {"rght": 25, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 20:35:34", "lft": 24, "post_type": 206247, "score": 0, "title": "C: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "Yes I am referring only to deep coverage, whole-genome sequencing", "comment_count": 0, "html": "<p>Yes I am referring only to deep coverage, whole-genome sequencing</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 747, "model": "server.post", "fields": {"rght": 27, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 20:36:22", "lft": 26, "post_type": 206247, "score": 0, "title": "C: Which human tumor cell line/sample genomes have been already sequenced completely?", "unanswered": false, "content": "@Chris : Yes I am referring only to deep coverage, whole-genome sequencing.", "comment_count": 0, "html": "<p>@Chris : Yes I am referring only to deep coverage, whole-genome sequencing.</p>", "child_count": 0, "closed": false, "tree_id": 73, "revision_count": 0, "parent": 308, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-which-human-tumor-cell-linesample-genomes-have-been-already-sequenced-completely", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 748, "model": "server.post", "fields": {"rght": 3, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 22:21:18", "lft": 2, "post_type": 206247, "score": 0, "title": "C: Convert microarray quantization in image", "unanswered": false, "content": "Can you provide a bit more information? What tools do you use for the microarray quantization? Can you give an example of the kind of image you that you want as a result? Can you show us what you have already done yourself and where exactly you are stuck? Also, read [this article][1] to learn how to ask questions in a way more likely to get you a satisfactory answer.\n\n\n  [1]: http://catb.org/~esr/faqs/smart-questions.html", "comment_count": 0, "html": "<p>Can you provide a bit more information? What tools do you use for the microarray quantization? Can you give an example of the kind of image you that you want as a result? Can you show us what you have already done yourself and where exactly you are stuck? Also, read <a href=\"http://catb.org/~esr/faqs/smart-questions.html\">this article</a> to learn how to ask questions in a way more likely to get you a satisfactory answer.</p>", "child_count": 0, "closed": false, "tree_id": 76, "revision_count": 0, "parent": 327, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-convert-microarray-quantization-in-image", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 749, "model": "server.post", "fields": {"rght": 5, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-16 22:21:59", "lft": 4, "post_type": 206247, "score": 2, "title": "C: Convert microarray quantization in image", "unanswered": false, "content": "Can you provide a bit more information? What tools do you use for the microarray quantization? Can you give an example of the kind of image you that you want as a result? Can you show us what you have already done yourself and where exactly you are stuck? Also, read this article: catb.org/~esr/faqs/smart-questions.html to learn how to ask questions in a way more likely to get you a satisfactory answer.", "comment_count": 0, "html": "<p>Can you provide a bit more information? What tools do you use for the microarray quantization? Can you give an example of the kind of image you that you want as a result? Can you show us what you have already done yourself and where exactly you are stuck? Also, read this article: catb.org/~esr/faqs/smart-questions.html to learn how to ask questions in a way more likely to get you a satisfactory answer.</p>", "child_count": 0, "closed": false, "tree_id": 76, "revision_count": 0, "parent": 327, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-convert-microarray-quantization-in-image", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 750, "model": "server.post", "fields": {"rght": 7, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 01:53:38", "lft": 6, "post_type": 206247, "score": 0, "title": "C: Convert microarray quantization in image", "unanswered": false, "content": "Yes, please do provide additional details, you can edit your original post to add them.", "comment_count": 0, "html": "<p>Yes, please do provide additional details, you can edit your original post to add them.</p>", "child_count": 0, "closed": false, "tree_id": 76, "revision_count": 0, "parent": 327, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-convert-microarray-quantization-in-image", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 751, "model": "server.post", "fields": {"rght": 9, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 05:04:22", "lft": 8, "post_type": 206247, "score": 0, "title": "C: Convert microarray quantization in image", "unanswered": false, "content": "I almost flagged this because it resembles some of the \"intelligent\" spam that bots post to my blog, in that it resembles English but does not make sense.", "comment_count": 0, "html": "<p>I almost flagged this because it resembles some of the \"intelligent\" spam that bots post to my blog, in that it resembles English but does not make sense.</p>", "child_count": 0, "closed": false, "tree_id": 76, "revision_count": 0, "parent": 327, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-convert-microarray-quantization-in-image", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 752, "model": "server.post", "fields": {"rght": 12, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 05:26:36", "lft": 11, "post_type": 206247, "score": 1, "title": "C: A: What is the best way to share scripts between members of a lab?", "unanswered": false, "content": "I've used Trac successfully for project/code management.  I'd also recommend Redmine - http://www.redmine.org/ - written in Ruby on Rails.", "comment_count": 0, "html": "<p>I've used Trac successfully for project/code management.  I'd also recommend Redmine - http://www.redmine.org/ - written in Ruby on Rails.</p>", "child_count": 0, "closed": false, "tree_id": 22, "revision_count": 0, "parent": 85, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-what-is-the-best-way-to-share-scripts-between-members-of-a-lab", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 753, "model": "server.post", "fields": {"rght": 3, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 09:23:00", "lft": 2, "post_type": 206247, "score": 1, "title": "C: Hardware resources for HPC in Bioinformatics", "unanswered": false, "content": "Hi Jarretinha... It would be good if you could add links. For instance I assume HCFMUSP is in Brazil, but honestly, the abreviation doesn't mean anything to me. Also, lots of people won't know what an FPGA is: you could make that a link to Wikipedia. Same with the different commercial solutions you're suggesting etc.", "comment_count": 0, "html": "<p>Hi Jarretinha... It would be good if you could add links. For instance I assume HCFMUSP is in Brazil, but honestly, the abreviation doesn't mean anything to me. Also, lots of people won't know what an FPGA is: you could make that a link to Wikipedia. Same with the different commercial solutions you're suggesting etc.</p>", "child_count": 0, "closed": false, "tree_id": 77, "revision_count": 0, "parent": 328, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-hardware-resources-for-hpc-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 754, "model": "server.post", "fields": {"rght": 8, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 10:47:14", "lft": 7, "post_type": 206247, "score": 1, "title": "C: A: I was studying a gene but it disappeared in the latest ensembl release. What should I do now?", "unanswered": false, "content": "I totally agree and in general the best way to solve such a problem is to contact the helpdesk service dedicated to the given database your are using. In general there are very responsive (e.g. The COSMIC team at Sanger).", "comment_count": 0, "html": "<p>I totally agree and in general the best way to solve such a problem is to contact the helpdesk service dedicated to the given database your are using. In general there are very responsive (e.g. The COSMIC team at Sanger).</p>", "child_count": 0, "closed": false, "tree_id": 47, "revision_count": 0, "parent": 332, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-i-was-studying-a-gene-but-it-disappeared-in-the-latest-ensembl-release-what-should-i-do-now", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 755, "model": "server.post", "fields": {"rght": 14, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 11:50:24", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "Seeing as this was the first suggestion for FiB, you get the accepted answer :)", "comment_count": 0, "html": "<p>Seeing as this was the first suggestion for FiB, you get the accepted answer :)</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 272, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 756, "model": "server.post", "fields": {"rght": 13, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 12:16:41", "lft": 12, "post_type": 206247, "score": 0, "title": "C: Hardware resources for HPC in Bioinformatics", "unanswered": false, "content": "How it sounds now? I can put more references.", "comment_count": 0, "html": "<p>How it sounds now? I can put more references.</p>", "child_count": 0, "closed": false, "tree_id": 77, "revision_count": 0, "parent": 328, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-hardware-resources-for-hpc-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 757, "model": "server.post", "fields": {"rght": 11, "author": 141, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 12:48:43", "lft": 10, "post_type": 206247, "score": 0, "title": "C: Computing the reverse and complement of a sequence with Pygr", "unanswered": false, "content": "This is not a question", "comment_count": 0, "html": "<p>This is not a question</p>", "child_count": 0, "closed": false, "tree_id": 29, "revision_count": 0, "parent": 92, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-computing-the-reverse-and-complement-of-a-sequence-with-pygr", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 141}}, {"pk": 758, "model": "server.post", "fields": {"rght": 15, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 12:56:13", "lft": 14, "post_type": 206247, "score": 0, "title": "C: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "unanswered": false, "content": "You should not put unreliable data into Genbank! Either you prove there is natural variation and you submit all the variants or you make sure you have reliable data and you don't have the problem.", "comment_count": 0, "html": "<p>You should not put unreliable data into Genbank! Either you prove there is natural variation and you submit all the variants or you make sure you have reliable data and you don't have the problem.</p>", "child_count": 0, "closed": false, "tree_id": 63, "revision_count": 0, "parent": 256, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-if-i-have-4-sequence-runs-2-in-each-direction-1-bp-is-different-on-each-should-i-resequence", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 759, "model": "server.post", "fields": {"rght": 17, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 12:58:53", "lft": 16, "post_type": 206247, "score": 0, "title": "C: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "unanswered": false, "content": "In this particular case, you can not talk about natural variation: you are sequencing fragments you've cloned into a plasmid! Unless you've contaminated your prep with two colonies from the plate, all the plasmids in one prep should be identical. If you have ambivalent bases, then it's because your sequencing is of bad quality. You should never submit bad quality data to Genbank.", "comment_count": 0, "html": "<p>In this particular case, you can not talk about natural variation: you are sequencing fragments you've cloned into a plasmid! Unless you've contaminated your prep with two colonies from the plate, all the plasmids in one prep should be identical. If you have ambivalent bases, then it's because your sequencing is of bad quality. You should never submit bad quality data to Genbank.</p>", "child_count": 0, "closed": false, "tree_id": 63, "revision_count": 0, "parent": 256, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-if-i-have-4-sequence-runs-2-in-each-direction-1-bp-is-different-on-each-should-i-resequence", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 760, "model": "server.post", "fields": {"rght": 15, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 14:56:22", "lft": 14, "post_type": 206247, "score": 0, "title": "C: Hardware resources for HPC in Bioinformatics", "unanswered": false, "content": "Thanks for the links, they are most helpful and also a very interesting question indeed.", "comment_count": 0, "html": "<p>Thanks for the links, they are most helpful and also a very interesting question indeed.</p>", "child_count": 0, "closed": false, "tree_id": 77, "revision_count": 0, "parent": 328, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-hardware-resources-for-hpc-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 761, "model": "server.post", "fields": {"rght": 11, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 14:59:45", "lft": 10, "post_type": 206247, "score": 0, "title": "C: Convert microarray quantization in image", "unanswered": false, "content": "Now that you mention it sure does feel an like automated bot. Let's give it a day or two to respond, if that does not happen we'll remove the question.", "comment_count": 0, "html": "<p>Now that you mention it sure does feel an like automated bot. Let's give it a day or two to respond, if that does not happen we'll remove the question.</p>", "child_count": 0, "closed": false, "tree_id": 76, "revision_count": 0, "parent": 327, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-convert-microarray-quantization-in-image", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 762, "model": "server.post", "fields": {"rght": 17, "author": 25, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 15:51:15", "lft": 16, "post_type": 206247, "score": 0, "title": "C: Hardware resources for HPC in Bioinformatics", "unanswered": false, "content": "Excellent edit! Thanks ;)", "comment_count": 0, "html": "<p>Excellent edit! Thanks ;)</p>", "child_count": 0, "closed": false, "tree_id": 77, "revision_count": 0, "parent": 328, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-hardware-resources-for-hpc-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 25}}, {"pk": 763, "model": "server.post", "fields": {"rght": 4, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 16:08:21", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Hardware resources for HPC in Bioinformatics", "unanswered": false, "content": "CUDA are on my whishlist. I've just acquired a SuperServer 6016GT-TF and totally intend to fill it up with NVIDIA Tesla/Fermi . CUDA for Bioinformatics really works. And it is quite affordable.\n\nCell are nice but hard to program/port. Compilers/libs for this type of architecture aren't in good shape right now. Anyway, the speedup is comparable to that in CUDA. OpenCL too isn't mature enough. \n\nBy the way, Xlinx FPGAs possess PowerPC cores which makes them some sort of Cell when properly assembled.\n\n", "comment_count": 0, "html": "<p>CUDA are on my whishlist. I've just acquired a SuperServer 6016GT-TF and totally intend to fill it up with NVIDIA Tesla/Fermi . CUDA for Bioinformatics really works. And it is quite affordable.</p>\n<p>Cell are nice but hard to program/port. Compilers/libs for this type of architecture aren't in good shape right now. Anyway, the speedup is comparable to that in CUDA. OpenCL too isn't mature enough. </p>\n<p>By the way, Xlinx FPGAs possess PowerPC cores which makes them some sort of Cell when properly assembled.</p>", "child_count": 0, "closed": false, "tree_id": 77, "revision_count": 0, "parent": 333, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-hardware-resources-for-hpc-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 764, "model": "server.post", "fields": {"rght": 4, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 17:07:11", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "Daniel : Thanks a lot for the detailed reply, I appreciate it. \n", "comment_count": 0, "html": "<p>Daniel : Thanks a lot for the detailed reply, I appreciate it. </p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 0, "parent": 336, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 765, "model": "server.post", "fields": {"rght": 18, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 17:31:30", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "Small stuff: if possible move tabulated blast output into an SQL database. You will save time needed to write the code iterating over text columns, say for finding best reciprocal hits (BRH). \n", "comment_count": 0, "html": "<p>Small stuff: if possible move tabulated blast output into an SQL database. You will save time needed to write the code iterating over text columns, say for finding best reciprocal hits (BRH). </p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 0, "parent": 305, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 766, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 18:44:39", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Hardware resources for HPC in Bioinformatics", "unanswered": false, "content": "Good point. The applications are the computer ... ;-) ", "comment_count": 0, "html": "<p>Good point. The applications are the computer ... ;-) </p>", "child_count": 0, "closed": false, "tree_id": 77, "revision_count": 0, "parent": 338, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-hardware-resources-for-hpc-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 767, "model": "server.post", "fields": {"rght": 8, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 19:09:36", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Hardware resources for HPC in Bioinformatics", "unanswered": false, "content": "Most people here deal with sequence data and microarrays. So, the basic idea is to use FPGAs to sequence data (higher demand) and CUDAs to microarrays and related. Molecular dynamics and related stuff rely on another cluster. \n<p>\nHere, we will develop solutions on FPGAs (the utmost dream is a FPGA card able to perform Burrows-Wheeler transform based alignments). WE are the tinkerers . . .\n<p>\nAnyway, some people might want a proprietary solution. It's good to know they are worth the trouble, though.", "comment_count": 0, "html": "<p>Most people here deal with sequence data and microarrays. So, the basic idea is to use FPGAs to sequence data (higher demand) and CUDAs to microarrays and related. Molecular dynamics and related stuff rely on another cluster. \n[HTML_REMOVED]\nHere, we will develop solutions on FPGAs (the utmost dream is a FPGA card able to perform Burrows-Wheeler transform based alignments). WE are the tinkerers . . .\n[HTML_REMOVED]\nAnyway, some people might want a proprietary solution. It's good to know they are worth the trouble, though.</p>", "child_count": 0, "closed": false, "tree_id": 77, "revision_count": 0, "parent": 338, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-hardware-resources-for-hpc-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 768, "model": "server.post", "fields": {"rght": 14, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 22:49:34", "lft": 13, "post_type": 206247, "score": 1, "title": "C: A: Which software development technique is used in your lab? ", "unanswered": false, "content": "Thank you very much, this is very interesting. Sorry for the personal question.. but do you have a blog, or did you write any document describing your experience? That would be very useful to many people. I would like to ask you more details but I don't know where to do it! :-)", "comment_count": 0, "html": "<p>Thank you very much, this is very interesting. Sorry for the personal question.. but do you have a blog, or did you write any document describing your experience? That would be very useful to many people. I would like to ask you more details but I don't know where to do it! :-)</p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 0, "parent": 342, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 769, "model": "server.post", "fields": {"rght": 13, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 22:50:11", "lft": 12, "post_type": 206247, "score": 2, "title": "C: Convert microarray quantization in image", "unanswered": false, "content": "This will become a good place to obtain the 'Critic' badge :-)", "comment_count": 0, "html": "<p>This will become a good place to obtain the 'Critic' badge :-)</p>", "child_count": 0, "closed": false, "tree_id": 76, "revision_count": 0, "parent": 327, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-convert-microarray-quantization-in-image", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 770, "model": "server.post", "fields": {"rght": 16, "author": 115, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-17 22:54:13", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Which software development technique is used in your lab? ", "unanswered": false, "content": "Ah, well... being in industry, it is much harder to write a blog. I've signed non-disclosure agreements, etc. I have a very out of date website I put together on biological database design, which I guess I'll add to my profile. It is: http://www.32geeks.com/biodb/\nMy email address is somewhere on those pages. But to spare you the hunt, it is melanie_renee_nelson@yahoo.com. ", "comment_count": 0, "html": "<p>Ah, well... being in industry, it is much harder to write a blog. I've signed non-disclosure agreements, etc. I have a very out of date website I put together on biological database design, which I guess I'll add to my profile. It is: http://www.32geeks.com/biodb/\nMy email address is somewhere on those pages. But to spare you the hunt, it is melanie_renee_nelson@yahoo.com. </p>", "child_count": 0, "closed": false, "tree_id": 74, "revision_count": 0, "parent": 342, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-which-software-development-technique-is-used-in-your-lab", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 115}}, {"pk": 771, "model": "server.post", "fields": {"rght": 15, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 00:48:18", "lft": 14, "post_type": 206247, "score": 0, "title": "C: Convert microarray quantization in image", "unanswered": false, "content": "hear hear, get your Critic badge right here", "comment_count": 0, "html": "<p>hear hear, get your Critic badge right here</p>", "child_count": 0, "closed": false, "tree_id": 76, "revision_count": 0, "parent": 327, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-convert-microarray-quantization-in-image", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 772, "model": "server.post", "fields": {"rght": 20, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 13:03:01", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "i've also seen bioinformatics jobs posted to programming language-specific local user group mailing lists such as perlmongers", "comment_count": 0, "html": "<p>i've also seen bioinformatics jobs posted to programming language-specific local user group mailing lists such as perlmongers</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 0, "parent": 344, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 773, "model": "server.post", "fields": {"rght": 22, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 13:05:29", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "craigslist should also not be overlooked - especially in major cities", "comment_count": 0, "html": "<p>craigslist should also not be overlooked - especially in major cities</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 0, "parent": 344, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 774, "model": "server.post", "fields": {"rght": 11, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 13:31:39", "lft": 10, "post_type": 206247, "score": 4, "title": "C: What license do you use when you release code and data?", "unanswered": false, "content": "An interesting situtation is that you may have no rights to release any of your work as open-source software as goverened by your contract with your instiutution.  The fact this happens anyway is because a lot of this flies under the radar in terms of IP.  Every time I've spoken to our local business team they always ask if any piece of work we take on will result in IP worth commercialising.  ", "comment_count": 0, "html": "<p>An interesting situtation is that you may have no rights to release any of your work as open-source software as goverened by your contract with your instiutution.  The fact this happens anyway is because a lot of this flies under the radar in terms of IP.  Every time I've spoken to our local business team they always ask if any piece of work we take on will result in IP worth commercialising.<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 0, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 775, "model": "server.post", "fields": {"rght": 15, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 17:35:50", "lft": 14, "post_type": 206247, "score": 3, "title": "C: What license do you use when you release code and data?", "unanswered": false, "content": "The best course of action is: don't ask don't tell policy ... ;-)", "comment_count": 0, "html": "<p>The best course of action is: don't ask don't tell policy ... ;-)</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 0, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 776, "model": "server.post", "fields": {"rght": 19, "author": 120, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 20:37:39", "lft": 18, "post_type": 206247, "score": 0, "title": "C: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "unanswered": false, "content": "In this case I sequenced more colonies and found a consensus sequence, however, I'm cloning PCR products, so I don't think it is possible to say that there could not be natural variation in the PCR amplicon pool.  One good example would be a bacterium with 2 different 16s inside a single cell, this could produce 2 populations  of PCR products.  If the ratio were 1:3, how often would you have to sample cloned colonies in order to observe this natural variation?", "comment_count": 0, "html": "<p>In this case I sequenced more colonies and found a consensus sequence, however, I'm cloning PCR products, so I don't think it is possible to say that there could not be natural variation in the PCR amplicon pool.  One good example would be a bacterium with 2 different 16s inside a single cell, this could produce 2 populations  of PCR products.  If the ratio were 1:3, how often would you have to sample cloned colonies in order to observe this natural variation?</p>", "child_count": 0, "closed": false, "tree_id": 63, "revision_count": 0, "parent": 256, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-if-i-have-4-sequence-runs-2-in-each-direction-1-bp-is-different-on-each-should-i-resequence", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 120}}, {"pk": 777, "model": "server.post", "fields": {"rght": 4, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 21:13:45", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Repeat subunit based multiple alignment of DNA", "unanswered": false, "content": "Small update: another aligner can use an arbitrary (but less than 250) alphabet:\nhttp://www.vmatch.de/", "comment_count": 0, "html": "<p>Small update: another aligner can use an arbitrary (but less than 250) alphabet:\nhttp://www.vmatch.de/</p>", "child_count": 0, "closed": false, "tree_id": 44, "revision_count": 0, "parent": 176, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-repeat-subunit-based-multiple-alignment-of-dna", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 778, "model": "server.post", "fields": {"rght": 21, "author": 71, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 22:21:20", "lft": 20, "post_type": 206247, "score": 0, "title": "C: What license do you use when you release code and data?", "unanswered": false, "content": "I haven't released software publicly myself, but IMO for libraries and toolkits Apache/MIT/BSD-style licensing is the appropriate way to go.  For full featured software stack you have a choice.  Personally I prefer more permissive licenses, but can understand the need to GPL the code.", "comment_count": 0, "html": "<p>I haven't released software publicly myself, but IMO for libraries and toolkits Apache/MIT/BSD-style licensing is the appropriate way to go.  For full featured software stack you have a choice.  Personally I prefer more permissive licenses, but can understand the need to GPL the code.</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 0, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 71}}, {"pk": 779, "model": "server.post", "fields": {"rght": 4, "author": 120, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 22:23:01", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How do I access and query entire genome sequences with R", "unanswered": false, "content": "thanks Chris, but that doesn't give me any of the annotations right?  I want to say gene symbol \"Rbcl\" and if it is present then it returns the coding sequence for that gene. ", "comment_count": 0, "html": "<p>thanks Chris, but that doesn't give me any of the annotations right?  I want to say gene symbol \"Rbcl\" and if it is present then it returns the coding sequence for that gene. </p>", "child_count": 0, "closed": false, "tree_id": 81, "revision_count": 0, "parent": 358, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-how-do-i-access-and-query-entire-genome-sequences-with-r", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 120}}, {"pk": 780, "model": "server.post", "fields": {"rght": 6, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 22:47:41", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: How do I access and query entire genome sequences with R", "unanswered": false, "content": "1) It's pretty easy to slurp down all 18k gene names and locations from someplace like Santa Cruz, and store it in a file locally.  This gets trickier if you're worried about aliases and such, in which case you'll want to do something like Neil or Pierre suggest and query a web service.\n\n2) Credit where credit is due - Neil pointed me to the seqinr package the other day\n", "comment_count": 0, "html": "<p>1) It's pretty easy to slurp down all 18k gene names and locations from someplace like Santa Cruz, and store it in a file locally.  This gets trickier if you're worried about aliases and such, in which case you'll want to do something like Neil or Pierre suggest and query a web service.</p>\n<p>2) Credit where credit is due - Neil pointed me to the seqinr package the other day</p>", "child_count": 0, "closed": false, "tree_id": 81, "revision_count": 0, "parent": 358, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-how-do-i-access-and-query-entire-genome-sequences-with-r", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 781, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-18 23:41:50", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: distance measure between chip-seq peak set profiles", "unanswered": false, "content": "One of shortcomings of the approaches that detect overall differences is that these don't answer what will be the next logical question: In what way are the two peak distributions different.", "comment_count": 0, "html": "<p>One of shortcomings of the approaches that detect overall differences is that these don't answer what will be the next logical question: In what way are the two peak distributions different.</p>", "child_count": 0, "closed": false, "tree_id": 79, "revision_count": 0, "parent": 356, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-distance-measure-between-chip-seq-peak-set-profiles", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 782, "model": "server.post", "fields": {"rght": 8, "author": 137, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 11:55:21", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: distance measure between chip-seq peak set profiles", "unanswered": false, "content": "I think you expect to much from a statistical test :)", "comment_count": 0, "html": "<p>I think you expect to much from a statistical test :)</p>", "child_count": 0, "closed": false, "tree_id": 79, "revision_count": 0, "parent": 356, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-distance-measure-between-chip-seq-peak-set-profiles", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 137}}, {"pk": 783, "model": "server.post", "fields": {"rght": 23, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 12:52:55", "lft": 22, "post_type": 206247, "score": 0, "title": "C: What license do you use when you release code and data?", "unanswered": false, "content": "LGPL seems favoured by our more developmentally oriented bioinformaticians I've noted.", "comment_count": 0, "html": "<p>LGPL seems favoured by our more developmentally oriented bioinformaticians I've noted.</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 0, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 784, "model": "server.post", "fields": {"rght": 25, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 15:50:47", "lft": 24, "post_type": 206247, "score": 0, "title": "C: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "Actually, I see we are using different marts, could you try the 'real' mart at http://www.biomart.org/biomart/martwsdl ?", "comment_count": 0, "html": "<p>Actually, I see we are using different marts, could you try the 'real' mart at http://www.biomart.org/biomart/martwsdl ?</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 362, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 785, "model": "server.post", "fields": {"rght": 4, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 15:54:53", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "many thanks Michael, I will try with another tool. wsimport works fine with the services created with ${JAVA_HOME}/bin/wsgen . For example I tested it with EBI/Intact http://plindenbaum.blogspot.com/2008/10/ebiintact-web-service-api-my-notebook.html", "comment_count": 0, "html": "<p>many thanks Michael, I will try with another tool. wsimport works fine with the services created with ${JAVA_HOME}/bin/wsgen . For example I tested it with EBI/Intact http://plindenbaum.blogspot.com/2008/10/ebiintact-web-service-api-my-notebook.html</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 365, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 786, "model": "server.post", "fields": {"rght": 8, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 16:15:13", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "Michael, a small typo; your URL should be http://www.biomart.org/biomart/martsoap  to martwsdl", "comment_count": 0, "html": "<p>Michael, a small typo; your URL should be http://www.biomart.org/biomart/martsoap  to martwsdl</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 365, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 787, "model": "server.post", "fields": {"rght": 10, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 16:16:00", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "Hum, I tried CXF/wsdl2java : same (empty) result", "comment_count": 0, "html": "<p>Hum, I tried CXF/wsdl2java : same (empty) result</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 365, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 788, "model": "server.post", "fields": {"rght": 12, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 16:16:19", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "Michael, a small typo; your URL should be biomart.org/biomart/martsoap  , not martwsdl", "comment_count": 0, "html": "<p>Michael, a small typo; your URL should be biomart.org/biomart/martsoap  , not martwsdl</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 365, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 789, "model": "server.post", "fields": {"rght": 14, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 16:18:46", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "but, as you said\n\ncurl --header 'Content-Type: text/xml' --data '<?xml version=\"1.0\"?><soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:mar=\"http://www.biomart.org:80/MartServiceSoap\">\n<soapenv:Header/>\n   <soapenv:Body>\n      <mar:getRegistry/>\n   </soapenv:Body>\n</soapenv:Envelope>\n' http://www.biomart.org/biomart/martsoap\n\nis OK :-/", "comment_count": 0, "html": "<p>but, as you said</p>\n<p>curl --header 'Content-Type: text/xml' --data '&lt;?xml version=\"1.0\"?&gt;[HTML_REMOVED]\n[HTML_REMOVED]\n   [HTML_REMOVED]\n<div class=\"highlight\"><pre>      <span class=\"sr\">&lt;mar:getRegistry/&gt;</span>\n</pre></div>\n\n   [HTML_REMOVED]\n[HTML_REMOVED]\n' http://www.biomart.org/biomart/martsoap</p>\n<p>is OK :-/</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 365, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 790, "model": "server.post", "fields": {"rght": 16, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 17:15:26", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "correct: biomart.org/biomart/martsoap is the service endpoint,\nwhile /martwsdl is the wsdl location. Whith soapui, you just put in the wsdl and the rest is automatic. Good luck! ", "comment_count": 0, "html": "<p>correct: biomart.org/biomart/martsoap is the service endpoint,\nwhile /martwsdl is the wsdl location. Whith soapui, you just put in the wsdl and the rest is automatic. Good luck! </p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 365, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 791, "model": "server.post", "fields": {"rght": 4, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 21:35:25", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: What license do you use when you release code and data?", "unanswered": false, "content": "I think this captures the essence of it, and the licence you wish for doesn't (really) exist yet. I'd like the simplicity of Creative Commons licenses that can be applied to software.", "comment_count": 0, "html": "<p>I think this captures the essence of it, and the licence you wish for doesn't (really) exist yet. I'd like the simplicity of Creative Commons licenses that can be applied to software.</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 0, "parent": 350, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 792, "model": "server.post", "fields": {"rght": 8, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 22:24:55", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How do I access and query entire genome sequences with R", "unanswered": false, "content": "is there a way to get sequences lengths as a data frame without reading in the whole file?", "comment_count": 0, "html": "<p>is there a way to get sequences lengths as a data frame without reading in the whole file?</p>", "child_count": 0, "closed": false, "tree_id": 81, "revision_count": 0, "parent": 358, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-how-do-i-access-and-query-entire-genome-sequences-with-r", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 793, "model": "server.post", "fields": {"rght": 18, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-19 23:06:37", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "i asked for help on SO  : http://stackoverflow.com/questions/2479069", "comment_count": 0, "html": "<p>i asked for help on SO  : http://stackoverflow.com/questions/2479069</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 365, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 794, "model": "server.post", "fields": {"rght": 27, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 08:24:31", "lft": 26, "post_type": 206247, "score": 0, "title": "C: What license do you use when you release code and data?", "unanswered": false, "content": "Very broad question... you see people only answer part of it, making it impossible to indicate a single 'correct' answer... the current one by Pierre does not answer all... perhaps split up?", "comment_count": 0, "html": "<p>Very broad question... you see people only answer part of it, making it impossible to indicate a single 'correct' answer... the current one by Pierre does not answer all... perhaps split up?</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 0, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 795, "model": "server.post", "fields": {"rght": 20, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 09:41:53", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "I got the anwser from the mart mailing list: http://www.mail-archive.com/mart-dev@ebi.ac.uk/msg02406.html ... hum....", "comment_count": 0, "html": "<p>I got the anwser from the mart mailing list: http://www.mail-archive.com/mart-dev@ebi.ac.uk/msg02406.html ... hum....</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 365, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 796, "model": "server.post", "fields": {"rght": 6, "author": 79, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 11:30:50", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: What license do you use when you release code and data?", "unanswered": false, "content": "I really like your sum-up Pierre..", "comment_count": 0, "html": "<p>I really like your sum-up Pierre..</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 0, "parent": 350, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 79}}, {"pk": 797, "model": "server.post", "fields": {"rght": 4, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 16:14:16", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "Thanks, Pierre. But none of these will work for me. I need all (or several) chromosomes, so cannot use GB style. Ideographica is the closest, but you can only annotate some genomic locations (cannot show variable data).", "comment_count": 0, "html": "<p>Thanks, Pierre. But none of these will work for me. I need all (or several) chromosomes, so cannot use GB style. Ideographica is the closest, but you can only annotate some genomic locations (cannot show variable data).</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 379, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 798, "model": "server.post", "fields": {"rght": 10, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-20 22:51:15", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: How do I access and query entire genome sequences with R", "unanswered": false, "content": "Jeremy - are you talking about the gene lengths? It's pretty easy to parse through the gene list from UCSC line by line and find just the length between first and last exon.  I'd probably parse it with Ruby or Perl first, then read the results into R.\n\nIf you actually need the sequence, I'd probably change my recommendation to the BSGenome package (http://bioconductor.org/packages/2.3/bioc/html/BSgenome.html) in combination with the BioStrings package.  It'll hold the whole genome in about 500mb which makes it easier to handle.", "comment_count": 0, "html": "<p>Jeremy - are you talking about the gene lengths? It's pretty easy to parse through the gene list from UCSC line by line and find just the length between first and last exon.  I'd probably parse it with Ruby or Perl first, then read the results into R.</p>\n<p>If you actually need the sequence, I'd probably change my recommendation to the BSGenome package (http://bioconductor.org/packages/2.3/bioc/html/BSgenome.html) in combination with the BioStrings package.  It'll hold the whole genome in about 500mb which makes it easier to handle.</p>", "child_count": 0, "closed": false, "tree_id": 81, "revision_count": 0, "parent": 358, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-how-do-i-access-and-query-entire-genome-sequences-with-r", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 799, "model": "server.post", "fields": {"rght": 22, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-21 11:10:37", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "I saw it, looks as if they didn't get what the problem is. I will write to the mart_dev with an in-depth description of the problems in the service and wsdl. That might need a little more time. ", "comment_count": 0, "html": "<p>I saw it, looks as if they didn't get what the problem is. I will write to the mart_dev with an in-depth description of the problems in the service and wsdl. That might need a little more time. </p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 365, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 800, "model": "server.post", "fields": {"rght": 6, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-21 22:41:41", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "Thanks Michael !", "comment_count": 0, "html": "<p>Thanks Michael !</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 384, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 801, "model": "server.post", "fields": {"rght": 8, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-21 23:16:05", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How to retrive the DNA sequence from a list of EMBL and GeneID", "unanswered": false, "content": "In that case, Pierre's solution is the best. Since you use Perl, you might like to look at the Bioperl EUtils Cookbook - http://www.bioperl.org/wiki/HOWTO:EUtilities_Cookbook.", "comment_count": 0, "html": "<p>In that case, Pierre's solution is the best. Since you use Perl, you might like to look at the Bioperl EUtils Cookbook - http://www.bioperl.org/wiki/HOWTO:EUtilities_Cookbook.</p>", "child_count": 0, "closed": false, "tree_id": 84, "revision_count": 0, "parent": 382, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-how-to-retrive-the-dna-sequence-from-a-list-of-embl-and-geneid", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 802, "model": "server.post", "fields": {"rght": 8, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 10:09:49", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "AcademicTransfer is good.", "comment_count": 0, "html": "<p>AcademicTransfer is good.</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 0, "parent": 299, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 803, "model": "server.post", "fields": {"rght": 29, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 10:40:28", "lft": 28, "post_type": 206247, "score": 0, "title": "C: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "Just sent my message to mart-dev, let's see what comes out of it.", "comment_count": 0, "html": "<p>Just sent my message to mart-dev, let's see what comes out of it.</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 362, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:02", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 804, "model": "server.post", "fields": {"rght": 32, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 13:26:12", "lft": 31, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "Absolutely agree; it's easy to get wrapped up in normalization choice and forget other factors. ", "comment_count": 0, "html": "<p>Absolutely agree; it's easy to get wrapped up in normalization choice and forget other factors. </p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 393, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 805, "model": "server.post", "fields": {"rght": 10, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 13:28:08", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "well, from practical observations I can tell you that most of the time a person that asks what you do does not expect an answer that requires reasoning and mental work", "comment_count": 0, "html": "<p>well, from practical observations I can tell you that most of the time a person that asks what you do does not expect an answer that requires reasoning and mental work</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 0, "parent": 390, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 806, "model": "server.post", "fields": {"rght": 6, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 14:07:17", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "I heard about Circos, it's very interesting. Thanks. Had some trouble with GD library while installing it on Mac, but will try again. Anyway, I need a classical plot for now. ", "comment_count": 0, "html": "<p>I heard about Circos, it's very interesting. Thanks. Had some trouble with GD library while installing it on Mac, but will try again. Anyway, I need a classical plot for now. </p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 380, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 807, "model": "server.post", "fields": {"rght": 8, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 14:09:51", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "Thank you, I didn't know about it. Still it does not do what I need and I think Flash will have memory problems with a lot of points. ", "comment_count": 0, "html": "<p>Thank you, I didn't know about it. Still it does not do what I need and I think Flash will have memory problems with a lot of points. </p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 381, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 808, "model": "server.post", "fields": {"rght": 4, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 14:19:30", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "Let me say that I do understand the tests. I'm one of the guys who develops statistical tests for such an end. My questions is about reliability, not power or accuracy. I found out that my notion of reliability (which is based on statistical mechanics ideas)  is too much different from that of peple on the wet bench. IMHO microarrays are not suitable for differential gene expression & similar experiments (way too high type-II error rate). But, as experimentalists keep using it, reliability still is a important matter.", "comment_count": 0, "html": "<p>Let me say that I do understand the tests. I'm one of the guys who develops statistical tests for such an end. My questions is about reliability, not power or accuracy. I found out that my notion of reliability (which is based on statistical mechanics ideas)  is too much different from that of peple on the wet bench. IMHO microarrays are not suitable for differential gene expression &amp; similar experiments (way too high type-II error rate). But, as experimentalists keep using it, reliability still is a important matter.</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 392, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 809, "model": "server.post", "fields": {"rght": 28, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 14:37:37", "lft": 27, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "Again, I'm asking about realiability. After normalization, everything is pretty straightforward. Those studies seems very interesting !!! Could you name them?", "comment_count": 0, "html": "<p>Again, I'm asking about realiability. After normalization, everything is pretty straightforward. Those studies seems very interesting !!! Could you name them?</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 393, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 810, "model": "server.post", "fields": {"rght": 20, "author": 142, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 14:42:29", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "Hi guys, thanks for all the help. However, after using the above formatdb line, I get a fatal error saying that the database was not found when using the blastall code. I think there is a problem in the indexing of the fasta to a 'database'. I wouldn't have thought I would need to index both database and query files. Is there another way to index the fasta to a db? Cheers!", "comment_count": 0, "html": "<p>Hi guys, thanks for all the help. However, after using the above formatdb line, I get a fatal error saying that the database was not found when using the blastall code. I think there is a problem in the indexing of the fasta to a 'database'. I wouldn't have thought I would need to index both database and query files. Is there another way to index the fasta to a db? Cheers!</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 0, "parent": 305, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 142}}, {"pk": 811, "model": "server.post", "fields": {"rght": 22, "author": 142, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 15:27:06", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: Compare two protein sequences using local BLAST", "unanswered": false, "content": "Scratch that! Got it working using the pretty well documented program parameters on the ncbi website: http://www.ncbi.nlm.nih.gov/staff/tao/URLAPI/blastall/", "comment_count": 0, "html": "<p>Scratch that! Got it working using the pretty well documented program parameters on the ncbi website: http://www.ncbi.nlm.nih.gov/staff/tao/URLAPI/blastall/</p>", "child_count": 0, "closed": false, "tree_id": 72, "revision_count": 0, "parent": 305, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-compare-two-protein-sequences-using-local-blast", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 142}}, {"pk": 812, "model": "server.post", "fields": {"rght": 30, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 15:54:52", "lft": 29, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "I think it is the normalization that is pretty straightforward, you pick a method and run it. The interpretation that comes after is a lot more difficult. Search for \"reproducibility of microarray data\" for many papers on this. I just quoted from memory not from a document.", "comment_count": 0, "html": "<p>I think it is the normalization that is pretty straightforward, you pick a method and run it. The interpretation that comes after is a lot more difficult. Search for \"reproducibility of microarray data\" for many papers on this. I just quoted from memory not from a document.</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 393, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 813, "model": "server.post", "fields": {"rght": 4, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 16:49:27", "lft": 3, "post_type": 206247, "score": 4, "title": "C: A: How do I import data from a torrent into a BioPerl, R, Bioclipse, or Taverna application?", "unanswered": false, "content": "The data underlying the torrents cannot be modified because unlike files that are downloaded by name it has check-sums that must match. You would need to publish a new torrent for modified data. So torrents are actually more reliable than a download. The second issue of disappearing data is also a vote for torrents. Unlike a download that can disappear unless someone republishes it on an FTP site a torrent is automatically distributed and shared thus it will live on even if the original source is gone.", "comment_count": 0, "html": "<p>The data underlying the torrents cannot be modified because unlike files that are downloaded by name it has check-sums that must match. You would need to publish a new torrent for modified data. So torrents are actually more reliable than a download. The second issue of disappearing data is also a vote for torrents. Unlike a download that can disappear unless someone republishes it on an FTP site a torrent is automatically distributed and shared thus it will live on even if the original source is gone.</p>", "child_count": 0, "closed": false, "tree_id": 88, "revision_count": 0, "parent": 394, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-how-do-i-import-data-from-a-torrent-into-a-bioperl-r-bioclipse-or-taverna-application", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 814, "model": "server.post", "fields": {"rght": 4, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:15:15", "lft": 3, "post_type": 206247, "score": 2, "title": "C: A: What do different bioinformatics positions mean?", "unanswered": false, "content": "Yes, I think most people posting jobs may even have less understanding of the various nuances of bio-informatics research than we do.", "comment_count": 0, "html": "<p>Yes, I think most people posting jobs may even have less understanding of the various nuances of bio-informatics research than we do.</p>", "child_count": 0, "closed": false, "tree_id": 89, "revision_count": 0, "parent": 400, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-what-do-different-bioinformatics-positions-mean", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 815, "model": "server.post", "fields": {"rght": 24, "author": 85, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:16:43", "lft": 23, "post_type": 206247, "score": 0, "title": "C: A: Where to advertise or find bioinformatics jobs", "unanswered": false, "content": "meh, really gotta read the comments above more carefully.  ", "comment_count": 0, "html": "<p>meh, really gotta read the comments above more carefully.<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 71, "revision_count": 0, "parent": 405, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:02", "slug": "c-a-where-to-advertise-or-find-bioinformatics-jobs", "lastedit_date": "2011-11-24 14:49:02", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 85}}, {"pk": 816, "model": "server.post", "fields": {"rght": 6, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:26:14", "lft": 5, "post_type": 206247, "score": 1, "title": "C: A: How difficult/reliable is it to programmatically (python) look up and download papers?", "unanswered": false, "content": "Mechanize is a great tool. You could even go an use twill (a library built on Mechanize) to further simplify the usage that you are after: http://pypi.python.org/pypi/twill/0.9", "comment_count": 0, "html": "<p>Mechanize is a great tool. You could even go an use twill (a library built on Mechanize) to further simplify the usage that you are after: http://pypi.python.org/pypi/twill/0.9</p>", "child_count": 0, "closed": false, "tree_id": 91, "revision_count": 0, "parent": 406, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-how-difficultreliable-is-it-to-programmatically-python-look-up-and-download-papers", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 817, "model": "server.post", "fields": {"rght": 15, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:46:06", "lft": 14, "post_type": 206247, "score": 1, "title": "C: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "Try starting with \"Lets get the kettle on Mum, I've got something to tell you ...\"", "comment_count": 0, "html": "<p>Try starting with \"Lets get the kettle on Mum, I've got something to tell you ...\"</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 0, "parent": 388, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 818, "model": "server.post", "fields": {"rght": 17, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 18:48:21", "lft": 16, "post_type": 206247, "score": 0, "title": "C: Convert microarray quantization in image", "unanswered": false, "content": "Ha ha! Just what I was thinking and now doing Giovanni.", "comment_count": 0, "html": "<p>Ha ha! Just what I was thinking and now doing Giovanni.</p>", "child_count": 0, "closed": false, "tree_id": 76, "revision_count": 0, "parent": 327, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-convert-microarray-quantization-in-image", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 819, "model": "server.post", "fields": {"rght": 35, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 19:14:20", "lft": 34, "post_type": 206247, "score": 0, "title": "C: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "Can you give a short definition of what you mean by reliability in the statistical sense? I confess I had to look up the definition myself, but if it is as is wikipedia \"In statistics, reliability is the consistency of a set of measurements or measuring instrument, often used to describe a test. Reliability is inversely related to random error.\" then the question makes no sense, because most or all normalization methods are deterministic.", "comment_count": 0, "html": "<p>Can you give a short definition of what you mean by reliability in the statistical sense? I confess I had to look up the definition myself, but if it is as is wikipedia \"In statistics, reliability is the consistency of a set of measurements or measuring instrument, often used to describe a test. Reliability is inversely related to random error.\" then the question makes no sense, because most or all normalization methods are deterministic.</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 387, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 820, "model": "server.post", "fields": {"rght": 16, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 20:52:55", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: What phylogeny viewing software do you use?", "unanswered": false, "content": "Me too. I'm reading this book on the bus each morning.", "comment_count": 0, "html": "<p>Me too. I'm reading this book on the bus each morning.</p>", "child_count": 0, "closed": false, "tree_id": 90, "revision_count": 0, "parent": 412, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-phylogeny-viewing-software-do-you-use", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 821, "model": "server.post", "fields": {"rght": 6, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 20:57:36", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: What do different bioinformatics positions mean?", "unanswered": false, "content": "Melanie : I have seen \"Bioinformatics Analyst\" position, where the primary duty is to develop/code [see : http://www.bioinformatics.org/forums/forum.php?forum_id=7896 ]. It is not always possible to classify the positions based on the job title.", "comment_count": 0, "html": "<p>Melanie : I have seen \"Bioinformatics Analyst\" position, where the primary duty is to develop/code [see : http://www.bioinformatics.org/forums/forum.php?forum_id=7896 ]. It is not always possible to classify the positions based on the job title.</p>", "child_count": 0, "closed": false, "tree_id": 89, "revision_count": 0, "parent": 408, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-do-different-bioinformatics-positions-mean", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 822, "model": "server.post", "fields": {"rght": 10, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 21:27:02", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "Thanks. Do you know if it supports multiple chromosomes?", "comment_count": 0, "html": "<p>Thanks. Do you know if it supports multiple chromosomes?</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 414, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 823, "model": "server.post", "fields": {"rght": 8, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-22 23:18:44", "lft": 7, "post_type": 206247, "score": 1, "title": "C: A: What do different bioinformatics positions mean?", "unanswered": false, "content": "Still, I think this is as good of an explanation as it can be. ", "comment_count": 0, "html": "<p>Still, I think this is as good of an explanation as it can be. </p>", "child_count": 0, "closed": false, "tree_id": 89, "revision_count": 0, "parent": 408, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-what-do-different-bioinformatics-positions-mean", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 824, "model": "server.post", "fields": {"rght": 6, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 00:28:24", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "If you develop the tests, you should be telling us which are the most reliable :-)\n\nI tend to agree with Michael's comment at the top. Normalization is not a measurement. If anything, the raw intensity is the measurement. But it is not a measurement in the same way that, say, putting a thermometer in water is a measurement. You might have a hypothesis about what observed intensities should be, but variation will ensure that this will never be consistent.\n\nI also agree with you that many microarray experiments are poor measures of gene expression - but that's the way the science chose to go.", "comment_count": 0, "html": "<p>If you develop the tests, you should be telling us which are the most reliable :-)</p>\n<p>I tend to agree with Michael's comment at the top. Normalization is not a measurement. If anything, the raw intensity is the measurement. But it is not a measurement in the same way that, say, putting a thermometer in water is a measurement. You might have a hypothesis about what observed intensities should be, but variation will ensure that this will never be consistent.</p>\n<p>I also agree with you that many microarray experiments are poor measures of gene expression - but that's the way the science chose to go.</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 392, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 825, "model": "server.post", "fields": {"rght": 16, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 00:31:59", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "I second the use of GenomeGraphs. It should support as many chromosomes (and other features) as you like. The figure shown is composed of several \"tracks\", rendered in the order given by the code. All you would need to do is add more makeIdeogram() lines, with the code to plot the data under each one.", "comment_count": 0, "html": "<p>I second the use of GenomeGraphs. It should support as many chromosomes (and other features) as you like. The figure shown is composed of several \"tracks\", rendered in the order given by the code. All you would need to do is add more makeIdeogram() lines, with the code to plot the data under each one.</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 414, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 826, "model": "server.post", "fields": {"rght": 8, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 01:14:12", "lft": 7, "post_type": 206247, "score": 1, "title": "C: A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "Pierre, this is great solution. I completely forgot about mysql server. However, I'd recommend to use refFlat table instead of knownGene and K.geneName instead of K.proteinID. In this case you will get HUGO gene name. Anyway, it's up to OP.", "comment_count": 0, "html": "<p>Pierre, this is great solution. I completely forgot about mysql server. However, I'd recommend to use refFlat table instead of knownGene and K.geneName instead of K.proteinID. In this case you will get HUGO gene name. Anyway, it's up to OP.</p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 0, "parent": 418, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 827, "model": "server.post", "fields": {"rght": 24, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 02:04:15", "lft": 23, "post_type": 206247, "score": 0, "title": "C: A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "Excellent ! I was looking for something like this. Thanks a lot Pierre. ", "comment_count": 0, "html": "<p>Excellent ! I was looking for something like this. Thanks a lot Pierre. </p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 0, "parent": 418, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 828, "model": "server.post", "fields": {"rght": 22, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 02:05:45", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "I heard of plink, yet to explore. Thanks for the link. ", "comment_count": 0, "html": "<p>I heard of plink, yet to explore. Thanks for the link. </p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 0, "parent": 419, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 829, "model": "server.post", "fields": {"rght": 4, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 02:05:55", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "Thanks for your points. ", "comment_count": 0, "html": "<p>Thanks for your points. </p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 0, "parent": 416, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 830, "model": "server.post", "fields": {"rght": 6, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 02:06:02", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "Thanks Michael. ", "comment_count": 0, "html": "<p>Thanks Michael. </p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 0, "parent": 417, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 831, "model": "server.post", "fields": {"rght": 8, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 02:12:22", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "I am afraid this is not exactly I am looking for. I wanted to check if a particular SNP is not mapped to a gene, whether there will be any known genes in +/- 60KB of that SNP. This particular BioMart query is fetching the sequence not annotation. I have tried one with annotation and it works. : http://www.biomart.org/biomart/martview/c26efcafd362abccc4af83039c441762.  But sometimes BioMart out put requires lot of post-processing. Also it will be nice if BioMart can have options to select fields multiple attributes. ", "comment_count": 0, "html": "<p>I am afraid this is not exactly I am looking for. I wanted to check if a particular SNP is not mapped to a gene, whether there will be any known genes in +/- 60KB of that SNP. This particular BioMart query is fetching the sequence not annotation. I have tried one with annotation and it works. : http://www.biomart.org/biomart/martview/c26efcafd362abccc4af83039c441762.  But sometimes BioMart out put requires lot of post-processing. Also it will be nice if BioMart can have options to select fields multiple attributes. </p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 0, "parent": 417, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 832, "model": "server.post", "fields": {"rght": 10, "author": 163, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 08:22:46", "lft": 9, "post_type": 206247, "score": 1, "title": "C: A: What phylogeny viewing software do you use?", "unanswered": false, "content": "FigTree is a cross platform Java program (the screen shot shows it running on Mac OS X, but it runs on Windows and Unix/Linux as well).", "comment_count": 0, "html": "<p>FigTree is a cross platform Java program (the screen shot shows it running on Mac OS X, but it runs on Windows and Unix/Linux as well).</p>", "child_count": 0, "closed": false, "tree_id": 90, "revision_count": 0, "parent": 411, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-what-phylogeny-viewing-software-do-you-use", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 163}}, {"pk": 833, "model": "server.post", "fields": {"rght": 31, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 08:54:31", "lft": 30, "post_type": 206247, "score": 0, "title": "C: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "I wanted to use a telephone, but was told to use a walkie-talkie instead...\nFor now, no chance for the SOAP service, have to try the REST service instead. The developers say, they are working on porting BioMart to Java, which I appreciate. ", "comment_count": 0, "html": "<p>I wanted to use a telephone, but was told to use a walkie-talkie instead...\nFor now, no chance for the SOAP service, have to try the REST service instead. The developers say, they are working on porting BioMart to Java, which I appreciate. </p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 362, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 834, "model": "server.post", "fields": {"rght": 10, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 08:56:52", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "Yes, sorry, I misunderstood your question. What Pierre described is much better here.", "comment_count": 0, "html": "<p>Yes, sorry, I misunderstood your question. What Pierre described is much better here.</p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 0, "parent": 417, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 835, "model": "server.post", "fields": {"rght": 33, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 09:10:16", "lft": 32, "post_type": 206247, "score": 0, "title": "C: Anyone using \"Biomart + Java Web Services\" ?", "unanswered": false, "content": "I saw your messages on the mart-dev mailing Michael. Thanks for that. Yes, some answers were weird \"your java thing cannot understand our service ? solution is: use REST...\" :-/", "comment_count": 0, "html": "<p>I saw your messages on the mart-dev mailing Michael. Thanks for that. Yes, some answers were weird \"your java thing cannot understand our service ? solution is: use REST...\" :-/</p>", "child_count": 0, "closed": false, "tree_id": 82, "revision_count": 0, "parent": 362, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-anyone-using-biomart-java-web-services", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 836, "model": "server.post", "fields": {"rght": 22, "author": 159, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 09:37:32", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "Thankyou for your answer.", "comment_count": 0, "html": "<p>Thankyou for your answer.</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 0, "parent": 399, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 159}}, {"pk": 837, "model": "server.post", "fields": {"rght": 12, "author": 159, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 09:37:34", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "Thankyou for your answer.", "comment_count": 0, "html": "<p>Thankyou for your answer.</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 0, "parent": 390, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 159}}, {"pk": 838, "model": "server.post", "fields": {"rght": 16, "author": 159, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 09:37:46", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "Thankyou for your answer.", "comment_count": 0, "html": "<p>Thankyou for your answer.</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 0, "parent": 397, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 159}}, {"pk": 839, "model": "server.post", "fields": {"rght": 4, "author": 159, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 09:37:51", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "Thankyou for your answer.", "comment_count": 0, "html": "<p>Thankyou for your answer.</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 0, "parent": 389, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 159}}, {"pk": 840, "model": "server.post", "fields": {"rght": 8, "author": 159, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 09:38:01", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "Thankyou for your answer. This is my favourite.", "comment_count": 0, "html": "<p>Thankyou for your answer. This is my favourite.</p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 0, "parent": 395, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 159}}, {"pk": 841, "model": "server.post", "fields": {"rght": 12, "author": 90, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 11:42:53", "lft": 11, "post_type": 206247, "score": 1, "title": "C: A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "Very nice solution - anything that takes us away from ad hoc Perl scripts is good!", "comment_count": 0, "html": "<p>Very nice solution - anything that takes us away from ad hoc Perl scripts is good!</p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 0, "parent": 418, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 90}}, {"pk": 842, "model": "server.post", "fields": {"rght": 37, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 11:47:27", "lft": 36, "post_type": 206247, "score": 0, "title": "C: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "It's true that many models are deterministic. But, the most used are model-based. Hence, stochastic/statistical in its nature (e. g. RMA). If one treats normalization as an experiment (which indeed it is), this question makes a lot of sense, though.", "comment_count": 0, "html": "<p>It's true that many models are deterministic. But, the most used are model-based. Hence, stochastic/statistical in its nature (e. g. RMA). If one treats normalization as an experiment (which indeed it is), this question makes a lot of sense, though.</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 387, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 843, "model": "server.post", "fields": {"rght": 14, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 11:52:17", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "Is I said in other comments, one can treat the normalization procedure as an experiment over the raw intensities. There is no legal impediment to do that. The normalization procedure will be you thermometer. And, just to remember, RMA do have hypothesis about intensities.", "comment_count": 0, "html": "<p>Is I said in other comments, one can treat the normalization procedure as an experiment over the raw intensities. There is no legal impediment to do that. The normalization procedure will be you thermometer. And, just to remember, RMA do have hypothesis about intensities.</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 392, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 844, "model": "server.post", "fields": {"rght": 26, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 12:00:46", "lft": 25, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "Normalization is the main source of variability (or lack of it) in microarray data. As the intensity level is non-linear and most normalization procedures do use a linear model, the choice of the model do alter the final result. ", "comment_count": 0, "html": "<p>Normalization is the main source of variability (or lack of it) in microarray data. As the intensity level is non-linear and most normalization procedures do use a linear model, the choice of the model do alter the final result. </p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 393, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 845, "model": "server.post", "fields": {"rght": 41, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 12:07:00", "lft": 40, "post_type": 206247, "score": 0, "title": "C: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "It is totally wrong that a method just because it involves 'a model' becomes non-deterministic! A linear model, given the same data, for example reproduces the same results, always. So, reliability is of \"utmost importance\", but it is solved.", "comment_count": 0, "html": "<p>It is totally wrong that a method just because it involves 'a model' becomes non-deterministic! A linear model, given the same data, for example reproduces the same results, always. So, reliability is of \"utmost importance\", but it is solved.</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 387, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 846, "model": "server.post", "fields": {"rght": 43, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 13:19:13", "lft": 42, "post_type": 206247, "score": 0, "title": "C: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "RMA depends on a linear statistical model. You can check it on the paper if you want. I agree with you if you use a given linear model and OLS  it will give the same results. Still, it is a statistical model. But, normalization is not so simple !!! People use a wealth of techniques. If it was just linear regression, this question would be trivial. But, as it depends on many instances on M-estimators, specific training sets, etc., I still think that its not solved. Otherwise, people wouldn't gather on a room for two days to discuss which one is the most reliable. ", "comment_count": 0, "html": "<p>RMA depends on a linear statistical model. You can check it on the paper if you want. I agree with you if you use a given linear model and OLS  it will give the same results. Still, it is a statistical model. But, normalization is not so simple !!! People use a wealth of techniques. If it was just linear regression, this question would be trivial. But, as it depends on many instances on M-estimators, specific training sets, etc., I still think that its not solved. Otherwise, people wouldn't gather on a room for two days to discuss which one is the most reliable. </p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 387, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 847, "model": "server.post", "fields": {"rght": 8, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 13:37:26", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "I've checked. Most methods are statistical and rely on parameter estimation for normalization. Looking to 1000 samples is almost the as Monte Carlo estimation. Of course it will produce the same result, at least on average. It's not a complicated question. I asked for the realiability of the method !!! Even quantile normalization relies on parameter estimation. My question is totally unrelated to the precision of one's computer . . . ", "comment_count": 0, "html": "<p>I've checked. Most methods are statistical and rely on parameter estimation for normalization. Looking to 1000 samples is almost the as Monte Carlo estimation. Of course it will produce the same result, at least on average. It's not a complicated question. I asked for the realiability of the method !!! Even quantile normalization relies on parameter estimation. My question is totally unrelated to the precision of one's computer . . . </p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 421, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 848, "model": "server.post", "fields": {"rght": 10, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 14:08:39", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "No, not on average, exactly.  I recommend you really try this out before you claim something. But use one and the same dataset and run the same method, say RMA 1000 times, then publish the result here. Also, you are mistakenly interchanging parameter estimation for non-deterministic outcome. So please, try it out with  one technique first. \n\n  ", "comment_count": 0, "html": "<p>No, not on average, exactly.  I recommend you really try this out before you claim something. But use one and the same dataset and run the same method, say RMA 1000 times, then publish the result here. Also, you are mistakenly interchanging parameter estimation for non-deterministic outcome. So please, try it out with  one technique first. </p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 421, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 849, "model": "server.post", "fields": {"rght": 10, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 14:40:15", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "I think many are overwhelmed by the complexity of new methods in general and it might be too much said that I for example understand SOAP, but I can generate clients and servers, using e.g. Axis2 tools from WSDLs and then usem them quite easily without knowing all the intricacies of the protocols. What do you think about this?", "comment_count": 0, "html": "<p>I think many are overwhelmed by the complexity of new methods in general and it might be too much said that I for example understand SOAP, but I can generate clients and servers, using e.g. Axis2 tools from WSDLs and then usem them quite easily without knowing all the intricacies of the protocols. What do you think about this?</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 0, "parent": 424, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 850, "model": "server.post", "fields": {"rght": 12, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 15:03:45", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "I have nothing personally against SOAP but I found it was a watershed moment when Google dropped support for its SOAP Search API. As I understand it there will always been a need for SOAP for really complex queries but any time you need a special library just to interact with a data source you are introducing another ingredient into the mix that can confuse people. So it is kind of a lowest common denominator thing.", "comment_count": 0, "html": "<p>I have nothing personally against SOAP but I found it was a watershed moment when Google dropped support for its SOAP Search API. As I understand it there will always been a need for SOAP for really complex queries but any time you need a special library just to interact with a data source you are introducing another ingredient into the mix that can confuse people. So it is kind of a lowest common denominator thing.</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 0, "parent": 424, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 851, "model": "server.post", "fields": {"rght": 12, "author": 52, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 15:43:19", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: What phylogeny viewing software do you use?", "unanswered": false, "content": "Ok. I think I got the impression because it looks so native to Aqua.", "comment_count": 0, "html": "<p>Ok. I think I got the impression because it looks so native to Aqua.</p>", "child_count": 0, "closed": false, "tree_id": 90, "revision_count": 0, "parent": 411, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-phylogeny-viewing-software-do-you-use", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 52}}, {"pk": 852, "model": "server.post", "fields": {"rght": 16, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 16:01:16", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "You might have to look at the definitions of some of the terms you are using first and clean that up, you are using them wrongly. e.g. \"intensity level is non-linear\" has no meaning, \"most normalization procedures do use a linear model\" where did you get that information from? \"Normalization is the main source of variability (or lack of it) in microarray data\" how can you arrive at this judgement? IMHO this is totally mistaken.....", "comment_count": 0, "html": "<p>You might have to look at the definitions of some of the terms you are using first and clean that up, you are using them wrongly. e.g. \"intensity level is non-linear\" has no meaning, \"most normalization procedures do use a linear model\" where did you get that information from? \"Normalization is the main source of variability (or lack of it) in microarray data\" how can you arrive at this judgement? IMHO this is totally mistaken.....</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 393, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 853, "model": "server.post", "fields": {"rght": 18, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 17:02:29", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "Your blog has been voted among the top 15 Bioinformatics blogs in 2010. Congrats! ", "comment_count": 0, "html": "<p>Your blog has been voted among the top 15 Bioinformatics blogs in 2010. Congrats! </p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 0, "parent": 126, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 854, "model": "server.post", "fields": {"rght": 22, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 17:03:31", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: Your favorite bioinformatics blogs (March 2010)", "unanswered": false, "content": "Thank you that's really nice.", "comment_count": 0, "html": "<p>Thank you that's really nice.</p>", "child_count": 0, "closed": false, "tree_id": 34, "revision_count": 0, "parent": 131, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-your-favorite-bioinformatics-blogs-march-2010", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 855, "model": "server.post", "fields": {"rght": 9, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 17:19:29", "lft": 4, "post_type": 206247, "score": 0, "title": "C: When is the best time to submit sequences to public databases like NCBI?", "unanswered": false, "content": "This is interesting, I don't (or rather haven't yet) submitted sequence data to NCBI or EBI, but I have submitted to ArrayExpress and GEO.  When I do this we just put a release date on the data in the future, generate a private reviewer URL or access for the reviewers and submit the paper.  The reviewers can see the data is annotated and deposited, and it's released on publication.  \n\nSo why isn't this the same for sequence data?", "comment_count": 0, "html": "<p>This is interesting, I don't (or rather haven't yet) submitted sequence data to NCBI or EBI, but I have submitted to ArrayExpress and GEO.  When I do this we just put a release date on the data in the future, generate a private reviewer URL or access for the reviewers and submit the paper.  The reviewers can see the data is annotated and deposited, and it's released on publication.<br />\n</p>\n<p>So why isn't this the same for sequence data?</p>", "child_count": 0, "closed": false, "tree_id": 94, "revision_count": 0, "parent": 425, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-when-is-the-best-time-to-submit-sequences-to-public-databases-like-ncbi", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 856, "model": "server.post", "fields": {"rght": 12, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 17:49:31", "lft": 11, "post_type": 206247, "score": 2, "title": "C: A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "@Jeremy \"only Pierre Lindenbaum understands how to use SOAP\" LOL :-))", "comment_count": 0, "html": "<p>@Jeremy \"only Pierre Lindenbaum understands how to use SOAP\" LOL :-))</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 0, "parent": 424, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 857, "model": "server.post", "fields": {"rght": 22, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 18:35:29", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "Clarifying the meaning: the intensity level scale is non-linear. Just to mention: RMA, GC-RMA, fRMA, quantile use a linear model. I'm sure I can find more examples. And a random reference about methods says: \"Consistent with previous results we observed a large effect of the normalization method on the outcome of the expression analyses.\". This observation is quite reasonable as the intensity scale (which defines the experiment) will be normalized. ", "comment_count": 0, "html": "<p>Clarifying the meaning: the intensity level scale is non-linear. Just to mention: RMA, GC-RMA, fRMA, quantile use a linear model. I'm sure I can find more examples. And a random reference about methods says: \"Consistent with previous results we observed a large effect of the normalization method on the outcome of the expression analyses.\". This observation is quite reasonable as the intensity scale (which defines the experiment) will be normalized. </p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 393, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 858, "model": "server.post", "fields": {"rght": 3, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 18:45:59", "lft": 2, "post_type": 206247, "score": 0, "title": "C: How to find all GWAS studies that a given gene has been implicated in?", "unanswered": false, "content": "Some definitions from the wikipedia: In genetic epidemiology, a genome-wide association study (GWA study, or GWAS) - also known as whole genome association study (WGA study) - is an examination of genetic variation across a given genome, designed to identify genetic associations with observable traits.", "comment_count": 0, "html": "<p>Some definitions from the wikipedia: In genetic epidemiology, a genome-wide association study (GWA study, or GWAS) - also known as whole genome association study (WGA study) - is an examination of genetic variation across a given genome, designed to identify genetic associations with observable traits.</p>", "child_count": 0, "closed": false, "tree_id": 95, "revision_count": 0, "parent": 427, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-how-to-find-all-gwas-studies-that-a-given-gene-has-been-implicated-in", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 859, "model": "server.post", "fields": {"rght": 5, "author": 85, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 18:46:50", "lft": 4, "post_type": 206247, "score": 0, "title": "C: How to find all GWAS studies that a given gene has been implicated in?", "unanswered": false, "content": "Thank you Istvan for the clarification!", "comment_count": 0, "html": "<p>Thank you Istvan for the clarification!</p>", "child_count": 0, "closed": false, "tree_id": 95, "revision_count": 0, "parent": 427, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-how-to-find-all-gwas-studies-that-a-given-gene-has-been-implicated-in", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 85}}, {"pk": 860, "model": "server.post", "fields": {"rght": 12, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 18:49:38", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "I do understand your point now. Default RMA will give the same results. A default ML of parameters will give the same too. Both could be invalid, but reliable anyway. So, my question is mock from the beginning. Maybe a question about validity would be more appropriate.", "comment_count": 0, "html": "<p>I do understand your point now. Default RMA will give the same results. A default ML of parameters will give the same too. Both could be invalid, but reliable anyway. So, my question is mock from the beginning. Maybe a question about validity would be more appropriate.</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 421, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 861, "model": "server.post", "fields": {"rght": 45, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 18:55:20", "lft": 44, "post_type": 206247, "score": 0, "title": "C: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "I think asking for the \"best method\" ends up being less productive than asking for opinions on the strengths and weaknesses of a few existing methods. ", "comment_count": 0, "html": "<p>I think asking for the \"best method\" ends up being less productive than asking for opinions on the strengths and weaknesses of a few existing methods. </p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 387, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 862, "model": "server.post", "fields": {"rght": 18, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 19:32:27", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "Although it can plot multiple chromosomes, you can specify only one genomic region with minBase/maxBase. So the same region is selected on all chromosomes. Also all chromosomes plotted with the same size and I didn't find a way to change it. So I don't think it's appropriate package. Anyway it will be useful for other cases, thank you.", "comment_count": 0, "html": "<p>Although it can plot multiple chromosomes, you can specify only one genomic region with minBase/maxBase. So the same region is selected on all chromosomes. Also all chromosomes plotted with the same size and I didn't find a way to change it. So I don't think it's appropriate package. Anyway it will be useful for other cases, thank you.</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 414, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 863, "model": "server.post", "fields": {"rght": 20, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 20:01:04", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "I see the downside and I never used this option before, actually it came to my mind that the graphics you show in the Qu. is most likely made by putting together individual images in a graphics program. I don't want to recommend to do this manually but if you are e.g. writing an article or a book this might look much more professional than any automatic result.", "comment_count": 0, "html": "<p>I see the downside and I never used this option before, actually it came to my mind that the graphics you show in the Qu. is most likely made by putting together individual images in a graphics program. I don't want to recommend to do this manually but if you are e.g. writing an article or a book this might look much more professional than any automatic result.</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 414, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 864, "model": "server.post", "fields": {"rght": 10, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 20:31:55", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: What do different bioinformatics positions mean?", "unanswered": false, "content": "Could be. But my point is, it is not at all possible to classify the positions based on the job title, atleast in the bioinformatics domain.", "comment_count": 0, "html": "<p>Could be. But my point is, it is not at all possible to classify the positions based on the job title, atleast in the bioinformatics domain.</p>", "child_count": 0, "closed": false, "tree_id": 89, "revision_count": 0, "parent": 408, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-do-different-bioinformatics-positions-mean", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 865, "model": "server.post", "fields": {"rght": 4, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 20:47:44", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Tips on how to set up a virtual online workbench for bioinformatics", "unanswered": false, "content": "Kepler project has the right spirit! I just forgot to say that it shoud be online. Have you ever tested it?", "comment_count": 0, "html": "<p>Kepler project has the right spirit! I just forgot to say that it shoud be online. Have you ever tested it?</p>", "child_count": 0, "closed": false, "tree_id": 96, "revision_count": 0, "parent": 430, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-tips-on-how-to-set-up-a-virtual-online-workbench-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 866, "model": "server.post", "fields": {"rght": 22, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 21:26:42", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "Maybe Jeremy is right with this? I thought I understood it for a while, but then I started using it ;)\nAnyway, is it really about SOAP too complex? What is it that makes it so complex?\n", "comment_count": 0, "html": "<p>Maybe Jeremy is right with this? I thought I understood it for a while, but then I started using it ;)\nAnyway, is it really about SOAP too complex? What is it that makes it so complex?</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 0, "parent": 424, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 867, "model": "server.post", "fields": {"rght": 17, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 21:34:20", "lft": 16, "post_type": 206247, "score": 1, "title": "C: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "Looks a bit as if it is a \"REST vs. SOAP\" fight and SOAP is loosing ,while in principle conceptually superior, but a bit overweight. What if the best of both worlds could be combined? Just found this: http://www.ibm.com/developerworks/webservices/library/ws-restwsdl/", "comment_count": 0, "html": "<p>Looks a bit as if it is a \"REST vs. SOAP\" fight and SOAP is loosing ,while in principle conceptually superior, but a bit overweight. What if the best of both worlds could be combined? Just found this: http://www.ibm.com/developerworks/webservices/library/ws-restwsdl/</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 0, "parent": 420, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 868, "model": "server.post", "fields": {"rght": 4, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 23:04:48", "lft": 3, "post_type": 206247, "score": 1, "title": "C: A: What tools/libraries do you use to visualize genomic feature data?", "unanswered": false, "content": "Just to chip in my first comment on BioStar. I also use Gbrowse for this job. Hugely configurable and very easy to install and add tracks to.\n\nI've recently been using Gbrowse2, which is a pretty slick improvement. A comprehensive install guide is available at the GMOD website http://gmod.org/wiki/GBrowse_2.0_HOWTO", "comment_count": 0, "html": "<p>Just to chip in my first comment on BioStar. I also use Gbrowse for this job. Hugely configurable and very easy to install and add tracks to.</p>\n<p>I've recently been using Gbrowse2, which is a pretty slick improvement. A comprehensive install guide is available at the GMOD website http://gmod.org/wiki/GBrowse_2.0_HOWTO</p>", "child_count": 0, "closed": false, "tree_id": 83, "revision_count": 0, "parent": 364, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-what-toolslibraries-do-you-use-to-visualize-genomic-feature-data", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 869, "model": "server.post", "fields": {"rght": 22, "author": 65, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 23:23:22", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "One approach might be to generate a PNG for each chromosome, then stitch the PNGs together with e.g. imagemagick:  \"convert -append *.png all.png\". But that won't solve the chromosome size problem.", "comment_count": 0, "html": "<p>One approach might be to generate a PNG for each chromosome, then stitch the PNGs together with e.g. imagemagick:  \"convert -append *.png all.png\". But that won't solve the chromosome size problem.</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 414, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 65}}, {"pk": 870, "model": "server.post", "fields": {"rght": 10, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-23 23:58:51", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "Thanks for your note Ian. I have noticed that differential expression levels in these probe sets mapped to same gene. For example, I noticed a particular probe set ID 'x' is up regulated in 'cases'. But in 'controls', instead of this probe set ID 'x' another probe set ID 'y' which mapped to same gene is upregulated. I am a bit confused If I can consider them as a differentially expressing hit. Or results should be reported only based on the consistent regulation of probe IDs. Please let me know your thoughts. ", "comment_count": 0, "html": "<p>Thanks for your note Ian. I have noticed that differential expression levels in these probe sets mapped to same gene. For example, I noticed a particular probe set ID 'x' is up regulated in 'cases'. But in 'controls', instead of this probe set ID 'x' another probe set ID 'y' which mapped to same gene is upregulated. I am a bit confused If I can consider them as a differentially expressing hit. Or results should be reported only based on the consistent regulation of probe IDs. Please let me know your thoughts. </p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 0, "parent": 433, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 871, "model": "server.post", "fields": {"rght": 12, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 09:06:44", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "Hi Khader.\n\nYou have hit on something really pretty important. There are times as you have illustrated where two different probe-sets behave differently  even when they map to the same gene. This is obviously a bit of a worry so when this happens I like to try to work out if there is a sensible explanation, if I cannot find one the best you can do is either flag them with a warning or exclude them. As a simple rule of thumb I would check that neither (or both) of them aren't promiscuous, secondly check whether one or both falls across a splice junction..(continued, below...)", "comment_count": 0, "html": "<p>Hi Khader.</p>\n<p>You have hit on something really pretty important. There are times as you have illustrated where two different probe-sets behave differently  even when they map to the same gene. This is obviously a bit of a worry so when this happens I like to try to work out if there is a sensible explanation, if I cannot find one the best you can do is either flag them with a warning or exclude them. As a simple rule of thumb I would check that neither (or both) of them aren't promiscuous, secondly check whether one or both falls across a splice junction..(continued, below...)</p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 0, "parent": 433, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 872, "model": "server.post", "fields": {"rght": 14, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 09:15:30", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "....if they do you may be getting a different (or weighted) change in expression between the probe-sets based on the differential expression (or stability) of the splice variants. This is where you need to apply a bit of biology 'nous' to understand something about the mapped genes themselves. One other possibility is that for example if it was profile data the probe-sets may have the same expression shape, but just a different magnitude. If you think this is possible you could try unitising all of your expression vectors (i.e. giving each a length of one) and then seeing if they converge.", "comment_count": 0, "html": "<p>....if they do you may be getting a different (or weighted) change in expression between the probe-sets based on the differential expression (or stability) of the splice variants. This is where you need to apply a bit of biology 'nous' to understand something about the mapped genes themselves. One other possibility is that for example if it was profile data the probe-sets may have the same expression shape, but just a different magnitude. If you think this is possible you could try unitising all of your expression vectors (i.e. giving each a length of one) and then seeing if they converge.</p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 0, "parent": 433, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 873, "model": "server.post", "fields": {"rght": 16, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 09:17:06", "lft": 15, "post_type": 206247, "score": 1, "title": "C: A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "Hi Khader. You have hit on something really pretty important. There are times as you have illustrated where two different probe-sets behave differently even when they map to the same gene. This is obviously a bit of a worry so when this happens I like to try to work out if there is a sensible explanation, if I cannot find one the best you can do is either flag them with a warning or exclude them. As a simple rule of thumb I would check whether either (or both) of them are promiscuous, secondly check whether one or both falls across a splice junction..(continued, below...)", "comment_count": 0, "html": "<p>Hi Khader. You have hit on something really pretty important. There are times as you have illustrated where two different probe-sets behave differently even when they map to the same gene. This is obviously a bit of a worry so when this happens I like to try to work out if there is a sensible explanation, if I cannot find one the best you can do is either flag them with a warning or exclude them. As a simple rule of thumb I would check whether either (or both) of them are promiscuous, secondly check whether one or both falls across a splice junction..(continued, below...)</p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 0, "parent": 433, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 874, "model": "server.post", "fields": {"rght": 18, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 09:17:14", "lft": 17, "post_type": 206247, "score": 1, "title": "C: A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "....if they do you may be getting a different (or weighted) change in expression between the probe-sets based on the differential expression (or stability) of the splice variants. This is where you need to apply a bit of biology 'nous' to understand something about the mapped genes themselves. One other possibility is that for example if it was profile data the probe-sets may have the same expression shape, but just a different magnitude. If you think this is possible you could try unitising all of your expression vectors (i.e. giving each a length of one) and then seeing if they converge.", "comment_count": 0, "html": "<p>....if they do you may be getting a different (or weighted) change in expression between the probe-sets based on the differential expression (or stability) of the splice variants. This is where you need to apply a bit of biology 'nous' to understand something about the mapped genes themselves. One other possibility is that for example if it was profile data the probe-sets may have the same expression shape, but just a different magnitude. If you think this is possible you could try unitising all of your expression vectors (i.e. giving each a length of one) and then seeing if they converge.</p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 0, "parent": 433, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 875, "model": "server.post", "fields": {"rght": 24, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 10:13:59", "lft": 23, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "Another way would be to hack a bit in the gdPlot code in GenomeGraphs. GenomeGraphs uses the Grid package for plotting, so it would be possible to change it a bit to support multiple gdPlots in one graphics window, but that would need some (of possibly my ) time ;)", "comment_count": 0, "html": "<p>Another way would be to hack a bit in the gdPlot code in GenomeGraphs. GenomeGraphs uses the Grid package for plotting, so it would be possible to change it a bit to support multiple gdPlots in one graphics window, but that would need some (of possibly my ) time ;)</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 414, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 876, "model": "server.post", "fields": {"rght": 12, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 10:15:10", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "this looks very promising, can you give the source code for your plots, please?", "comment_count": 0, "html": "<p>this looks very promising, can you give the source code for your plots, please?</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 437, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 877, "model": "server.post", "fields": {"rght": 6, "author": 172, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 10:32:13", "lft": 5, "post_type": 206247, "score": 2, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "I am the developer of Ruffus. This is designed to be a \"make\" replacement with simpler(!) syntax. I wanted all the power of make and more while writing \"normal\" python scripts. \n\nRuffus has undergone substantial development lately, especially to simplify the syntax and improve the error messages. If your experience was with the ruffus of a few months ago, it might be worth having a quick look again and seeing if it has improved enough to change your mind. (Or it just may not be your cup of tea!) As always suggestions (even critical comments) are welcome.", "comment_count": 0, "html": "<p>I am the developer of Ruffus. This is designed to be a \"make\" replacement with simpler(!) syntax. I wanted all the power of make and more while writing \"normal\" python scripts. </p>\n<p>Ruffus has undergone substantial development lately, especially to simplify the syntax and improve the error messages. If your experience was with the ruffus of a few months ago, it might be worth having a quick look again and seeing if it has improved enough to change your mind. (Or it just may not be your cup of tea!) As always suggestions (even critical comments) are welcome.</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 80, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 172}}, {"pk": 878, "model": "server.post", "fields": {"rght": 30, "author": 172, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 10:37:01", "lft": 29, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "I am the developer of Ruffus (and just posted a reply to Istvan above). \n\nRuffus has recently acquired much more tracing (like make -n but understandable), and a \"touch\" mode (like make -t you can update selected parts of the pipeline). \n\nI am always interested from people still using make as it was the frustrations of unmaintainable makefiles which drove us to develop Ruffus in the first place. I would be very grateful if you could email me more comments / feedback if you don't mind.\nThanks", "comment_count": 0, "html": "<p>I am the developer of Ruffus (and just posted a reply to Istvan above). </p>\n<p>Ruffus has recently acquired much more tracing (like make -n but understandable), and a \"touch\" mode (like make -t you can update selected parts of the pipeline). </p>\n<p>I am always interested from people still using make as it was the frustrations of unmaintainable makefiles which drove us to develop Ruffus in the first place. I would be very grateful if you could email me more comments / feedback if you don't mind.\nThanks</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 220, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 172}}, {"pk": 879, "model": "server.post", "fields": {"rght": 6, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 11:27:07", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Tips on how to set up a virtual online workbench for bioinformatics", "unanswered": false, "content": "I'm aware of the nontriviality of such an endeavour. But, as we have legal difficulties to hire qualified people, this is our best bet. Hard time fo find some examples of the architecture of such a service. Right now I just need to provide a prototype of the workbench. Thinking about Zope/Plone or Django/Plone to produce the interface/front end. ", "comment_count": 0, "html": "<p>I'm aware of the nontriviality of such an endeavour. But, as we have legal difficulties to hire qualified people, this is our best bet. Hard time fo find some examples of the architecture of such a service. Right now I just need to provide a prototype of the workbench. Thinking about Zope/Plone or Django/Plone to produce the interface/front end. </p>", "child_count": 0, "closed": false, "tree_id": 96, "revision_count": 0, "parent": 431, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-tips-on-how-to-set-up-a-virtual-online-workbench-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 880, "model": "server.post", "fields": {"rght": 8, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 11:38:12", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Tips on how to set up a virtual online workbench for bioinformatics", "unanswered": false, "content": "I should confess I am a member of the CARMEN project and that we ended up building a system from scratch for this without managing to deploy a single reused component people might recognise from Pierre's list..  I was not in charge of the architecture details.  We do use Plone as the CMS associated with the project, but not as a front end to the workflow/data/services portal.", "comment_count": 0, "html": "<p>I should confess I am a member of the CARMEN project and that we ended up building a system from scratch for this without managing to deploy a single reused component people might recognise from Pierre's list..  I was not in charge of the architecture details.  We do use Plone as the CMS associated with the project, but not as a front end to the workflow/data/services portal.</p>", "child_count": 0, "closed": false, "tree_id": 96, "revision_count": 0, "parent": 431, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-tips-on-how-to-set-up-a-virtual-online-workbench-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 881, "model": "server.post", "fields": {"rght": 8, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 12:28:09", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: How difficult/reliable is it to programmatically (python) look up and download papers?", "unanswered": false, "content": "OK looks like it requires the object has a DOI, so you MAY have some issues with older articles.", "comment_count": 0, "html": "<p>OK looks like it requires the object has a DOI, so you MAY have some issues with older articles.</p>", "child_count": 0, "closed": false, "tree_id": 91, "revision_count": 0, "parent": 440, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-difficultreliable-is-it-to-programmatically-python-look-up-and-download-papers", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 882, "model": "server.post", "fields": {"rght": 10, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 12:46:42", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: How difficult/reliable is it to programmatically (python) look up and download papers?", "unanswered": false, "content": "This could be a limitation on the API as the web interface allows a reasonable proxy to a pubmed search although at present it doesn't support the [tags] search that I really like using for Pubmed searches (i.e. bloggs_j[1AU]). Still it looks pretty useful.", "comment_count": 0, "html": "<p>This could be a limitation on the API as the web interface allows a reasonable proxy to a pubmed search although at present it doesn't support the [tags] search that I really like using for Pubmed searches (i.e. bloggs_j[1AU]). Still it looks pretty useful.</p>", "child_count": 0, "closed": false, "tree_id": 91, "revision_count": 0, "parent": 440, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-difficultreliable-is-it-to-programmatically-python-look-up-and-download-papers", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 883, "model": "server.post", "fields": {"rght": 14, "author": 135, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 12:51:51", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "I can't find any useful RSS, do you have any at hand?", "comment_count": 0, "html": "<p>I can't find any useful RSS, do you have any at hand?</p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 0, "parent": 439, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 135}}, {"pk": 884, "model": "server.post", "fields": {"rght": 4, "author": 135, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 12:52:13", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "Nice resource, thanks!", "comment_count": 0, "html": "<p>Nice resource, thanks!</p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 0, "parent": 438, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 135}}, {"pk": 885, "model": "server.post", "fields": {"rght": 10, "author": 135, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 12:52:52", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "I already listen to Twitter and I found some CfP there, but the deadlines were always horribly close...", "comment_count": 0, "html": "<p>I already listen to Twitter and I found some CfP there, but the deadlines were always horribly close...</p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 0, "parent": 439, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 135}}, {"pk": 886, "model": "server.post", "fields": {"rght": 4, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 12:54:48", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "Thanks Neil, I was just about to add that view link from CRAN.", "comment_count": 0, "html": "<p>Thanks Neil, I was just about to add that view link from CRAN.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 0, "parent": 442, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 887, "model": "server.post", "fields": {"rght": 18, "author": 71, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 13:06:35", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "How well does R scale these days (not counting the Revolution Enterprise version)?", "comment_count": 0, "html": "<p>How well does R scale these days (not counting the Revolution Enterprise version)?</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 0, "parent": 442, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 71}}, {"pk": 888, "model": "server.post", "fields": {"rght": 20, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 13:26:35", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "As R is an interpreted language it basically will not beat an implementation in something like C or C++.\n\nIt also has memory issues (it loads a lot into memory). None of these are insurmountable and the availability of lots of powerful stats functionality in R makes it attractive.\n\nIf a piece of the code I'm working with is problematic I implement it in C and then access it from R. If memory is an issue I use something like 'ff' or read data in from a database as I need it. The alternative I guess is to use proprietary software like SAS or Matlab.", "comment_count": 0, "html": "<p>As R is an interpreted language it basically will not beat an implementation in something like C or C++.</p>\n<p>It also has memory issues (it loads a lot into memory). None of these are insurmountable and the availability of lots of powerful stats functionality in R makes it attractive.</p>\n<p>If a piece of the code I'm working with is problematic I implement it in C and then access it from R. If memory is an issue I use something like 'ff' or read data in from a database as I need it. The alternative I guess is to use proprietary software like SAS or Matlab.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 0, "parent": 442, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 889, "model": "server.post", "fields": {"rght": 6, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 13:33:35", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "Thanks Giovanni, I hadn't looked there. I guess I was specifically looking for experiences from Bioinformaticians, but these links look very useful.", "comment_count": 0, "html": "<p>Thanks Giovanni, I hadn't looked there. I guess I was specifically looking for experiences from Bioinformaticians, but these links look very useful.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 0, "parent": 443, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 890, "model": "server.post", "fields": {"rght": 8, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 13:37:55", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "Thanks Daniel, we don't have this on our HPC nodes just the canonical R release, that could be a cost thing. Not sure if it would be free if the University put it on a service, but that's something they could find out. I will definitely ask them about it and try it out on my local cluster in the meantime.", "comment_count": 0, "html": "<p>Thanks Daniel, we don't have this on our HPC nodes just the canonical R release, that could be a cost thing. Not sure if it would be free if the University put it on a service, but that's something they could find out. I will definitely ask them about it and try it out on my local cluster in the meantime.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 0, "parent": 444, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 891, "model": "server.post", "fields": {"rght": 16, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 13:39:25", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "The non-Enterprise version that comes with the Ubuntu repositories is most definitely free, but I don't know what their 'commercial' offering actually extends beyond this other than support.", "comment_count": 0, "html": "<p>The non-Enterprise version that comes with the Ubuntu repositories is most definitely free, but I don't know what their 'commercial' offering actually extends beyond this other than support.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 0, "parent": 444, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 892, "model": "server.post", "fields": {"rght": 11, "author": 165, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 13:48:30", "lft": 10, "post_type": 206247, "score": 0, "title": "C: When is the best time to submit sequences to public databases like NCBI?", "unanswered": false, "content": "But is there any advantage to releasing your data before you have even submitted a manuscript?", "comment_count": 0, "html": "<p>But is there any advantage to releasing your data before you have even submitted a manuscript?</p>", "child_count": 0, "closed": false, "tree_id": 94, "revision_count": 0, "parent": 425, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-when-is-the-best-time-to-submit-sequences-to-public-databases-like-ncbi", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 165}}, {"pk": 893, "model": "server.post", "fields": {"rght": 10, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 14:12:26", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "Thanks for that. I am currently solving the problem by the former i.e. splitting, batching then collating and performing summary analyses. In the mid->long term however I need the latter. There are already some emerging, truly parallelized, functions that I can take advantage of that will deliver significant speed up. My question specifically is trying to ascertain what if anything people are using in terms of packages and R with HPC resources. There are a few suggestions here that I am following up. Even simple functions in parallel form such as 'sort' can be extremely useful.", "comment_count": 0, "html": "<p>Thanks for that. I am currently solving the problem by the former i.e. splitting, batching then collating and performing summary analyses. In the mid-&gt;long term however I need the latter. There are already some emerging, truly parallelized, functions that I can take advantage of that will deliver significant speed up. My question specifically is trying to ascertain what if anything people are using in terms of packages and R with HPC resources. There are a few suggestions here that I am following up. Even simple functions in parallel form such as 'sort' can be extremely useful.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 0, "parent": 445, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 894, "model": "server.post", "fields": {"rght": 12, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 14:20:22", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "Yes indeed, adding parallelism to the bottlenecks will give you  the maximum benefit.", "comment_count": 0, "html": "<p>Yes indeed, adding parallelism to the bottlenecks will give you  the maximum benefit.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 0, "parent": 445, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 895, "model": "server.post", "fields": {"rght": 12, "author": 73, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 14:34:07", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Appropriate podcasts for a bioinformatician?", "unanswered": false, "content": "I love RadioLab too.", "comment_count": 0, "html": "<p>I love RadioLab too.</p>", "child_count": 0, "closed": false, "tree_id": 65, "revision_count": 0, "parent": 274, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-appropriate-podcasts-for-a-bioinformatician", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 73}}, {"pk": 896, "model": "server.post", "fields": {"rght": 32, "author": 35, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 15:06:53", "lft": 31, "post_type": 206247, "score": 0, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "Leo, thanks for the comment. I will check out Ruffus again and get back to you with comments. The trace and touch modes do sound good. ", "comment_count": 0, "html": "<p>Leo, thanks for the comment. I will check out Ruffus again and get back to you with comments. The trace and touch modes do sound good. </p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 220, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 35}}, {"pk": 897, "model": "server.post", "fields": {"rght": 14, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 16:03:57", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Drawing chromosome ideogams with data", "unanswered": false, "content": "Looks good. I will explore it further. Thanks a lot, Jan.", "comment_count": 0, "html": "<p>Looks good. I will explore it further. Thanks a lot, Jan.</p>", "child_count": 0, "closed": false, "tree_id": 85, "revision_count": 0, "parent": 437, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-drawing-chromosome-ideogams-with-data", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 898, "model": "server.post", "fields": {"rght": 14, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 16:14:15", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "Thanks Chris that's extremely helpful I'll have a look at multicore/doMC. Currently I am using one script to generate a batch array and another to pick up the pieces afterwards !", "comment_count": 0, "html": "<p>Thanks Chris that's extremely helpful I'll have a look at multicore/doMC. Currently I am using one script to generate a batch array and another to pick up the pieces afterwards !</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 0, "parent": 452, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 899, "model": "server.post", "fields": {"rght": 27, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 16:46:44", "lft": 26, "post_type": 206247, "score": 0, "title": "C: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "you could make some very good research on it, because there are few models of complex eukaryotes like this, in which you can compare individuals coming from different generations. I remember having read an old article on The scientist on a study like this, on a fungus... when I will be back at home today I will look for it and then I can answer you here.", "comment_count": 0, "html": "<p>you could make some very good research on it, because there are few models of complex eukaryotes like this, in which you can compare individuals coming from different generations. I remember having read an old article on The scientist on a study like this, on a fungus... when I will be back at home today I will look for it and then I can answer you here.</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 451, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 900, "model": "server.post", "fields": {"rght": 4, "author": 178, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:06:50", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "I admit that this is premature and I have not done my due diligence.  All I have done so far (I thought of this last night watching a show where cicada were all over the place) is went to Entrez and only found one article relating to the periodical cicada.  I am getting the article through our college library.  \nMy initial thought was dealing with evolution and if we could see any divergence between the populations since they are gentically isolated.  How do I know that I have searched enough to comfortably say that these populations have not been sequenced?  ", "comment_count": 0, "html": "<p>I admit that this is premature and I have not done my due diligence.  All I have done so far (I thought of this last night watching a show where cicada were all over the place) is went to Entrez and only found one article relating to the periodical cicada.  I am getting the article through our college library.<br />\nMy initial thought was dealing with evolution and if we could see any divergence between the populations since they are gentically isolated.  How do I know that I have searched enough to comfortably say that these populations have not been sequenced?<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 453, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 178}}, {"pk": 901, "model": "server.post", "fields": {"rght": 31, "author": 178, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:08:05", "lft": 30, "post_type": 206247, "score": 0, "title": "C: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "Any help would be greatly appreciated - thanks!", "comment_count": 0, "html": "<p>Any help would be greatly appreciated - thanks!</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 451, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 178}}, {"pk": 902, "model": "server.post", "fields": {"rght": 31, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:12:08", "lft": 30, "post_type": 206247, "score": 2, "title": "C: What license do you use when you release code and data?", "unanswered": false, "content": "There's a nice, readable review of open source software licences at Smashing Magazine: http://www.smashingmagazine.com/2010/03/24/a-short-guide-to-open-source-and-similar-licenses/", "comment_count": 0, "html": "<p>There's a nice, readable review of open source software licences at Smashing Magazine: http://www.smashingmagazine.com/2010/03/24/a-short-guide-to-open-source-and-similar-licenses/</p>", "child_count": 0, "closed": false, "tree_id": 80, "revision_count": 0, "parent": 349, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-what-license-do-you-use-when-you-release-code-and-data", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 903, "model": "server.post", "fields": {"rght": 24, "author": 178, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:17:28", "lft": 23, "post_type": 206247, "score": 0, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "Thanks for the input.  As a community college instructor, it is frustrating to just go over a technique with very little revelevance.  Adding something, anything, where they are contributing something, even if it just sequences to various databases is better than nothing!\nI just want to give my students any type of experience that will make them better prepared for transferring to a university, so even if it is not publishable, but maybe could do a poster presentation would be great.", "comment_count": 0, "html": "<p>Thanks for the input.  As a community college instructor, it is frustrating to just go over a technique with very little revelevance.  Adding something, anything, where they are contributing something, even if it just sequences to various databases is better than nothing!\nI just want to give my students any type of experience that will make them better prepared for transferring to a university, so even if it is not publishable, but maybe could do a poster presentation would be great.</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 455, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 178}}, {"pk": 904, "model": "server.post", "fields": {"rght": 33, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:18:41", "lft": 32, "post_type": 206247, "score": 0, "title": "C: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "life cycles of cicadas happen to be prime numbers :-)  cf. WP ", "comment_count": 0, "html": "<p>life cycles of cicadas happen to be prime numbers :-)  cf. WP </p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 451, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 905, "model": "server.post", "fields": {"rght": 17, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:27:03", "lft": 16, "post_type": 206247, "score": 2, "title": "C: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "If you want to do something around the chronobiology of the cicadas, maybe mail Bora Zivkovic (Coturnix@gmail.com) for ideas and/or advice. He's an expert in this matter (see his blog http://scienceblogs.com/clock)", "comment_count": 0, "html": "<p>If you want to do something around the chronobiology of the cicadas, maybe mail Bora Zivkovic (Coturnix@gmail.com) for ideas and/or advice. He's an expert in this matter (see his blog http://scienceblogs.com/clock)</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 451, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 906, "model": "server.post", "fields": {"rght": 12, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:45:22", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "My strategy is to have as many feeds from societes and labs as possible. And search and anotate them on a regular basis. There is no centralized RSS, even for ISCB. You can find the top meeting on Genome Technology, they have good feeds.", "comment_count": 0, "html": "<p>My strategy is to have as many feeds from societes and labs as possible. And search and anotate them on a regular basis. There is no centralized RSS, even for ISCB. You can find the top meeting on Genome Technology, they have good feeds.</p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 0, "parent": 439, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 907, "model": "server.post", "fields": {"rght": 6, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:45:47", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "To be clear, I don't mean to dig on your idea at all. I think it's fantastic that you want to involve students in some real research. It just seems like you're not even to the point where you know what questions to ask. With any new project, there's a ramp up phase, where you spend some time digging around in the literature to see what's been done and what needs to be done. That should be your first step.", "comment_count": 0, "html": "<p>To be clear, I don't mean to dig on your idea at all. I think it's fantastic that you want to involve students in some real research. It just seems like you're not even to the point where you know what questions to ask. With any new project, there's a ramp up phase, where you spend some time digging around in the literature to see what's been done and what needs to be done. That should be your first step.</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 453, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 908, "model": "server.post", "fields": {"rght": 10, "author": 178, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:53:43", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "I didn't think you were slamming my idea and I understand where you were coming from.  This is just part of my \"digging around\" phase - asking experts for their advice.  I thought that not only could this save time, but I may find additional information and/or contacts.  ", "comment_count": 0, "html": "<p>I didn't think you were slamming my idea and I understand where you were coming from.  This is just part of my \"digging around\" phase - asking experts for their advice.  I thought that not only could this save time, but I may find additional information and/or contacts.<br />\n</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 453, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 178}}, {"pk": 909, "model": "server.post", "fields": {"rght": 22, "author": 178, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 17:54:54", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "I think that would be great!  I'll start gathering some more information then!", "comment_count": 0, "html": "<p>I think that would be great!  I'll start gathering some more information then!</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 461, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 178}}, {"pk": 910, "model": "server.post", "fields": {"rght": 41, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 18:00:26", "lft": 40, "post_type": 206247, "score": 0, "title": "C: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "One good thing about cicadas is that people can relate to them ... Thus anything you may find has a better chance to be talked about in the news and other circles. As Pierre said those are prime numbers, and prime numbers are quite uncommon in nature. Finding out how that time is kept has many implications. Definitely team up with someone who has access to sequencing facility. ", "comment_count": 0, "html": "<p>One good thing about cicadas is that people can relate to them ... Thus anything you may find has a better chance to be talked about in the news and other circles. As Pierre said those are prime numbers, and prime numbers are quite uncommon in nature. Finding out how that time is kept has many implications. Definitely team up with someone who has access to sequencing facility. </p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 451, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 911, "model": "server.post", "fields": {"rght": 12, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 18:05:22", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "Fair enough - best of luck.", "comment_count": 0, "html": "<p>Fair enough - best of luck.</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 453, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 912, "model": "server.post", "fields": {"rght": 20, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 18:09:53", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "unanswered": false, "content": "Ian, thanks a lot for your detailed explanation. I will check those probe set IDs in detail and see if I can include/exclude them. ", "comment_count": 0, "html": "<p>Ian, thanks a lot for your detailed explanation. I will check those probe set IDs in detail and see if I can include/exclude them. </p>", "child_count": 0, "closed": false, "tree_id": 78, "revision_count": 0, "parent": 433, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-is-it-possible-for-two-different-affymetrix-probe-set-id-to-have-common-annotations-to-same-gene", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 913, "model": "server.post", "fields": {"rght": 12, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 18:28:03", "lft": 11, "post_type": 206247, "score": 1, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "Just follow the citation track of Lloyd & Dybas classical papers on Magicicada. Every subsequent paper on the subject cites them.", "comment_count": 0, "html": "<p>Just follow the citation track of Lloyd &amp; Dybas classical papers on Magicicada. Every subsequent paper on the subject cites them.</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 461, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 914, "model": "server.post", "fields": {"rght": 12, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 18:35:59", "lft": 11, "post_type": 206247, "score": 1, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "\"The first step in science is to make a hypothesis\". I wouldn't generalise it like that; not all research is hypothesis-driven. ", "comment_count": 0, "html": "<p>\"The first step in science is to make a hypothesis\". I wouldn't generalise it like that; not all research is hypothesis-driven. </p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 453, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 118}}, {"pk": 915, "model": "server.post", "fields": {"rght": 18, "author": 137, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 18:49:19", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "Yes, Ewens book is definitely worth reading. It balances mathematical rigor with intuitive explanations.", "comment_count": 0, "html": "<p>Yes, Ewens book is definitely worth reading. It balances mathematical rigor with intuitive explanations.</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 0, "parent": 330, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 137}}, {"pk": 916, "model": "server.post", "fields": {"rght": 10, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 19:05:34", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "so can see all comments about an article in these or just one person's comment at a time?", "comment_count": 0, "html": "<p>so can see all comments about an article in these or just one person's comment at a time?</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 0, "parent": 458, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 917, "model": "server.post", "fields": {"rght": 24, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 19:09:23", "lft": 23, "post_type": 206247, "score": 0, "title": "C: A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "this seems broken right now but it could be a huge asset", "comment_count": 0, "html": "<p>this seems broken right now but it could be a huge asset</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 0, "parent": 464, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 918, "model": "server.post", "fields": {"rght": 20, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 19:12:06", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "it is amazing how much people are willing to do for free", "comment_count": 0, "html": "<p>it is amazing how much people are willing to do for free</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 0, "parent": 463, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 919, "model": "server.post", "fields": {"rght": 8, "author": 61, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 19:17:12", "lft": 7, "post_type": 206247, "score": 1, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "I also think that any new data submitable to GenBank is better than sequencing the same plasmid over and over again :-).\n\nWhat I was trying to say is that sometimes not very sophisticated methods (Feulgen staining is ancient) can produce very useful results. Good if you go for name recognition on a tight budget.\n\nDNA cloning and sequencing is way more widely used in labs so it makes sense to go for it with students.", "comment_count": 0, "html": "<p>I also think that any new data submitable to GenBank is better than sequencing the same plasmid over and over again :-).</p>\n<p>What I was trying to say is that sometimes not very sophisticated methods (Feulgen staining is ancient) can produce very useful results. Good if you go for name recognition on a tight budget.</p>\n<p>DNA cloning and sequencing is way more widely used in labs so it makes sense to go for it with students.</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 455, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 61}}, {"pk": 920, "model": "server.post", "fields": {"rght": 20, "author": 37, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 19:17:45", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "PLoS journals also gather trackbacks and pingbacks, so blog comment from around the web is aggregated on each article too.", "comment_count": 0, "html": "<p>PLoS journals also gather trackbacks and pingbacks, so blog comment from around the web is aggregated on each article too.</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 0, "parent": 459, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:03", "slug": "c-a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:49:03", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 37}}, {"pk": 921, "model": "server.post", "fields": {"rght": 16, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 19:47:11", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "in connotea you can get all the bookmarks for a given article. e.g: http://www.connotea.org/article/1e67ed7e61c089a845da109b968900f8", "comment_count": 0, "html": "<p>in connotea you can get all the bookmarks for a given article. e.g: http://www.connotea.org/article/1e67ed7e61c089a845da109b968900f8</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 0, "parent": 458, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 922, "model": "server.post", "fields": {"rght": 18, "author": 50, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 19:48:27", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "Several journals accept comments and I expect others to follow. I think Nature publishing is thinking about this. What will be missing then is some way to aggregate across the different sites. I hope the publishers can agree on simple standard ways for people to access comments and ratings of papers. ", "comment_count": 0, "html": "<p>Several journals accept comments and I expect others to follow. I think Nature publishing is thinking about this. What will be missing then is some way to aggregate across the different sites. I hope the publishers can agree on simple standard ways for people to access comments and ratings of papers. </p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 0, "parent": 459, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 50}}, {"pk": 923, "model": "server.post", "fields": {"rght": 4, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 19:54:33", "lft": 3, "post_type": 206247, "score": 1, "title": "C: A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "Hey Scott, it's great to see you being active on the site. If you're not directly providing an answer to the question though, consider adding a comment instead, or just upvoting the question. That helps keep the signal to noise ratio high.", "comment_count": 0, "html": "<p>Hey Scott, it's great to see you being active on the site. If you're not directly providing an answer to the question though, consider adding a comment instead, or just upvoting the question. That helps keep the signal to noise ratio high.</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 0, "parent": 457, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 924, "model": "server.post", "fields": {"rght": 14, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 20:03:21", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "That's a fair critique, PhiS. Still, you should have some idea of what you're getting after. My point was that sequencing an organism without a reason or plan is a bad idea, as the methods you use will depend on what answers you're looking for.", "comment_count": 0, "html": "<p>That's a fair critique, PhiS. Still, you should have some idea of what you're getting after. My point was that sequencing an organism without a reason or plan is a bad idea, as the methods you use will depend on what answers you're looking for.</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 453, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 925, "model": "server.post", "fields": {"rght": 16, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 20:03:46", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "unanswered": false, "content": "That's a fair critique, PhiS. Still, you should have some idea of what you're getting after. I guess my point was that sequencing an organism without a reason or plan is a bad idea, as the methods you use will depend on what answers you're looking for", "comment_count": 0, "html": "<p>That's a fair critique, PhiS. Still, you should have some idea of what you're getting after. I guess my point was that sequencing an organism without a reason or plan is a bad idea, as the methods you use will depend on what answers you're looking for</p>", "child_count": 0, "closed": false, "tree_id": 99, "revision_count": 0, "parent": 453, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-is-there-any-useful-information-to-be-gathered-analyzing-the-genomes-of-different-populations-of-cicadas", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 926, "model": "server.post", "fields": {"rght": 6, "author": 178, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 20:06:35", "lft": 5, "post_type": 206247, "score": 1, "title": "C: A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "New to this site - wasn't try to ruffle any feathers.", "comment_count": 0, "html": "<p>New to this site - wasn't try to ruffle any feathers.</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 0, "parent": 457, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 178}}, {"pk": 927, "model": "server.post", "fields": {"rght": 8, "author": 70, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 20:11:37", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Is there a site where call for papers and conferences are listed in one place?", "unanswered": false, "content": "Looks good! Thanx for the tip.", "comment_count": 0, "html": "<p>Looks good! Thanx for the tip.</p>", "child_count": 0, "closed": false, "tree_id": 97, "revision_count": 0, "parent": 450, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-is-there-a-site-where-call-for-papers-and-conferences-are-listed-in-one-place", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 70}}, {"pk": 928, "model": "server.post", "fields": {"rght": 14, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 20:55:26", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: How to map a SNP to a gene around +/- 60KB ? ", "unanswered": false, "content": "Ditto. Very nice solution, I didn't even know that server existed. looks like they may be getting a bit more traffic in the future.", "comment_count": 0, "html": "<p>Ditto. Very nice solution, I didn't even know that server existed. looks like they may be getting a bit more traffic in the future.</p>", "child_count": 0, "closed": false, "tree_id": 92, "revision_count": 0, "parent": 418, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-how-to-map-a-snp-to-a-gene-around-60kb", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 929, "model": "server.post", "fields": {"rght": 22, "author": 1, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-24 23:10:50", "lft": 21, "post_type": 206247, "score": 0, "title": "C: A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "I have Genes VII ... now I feel behind the times. A beautifully written and produced masterpiece.", "comment_count": 0, "html": "<p>I have Genes VII ... now I feel behind the times. A beautifully written and produced masterpiece.</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 0, "parent": 475, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 1}}, {"pk": 930, "model": "server.post", "fields": {"rght": 11, "author": 85, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 01:40:06", "lft": 10, "post_type": 206247, "score": 0, "title": "C: How to find all GWAS studies that a given gene has been implicated in?", "unanswered": false, "content": "Real bummer that no one's seemed to have tackled this, isn't it?", "comment_count": 0, "html": "<p>Real bummer that no one's seemed to have tackled this, isn't it?</p>", "child_count": 0, "closed": false, "tree_id": 95, "revision_count": 0, "parent": 427, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-how-to-find-all-gwas-studies-that-a-given-gene-has-been-implicated-in", "lastedit_date": "2011-11-24 14:49:04", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 85}}, {"pk": 931, "model": "server.post", "fields": {"rght": 12, "author": 127, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 02:26:39", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: How difficult/reliable is it to programmatically (python) look up and download papers?", "unanswered": false, "content": "That API actually looks good for a web app I'm working on. Thanks! However, my initial question is more targeted at a python script that would retrieve a given list of papers if a list of say, PubMedIDs are provided. Will look into Mechanize and see how that goes.", "comment_count": 0, "html": "<p>That API actually looks good for a web app I'm working on. Thanks! However, my initial question is more targeted at a python script that would retrieve a given list of papers if a list of say, PubMedIDs are provided. Will look into Mechanize and see how that goes.</p>", "child_count": 0, "closed": false, "tree_id": 91, "revision_count": 0, "parent": 440, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-how-difficultreliable-is-it-to-programmatically-python-look-up-and-download-papers", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 127}}, {"pk": 932, "model": "server.post", "fields": {"rght": 4, "author": 91, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 02:37:07", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Markov chain for generating random protein sequences", "unanswered": false, "content": "Thanks. The first link helped.", "comment_count": 0, "html": "<p>Thanks. The first link helped.</p>", "child_count": 0, "closed": false, "tree_id": 102, "revision_count": 0, "parent": 477, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-markov-chain-for-generating-random-protein-sequences", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 91}}, {"pk": 933, "model": "server.post", "fields": {"rght": 12, "author": 183, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 03:43:39", "lft": 11, "post_type": 206247, "score": 2, "title": "C: A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "just fixed it. try it now!", "comment_count": 0, "html": "<p>just fixed it. try it now!</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 0, "parent": 464, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 183}}, {"pk": 934, "model": "server.post", "fields": {"rght": 12, "author": 116, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 04:18:04", "lft": 11, "post_type": 206247, "score": 1, "title": "C: A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "Agreed. At least among people of my cohort (senior graduate students/early postdocs) we still teach ourselves, mainly by piecing together info from the wealth of resources on the internet.", "comment_count": 0, "html": "<p>Agreed. At least among people of my cohort (senior graduate students/early postdocs) we still teach ourselves, mainly by piecing together info from the wealth of resources on the internet.</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 0, "parent": 320, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 116}}, {"pk": 935, "model": "server.post", "fields": {"rght": 8, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 08:54:32", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Tips to build a data storage for bioinformatics", "unanswered": false, "content": "> ...better ask this on a sys-admin board, I guess there are some.\nA site like BioStar and StackOverflow for sys-admins is http://serverfault.com/", "comment_count": 0, "html": "<blockquote>\n<p>...better ask this on a sys-admin board, I guess there are some.\nA site like BioStar and StackOverflow for sys-admins is http://serverfault.com/</p>\n</blockquote>", "child_count": 0, "closed": false, "tree_id": 101, "revision_count": 0, "parent": 473, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-tips-to-build-a-data-storage-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 936, "model": "server.post", "fields": {"rght": 10, "author": 67, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 08:55:24", "lft": 9, "post_type": 206247, "score": 1, "title": "C: A: Tips to build a data storage for bioinformatics", "unanswered": false, "content": "A site like BioStar and StackOverflow for sysadmins is http://serverfault.com/", "comment_count": 0, "html": "<p>A site like BioStar and StackOverflow for sysadmins is http://serverfault.com/</p>", "child_count": 0, "closed": false, "tree_id": 101, "revision_count": 0, "parent": 473, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-tips-to-build-a-data-storage-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 67}}, {"pk": 937, "model": "server.post", "fields": {"rght": 14, "author": 159, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 09:03:14", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: How do you explain what you do to the guy on the street or your mum?", "unanswered": false, "content": "Thankyou. 50 bonus points. ", "comment_count": 0, "html": "<p>Thankyou. 50 bonus points. </p>", "child_count": 0, "closed": false, "tree_id": 87, "revision_count": 0, "parent": 472, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-how-do-you-explain-what-you-do-to-the-guy-on-the-street-or-your-mum", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 159}}, {"pk": 938, "model": "server.post", "fields": {"rght": 12, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 09:43:16", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Are there websites which allow users to post comments on peer-reviewed articles?", "unanswered": false, "content": "Thanks for these links Egon, I hadn't used ResearchBlogging before.", "comment_count": 0, "html": "<p>Thanks for these links Egon, I hadn't used ResearchBlogging before.</p>", "child_count": 0, "closed": false, "tree_id": 100, "revision_count": 0, "parent": 466, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-are-there-websites-which-allow-users-to-post-comments-on-peer-reviewed-articles", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 939, "model": "server.post", "fields": {"rght": 33, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 11:10:14", "lft": 32, "post_type": 206247, "score": 0, "title": "C: Which R packages, if any, are best for parallel computing ?", "unanswered": false, "content": "Thanks everyone for the answers. In the end I'm going for Revolution-R as the best answer mainly because it is a big step forward for learning and programming in parallel with R. It includes at install the domC and multicore packages that Chris mentioned and achieves some pretty impressive speed ups on processes like matrix multiplication. Watch out for it hammering the CPUs though.", "comment_count": 0, "html": "<p>Thanks everyone for the answers. In the end I'm going for Revolution-R as the best answer mainly because it is a big step forward for learning and programming in parallel with R. It includes at install the domC and multicore packages that Chris mentioned and achieves some pretty impressive speed ups on processes like matrix multiplication. Watch out for it hammering the CPUs though.</p>", "child_count": 0, "closed": false, "tree_id": 98, "revision_count": 0, "parent": 441, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-which-r-packages-if-any-are-best-for-parallel-computing", "lastedit_date": "2011-11-24 14:49:04", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 940, "model": "server.post", "fields": {"rght": 6, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 11:33:38", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: When is the best time to submit sequences to public databases like NCBI?", "unanswered": false, "content": "if you publish, you need to release the data on a public domain, otherwise your results won't be reproducible (at least for most of the journals). So either publish or patent it, you have to choose.", "comment_count": 0, "html": "<p>if you publish, you need to release the data on a public domain, otherwise your results won't be reproducible (at least for most of the journals). So either publish or patent it, you have to choose.</p>", "child_count": 0, "closed": false, "tree_id": 94, "revision_count": 0, "parent": 446, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-when-is-the-best-time-to-submit-sequences-to-public-databases-like-ncbi", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 941, "model": "server.post", "fields": {"rght": 4, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 11:57:41", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: test whether the variance in a group is lower than in another", "unanswered": false, "content": "thanks, I forgot to say that I also looked at the Bartlett's test, but discarded it because it is sensitive to departures from normality and my data is not normal. Thanks anyway.", "comment_count": 0, "html": "<p>thanks, I forgot to say that I also looked at the Bartlett's test, but discarded it because it is sensitive to departures from normality and my data is not normal. Thanks anyway.</p>", "child_count": 0, "closed": false, "tree_id": 105, "revision_count": 0, "parent": 485, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-test-whether-the-variance-in-a-group-is-lower-than-in-another", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 942, "model": "server.post", "fields": {"rght": 12, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 11:59:35", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Tips to build a data storage for bioinformatics", "unanswered": false, "content": "This is a great and nice answer! Thanks Michael! But, top brands are underrepresented in Brazil. Most solution specialists are friends of mine from grad/undergrad times. For instance, IBM regularly hires people like myself for solution deployment, validation and maintenance. There are very few HPC (official) vendors, too. Our connection is already fibre (nice!!!). It's good to hear that in the end bioinformatics data are not so different. I'll talk with other sysadmins right now. The system accepts hotswap already. Using ext4. I'm not very comfortable with cryptography. Any recomendation?", "comment_count": 0, "html": "<p>This is a great and nice answer! Thanks Michael! But, top brands are underrepresented in Brazil. Most solution specialists are friends of mine from grad/undergrad times. For instance, IBM regularly hires people like myself for solution deployment, validation and maintenance. There are very few HPC (official) vendors, too. Our connection is already fibre (nice!!!). It's good to hear that in the end bioinformatics data are not so different. I'll talk with other sysadmins right now. The system accepts hotswap already. Using ext4. I'm not very comfortable with cryptography. Any recomendation?</p>", "child_count": 0, "closed": false, "tree_id": 101, "revision_count": 0, "parent": 473, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-tips-to-build-a-data-storage-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 943, "model": "server.post", "fields": {"rght": 6, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 11:59:51", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: test whether the variance in a group is lower than in another", "unanswered": false, "content": "Then Forsythe test maybe? http://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test maybe. Look at the section: \"Comparison with Levene's test\"", "comment_count": 0, "html": "<p>Then Forsythe test maybe? http://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test maybe. Look at the section: \"Comparison with Levene's test\"</p>", "child_count": 0, "closed": false, "tree_id": 105, "revision_count": 0, "parent": 485, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-test-whether-the-variance-in-a-group-is-lower-than-in-another", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 944, "model": "server.post", "fields": {"rght": 6, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 13:23:41", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Markov chain for generating random protein sequences", "unanswered": false, "content": "For 1st and 2nd order chains you can use Sean Eddy's Squid lib. It's written in C. But, you could add some randomizations as a control. In this case you could use uShuffle to preserve high-level orderings. Then you'll see why biology is very much local . . .", "comment_count": 0, "html": "<p>For 1st and 2nd order chains you can use Sean Eddy's Squid lib. It's written in C. But, you could add some randomizations as a control. In this case you could use uShuffle to preserve high-level orderings. Then you'll see why biology is very much local . . .</p>", "child_count": 0, "closed": false, "tree_id": 102, "revision_count": 0, "parent": 477, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-markov-chain-for-generating-random-protein-sequences", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 945, "model": "server.post", "fields": {"rght": 8, "author": 165, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 13:59:38", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: When is the best time to submit sequences to public databases like NCBI?", "unanswered": false, "content": "Patenting is a different issue really.  I think that a small proportion of sequences are withheld for patenting purposes although there is no way to know what is being stored being the wall of private biotechs. I am interested in knowing what most people do with their sequences: release them a soon as they have been quality checked; wait until they are submitting a manuscript; wait until the manuscript is accepted.", "comment_count": 0, "html": "<p>Patenting is a different issue really.  I think that a small proportion of sequences are withheld for patenting purposes although there is no way to know what is being stored being the wall of private biotechs. I am interested in knowing what most people do with their sequences: release them a soon as they have been quality checked; wait until they are submitting a manuscript; wait until the manuscript is accepted.</p>", "child_count": 0, "closed": false, "tree_id": 94, "revision_count": 0, "parent": 446, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-when-is-the-best-time-to-submit-sequences-to-public-databases-like-ncbi", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 165}}, {"pk": 946, "model": "server.post", "fields": {"rght": 5, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 14:08:41", "lft": 4, "post_type": 206247, "score": 0, "title": "C: amino acid content statistical test", "unanswered": false, "content": "Could be a little more specific? What are you looking for? Just that two organisms have a diference in codon content? ", "comment_count": 0, "html": "<p>Could be a little more specific? What are you looking for? Just that two organisms have a diference in codon content? </p>", "child_count": 0, "closed": false, "tree_id": 104, "revision_count": 0, "parent": 479, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-amino-acid-content-statistical-test", "lastedit_date": "2011-11-24 14:49:04", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 947, "model": "server.post", "fields": {"rght": 10, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 14:20:47", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Tips on how to set up a virtual online workbench for bioinformatics", "unanswered": false, "content": "I am a member of the CARMEN project and the work package in charge of architecture looked at a number of the solutions above for services and workflow management.  Unfortunately it was impossible to integrate these tools with what we wanted to do with the project and a so a fully home-grown solution was developed.  Including a web based workflow editor.  We do use Plone as the CMS associated with the project, but not as a front end to the workflow/data/services portal", "comment_count": 0, "html": "<p>I am a member of the CARMEN project and the work package in charge of architecture looked at a number of the solutions above for services and workflow management.  Unfortunately it was impossible to integrate these tools with what we wanted to do with the project and a so a fully home-grown solution was developed.  Including a web based workflow editor.  We do use Plone as the CMS associated with the project, but not as a front end to the workflow/data/services portal</p>", "child_count": 0, "closed": false, "tree_id": 96, "revision_count": 0, "parent": 431, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-tips-on-how-to-set-up-a-virtual-online-workbench-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 948, "model": "server.post", "fields": {"rght": 9, "author": 118, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 14:34:13", "lft": 8, "post_type": 206247, "score": 0, "title": "C: Which C++ libraries are best for dealing with fastq files?", "unanswered": false, "content": "Which OS/CPU architecture do you need it for?", "comment_count": 0, "html": "<p>Which OS/CPU architecture do you need it for?</p>", "child_count": 0, "closed": false, "tree_id": 106, "revision_count": 0, "parent": 486, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-which-c-libraries-are-best-for-dealing-with-fastq-files", "lastedit_date": "2011-11-24 14:49:04", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 118}}, {"pk": 949, "model": "server.post", "fields": {"rght": 11, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 14:40:15", "lft": 10, "post_type": 206247, "score": 0, "title": "C: Which C++ libraries are best for dealing with fastq files?", "unanswered": false, "content": "RHEL5 x86_64 ..", "comment_count": 0, "html": "<p>RHEL5 x86_64 ..</p>", "child_count": 0, "closed": false, "tree_id": 106, "revision_count": 0, "parent": 486, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-which-c-libraries-are-best-for-dealing-with-fastq-files", "lastedit_date": "2011-11-24 14:49:04", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 950, "model": "server.post", "fields": {"rght": 4, "author": 112, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 14:42:33", "lft": 3, "post_type": 206247, "score": 1, "title": "C: A: Which C++ libraries are best for dealing with fastq files?", "unanswered": false, "content": "+1 - Highly recommended. That header supports compressed files, too, which speeds IO-bound processing. One caveat for C++ though - that header wants char* and FILE*, not C++ strings and iostreams, but that's easy enough to manage.", "comment_count": 0, "html": "<p>+1 - Highly recommended. That header supports compressed files, too, which speeds IO-bound processing. One caveat for C++ though - that header wants char<em> and FILE</em>, not C++ strings and iostreams, but that's easy enough to manage.</p>", "child_count": 0, "closed": false, "tree_id": 106, "revision_count": 0, "parent": 488, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-which-c-libraries-are-best-for-dealing-with-fastq-files", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 112}}, {"pk": 951, "model": "server.post", "fields": {"rght": 11, "author": 88, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 15:16:46", "lft": 10, "post_type": 206247, "score": 0, "title": "C: test whether the variance in a group is lower than in another", "unanswered": false, "content": "What is your non-normality assumption based on? Have you thought about transforming the data (with log transformation, for example) to be more normal?", "comment_count": 0, "html": "<p>What is your non-normality assumption based on? Have you thought about transforming the data (with log transformation, for example) to be more normal?</p>", "child_count": 0, "closed": false, "tree_id": 105, "revision_count": 0, "parent": 483, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-test-whether-the-variance-in-a-group-is-lower-than-in-another", "lastedit_date": "2011-11-24 14:49:04", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 88}}, {"pk": 952, "model": "server.post", "fields": {"rght": 22, "author": 73, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 15:37:42", "lft": 21, "post_type": 206247, "score": 1, "title": "C: A: How to organize a pipeline of small scripts together?", "unanswered": false, "content": "I'll try it. I actually just googled \"makefile bioinformatics\" and found this, which was helpful: http://www.slideshare.net/giovanni/makefiles-bioinfo", "comment_count": 0, "html": "<p>I'll try it. I actually just googled \"makefile bioinformatics\" and found this, which was helpful: http://www.slideshare.net/giovanni/makefiles-bioinfo</p>", "child_count": 0, "closed": false, "tree_id": 26, "revision_count": 0, "parent": 153, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-how-to-organize-a-pipeline-of-small-scripts-together", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 73}}, {"pk": 953, "model": "server.post", "fields": {"rght": 12, "author": 58, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 15:41:15", "lft": 11, "post_type": 206247, "score": 3, "title": "C: A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "If you're looking at providing R services you might want to look at http://www.rforge.net/Rserve/ \"Rserve is a TCP/IP server which allows other programs to use facilities of R (see www.r-project.org) from various languages without the need to initialize R or link against R library. Every connection has a separate workspace and working directory. Client-side implementations are available for popular languages such as C/C++ and Java. Typical use is to integrate R backend for computation of statstical models, plots etc. in other applications.\"", "comment_count": 0, "html": "<p>If you're looking at providing R services you might want to look at http://www.rforge.net/Rserve/ \"Rserve is a TCP/IP server which allows other programs to use facilities of R (see www.r-project.org) from various languages without the need to initialize R or link against R library. Every connection has a separate workspace and working directory. Client-side implementations are available for popular languages such as C/C++ and Java. Typical use is to integrate R backend for computation of statstical models, plots etc. in other applications.\"</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 0, "parent": 490, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 58}}, {"pk": 954, "model": "server.post", "fields": {"rght": 16, "author": 168, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 15:50:01", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "Thanks Daniel, we are definitely looking at Rserve as well, but I have to admit I hadn't thought of using it for our C/C++ code, but having just looked at the documentation that looks like a great way to go.", "comment_count": 0, "html": "<p>Thanks Daniel, we are definitely looking at Rserve as well, but I have to admit I hadn't thought of using it for our C/C++ code, but having just looked at the documentation that looks like a great way to go.</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 0, "parent": 490, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 168}}, {"pk": 955, "model": "server.post", "fields": {"rght": 6, "author": 29, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 17:52:41", "lft": 5, "post_type": 206247, "score": 0, "title": "C: A: Which C++ libraries are best for dealing with fastq files?", "unanswered": false, "content": "bouuhhhh in  http://lh3lh3.users.sourceforge.net/kseq.shtml  ANY malloc should be checked against NULL (line 56 , 121 , 188 ...) :-(", "comment_count": 0, "html": "<p>bouuhhhh in  http://lh3lh3.users.sourceforge.net/kseq.shtml  ANY malloc should be checked against NULL (line 56 , 121 , 188 ...) :-(</p>", "child_count": 0, "closed": false, "tree_id": 106, "revision_count": 0, "parent": 488, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-which-c-libraries-are-best-for-dealing-with-fastq-files", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 29}}, {"pk": 956, "model": "server.post", "fields": {"rght": 12, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 18:10:16", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Tips on how to set up a virtual online workbench for bioinformatics", "unanswered": false, "content": "What was the problem with zope/plone?", "comment_count": 0, "html": "<p>What was the problem with zope/plone?</p>", "child_count": 0, "closed": false, "tree_id": 96, "revision_count": 0, "parent": 431, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-tips-on-how-to-set-up-a-virtual-online-workbench-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 957, "model": "server.post", "fields": {"rght": 23, "author": 86, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 18:22:16", "lft": 22, "post_type": 206247, "score": 1, "title": "C: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "unanswered": false, "content": "@ALL : We have checked with various vendors and finally ordered the server from [PSSCLABS][1]. Got good pricing, they are good at technologies and seems to have good experience in providing solutions for [bioinformatics/genomics][2] related research. I will update this with my feedback after the server is ready. \n\n  [1]: http://www.pssclabs.com/\n  [2]: http://www.pssclabs.com/roche/roche_main_sub.asp", "comment_count": 0, "html": "<p>@ALL : We have checked with various vendors and finally ordered the server from <a href=\"http://www.pssclabs.com/\">PSSCLABS</a>. Got good pricing, they are good at technologies and seems to have good experience in providing solutions for <a href=\"http://www.pssclabs.com/roche/roche_main_sub.asp\">bioinformatics/genomics</a> related research. I will update this with my feedback after the server is ready. </p>", "child_count": 0, "closed": false, "tree_id": 45, "revision_count": 0, "parent": 168, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:33", "slug": "c-looking-for-linux-vendors-to-order-a-centosubuntu-based-webserver-to-host-bioinformatics-apps", "lastedit_date": "2011-11-24 14:49:04", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 86}}, {"pk": 958, "model": "server.post", "fields": {"rght": 8, "author": 72, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 18:37:50", "lft": 7, "post_type": 206247, "score": 0, "title": "C: A: Recommend your favorite bioinformatics books", "unanswered": false, "content": "The Genome War is good - it touches on the aspects of whole genome shotgun assembly pretty well", "comment_count": 0, "html": "<p>The Genome War is good - it touches on the aspects of whole genome shotgun assembly pretty well</p>", "child_count": 0, "closed": false, "tree_id": 48, "revision_count": 0, "parent": 184, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-recommend-your-favorite-bioinformatics-books", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 72}}, {"pk": 959, "model": "server.post", "fields": {"rght": 18, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 20:05:22", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "How about the C implementation of Axis2? I found the Java Axis2 to be quite standard compliant, maybe it's worth giving that a try? I would like to try to convince providers to provide interoperable services, so maybe the point is mainly to find libraries to support this.", "comment_count": 0, "html": "<p>How about the C implementation of Axis2? I found the Java Axis2 to be quite standard compliant, maybe it's worth giving that a try? I would like to try to convince providers to provide interoperable services, so maybe the point is mainly to find libraries to support this.</p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 0, "parent": 490, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 960, "model": "server.post", "fields": {"rght": 12, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 21:06:29", "lft": 11, "post_type": 206247, "score": 0, "title": "C: A: Which application is truly missing in bioinformatics?", "unanswered": false, "content": "Now that's a miracle !!! :)", "comment_count": 0, "html": "<p>Now that's a miracle !!! :)</p>", "child_count": 0, "closed": false, "tree_id": 107, "revision_count": 0, "parent": 498, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-which-application-is-truly-missing-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 961, "model": "server.post", "fields": {"rght": 14, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 21:23:30", "lft": 13, "post_type": 206247, "score": 0, "title": "C: A: Tips to build a data storage for bioinformatics", "unanswered": false, "content": "Hmm, maybe not the worst idea to buy a ready-made rack from e.g. HAL, Sun/Oracle, but of course, it's maybe hard to find the retailer of your trust. Reg. bioinformatics data, maybe the main difference in the future (high-th. seq, -omics) is that one has to make the decision, which data you can afford to store and which you can afford to throw away. That's the bioinformatics decision.\n Also transfer of a TB data from sequencer to storage is a problem. Some sequencers (eg 454 titanium) have compute clusters attached that due the processing and (temp.) storage. ", "comment_count": 0, "html": "<p>Hmm, maybe not the worst idea to buy a ready-made rack from e.g. HAL, Sun/Oracle, but of course, it's maybe hard to find the retailer of your trust. Reg. bioinformatics data, maybe the main difference in the future (high-th. seq, -omics) is that one has to make the decision, which data you can afford to store and which you can afford to throw away. That's the bioinformatics decision.\n Also transfer of a TB data from sequencer to storage is a problem. Some sequencers (eg 454 titanium) have compute clusters attached that due the processing and (temp.) storage. </p>", "child_count": 0, "closed": false, "tree_id": 101, "revision_count": 0, "parent": 473, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-tips-to-build-a-data-storage-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 962, "model": "server.post", "fields": {"rght": 16, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-25 21:25:01", "lft": 15, "post_type": 206247, "score": 0, "title": "C: A: Tips to build a data storage for bioinformatics", "unanswered": false, "content": "Oh, and btw. no experiance with crypt. filesystems except existence proof. I have nothing to hide ;)", "comment_count": 0, "html": "<p>Oh, and btw. no experiance with crypt. filesystems except existence proof. I have nothing to hide ;)</p>", "child_count": 0, "closed": false, "tree_id": 101, "revision_count": 0, "parent": 473, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-tips-to-build-a-data-storage-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 963, "model": "server.post", "fields": {"rght": 4, "author": 54, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-26 08:33:36", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: What is your experience with bioinformatics webservices?", "unanswered": false, "content": "I agree, SOAP is *not* difficult, especially if you use a SOAP implementation like Axis2 or JavaWS. Moast depends on the WSDL being made correctly. soapenc:array is a big lagacy problem. That comes when people don't know how to do their XML schema of complex types right. It's a shame that very large institutions are unable ore unwilling to test their services properly. ", "comment_count": 0, "html": "<p>I agree, SOAP is <em>not</em> difficult, especially if you use a SOAP implementation like Axis2 or JavaWS. Moast depends on the WSDL being made correctly. soapenc:array is a big lagacy problem. That comes when people don't know how to do their XML schema of complex types right. It's a shame that very large institutions are unable ore unwilling to test their services properly. </p>", "child_count": 0, "closed": false, "tree_id": 93, "revision_count": 0, "parent": 422, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-what-is-your-experience-with-bioinformatics-webservices", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 54}}, {"pk": 964, "model": "server.post", "fields": {"rght": 4, "author": 22, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-26 11:48:53", "lft": 3, "post_type": 206247, "score": 0, "title": "C: A: Which application is truly missing in bioinformatics?", "unanswered": false, "content": "rotfl.... +100!", "comment_count": 0, "html": "<p>rotfl.... +100!</p>", "child_count": 0, "closed": false, "tree_id": 107, "revision_count": 0, "parent": 495, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-which-application-is-truly-missing-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 22}}, {"pk": 965, "model": "server.post", "fields": {"rght": 18, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-26 13:30:26", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: Tips to build a data storage for bioinformatics", "unanswered": false, "content": "I really prefer the cluster way to solve the question, i.e., to build the solution around the data. As I said, HPC vendors in Brazil are lame. It's much easier to deploy your own solution, even with abundant funding. Data triage and other biocuration tasks will be addressed soon. I think that transfer will not be much of a problem. But, long term storage for legal reasons will be a pain in the ass, certainly.", "comment_count": 0, "html": "<p>I really prefer the cluster way to solve the question, i.e., to build the solution around the data. As I said, HPC vendors in Brazil are lame. It's much easier to deploy your own solution, even with abundant funding. Data triage and other biocuration tasks will be addressed soon. I think that transfer will not be much of a problem. But, long term storage for legal reasons will be a pain in the ass, certainly.</p>", "child_count": 0, "closed": false, "tree_id": 101, "revision_count": 0, "parent": 473, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-tips-to-build-a-data-storage-for-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 966, "model": "server.post", "fields": {"rght": 10, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-26 13:42:29", "lft": 9, "post_type": 206247, "score": 0, "title": "C: A: Which application is truly missing in bioinformatics?", "unanswered": false, "content": "Don't need to be a generic killer app. Just the one which would make your life more colorful !!! Maybe we are all dreaming about the same thing . . .", "comment_count": 0, "html": "<p>Don't need to be a generic killer app. Just the one which would make your life more colorful !!! Maybe we are all dreaming about the same thing . . .</p>", "child_count": 0, "closed": false, "tree_id": 107, "revision_count": 0, "parent": 499, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-which-application-is-truly-missing-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 967, "model": "server.post", "fields": {"rght": 19, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-26 13:42:51", "lft": 18, "post_type": 206247, "score": 0, "title": "C: Which application is truly missing in bioinformatics?", "unanswered": false, "content": "Yeah ! I'm a math nerd . . .", "comment_count": 0, "html": "<p>Yeah ! I'm a math nerd . . .</p>", "child_count": 0, "closed": false, "tree_id": 107, "revision_count": 0, "parent": 494, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-which-application-is-truly-missing-in-bioinformatics", "lastedit_date": "2011-11-24 14:49:04", "level": 1, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 968, "model": "server.post", "fields": {"rght": 18, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-26 13:54:37", "lft": 17, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "\"Inline Link - http://foo.com\".", "comment_count": 0, "html": "<p>\"Inline Link - http://foo.com\".</p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 393, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 969, "model": "server.post", "fields": {"rght": 20, "author": 147, "answer_accepted": false, "tag_string": "", "creation_date": "2010-03-26 13:55:16", "lft": 19, "post_type": 206247, "score": 0, "title": "C: A: What are the most reliable normalization methods for microarrays?", "unanswered": false, "content": "[Inline Link](http://foo.com)", "comment_count": 0, "html": "<p><a href=\"http://foo.com\">Inline Link</a></p>", "child_count": 0, "closed": false, "tree_id": 86, "revision_count": 0, "parent": 393, "views": 0, "deleted": false, "answer_count": 0, "touch_date": "2011-11-24 14:49:04", "slug": "c-a-what-are-the-most-reliable-normalization-methods-for-microarrays", "lastedit_date": "2011-11-24 14:49:04", "level": 2, "post_accepted": false, "tag_set": [], "lastedit_user": 147}}, {"pk": 1, "model": "server.modlog", "fields": {"author": 1, "text": "Delete", "mod_type": 1, "date": "2009-09-30 18:57:55", "other": "", "user": null, "action": 3, "post": 6}}, {"pk": 2, "model": "server.modlog", "fields": {"author": 1, "text": "Delete", "mod_type": 1, "date": "2009-10-18 16:23:04", "other": "", "user": null, "action": 3, "post": 20}}, {"pk": 3, "model": "server.modlog", "fields": {"author": 1, "text": "Delete", "mod_type": 1, "date": "2009-10-18 16:25:02", "other": "", "user": null, "action": 3, "post": 21}}, {"pk": 4, "model": "server.modlog", "fields": {"author": 1, "text": "Close", "mod_type": 1, "date": "2010-03-08 13:51:12", "other": "", "user": null, "action": 1, "post": 92}}, {"pk": 5, "model": "server.modlog", "fields": {"author": 1, "text": "Delete", "mod_type": 1, "date": "2010-03-08 21:45:27", "other": "", "user": null, "action": 3, "post": 230}}, {"pk": 6, "model": "server.modlog", "fields": {"author": 29, "text": "Delete", "mod_type": 1, "date": "2010-03-12 17:19:28", "other": "", "user": null, "action": 3, "post": 279}}, {"pk": 7, "model": "server.modlog", "fields": {"author": 29, "text": "Undelete", "mod_type": 1, "date": "2010-03-12 17:19:58", "other": "", "user": null, "action": 4, "post": 279}}, {"pk": 8, "model": "server.modlog", "fields": {"author": 145, "text": "Delete", "mod_type": 1, "date": "2010-03-16 11:41:29", "other": "", "user": null, "action": 3, "post": 314}}, {"pk": 9, "model": "server.modlog", "fields": {"author": 29, "text": "Delete", "mod_type": 1, "date": "2010-03-22 18:17:15", "other": "", "user": null, "action": 3, "post": 404}}, {"pk": 10, "model": "server.modlog", "fields": {"author": 1, "text": "Delete", "mod_type": 1, "date": "2010-03-24 13:03:47", "other": "", "user": null, "action": 3, "post": 327}}, {"pk": 11, "model": "server.modlog", "fields": {"author": 22, "text": "Delete", "mod_type": 1, "date": "2010-05-20 10:28:36", "other": "", "user": null, "action": 3, "post": 385}}, {"pk": 1, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "test", "title": "You can ask any question here, as long as it is data analysis related.", "content": "This is the first question, more of a test rather than actual content.", "date": "2009-09-30 14:12:07", "action": 0, "post": 1}}, {"pk": 2, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "test start", "title": "You can ask any question here, as long as it is data analysis related.", "content": "This is the first question, more of a test rather than actual content.\n\nHopefully we will be able to jump start the system to contain more useful information.", "date": "2009-09-30 14:18:11", "action": 0, "post": 1}}, {"pk": 3, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "bed gff", "title": "How do I convert from BED format to GFF format?", "content": "I have a file in GFF format and I need to convert it to BED format. What do I do?", "date": "2009-09-30 14:55:00", "action": 0, "post": 2}}, {"pk": 4, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How do I convert from BED format to GFF format?", "content": "Both formats are tab delimited text files used to represent DNA features in genomes. The order of columns between the two are different, there are also columns that correspond to attributes missing from one or the other format. Nonetheless **the most important** difference between the two is the coordinate systems that they assume. \n\nThe [BED](http://genome.ucsc.edu/FAQ/FAQformat#format1) format developed at `UCSC` uses a zero based indexing and an open end interval whereas the [GFF](http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml) format developed at `Sanger` assumes a 1 based coordinate system that includes both start and end coordinates. Therefore\n\nThe `[0,100]` interval in `BED` format corresponds to `[1,100]` in `GFF` format and both are `100` base long. That the first element in BED format will be have the index of `0` where the last `100th` element will have the index of `99`! Whereas in `GFF` the first element will have the index of `1` and the last element will have the index of `100`.\n\nTo convert between the two you may use [Galayx](http://main.g2.bx.psu.edu/) and select the section called `Select Formats` that will list various transformation options.\n", "date": "2009-09-30 14:56:18", "action": 0, "post": 3}}, {"pk": 5, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "bed gff galaxy", "title": "How do I convert from BED format to GFF format?", "content": "I have a file in GFF format and I need to convert it to BED format. What do I do?", "date": "2009-09-30 15:09:43", "action": 0, "post": 2}}, {"pk": 6, "model": "server.postrevision", "fields": {"author": 2, "tag_string": "yeast motif", "title": "Finding common motifs in sequences", "content": "I have a few hundred yeast sequences (20-80bp long) and I want to find common motifs (conserved bases at certain indices) in them. I am using a Mac", "date": "2009-09-30 16:09:06", "action": 0, "post": 4}}, {"pk": 7, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "microarray clustering", "title": "Recommend easy to use microarray clustering software", "content": "One of my favorites is the [MEV](http://www.tm4.org/mev.html) micro-array data analysis tool.\nIt is simple to use and it has a very large number of features. \n\nWorks well for any type of data. You can aslo load into it a file in a simple format like this:\n\n<pre>\nGENE1, value1, value2\nGENE2, value1, value2\n</pre>\n", "date": "2009-09-30 16:44:22", "action": 0, "post": 5}}, {"pk": 8, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "microarray clustering", "title": "Recommend easy to use microarray clustering software", "content": "One of my favorites is the [MEV](http://www.tm4.org/mev.html) micro-array data analysis tool.\nIt is simple to use and it has a very large number of features. \n\nWorks well for any type of data. You can also load into it data from a file that is in a simple text format:\n\n<pre>\nGENE1, value1, value2\nGENE2, value1, value2\n</pre>\n", "date": "2009-09-30 16:49:51", "action": 0, "post": 5}}, {"pk": 9, "model": "server.postrevision", "fields": {"author": 4, "tag_string": "test", "title": "test by zhenhai", "content": "Hi, I just created my user id a few minutes ago. \n\nPost this question to see how it works.", "date": "2009-09-30 18:49:39", "action": 0, "post": 6}}, {"pk": 10, "model": "server.postrevision", "fields": {"author": 4, "tag_string": "", "title": "A: Finding common motifs in sequences", "content": "try this out?\n\nhttp://fraenkel.mit.edu/webmotifs/form.html", "date": "2009-09-30 18:55:02", "action": 0, "post": 7}}, {"pk": 11, "model": "server.postrevision", "fields": {"author": 5, "tag_string": "", "title": "A: Finding common motifs in sequences", "content": "You can also use MEME:  http://meme.sdsc.edu/.", "date": "2009-09-30 19:32:29", "action": 0, "post": 8}}, {"pk": 12, "model": "server.postrevision", "fields": {"author": 6, "tag_string": "", "title": "A: Finding common motifs in sequences", "content": "ACGGGCCCGACGATGCGTCGTA\n\nACGTACGTCGAACCGTCGTCGT\n\nACGTGCGTCGAAACGTCAGTCG\n\nACGGGTTCGATCGTCGTCGTCG\n may be in Python I will break down the first sequence of required motif length into a sliding window and will search for those list of motifs in the rest of sequences using regular expression in python using re.search() method.", "date": "2009-09-30 19:35:28", "action": 0, "post": 9}}, {"pk": 13, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How do I convert from BED format to GFF format?", "content": "Both formats are tab delimited text files used to represent DNA features in genomes. The order of columns between the two are different, there are also columns that correspond to attributes missing from one or the other format. Nonetheless **the most important** difference between the two is the coordinate systems that they assume. \n\nThe [BED](http://genome.ucsc.edu/FAQ/FAQformat#format1) format developed at `UCSC` uses a zero based indexing and an open end interval whereas the [GFF](http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml) format developed at `Sanger` assumes a 1 based coordinate system that includes both start and end coordinates. Therefore\n\nThe `[0,100]` interval in `BED` format corresponds to `[1,100]` in `GFF` format and both are `100` base long. That the first element in BED format will be have the index of `0` where the last `100th` element will have the index of `99`! Whereas in `GFF` the first element will have the index of `1` and the last element will have the index of `100`.\n\nTo convert between the two you may use [Galaxy](http://main.g2.bx.psu.edu/) and select the section called `Select Formats` that will list various transformation options.\n", "date": "2009-09-30 19:46:25", "action": 0, "post": 3}}, {"pk": 14, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "microarray clustering", "title": "Recommend easy to use microarray clustering software", "content": "One of my favorites is the [MEV](http://www.tm4.org/mev.html) micro-array data analysis tool.\nIt is simple to use and it has a very large number of features. \n\nWorks well for any type of data. You can also load into it data from a file that is in a simple text format:\n\n<pre>\nGENE1, value1, value2\nGENE2, value1, value2\n</pre>\n\nFeel free to post your favorite clustering tool.", "date": "2009-09-30 19:50:02", "action": 0, "post": 5}}, {"pk": 15, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Finding common motifs in sequences", "content": "<pre>\nACGGGCCCGACGATGCGTCGTA\n\nACGTACGTCGAACCGTCGTCGT\n\nACGTGCGTCGAAACGTCAGTCG\n\nACGGGTTCGATCGTCGTCGTCG\n</pre>\n may be in Python I will break down the first sequence of required motif length into a sliding window and will search for those list of motifs in the rest of sequences using regular expression in python using `re.search()` method.", "date": "2009-10-01 01:09:51", "action": 0, "post": 9}}, {"pk": 16, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "python dinucleotide", "title": "How to generate dinucleotide occupancy counts for each coordinate of my reads?", "content": "I want to generate di-nucleotide occupancy counts for each position summed over each of the input sequences. An example output:\n\n![dinucleotide occupancy][1]\n\n\n  [1]: http://github.com/ialbert/biostar-codesample/raw/master/python/images/dinuc.png", "date": "2009-10-05 15:51:37", "action": 0, "post": 10}}, {"pk": 17, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How to generate multi-nucleotide occupancy counts for each coordinate of my reads?", "content": "The code snippet below will populate the ``store`` dictionary keyed by the di-nucleotide and values as lists that contain the occupancy for each index.\n\n<pre>\ndef dinuc_update(sequence, size, store={}):\n    \"\"\"\n    Accumulates dinucleotide position counts at each index.\n    \"\"\"\n    def zeroes():\n        \"Generates an empty array that hold the positions\"\n        return [ 0 ] * size\n \n    left, right = sequence, sequence[1:]\n    for index, a, b in zip(count(), left, right):\n        # upon encoutering a missing key initialize \n        # that value for that key to the return value of the empty() function\n        store.setdefault(a+b, zeroes())[index] += 1\n\n    return store\n</pre>\n\nThe code at [dinucpatt.py][1] demonstrates its use in a full program. Set the ``size`` to the maximal possible sequence size. A typical use case:\n\n<pre>\nstore = {}\nseq1 = 'ATGC'\ndinuc_update(seq1, size=3, store=store)    \n\nseq2 = 'ATCG'\ndinuc_update(seq2, size=3, store=store)\n\nprint store\n</pre>\n\nwill print:\n\n<pre>\n{'CG': [0, 0, 1], 'TG': [0, 1, 0], 'GC': [0, 0, 1], \n'AT': [2, 0, 0], 'TC': [0, 1, 0]}\n</pre>\n\n  [1]: http://github.com/ialbert/biostar-codesample/blob/master/python/dinucpatt.py", "date": "2009-10-05 16:03:01", "action": 0, "post": 11}}, {"pk": 18, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Recommend easy to use microarray clustering software", "content": "One of my favorites is the [MEV](http://www.tm4.org/mev.html) micro-array data analysis tool.\nIt is simple to use and it has a very large number of features. \n\nWorks well for any type of data. You can also load into it data from a file that is in a simple text format:\n\n<pre>\nGENE1, value1, value2\nGENE2, value1, value2\n</pre>\n\nFeel free to post your favorite clustering tool.", "date": "2009-10-05 16:09:57", "action": 0, "post": 12}}, {"pk": 19, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "microarray clustering", "title": "Recommend easy to use microarray clustering software", "content": "Feel free to post your favorite clustering tool.", "date": "2009-10-05 16:10:10", "action": 0, "post": 5}}, {"pk": 20, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "python dinucleotide", "title": "How to generate dinucleotide occupancy counts for each coordinate of my reads?", "content": "I need to generate di-nucleotide occupancy counts for each position of a given sequence then summed over each of the input sequences. An example desired output:\n\n![dinucleotide occupancy][1]\n\n\n  [1]: http://github.com/ialbert/biostar-codesample/raw/master/python/images/dinuc.png", "date": "2009-10-05 16:12:09", "action": 0, "post": 10}}, {"pk": 21, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "", "title": "A: How to generate multi-nucleotide occupancy counts for each coordinate of my reads?", "content": "The code snippet below will populate the ``store`` dictionary keyed by the di-nucleotide and values as lists that contain the occupancy for each index.\n\n<pre>\nfrom itertools import count\n\ndef dinuc_update(sequence, size, store={}):\n    \"\"\"\n    Accumulates dinucleotide position counts at each index.\n    \"\"\"\n    def zeroes():\n        \"Generates an empty array that hold the positions\"\n        return [ 0 ] * size\n \n    left, right = sequence, sequence[1:]\n    for index, a, b in zip(count(), left, right):\n        # upon encoutering a missing key initialize \n        # that value for that key to the return value of the empty() function\n        store.setdefault(a+b, zeroes())[index] += 1\n\n    return store\n</pre>\n\nThe code at [dinucpatt.py][1] demonstrates its use in a full program. Set the ``size`` to the maximal possible sequence size. A typical use case:\n\n<pre>\nstore = {}\nseq1 = 'ATGC'\ndinuc_update(seq1, size=3, store=store)    \n\nseq2 = 'ATCG'\ndinuc_update(seq2, size=3, store=store)\n\nprint store\n</pre>\n\nwill print:\n\n<pre>\n{'CG': [0, 0, 1], 'TG': [0, 1, 0], 'GC': [0, 0, 1], \n'AT': [2, 0, 0], 'TC': [0, 1, 0]}\n</pre>\n\n  [1]: http://github.com/ialbert/biostar-codesample/blob/master/python/dinucpatt.py", "date": "2009-10-05 16:13:19", "action": 0, "post": 11}}, {"pk": 22, "model": "server.postrevision", "fields": {"author": 11, "tag_string": "solid deep sequence", "title": "CHIP DNA deep sequence", "content": "Hi, everyone,\nI am posting this question for my friend.\nHe is analyzing his CHIP DNA solid deep sequence data, and find out that near 80% reads can not be mapped to the human genome. We are wondering if this high percentage unmapped reads is normal in CHIP DNA deep sequence or there may be something wrong with his result.", "date": "2009-10-06 18:58:10", "action": 0, "post": 13}}, {"pk": 23, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: CHIP DNA deep sequence", "content": "I recall that our first samples that we ran on the Solid sequencer have had bad performance. Not quite an 80% loss but around 40%-60% reads were unmappable (yeast). Some other lab members will hopefully chime in with more details. ", "date": "2009-10-06 20:10:32", "action": 0, "post": 14}}, {"pk": 24, "model": "server.postrevision", "fields": {"author": 4, "tag_string": "", "title": "A: CHIP DNA deep sequence", "content": "Hi there,\n\nWe have done numbers of SOLiD sequencing run on yeast samples. Normally there are only 30-40 percent of total tags can be uniquely mapped back to yeast genome. \n\nWhat I would recommend is do it on solexa. You get much higher quality tags.\n\ncheers,", "date": "2009-10-06 20:41:24", "action": 0, "post": 15}}, {"pk": 25, "model": "server.postrevision", "fields": {"author": 12, "tag_string": "", "title": "A: CHIP DNA deep sequence", "content": "Your 20% mapping yield looks like low for normal ChIP experiment, even for human. Several factors can reduce this mapping yield. I am wondering which kind of ChIP was used in your case. That is, which kind of proteins was ChIPed?", "date": "2009-10-06 22:04:41", "action": 0, "post": 16}}, {"pk": 26, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "guidelines", "title": "Site use guidelines", "content": "Here are a few guidelines:\n\n 1. The site's goal is to answer bioinformatics and systems biology related questions\n 2. Don't forget to vote for answers that you like! Any registered user may vote on any answer.\n 3. When you ask a question you may also select the best answer\n 4. Subscribe to the RSS feeds for all questions or a single question to keep up to date with the developments", "date": "2009-10-07 15:14:13", "action": 0, "post": 1}}, {"pk": 27, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "", "title": "A: Site use guidelines", "content": "If you are shy about asking the question on your own behalf submit it to to the **Question Bot** and it will be posted on your behalf. Send email to the `Question Bot` link at the bottom.", "date": "2009-10-07 16:41:44", "action": 0, "post": 17}}, {"pk": 28, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Site use guidelines", "content": "If you are shy about asking the question on your own behalf submit it to to the **Question Bot** and it will be posted anonymously. Send email to the `Question Bot` link at the bottom.", "date": "2009-10-07 17:16:18", "action": 0, "post": 17}}, {"pk": 29, "model": "server.postrevision", "fields": {"author": 13, "tag_string": "", "title": "A: Site use guidelines", "content": "Hi,\n\nI don't think a new user can vote on a question or an answer.\nThe site says I need 15 reputation...", "date": "2009-10-09 03:28:20", "action": 0, "post": 18}}, {"pk": 30, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How to generate multi-nucleotide occupancy counts for each coordinate of my reads?", "content": "The code snippet below will populate the ``store`` dictionary keyed by the nucleotide patterns and values as lists that contain the occupancy for each index. (Updated answer now includes arbitrary lenght nucleotide counts)\n\n<pre>\nfrom itertools import count\n\ndef pattern_update(sequence, width=2, store={}):\n    \"\"\"\n    Accumulates nucleotide patterns of a certain width with \n    position counts at each index.\n    \"\"\"\n   \n    # open intervals need a padding at end for proper slicing\n    size  = len(sequence) + 1\n\n    def zeroes():\n        \"Generates an empty array that holds the positions\"\n        return [ 0 ] * (size - width)\n    \n    # these are the end indices\n    ends = range(width, size)\n\n    for lo, hi in zip(count(), ends):\n        # upon encoutering a missing key initialize \n        # that value for that key to the return value of the empty() function\n        key = sequence[lo:hi]\n        store.setdefault(key, zeroes())[lo] += 1\n\n    return store\n\n</pre>\n\nThe code at [multipatt.py][1] demonstrates its use in a full program. Set the ``size`` to the maximal possible sequence size. A typical use case:\n\n<pre>\n    store = {}\n    seq1 = 'ATGCT'\n    pattern_update(seq1, width=2, store=store)    \n\n    seq2 = 'ATCGC'\n    pattern_update(seq2, width=2, store=store)    \n\n    print store\n</pre>\n\nwill print:\n\n<pre>\n{'CG': [0, 0, 1, 0], 'GC': [0, 0, 1, 1], 'AT': [2, 0, 0, 0], \n'TG': [0, 1, 0, 0], 'TC': [0, 1, 0, 0], 'CT': [0, 0, 0, 1]}\n</pre>\n\n  [1]: http://github.com/ialbert/biostar-codesample/blob/master/python/multipatt.py", "date": "2009-10-13 14:41:12", "action": 0, "post": 11}}, {"pk": 31, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "nucleotides", "title": "How to generate multi-nucleotide occupancy counts for each coordinate of my reads?", "content": "I need to generate nucleotide occupancy counts for each position of a given sequence then summed over each of the input sequences. An example desired output (for di-nucleotide AT):\n\n![dinucleotide occupancy][1]\n\n\n  [1]: http://github.com/ialbert/biostar-codesample/raw/master/python/images/dinuc.png", "date": "2009-10-13 14:53:15", "action": 0, "post": 10}}, {"pk": 32, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How to generate multi-nucleotide occupancy counts for each coordinate of my reads?", "content": "The code snippet below will populate the ``store`` dictionary keyed by the nucleotide patterns and values as lists that contain the occupancy for each index. (Updated answer now includes arbitrary lenght nucleotide counts)::\n\n\n\n    from itertools import count\n\n    def pattern_update(sequence, width=2, store={}):\n        \"\"\"\n        Accumulates nucleotide patterns of a certain width with \n        position counts at each index.\n        \"\"\"\n       \n        # open intervals need a padding at end for proper slicing\n        size  = len(sequence) + 1\n\n        def zeroes():\n            \"Generates an empty array that holds the positions\"\n            return [ 0 ] * (size - width)\n        \n        # these are the end indices\n        ends = range(width, size)\n\n        for lo, hi in zip(count(), ends):\n            # upon encoutering a missing key initialize \n            # that value for that key to the return value of the empty() function\n            key = sequence[lo:hi]\n            store.setdefault(key, zeroes())[lo] += 1\n\n        return store\n\n\n\nThe code at [multipatt.py][1] demonstrates its use in a full program. Set the ``size`` to the maximal possible sequence size. A typical use case::\n\n\n    store = {}\n    seq1 = 'ATGCT'\n    pattern_update(seq1, width=2, store=store)    \n\n    seq2 = 'ATCGC'\n    pattern_update(seq2, width=2, store=store)    \n\n    print store\n\nwill print::\n\n\n    {'CG': [0, 0, 1, 0], 'GC': [0, 0, 1, 1], 'AT': [2, 0, 0, 0], \n    'TG': [0, 1, 0, 0], 'TC': [0, 1, 0, 0], 'CT': [0, 0, 0, 1]}\n\n\n[1]: http://github.com/ialbert/biostar-codesample/blob/master/python/multipatt.py\n    ", "date": "2009-10-13 15:00:00", "action": 0, "post": 11}}, {"pk": 33, "model": "server.postrevision", "fields": {"author": 4, "tag_string": "", "title": "A: Recommend easy to use microarray clustering software", "content": "I would recommend a combination of cluster and treeview.\n\npretty powerful!", "date": "2009-10-16 12:25:38", "action": 0, "post": 19}}, {"pk": 34, "model": "server.postrevision", "fields": {"author": 14, "tag_string": "boy george", "title": "do you have to be a guy to dress up as boy george", "content": "any ideas im a girl", "date": "2009-10-18 03:22:53", "action": 0, "post": 20}}, {"pk": 35, "model": "server.postrevision", "fields": {"author": 14, "tag_string": "boy george", "title": "do you have to be a guy to dress up as boy george", "content": "any ideas im a girl", "date": "2009-10-18 03:23:34", "action": 0, "post": 21}}, {"pk": 36, "model": "server.postrevision", "fields": {"author": 15, "tag_string": "geneid", "title": "Gene ID conversion tool", "content": "Hey,\n\nI was using DAVID (http://david.abcc.ncifcrf.gov/conversion.jsp) to do the gene ID conversion, e.g.conversion between Agilent ID, Genebank accession id and Entrez gene ID, but I found the DAVID database is not updated. Does anyone know a better updataed conversion tool to do this job? Thanks! ", "date": "2009-10-23 17:42:24", "action": 0, "post": 22}}, {"pk": 37, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Gene ID conversion tool", "content": "I don't know of a direct solution myself, but this is a topic that may be of interest for the biological data analysis class that I am teaching. \n\nIf you specify the organism/genomic builds that you are interested in we may be able to generate a full translation list as an in class example or a homework. I was planning on covering an `Affymetrix ID` to `Genebank example` anyhow.\n", "date": "2009-10-23 19:46:45", "action": 0, "post": 23}}, {"pk": 38, "model": "server.postrevision", "fields": {"author": 13, "tag_string": "shrimp sequencing short aligner", "title": "How to set SHRiMP parameters for best sensitivity with 35bp colorspace data?", "content": "Hi,\n\nI have 35bp Solid colorspace sequencing data, and the actual sequences to be mapped are 20-25bp after removing the linker sequence.\n\nI hope to find all the hits allowing no more than n mismatches (say n=3), not only the best hit.\n\nI know there is a -M option to specify -M sensitivity,35bp. I wonder whether this setting will guarantee the best sensitivity in this case. Since my reads are only 20-25bp long, should I changed the default 4 spaced seeds to 3?\n\nI'm new to SHRiMP, so I'd like to hear some suggestions on setting the parameters of SHRiMP to achieve the best sensitivity.\n\nThank you!", "date": "2009-12-01 07:13:53", "action": 0, "post": 24}}, {"pk": 39, "model": "server.postrevision", "fields": {"author": 17, "tag_string": "", "title": "A: How to set SHRiMP parameters for best sensitivity with 35bp colorspace data?", "content": "I just read the SHRiMP manual again, but I think that their explanation about -M option may not be enough to answer your question. I usually use the \"seed\" mode by using -s, -n, and -w and the option -M is a new feature of the version 1.3.1, which I have never tried before.\n\nI recommend for you to use the \"seed\" mode--the default would be good, but please adjust the -s option if you want more sensitivity. Always fast speed compensates sensitivity and the -M option seems to exist for this purpose.\n\nHope my message to be helpful for your project.", "date": "2009-12-01 14:57:35", "action": 0, "post": 25}}, {"pk": 40, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How to set SHRiMP parameters for best sensitivity with 35bp colorspace data?", "content": "> Since my reads are only 20-25bp long,\n> should I changed the default 4 spaced\n> seeds to 3?\n\nwhile the shrimp manual says:\n\n- We recommend using the default 4 seeds of weight 12 in most cases.\n\nyou could try running on a smaller sample and see what happens. ", "date": "2009-12-01 18:00:53", "action": 0, "post": 26}}, {"pk": 41, "model": "server.postrevision", "fields": {"author": 18, "tag_string": "", "title": "A: Gene ID conversion tool", "content": "The following link has a list of ID conversion tools:\n\nhttp://hum-molgen.org/NewsGen/08-2009/000020.html", "date": "2009-12-08 21:45:54", "action": 0, "post": 27}}, {"pk": 42, "model": "server.postrevision", "fields": {"author": 19, "tag_string": "meme sge motif motif compilation", "title": "Tips on compiling and using MEME 4.3 with a Sun Grid Engine computation cluster", "content": "Has anyone compiled and used MEME 4.x for use in a parallel computation environment, based upon operation with a Sun Grid Engine (SGE) cluster?\n\nI can compile the suite and its tests pass. However, when I attempt to use the `-p n` option, to specify `n` computation nodes, I get several error messages:\n\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    1: Command not found.\n\nWe do not have `/gridware/codine/util/arch`, but we do have `/gridengine/sgi/util/arch`.\n\nI tried looking around MEME's source code, particularly at `meme.c` and `mp.h`, but there are no references to these paths.\n\nI'm wondering if I am missing makefile directives. Here is my `./configure` statement:\n\n    ./configure --prefix=/home/areynolds/proj/meme/meme_4.3.0_build --with-url=\"http://meme.nbcr.net/meme\" --enable-openmp --enable-debug\n\nIs MPI a requirement; are there directives I am missing for MPI?\n\nThank you for any advice.", "date": "2010-01-13 12:59:22", "action": 0, "post": 28}}, {"pk": 43, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Tips on compiling and using MEME 4.3 with a Sun Grid Engine computation cluster", "content": "This may not be overly useful but it very much sounds like a configuration problem.\n\nUsually there is  configure flag that needs to be set to point to the libraries, something like:\n\n    --with-mpidir=MPIDIR\n    --with-mpicc=MPICC\n\nIt also appears that the MEME suite does not support Open MPI (as per [install notes][1]).\n\nI would also recommend posting on the MEME user forum:\n\n[https://www.nbcr.net/forum/viewforum.php?f=5][2]\n\n\n  [1]: http://meme.sdsc.edu/meme4/meme-install.html\n  [2]: https://www.nbcr.net/forum/viewforum.php?f=5", "date": "2010-01-13 21:17:50", "action": 0, "post": 29}}, {"pk": 44, "model": "server.postrevision", "fields": {"author": 19, "tag_string": "", "title": "A: How do I convert from BED format to GFF format?", "content": "Here's a Perl script I wrote if you wanted to do something local. \n\nThere's some code in there for translating yeast chromosome names that can be removed, if not needed. I also used a `Site` feature in the GFF file as the region ID, which might also need tweaking, depending on what features you're interested in.\n\n    #!/usr/bin/perl -w\n\n    use strict;\n    use Bio::Tools::GFF;\n    use feature qw(say switch);\n\n    my $gffio = Bio::Tools::GFF->new(-fh => \\*STDIN, -gff_version => 2);\n    my $feature;\n\n    while ($feature = $gffio->next_feature()) {\n        # print $gffio->gff_string($feature).\"\\n\";\n\n        # cf. http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml\n        my $seq_id = $feature->seq_id();   \n        my $start = $feature->start() - 1;\n        my $end = $feature->end();\n        my $strand = $feature->strand();\n        my @sites = $feature->get_tag_values('Site');\n\n        # translate strand\n        given ( $strand ) {\n            when ($_ == 1)  { $strand = \"+\"; }\n            when ($_ == -1) { $strand = \"-\"; }\n        }\n    \n        # translate yeast chromosome to UCSC browser-readable chromosome\n        # cf. http://www.yeastgenome.org/sgdpub/Saccharomyces_cerevisiae.pdf\n        given ( $seq_id ) {\n            when ( $_ eq \"I\" )    { $seq_id = \"chr1\"; }\n            when ( $_ eq \"II\" )   { $seq_id = \"chr2\"; }\n            when ( $_ eq \"III\" )  { $seq_id = \"chr3\"; }\n            when ( $_ eq \"IV\" )   { $seq_id = \"chr4\"; }\n            when ( $_ eq \"V\" )    { $seq_id = \"chr5\"; }\n            when ( $_ eq \"VI\" )   { $seq_id = \"chr6\"; }\n            when ( $_ eq \"VII\" )  { $seq_id = \"chr7\"; }\n            when ( $_ eq \"VIII\" ) { $seq_id = \"chr8\"; }\n            when ( $_ eq \"IX\" )   { $seq_id = \"chr9\"; }\n            when ( $_ eq \"X\" )    { $seq_id = \"chr10\"; }\n            when ( $_ eq \"XI\" )   { $seq_id = \"chr11\"; }\n            when ( $_ eq \"XII\" )  { $seq_id = \"chr12\"; }\n            when ( $_ eq \"XIII\" ) { $seq_id = \"chr13\"; }\n            when ( $_ eq \"XIV\" )  { $seq_id = \"chr14\"; }\n            when ( $_ eq \"XV\" )   { $seq_id = \"chr15\"; }\n            when ( $_ eq \"XVI\" )  { $seq_id = \"chr16\"; }\n            default { }\n        }\n\n        # output\n        print \"$seq_id\\t$start\\t$end\\t$sites[0]\\t0.0\\t$strand\\n\";\n    }\n    $gffio->close();\n\nTo use it:\n\n    gff2bed.pl < data.gff > data.bed", "date": "2010-01-15 08:48:14", "action": 0, "post": 30}}, {"pk": 45, "model": "server.postrevision", "fields": {"author": 3, "tag_string": "solid rna galaxy", "title": "How do I map, align, and plot my SOLiD results?", "content": "Hi, I recently performed an RNA immunoprecipitation followed by SOLiD sequencing (50 bp fragmented reads). I haven't received my first SOLiD sequencing results yet, but I was told I should have them soon. I've tried doing my own research on how to map, align, and plot my results but I don't have a concrete workflow as to how I will analyze my results yet. I have very little experience doing any programming and would prefer to use galaxy. There are labs on my campus I can go to to get my color space data mapped, but I would like to do things myself. Is there a way on galaxy (or another program) to convert my color space data to sequence, then map those reads to the yeast transcriptome and analyze it? Even if you can't answer my question directly I'd appreciate any tips from anyone who has worked with RNA-seq data already.    \n\nThanks in advance ", "date": "2010-01-22 03:14:17", "action": 0, "post": 31}}, {"pk": 46, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How do I map, align, and plot my SOLiD results?", "content": "Personally I would advise that if you know someone who can partially perform the task you should have them do it, and ask them to explain and show it to you how they've done it.\n\nThe task at hand is complex. The solution always depends immensely on the particulars of the problem, moreover you will be facing myriads of frustrating limitations, errors and problems.\n\nLearning directly from someone who has done it, establishing a personal rapport with them will allow you to ease into this problem domain. In fact when you are finished mapping your RNA - your are still likely to be far from being done - yet you might have expanded a lot of energy and excitement. \n\n\n", "date": "2010-01-22 15:13:42", "action": 0, "post": 32}}, {"pk": 47, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "general", "title": "Which operating system do you prefer for bioinformatics?", "content": "So, you will probably hate me for asking this question here, as there are lot of forum and blog posts on internet about it and it is also a very subjective question.\n\nHowever, it may be a starting point for a good discussion, if we don't flame... Which operating system do you usually use for your work? Did you install it by yourself, and do you have administrative rights on it, or is there any IT administrator in your lab? ", "date": "2010-01-26 15:14:38", "action": 0, "post": 33}}, {"pk": 48, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective", "title": "Which programming languages are good to study for bioinformatics?", "content": "This is also a very classic question, however, it can be a very useful discussion for novices which are wishing to work in the bioinformatics field, and have to decide how to organize their time.\nI have seen some surveys on this, for example on bioinformatics.org and on bioinformaticszen, but none of these cases were open discussions.\n\n\nWhich is your favorite programming language in bioinformatics? I actually use very much of Python and R, and hate Perl :-)\n\n\n\n\n\n", "date": "2010-01-26 15:45:06", "action": 0, "post": 34}}, {"pk": 49, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Which operating system do you prefer for bioinformatics?", "content": "Often people are limited to their choices by factors outside of their control. One lab that I work with requires the use of Mac computers another is using Windows mostly. Large scale computations seem to be best suited for Linux systems.\n\nLuckily there is a migration towards unified capabilities across all platforms. Installing Cygwin on Windows allows us to tap into the power of Unix, while Linux distros have advanced graphical user interfaces like Windows and Macs.\n\nFrom my own observations of non technical people, the installation of new and interdependent software packages seems to be the most difficult on Mac computers and easiest on Windows due to the computational architecture that makes all Windows computers identical. \n", "date": "2010-01-26 20:23:45", "action": 0, "post": 35}}, {"pk": 50, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "It is important to be considerate and not characterize one particular approach negatively. My favorite quote is:\n\n**Programming is pure thought.**\n\nHopefully everyone is able to pick an approach that matches their individual way of thinking. While I myself do not program in Perl, I consider it to be one of the most popular and powerful platforms for doing bioinformatics analysis. ", "date": "2010-01-26 20:32:29", "action": 0, "post": 36}}, {"pk": 51, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Which operating system do you prefer for bioinformatics?", "content": "Tips for installing software om Max OS X:\n\n - install the Apple developer tools called **Xcode** [http://developer.apple.com/tools/xcode/][1]\n - install **MacPorts** from [http://www.macports.org/][2]\n\nYou can now easily install everything from command line using the `port` command. List all available software\n\n    port list\n\nInstall libraries and software. etc:\n\n    port install <some-library>\n\n  [1]: http://developer.apple.com/tools/xcode/\n  [2]: http://www.macports.org/", "date": "2010-01-26 20:38:24", "action": 0, "post": 37}}, {"pk": 52, "model": "server.postrevision", "fields": {"author": 24, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "Any programming language is good as long you know what you're doing.", "date": "2010-01-26 23:42:14", "action": 0, "post": 38}}, {"pk": 53, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Gene ID conversion tool", "content": "You can also do it with the following services:\n\n - [uniprot][1] - Click on 'Id Mapping' from the home page.\n - [biomart][2] - choose a database and a version, then put the ids you want to convert under Filters->Id List limit (select the proper input id in the menu), and then the output ids under 'Attributes'. Biomart is a general tool that enables you to extract a lot of different informations from databases - sequences, ontologies, transcripts, homologues - but maybe for converting gene ids is a bit too complex.\n - [galaxy][3] - I can't help too much about this here but I am sure it has a function for doing that - and many other things.\n\n\n  [1]: http://www.uniprot.org/?tab=mapping\n  [2]: http://www.biomart.org/biomart/martview/\n  [3]: http://main.g2.bx.psu.edu/", "date": "2010-01-27 10:08:52", "action": 0, "post": 39}}, {"pk": 54, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Finding common motifs in sequences", "content": "Meme has been the first program to be published for doing that.\nAs an alternative you can find one of the [EMBOSS tools][1]; if you are scared by a terminal and want to do it from a web-based interface, you can use the EMBOSS tools from [galaxy][2]\n\n\n  [1]: http://www.be.embnet.org/embosshelp/\n  [2]: http://main.g2.bx.psu.edu/", "date": "2010-01-28 15:31:50", "action": 0, "post": 40}}, {"pk": 55, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective geneontology go", "title": "how much do you trust GeneOntology?", "content": "[GeneOntology][1] is a nice project to provide a standard terminology for genes and gene functions, to help avoid the use of synonyms and wrong spelling when describing a gene.\n\nI have been using the GeneOntology for a while, but honestly I think that it contains many errors and that many terms have not enough terms associated. Moreover, the terminology they use is not always clear and there are some duplications.\n\nIt is frequent to read in article or in slideshows charts were the GO classification is used to infer the properties of a set of genes... But I wonder if the authors check the GO annotations that they use.\n\nWhat is your experience about [GO][2]?\n\n\n  [1]: http://www.geneontology.org/\n  [2]: http://www.geneontology.org/", "date": "2010-01-28 16:17:37", "action": 0, "post": 41}}, {"pk": 56, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Site use guidelines", "content": "The StackExchange websites have been designed for making questions related to programming and technical issues.\n\nFor example, for this reason, if you try to write a question which starts with 'What is your favorite experience...' you get a disclaimer saying that 'your question seems to be probably subjective and it is likely to be closed'.\n\nHowever, I think that it is very useful to make subjective and opinion-based questions on bioinformatics, as there are few places to do so... So, what is your policy? Will you accept subjective questions?", "date": "2010-01-28 16:22:04", "action": 0, "post": 42}}, {"pk": 57, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "The choice of a programming language is purely subjective, but when a student asks you which programming language he should start with, you have to make an answer, or at least provide some informations.\n\nI think that a bioinformatician who studies **R** and at least two or three libraries (lattice/ggplot2, plyr) early can have an advantage, because he will be able to represent his data properly and obtain good results without too much effort. If your supervisor is not a computer scientist, he will be a lot more impressed by plots and charts than by programs, even if they are well written, with unittests etc.\n\n**Python** is a good programming language to learn as a general purpose tool. Its bigger advantages are its easy to read syntax, and its paradigm 'there is only one way to do it', so the number of language keywords is reduced to the minimum, and two programs with the same function written by different people will be very similar (which is what doesn't happen with perl). \nThe negative points of python are that its CSV files reading/plotting interface is not ready yet (the best is pylab), so you must rely on R to produce nice plots.\n\nHonestly I don't like **perl**, because I think it can induce to many bad-behaviours in novel programmers. For example, in perl there are many similar constructs to accomplish the same objective: so, it is very difficult to understand a program written by someone else, because you have to known all the possible constructs and hope there are enough comments. It is already very difficult to reproduce a bioinformatician experiment, if you write your code in a difficult language it is a lot worst. \nMoreover, I know of many people who have been using perl for years, but that don't even use functions, because it looks too complicated. How can it be? It looks very inefficient. \nThe only good point of perl is its repositories, bioperl and CPAN; however, I know of people using perl that don't even know of the existence of these, so I don't understand why they keep going with perl.\n\n\nApart from programming language, is it very useful to learn the basic usage of **gnu-make**, or of a derivate. This program is very useful when you have lot of different scripts, as it allows you to define a pipeline in order to run them. \nSome basic **bash commands** may also be very useful if you work with a lot of flat files (head, sed, gawk, grep, ...)", "date": "2010-01-28 17:58:20", "action": 0, "post": 43}}, {"pk": 58, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How much do you trust GeneOntology annotations?", "content": "The GO terms and classifications are primarily an based on opinions and a human interpretation of a small group of people of what the current state of the knowledge is.Thus  are more subjective than say experimental measurements would be. \n\nIn fact it is surprising that it works at all; and it does indeed.  We just need to becareful not too read to much into it.", "date": "2010-01-28 22:41:29", "action": 0, "post": 44}}, {"pk": 59, "model": "server.postrevision", "fields": {"author": 3, "tag_string": "", "title": "A: How much do you trust GeneOntology annotations?", "content": "In my experience it's case by case. In other words just because you are getting significant p-values, does not mean the results are biologically significant. I once submitted clusters of microarray data and received a bunch of hits that were significant by p-value, but really didn't have a theme. The GO terms I saw were from many different processes without an overall term (besides biological process) which linked them together. When I've looked at published GO terms searches I generally see a strong theme among many of the terms (however that doesn't necessarily mean it has biological significance until tested empirically). So seeing themes among your terms may suggest higher significance, but it should make biological sense too. \n\n", "date": "2010-01-29 05:50:26", "action": 0, "post": 45}}, {"pk": 60, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective string protein interacti", "title": "What is your experience with the STRING (interactions) database?", "content": "STRING is a database of predicted protein-protein interactions at EMBL. It cluster the results from many sources of protein-protein interactions databases, like Mint, etc.., and it also use the informations from KEGG-pathways and reactome, to provide the best annotations for the interactions of a protein.\n\nI am a bit confused from the results that I see there, because when I look at the genes in the pathway I am studying, I see many errors and annotations that I don't understand.\n\nWhat is your experience with STRING? If you want to do me a favor, go there and try to see the interactions annotated for a gene that you know already. Do you see anything weird?", "date": "2010-01-29 11:42:23", "action": 0, "post": 46}}, {"pk": 61, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: What is your experience with the STRING (interactions) database?", "content": "I have not used STRING in particular but I have worked with protein interactions before (DIP dataset). I recall that even experimentally produced protein-protein interactions may have very large false positive ratios  (as for false negatives, who knows?) Some papers claim that up to 50% of the interactions were spurious; and repeated experiments showed very small overlaps. Predictions may be even less reliable.\n\n\nAt the same time the DIP dataset performed substantially better if we only considered the interactions for which there were multiple sources of evidence, so that may be a strategy to consider in your case as well.\n", "date": "2010-01-29 14:06:06", "action": 0, "post": 47}}, {"pk": 62, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "subjective geneontology go", "title": "How much do you trust GeneOntology?", "content": "[GeneOntology][1] is a nice project to provide a standard terminology for genes and gene functions, to help avoid the use of synonyms and wrong spelling when describing a gene.\n\nI have been using the GeneOntology for a while, but honestly I think that it contains many errors and that many terms have not enough terms associated. Moreover, the terminology they use is not always clear and there are some duplications.\n\nIt is frequent to read in article or in slideshows charts were the GO classification is used to infer the properties of a set of genes... But I wonder if the authors check the GO annotations that they use.\n\nWhat is your experience about [GO][2]?\n\n\n  [1]: http://www.geneontology.org/\n  [2]: http://www.geneontology.org/", "date": "2010-01-29 14:08:07", "action": 0, "post": 41}}, {"pk": 63, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "sequence", "title": "Where can I get the secondary structure of a protein?", "content": "As in the title... I have a protein and I would like to know its secundary structure.\nI couldn't find it in uniprot, althought I tought they had annotations for it there.\nIn the end I have used a predictor ([jpred][1]) but there it should be a database somewhere.\n\nnote: I am tagging this question as 'sequence' because as a novice I am not allowed to create new tags (I tought I already created some before, you must have changed some option)\n\n  [1]: http://www.compbio.dundee.ac.uk/www-jpred", "date": "2010-02-12 17:33:06", "action": 0, "post": 48}}, {"pk": 64, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Where can I get the secondary structure of a protein?", "content": "Protein structure prediction is a complex issue that is likely to require multiple approaches. There are many methods/tools listed at the \n\n - [Expert Protein Analysis System website][1]\n\n\n  [1]: http://www.expasy.ch/", "date": "2010-02-12 20:01:49", "action": 0, "post": 49}}, {"pk": 65, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: Where can I get the secondary structure of a protein?", "content": "I think you found the best answer yourself: use a predictor! There are several out there...\n\nYou suggest that there should be a Secondary Structure Database. I'm not sure that makes much sense, let me explain my point of view (which may not be that of everyone): most often, the data that is found in databases is the \"state of knowledge\" of the described object, based on experimentation.\n\nThat may be the case for secondary structures of proteins, but only in the case where the said proteins have been crystalized. In those cases, it is not only the secondary structures but also the tertiary structures (with the caveat that the crystal structure of a protein does not prove \"all\" states that a protein may take in real \"dynamic\" physiological conditions).\n\nFor all those proteins that have not been crystalized, then we can only rely on predictions. And I use them quite frequently: they are extremely useful! But as far as I know, no prediction is accepted as fact. They're \"educated guesses\" that are often correct, but sometimes wrong. The results may differ from one prediction method to another. Also they change each time the algorithms are improved...\n\nIf there was a database of predicted secondary structures, people would likely take them for granted (make the equation prediction = fact) which would be quite \"unscientific\".\n\nI think such a resource would be more of a hindrance than an asset to the scientific community...", "date": "2010-02-12 21:57:06", "action": 0, "post": 50}}, {"pk": 66, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "sequence protein structure", "title": "Where can I get the secondary structure of a protein?", "content": "As in the title... I have a protein and I would like to know its secundary structure.\nI couldn't find it in uniprot, althought I tought they had annotations for it there.\nIn the end I have used a predictor ([jpred][1]) but there it should be a database somewhere.\n\nnote: I am tagging this question as 'sequence' because as a novice I am not allowed to create new tags (I tought I already created some before, you must have changed some option)\n\n  [1]: http://www.compbio.dundee.ac.uk/www-jpred", "date": "2010-02-13 18:08:36", "action": 0, "post": 48}}, {"pk": 67, "model": "server.postrevision", "fields": {"author": 13, "tag_string": "sequence", "title": "Turn off BLAST search on reverse complement strand in blastn", "content": "I have a quick question:\nHow can I turn off search on reverse complement strand of my query nucleotide sequence in blastn?\n\nFor example, I don't want 'GUAAAGCCAAAUCUUCGGUUA' to be a hit when I use 'UAACCGAAGAUUUGGCUUUAC' as the query.\n\nMaybe I missed it when I read the man page, but I really appreciate it if someone can point out the parameter I should use.\n\nThanks!", "date": "2010-02-16 01:13:06", "action": 0, "post": 51}}, {"pk": 68, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Turn off BLAST search on reverse complement strand in blastn", "content": "The -S flag can select the strands:\n\n    -S  Query strands to search against database \n        (for blast[nx], and tblastx) 3 is both, 1 is top, 2 is bottom [Integer]", "date": "2010-02-16 02:31:37", "action": 0, "post": 52}}, {"pk": 69, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "sequence blast", "title": "Turn off BLAST search on reverse complement strand in blastn", "content": "I have a quick question:\nHow can I turn off search on reverse complement strand of my query nucleotide sequence in blastn?\n\nFor example, I don't want 'GUAAAGCCAAAUCUUCGGUUA' to be a hit when I use 'UAACCGAAGAUUUGGCUUUAC' as the query.\n\nMaybe I missed it when I read the man page, but I really appreciate it if someone can point out the parameter I should use.\n\nThanks!", "date": "2010-02-16 19:20:31", "action": 0, "post": 51}}, {"pk": 70, "model": "server.postrevision", "fields": {"author": 26, "tag_string": "solid", "title": "How to do quality trimming of SoLid Reads in colour space?", "content": "The reads returned from the Solid sequencing provider are littered with dots and some bases have a negative quality value. Does anyone know if there is a good method to extract high quality regions from the reads without distorting the reading of bases in colour space?", "date": "2010-02-19 07:29:18", "action": 0, "post": 53}}, {"pk": 71, "model": "server.postrevision", "fields": {"author": 26, "tag_string": "", "title": "A: How do I map, align, and plot my SOLiD results?", "content": "You can try BWA as well:\nhttp://maq.sourceforge.net/bwa-man.shtml", "date": "2010-02-19 07:31:24", "action": 0, "post": 54}}, {"pk": 72, "model": "server.postrevision", "fields": {"author": 27, "tag_string": "", "title": "A: How to do quality trimming of SoLid Reads in colour space?", "content": "The [Solid Accuracy Enhancer Tool][1] might be useful for this.\n\n\n  [1]: http://solidsoftwaretools.com/gf/project/saet/", "date": "2010-02-19 13:33:45", "action": 0, "post": 55}}, {"pk": 73, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "sequence", "title": "how to get the sequence of a genomic region from UCSC?", "content": "Let's say I want to download the fasta sequence of the region chr1:100000..200000 from the UCSC browser.\nHow do you do that? I can't find a button to 'export to fasta' in the UCSC genome browser. I think that the solution is to click on one of the tracks displayed, but I am not sure of which.\nIf I go to the Tables section, I can't find a table with the fasta sequences among the many.", "date": "2010-02-21 16:13:39", "action": 0, "post": 56}}, {"pk": 74, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How to get the sequence of a genomic region from UCSC?", "content": "The Genome Browser is for visualization.\n\nTo get data in many formats use the [UCSC Table Browser][1] then select the output format of your choice.\n\nYou may also need to select the right **group** and **track** to get the data you want.\n\n  [1]: http://genome.ucsc.edu/cgi-bin/hgTables?org=human", "date": "2010-02-21 19:11:20", "action": 0, "post": 57}}, {"pk": 75, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "sequence ucsc fasta", "title": "How to get the sequence of a genomic region from UCSC?", "content": "Let's say I want to download the fasta sequence of the region chr1:100000..200000 from the UCSC browser.\nHow do you do that? I can't find a button to 'export to fasta' in the UCSC genome browser. I think that the solution is to click on one of the tracks displayed, but I am not sure of which.\nIf I go to the Tables section, I can't find a table with the fasta sequences among the many.", "date": "2010-02-22 15:40:46", "action": 0, "post": 56}}, {"pk": 76, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "general subjective", "title": "What is the best way to share scripts between members of a lab?", "content": " One of the most awful problems in my group is avoiding to rewrite scripts that have been already written by others. Since we have different projects and we work with different data, everybody ends up writing its own scripts in his favorite programming language, and it is very frequent to waste an afternoon on writing a new program and then discover that your workmate already had a script to do that.\n\nApart from the most logical answer (\"talk with your workmates\"), we are thinking about having a common place to store our best scripts, and if possible work together on them.\nIt would be similar to an image library like this: http://matplotlib.sourceforge.net/gallery.html , where to put the script and an example of its output (most of our scripts produce graphs), and if possible integrated with Git. \n\nDo you have any idea? How to you cope with the problem in your lab?", "date": "2010-02-25 15:39:15", "action": 0, "post": 58}}, {"pk": 77, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How to get the sequence of a genomic region from UCSC?", "content": "Use the **DAS** server:\n\n[http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=chr1:100000,200000][1]\n\n\n  [1]: http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=chr1:100000,200000", "date": "2010-02-25 17:32:53", "action": 0, "post": 59}}, {"pk": 78, "model": "server.postrevision", "fields": {"author": 30, "tag_string": "", "title": "A: Finding common motifs in sequences", "content": "Some time ago I used SOMBRERO ([http://bioinf.nuigalway.ie/sombrero/download.html][1]) with a good degree of success on finding motifs in a very diverse set of sequences. They have a Mac version for download as well as parallel versions for Irix and Linux.\n\n\n  [1]: http://bioinf.nuigalway.ie/sombrero/download.html", "date": "2010-02-25 17:51:28", "action": 0, "post": 60}}, {"pk": 79, "model": "server.postrevision", "fields": {"author": 30, "tag_string": "", "title": "A: What is the best way to share scripts between members of a lab?", "content": "I would recommend you to setup a wiki for your group. If you do not have a server readily you can always use one of the many wiki services available for free like Wikispaces (www.wikispaces.com).", "date": "2010-02-25 17:54:49", "action": 0, "post": 61}}, {"pk": 80, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: What is the best way to share scripts between members of a lab?", "content": "Integrating with the source code management tool is essential, that way when code gets changed everyone can easily get the updated version. Wikis are also a good idea.", "date": "2010-02-25 18:24:46", "action": 0, "post": 62}}, {"pk": 81, "model": "server.postrevision", "fields": {"author": 34, "tag_string": "", "title": "A: What is your experience with the STRING (interactions) database?", "content": "I've been using STRING extensively, but not for protein-protein interactions work. STRING, as you note, is a bit of a mutt in terms of the different data sources it mines. Some that you're missing include a broad literature-based search, as well as gene expression data sets. So if you're interested primarily in physical interactions or any other single type of data source, STRING is a poor choice for your work. On the other hand, STRING does provide confidence scores for each association, as well as annotation for their data source types (with the license). So you can use those to filter out the interactions derived from data types you don't want to see.", "date": "2010-02-25 21:33:37", "action": 0, "post": 63}}, {"pk": 82, "model": "server.postrevision", "fields": {"author": 34, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "Perl can be quite lovely if you choose to write it well. If you find yourself in need of writing some perl, I'd highly recommend getting the Perl Best Practices book and going through it to learn how to make your perl code not suck. Essential tools for helping with that are perlcritic and perltidy, both of which I have bound to quick keystrokes in my emacs cperl-mode so as to make sure my code is in reasonably good shape. There's lots of blog articles out there about writing \"Modern Perl\" or \"Enlightened Perl\" that help make the language not just bearable but actually quite nice for a certain type of brain.\n\nOne thing that Perl does very well that no other language does is quick text processing on the command line. If you want to do some simple processing of a text file (which is pretty standard in this business), perl is a fantastic package to do so. Stringing together a set of UNIX utilities on a Linux system will usually have you running for a half dozen manpages looking for conflicting and unique switches, where with perl I find that there's far less I have to remember to get the same effect. The book Minimal Perl goes in to this sort of thing in detail (perl as a better awk/sed/grep/etc) and I highly recommend having a look. At the very least, I've found that using perl in this fashion filled a hole in my toolkit that I didn't even realize was there. R and Python can, of course, do this sort of thing too, but not nearly so well as Perl.", "date": "2010-02-25 21:41:22", "action": 0, "post": 64}}, {"pk": 83, "model": "server.postrevision", "fields": {"author": 32, "tag_string": "", "title": "A: Which operating system do you prefer for bioinformatics?", "content": "My tip: install Cygwin if you are using Windows ", "date": "2010-02-25 21:50:25", "action": 0, "post": 65}}, {"pk": 84, "model": "server.postrevision", "fields": {"author": 32, "tag_string": "", "title": "A: Site use guidelines", "content": "Who is running this site?", "date": "2010-02-25 21:52:10", "action": 0, "post": 66}}, {"pk": 85, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: Which operating system do you prefer for bioinformatics?", "content": "All of the 3 major platforms have their advantages, and I use all 3 practically every day. Mac OS X is my primary desktop OS, for a number of reasons, but mostly because I just seem more productive using it than any of the alternatives. All of my coding work is done over SSH on Linux (almost exclusively Ubuntu) servers. The power of Aptitude package management, and the robustness of this platform means that there really is no other choice for this kind of work. Finally I run Windows 7 on my netbook, because it is an excellent OS for that platform, and enables me to do everything I want that machine to be capable of, note-taking, blog writing, as a display machine for Powerpoint etc.\n\nI wouldn't consider using any machine that I didn't have admin rights on for work purposes, if I have to jump through hoops to get stuff installed, it just slows me down too much. This is another reason for using OS X for my primary desktop, it allows me to escape the University's \"Common Desktop\" policy for Windows PCs, which would take control of my computer out of my hands.", "date": "2010-02-26 09:51:33", "action": 0, "post": 67}}, {"pk": 86, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: Which operating system do you prefer for bioinformatics?", "content": "All of the 3 major platforms have their advantages, and I use all 3 practically every day. Mac OS X is my primary desktop OS, for a number of reasons, but mostly because I just seem more productive using it than any of the alternatives. All of my coding work is done over SSH on Linux (almost exclusively Ubuntu) servers. The power of Aptitude package management, and the robustness of this platform means that there really is no other choice for this kind of work. Finally I run Windows 7 on my netbook, because it is an excellent OS for that platform, and enables me to do everything I want that machine to be capable of, note-taking, blog writing, as a display machine for Powerpoint etc. It is also useful to have Internet Explorer kicking around somewhere for compatability testing.\n\nI wouldn't consider using any machine that I didn't have admin rights on for work purposes, if I have to jump through hoops to get stuff installed, it just slows me down too much. This is another reason for using OS X for my primary desktop, it allows me to escape the University's \"Common Desktop\" policy for Windows PCs, which would take control of my computer out of my hands.", "date": "2010-02-26 09:56:37", "action": 0, "post": 67}}, {"pk": 87, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: What is the best way to share scripts between members of a lab?", "content": "If you want to see the code, but also store associated information, such as expected outputs etc, then a wiki probably is the best choice (we prefer [DokuWiki][1] here), although this would involve a lot of manual effort to document each script. \n\nUse of a site such as GitHub would give you version control + a handy place to read code, although it is not free to host private repositories there, which I guess is what the majority of labs would require. \n\nIf privacy is not a concern, then I would consider GitHub [gists][2] for code, which can then be embedded in a [Posterous][3] blog for comments. Posterous automatically unfolds Gist URLs into code samples in blog posts, so then you can annotate them easily. This would be a lot less manual effort than a wiki.\n\n\n  [1]: http://www.dokuwiki.org/dokuwiki\n  [2]: http://gist.github.com/\n  [3]: http://posterous.com/", "date": "2010-02-26 10:07:14", "action": 0, "post": 68}}, {"pk": 88, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "general", "title": "Using HDF5 to store  bio-data", "content": "Hi all,\nhas anobody ever used the [HDF5 API][1] to store some biological data (genotypes...). I know about this [kind of reference][2] (BioHDF...)  but I'm looking for some **source code** I could browse to understand how I can access data faster.\n\nPierre\n\n\nPS: hum, I'm a new user. I'm not allowed to add the following tags: storage database hdf5 source code \n\n  [1]: http://www.hdfgroup.org/HDF5/\n  [2]: http://www.geospiza.com/finchtalk/2008/03/genotyping-with-hdf.html", "date": "2010-02-26 12:50:17", "action": 0, "post": 69}}, {"pk": 89, "model": "server.postrevision", "fields": {"author": 39, "tag_string": "", "title": "A: What is the best way to share scripts between members of a lab?", "content": "You might also want to setup a simple snippets database. Navysnip application by Jason Strutz is easy to install and run if you have ruby and rubyonrails installed.\n\ngit clone git://github.com/navyrain/navysnip.git\n  cd navysnip\n  sudo rake gems:install\n  rake db:migrate\n  ruby script/server\nThen visit your app at http://localhost:3000\n\ncheck out http://github.com/navyrain/navysnip  for complete details", "date": "2010-02-26 13:15:16", "action": 0, "post": 70}}, {"pk": 90, "model": "server.postrevision", "fields": {"author": 41, "tag_string": "", "title": "A: Using HDF5 to store  bio-data", "content": "Hello Pierre!\n\nI have been talking with the BioHDF guys and from what they tell me, their work will be centered around a number of command-line APIs, written in C, that will address some areas of usage which for now do not seem to overlap. \n\nI have seen this example on their site:\nhttp://www.hdfgroup.org/projects/biohdf/biohdf_tools.html\nDon't know if that helps.\n\nI have been talking with them to see if we can achieve an API for saving genotype data. Don't know yet where that will lead me.\n\nIf you are looking for something more versatile, you will probably have to delve in the official HDF5 C code ( http://www.hdfgroup.org/HDF5/Tutor/ ), which seems to be the only one that offers all the functionality and goodies of that impressive storage system. ", "date": "2010-02-26 13:47:41", "action": 0, "post": 71}}, {"pk": 91, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "hdf biohdf", "title": "Using HDF5 to store  bio-data", "content": "Hi all,\nhas anobody ever used the [HDF5 API][1] to store some biological data (genotypes...). I know about this [kind of reference][2] (BioHDF...)  but I'm looking for some **source code** I could browse to understand how I can access data faster.\n\nPierre\n\n\nPS: hum, I'm a new user. I'm not allowed to add the following tags: storage database hdf5 source code \n\n  [1]: http://www.hdfgroup.org/HDF5/\n  [2]: http://www.geospiza.com/finchtalk/2008/03/genotyping-with-hdf.html", "date": "2010-02-26 13:48:47", "action": 0, "post": 69}}, {"pk": 92, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Using HDF5 to store  bio-data", "content": "Unfortunately I don't have any example to shows you yet.\nI don't know how to program in C/C++ so I have been looking at two hdf5 wrappers in python, [PyTables][1] and [H5PY][2].\n\nPyTables has a database-like approach in which HDF5 is used as a sort of hierarchical database, in which a column can be a table itself, allowing to store nested data. For example, you have a table called 'SNPs' with two columns, 'id' and 'genotypes'; the column 'genotypes' contains a nested table, with the columns 'individual' and 'genotype'; and so on.\n\nH5Py is basically a re-implementation of numpy's arrays, so you can store and access arrays/matrixes as you would do with numpy (it is similar to arrays and matrixes in matlab, R, and any other language with this data type) and they are stored in an HDF5 file so the access is faster.\n\n\n  [1]: http://www.pytables.org/moin\n  [2]: http://h5py.alfven.org/", "date": "2010-02-26 13:54:03", "action": 0, "post": 72}}, {"pk": 93, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Using HDF5 to store  bio-data", "content": "In the [GeneTrack][1] software we have used HDF to store values for each genomic base. Its main advantage over other storage systems was that it was able to return consecutive values with minimal overhead. \n\nFor example it is extremely fast to retrieve say 100 thousand consecutive values starting with a certain index.We used the [Python bindings][2] to HDF. An added advantage of these bindings is that they will return the data back as numpy arrays (very fast numerical operations). \n\nHere is the relevant code that deals with HDF only: [hdf.py][3]\n\nThe HDF schema is set up in a different module, but in the end it simply something like:\n\n    class MySchema( IsDescription ):\n        \"\"\"\n        Stores a triplet of float values for each index.\n        \"\"\"\n        ix = IntCol  ( pos=1 )  # index\n        wx = FloatCol( pos=2 )  # values on the W (forward) strand\n        cx = FloatCol( pos=3 )  # value on the C (reverse) strand\n        ax = FloatCol( pos=4 )  # weighted value on the combined W + C strands\n\n\n  [1]: http://code.google.com/p/genetrack/\n  [2]: http://www.pytables.org/moin\n  [3]: http://code.google.com/p/genetrack/source/browse/trunk/atlas/hdf.py", "date": "2010-02-26 13:56:22", "action": 0, "post": 73}}, {"pk": 94, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Using HDF5 to store  bio-data", "content": "In the [GeneTrack][1] software we have used HDF to store values for each genomic base. Its main advantage over other storage systems was that it was able to return consecutive values with minimal overhead. \n\nFor example it is *extremely fast* (ms) in retrieving say 100,000 consecutive values starting with a certain index.We used the [Python bindings][2] to HDF. An added advantage of these bindings is that they will return the data back as numpy arrays (very fast numerical operations). \n\nHere is the relevant code that deals with HDF only: [hdf.py][3]\n\nThe HDF schema is set up in a different module, but in the end it simply something like:\n\n    class MySchema( IsDescription ):\n        \"\"\"\n        Stores a triplet of float values for each index.\n        \"\"\"\n        ix = IntCol  ( pos=1 )  # index\n        wx = FloatCol( pos=2 )  # values on the W (forward) strand\n        cx = FloatCol( pos=3 )  # value on the C (reverse) strand\n        ax = FloatCol( pos=4 )  # weighted value on the combined W + C strands\n\n\n  [1]: http://code.google.com/p/genetrack/\n  [2]: http://www.pytables.org/moin\n  [3]: http://code.google.com/p/genetrack/source/browse/trunk/atlas/hdf.py", "date": "2010-02-26 14:01:39", "action": 0, "post": 73}}, {"pk": 95, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "guidelines", "title": "Site use guidelines", "content": "Here are a few guidelines:\n\n 1. The site's goal is to answer bioinformatics and systems biology related questions\n 2. Answer questions to gain *reputation*. \n 3. Don't forget to vote for answers that you like! Registered users may vote on answers.\n 4. If you are the one asking the original question you may also select the best answer\n 5. Subscribe to the RSS feeds for all questions or a single question to keep up to date with the developments", "date": "2010-02-26 14:10:59", "action": 0, "post": 1}}, {"pk": 96, "model": "server.postrevision", "fields": {"author": 41, "tag_string": "", "title": "A: Using HDF5 to store  bio-data", "content": "What I do have is a netCDF-3 based Java application that I could show you.\nNetCDF-3 is basically the same idea as HDF, but quite more limited as it cannot do compound datatypes among other limitations.\n\nBut here's a small test code example to toy with:\n\npackage netCDF;\n\n\nimport java.io.File;\nimport ucar.ma2.*;\nimport ucar.nc2.*;\nimport java.io.IOException;\nimport java.util.ArrayList;\n\n/**\n *\n * @author Fernando Mu\u00f1iz Fernandez\n * IBE, Institute of Evolutionary Biology (UPF-CSIC)\n * CEXS-UPF-PRBB\n * \n * THIS TO CREATE THE netCDF-3 GENOTYPE FILE\n */\npublic class CreateNetcdf {\n\n     public static NetcdfFileWriteable setDimsAndAttributes(Integer studyId, \n                                          String technology, \n                                          String description, \n                                          String strand, \n                                          int sampleSetSize,\n                                          int markerSetSize) throws InvalidRangeException, IOException {\n\n        ///////////// CREATE netCDF-3 FILE ////////////\n        String genotypesFolder = \"/media/data/genotypes\";\n        File pathToStudy = new File(genotypesFolder+\"/netCDF_test\");\n        int gtSpan = constants.cNetCDF.Strides.STRIDE_GT;\n        int markerSpan = constants.cNetCDF.Strides.STRIDE_MARKER_NAME;\n        int sampleSpan = constants.cNetCDF.Strides.STRIDE_SAMPLE_NAME;\n        \n        String matrixName = \"prototype\";\n        String writeFileName = pathToStudy+\"/\"+matrixName+\".nc\";\n        NetcdfFileWriteable ncfile = NetcdfFileWriteable.createNew(writeFileName, false);\n\n        // add dimensions\n        Dimension samplesDim = ncfile.addDimension(\"samples\", sampleSetSize);\n        Dimension markersDim = ncfile.addDimension(\"markers\", markerSetSize);\n        Dimension gtSpanDim = ncfile.addDimension(\"span\", gtSpan);\n        ArrayList dims = new ArrayList();\n        dims.add(samplesDim);\n        dims.add(markersDim);\n        dims.add(gtSpanDim);\n\n        ArrayList markerGenotypeDims = new ArrayList();\n        markerGenotypeDims.add(markersDim);\n        markerGenotypeDims.add(markerSpan);\n\n        ArrayList markerPositionDim = new ArrayList();\n        markerPositionDim.add(markersDim);\n\n        ArrayList markerPropertyDim32 = new ArrayList();\n        markerPropertyDim32.add(markersDim);\n        markerPropertyDim32.add(32);\n\n        ArrayList markerPropertyDim16 = new ArrayList();\n        markerPropertyDim16.add(markersDim);\n        markerPropertyDim16.add(16);\n\n        ArrayList markerPropertyDim8 = new ArrayList();\n        markerPropertyDim8.add(markersDim);\n        markerPropertyDim8.add(8);\n\n        ArrayList markerPropertyDim2 = new ArrayList();\n        markerPropertyDim2.add(markersDim);\n        markerPropertyDim2.add(2);\n\n        ArrayList markerPropertyDim1 = new ArrayList();\n        markerPropertyDim1.add(markersDim);\n        markerPropertyDim1.add(1);\n\n        ArrayList sampleSetDims = new ArrayList();\n        sampleSetDims.add(samplesDim);\n        sampleSetDims.add(sampleSpan);\n\n        // Define Marker Variables\n        ncfile.addVariable(\"markerset\", DataType.CHAR, markerGenotypeDims);\n        ncfile.addVariableAttribute(\"markerset\", constants.cNetCDF.Attributes.LENGTH, markerSetSize);\n\n        ncfile.addVariable(\"marker_chromosome\", DataType.CHAR, markerPropertyDim8);\n        ncfile.addVariable(\"marker_position\", DataType.CHAR, markerPropertyDim32);\n        ncfile.addVariable(\"marker_position_int\", DataType.INT, markerPositionDim);\n        ncfile.addVariable(\"marker_strand\", DataType.CHAR, markerPropertyDim8);\n\n        ncfile.addVariable(\"marker_property_1\", DataType.CHAR, markerPropertyDim1);\n        ncfile.addVariable(\"marker_property_2\", DataType.CHAR, markerPropertyDim2);\n        ncfile.addVariable(\"marker_property_8\", DataType.CHAR, markerPropertyDim8);\n        ncfile.addVariable(\"marker_property_16\", DataType.CHAR, markerPropertyDim16);\n        ncfile.addVariable(\"marker_property_32\", DataType.CHAR, markerPropertyDim32);\n\n        // Define Sample Variables\n        ncfile.addVariable(\"sampleset\", DataType.CHAR, sampleSetDims);\n        ncfile.addVariableAttribute(\"sampleset\", constants.cNetCDF.Attributes.LENGTH, sampleSetSize);\n\n        // Define Genotype Variables\n        ncfile.addVariable(\"genotypes\", DataType.CHAR, dims);\n        ncfile.addVariableAttribute(\"genotypes\", constants.cNetCDF.Attributes.GLOB_STRAND, \"+/-\");\n\n        // add global attributes\n        ncfile.addGlobalAttribute(constants.cNetCDF.Attributes.GLOB_STUDY, studyId);\n        ncfile.addGlobalAttribute(constants.cNetCDF.Attributes.GLOB_TECHNOLOGY, \"INTERNAL\");\n        ncfile.addGlobalAttribute(constants.cNetCDF.Attributes.GLOB_DESCRIPTION, \"Matrix created by MOAPI through addition of 2 matrices\");\n        \n        return ncfile;\n\n    }\n}\n\nUse the above in the following way:\n\npackage netCDF;\n\nimport java.util.List;\nimport ucar.ma2.*;\nimport ucar.nc2.*;\nimport java.io.IOException;\n\n/**\n *\n * @author Fernando Mu\u00f1iz Fernandez\n * IBE, Institute of Evolutionary Biology (UPF-CSIC)\n * CEXS-UPF-PRBB\n * \n * THIS TO GENERATE A netCDF-3 GENOTYPE DB\n */\n\npublic class TestWriteNetcdf {\n    \n    public static void main(String[] arg) throws InvalidRangeException, IOException {\n        \n        NetcdfFileWriteable ncfile = netCDF.CreateNetcdf.setDimsAndAttributes(0, \n                                                                          \"INTERNAL\", \n                                                                          \"test in TestWriteNetcdf\", \n                                                                          \"+/-\", \n                                                                          5,\n                                                                          10);\n                \n        // create the file\n        try {\n            ncfile.create();\n        } catch (IOException e) {\n            System.err.println(\"ERROR creating file \"+ncfile.getLocation()+\"\\n\"+e);\n        }\n        \n        \n        ////////////// FILL'ER UP! ////////////////\n        List<Dimension> dims = ncfile.getDimensions();\n        Dimension samplesDim = dims.get(0);\n        Dimension markersDim = dims.get(1);\n        Dimension markerSpanDim = dims.get(2);\n        \n        ArrayChar charArray = new ArrayChar.D3(samplesDim.getLength(),markersDim.getLength(),markerSpanDim.getLength());\n        int i,j;\n        Index ima = charArray.getIndex();\n        \n        \n        int method = 1;\n        switch (method) {\n            case 1: \n                // METHOD 1: Feed the complete genotype in one go\n                for (i=0; i<samplesDim.getLength(); i++) {\n                    for (j=0; j<markersDim.getLength(); j++) {\n                        char c = (char) ((char) j + 65);\n                        String s = Character.toString(c) + Character.toString(c);\n                        charArray.setString(ima.set(i,j,0),s);\n                        System.out.println(\"SNP: \"+i);\n                    }\n                }\n                break;\n            case 2: \n                //METHOD 2: One snp at a time -> feed in all samples\n                for (i=0; i<markersDim.getLength(); i++) {\n                    charArray.setString(ima.set(i,0), \"s\"+i+\"I0\");\n                    System.out.println(\"SNP: \"+i);\n                }\n                break;\n            case 3: \n                //METHOD 3: One sample at a time -> feed in all snps\n                break;\n        }\n        \n        \n        \n        int[] offsetOrigin = new int[3]; //0,0\n        try {\n            ncfile.write(\"genotypes\", offsetOrigin, charArray);\n            //ncfile.write(\"genotype\", origin, A);\n        } catch (IOException e) {\n            System.err.println(\"ERROR writing file\");\n        } catch (InvalidRangeException e) {\n            e.printStackTrace();\n        }\n        \n        // close the file\n        try {\n            ncfile.close();\n        } catch (IOException e) {\n            System.err.println(\"ERROR creating file \"+ncfile.getLocation()+\"\\n\"+e);\n        }\n\n    }\n}\n\n\n", "date": "2010-02-26 14:26:41", "action": 0, "post": 74}}, {"pk": 97, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: Site use guidelines", "content": "This is an excellent initiative: congratulations and thank you for setting it up!\n\nI guess this site will be all the more useful as there are more contributers... So I guess that good questions for the administrator(s) of this site are: \n\n - Do you have a plan for advertising this site/attracting new Users?\n - How can the Users help?\n\n", "date": "2010-02-26 14:44:01", "action": 0, "post": 75}}, {"pk": 98, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "compilation", "title": "Looking for a 'Hello world\" plugin for Taverna.", "content": "Hi all,\nI'd like to create a very simple plugin for [Taverna 2.0][1], something very simple like like implementing a 'convertDnaToRna'. There is already some source code that can be found on the net e.g. Egon Willighagen's code at [http://github.com/egonw/cdk-taverna][2] but it requires to know **Maven** and.... I'm too **lazy** :-)\n\nHow can I implement this kind of simple plugin without maven ? ( I *just* want to compile, package & create the right XML config files)\n\n\nThanks !\n\n  [1]: http://www.taverna.org.uk/\n  [2]: http://github.com/egonw/cdk-taverna", "date": "2010-02-26 15:37:25", "action": 0, "post": 76}}, {"pk": 99, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "compilation taverna", "title": "Looking for a 'Hello world\" plugin for Taverna.", "content": "Hi all,\nI'd like to create a very simple plugin for [Taverna 2.0][1], something very simple like like implementing a 'convertDnaToRna'. There is already some source code that can be found on the net e.g. Egon Willighagen's code at [http://github.com/egonw/cdk-taverna][2] but it requires to know **Maven** and.... I'm too **lazy** :-)\n\nHow can I implement this kind of simple plugin without maven ? ( I *just* want to compile, package & create the right XML config files)\n\n\nThanks !\n\n  [1]: http://www.taverna.org.uk/\n  [2]: http://github.com/egonw/cdk-taverna", "date": "2010-02-26 15:39:23", "action": 0, "post": 76}}, {"pk": 100, "model": "server.postrevision", "fields": {"author": 43, "tag_string": "bed", "title": "How do I convert an Illumina export file to BED?", "content": "I have some illumina data generated from the latest version of the illumina pipeline (1.6.0) I need to convert my data into BED to view in ucsc genome browser.\n\nThis seems like it should be a fairly common task, however, I am unable to find any scripts to convert my data.", "date": "2010-02-26 15:49:18", "action": 0, "post": 77}}, {"pk": 101, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "", "title": "A: How do I convert an Illumina export file to BED?", "content": "I found a script [on another site][1], Uses perl but I have not checked for correctness:\n \n    #!/usr/bin/perl\n    \n    use strict;\n    use warnings;\n    use IO::File;\n    \n    my $filename = shift @ARGV;\n    die \"Usage\\n\\tperl sorted2bed.pl s_X_sorted.txt > s_X_sorted.bed\\n\" unless $filename;\n    chomp $filename;\n    \n    my $fh = new IO::File;\n    $fh->open(\"< $filename\") or die \"Can't open file $filename for reading: $!\";\n    \n    my $count = 1;\n    while(my $line = <$fh>){\n       warn \"Line $count\\n\" if $count%1000 == 0;\n       $count++;\n       my @line = split \"\\t\", $line;\n       my $chr = $line[10];\n       $chr =~ s/(.+)\\.fa/$1/;\n       #Illumina is 1-based, BED is 0-based\n       my $start = $line[12]-1;\n       my $read = $line[8];\n       my $end = $start + length $read;\n       my $strand = $line[13] eq 'F' ? '+': '-';\n       my $score = $line[15];\n       my $bedline = \"$chr\\t$start\\t$end\\t$read\\t$score\\t$strand\\n\";\n       print $bedline;\n    }\n    $fh->close;\n    \n    warn \"Done\";\n\n\n  [1]: http://mng.iop.kcl.ac.uk/site/node/378", "date": "2010-02-26 16:15:18", "action": 0, "post": 78}}, {"pk": 102, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "general", "title": "How to organize a pipeline of small scripts together?", "content": "In bioinformatics it is very common to end up with a lot of small scripts, each one with a different scope - plotting a chart, converting a file into another format, execute small operations - so it is very important to have a good way to clue them together, to define which should be executed before the others and so on.\n\nHow do you deal with the problem? Do you use makefiles, taverna workflows, batch scripts, or any other solution?", "date": "2010-02-26 16:49:35", "action": 0, "post": 79}}, {"pk": 103, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "I don't have personal experience with this package but it is something that I plan to explore in the near future:\n\n**[Ruffus ][1]** a lightweight python module to run computational pipelines. \n\n\n  [1]: http://code.google.com/p/ruffus/", "date": "2010-02-26 16:58:09", "action": 0, "post": 80}}, {"pk": 104, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "My favorite way of defining pipelines is by writing Makefiles, about which you can find [a very good introduction][1] in Software Carpentry for Bioinformatics: http://swc.scipy.org/lec/build.html .\n\nAlthough they have been originally developed for compiling programs, Makefiles allow to define which operations are needed to create each file, with a declarative syntax that it is a bit old-style but still does its job. Each Makefile is composed of a set of rules, which define operations needed to calculate a file and that can be combined together to make a pipeline. Other advantages of makefiles are conditional execution of tasks, so you can stop the execution of a pipeline and get back to it later, without having to repeat calculations. However, one of the big disadvantages of Makefiles is its old syntax... in particular, rules are identified by the names of the files that they create, and there is no such thing as 'titles' for rules, which make more tricky.\n\nI think one of the best solutions would be to use [BioMake][2], that allow to define tasks with titles that are not the name of the output files. To understand it better, look at [this example][3]: you see that each rule has a title and a series of parameters like its output, inputs, comments, etc.\n\nUnfortunately, I can't make biomake to run on my computer, as it requires very old dependencies and it is written in a very difficult perl. I have tried many alternatives and I think that [rake][4] is the one that is more close to biomake, but unfortunately I don't understand ruby's syntax. \n\nSo, I am still looking for a good alternative... Maybe one day I will have to time to re-write BioMake in python :-)\n\n\n  [1]: http://software-carpentry.org/build.html\n  [2]: http://skam.sourceforge.net/skam-intro.html\n  [3]: http://skam.sourceforge.net/skam-intro.html\n  [4]: http://rake.rubyforge.org/files/doc/rational_rdoc.html", "date": "2010-02-26 17:03:52", "action": 0, "post": 81}}, {"pk": 105, "model": "server.postrevision", "fields": {"author": 46, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "Since I work a lot with Python, I usually write a wrapper method that embeds the external script/program, i.e. calls it, parses its output and returns the desired information. The 'glueing' of several such methods then takes place within my Python code that calls all these wrappers. I guess that's a very common thing to do.\n\nChris", "date": "2010-02-26 17:04:53", "action": 0, "post": 82}}, {"pk": 106, "model": "server.postrevision", "fields": {"author": 6, "tag_string": "", "title": "A: Where can I get the secondary structure of a protein?", "content": "If you have the PDB file then you can use the standard tool called DSSP , it is supposed to be the gold standard for obtaining secondary structure. In case you just have sequence then I personally prefer PSIPRED , it takes evolutionary information into account to predict the secondary structure . According to CASP evaluation it is one of the best secondary structure predictor available.", "date": "2010-02-26 17:16:41", "action": 0, "post": 83}}, {"pk": 107, "model": "server.postrevision", "fields": {"author": 52, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "My answer would be: don't bother. I've often found that much of the scripts I write are never used again after the initial use. Therefore spending time using a complex framework that considers dependency between scripts is a waste because the results might be negative and you never visit the analysis again. Even if you do end up using the script multiple times a simple hacky bash script might be more than enough to meet the requirements.\n\nThere will however be the 1-2% of initial analyses that return a interesting result and therefore need to be expanded with more deeper investigation. I think this is the point to invest more time time in organising the project. For me I use Rake because it's simple and allows me to write in the language I'm used to (Ruby).\n\nOverall I think pragmatism is the important factor in computational biology. Just do enough to get the results you need and only invest more time when it's necessary. There's so many blind alleys in computational analysis of biological data it's not worth investing too much of your time until it's necessary.\n", "date": "2010-02-26 20:16:31", "action": 0, "post": 84}}, {"pk": 108, "model": "server.postrevision", "fields": {"author": 23, "tag_string": "", "title": "A: What is the best way to share scripts between members of a lab?", "content": "My lab uses a network-attached storage unit which every Linux workstation mounts by NFS at startup. It was reasonably cheap -- a couple hundred dollars per TB. We also keep copies of public databases on there. We put data sets on there as we're working on them, and also put the more important scripts in a Mercurial repositiory.\n\nAs Marcos and Istvan mentioned, a wiki integrated with your VCS would be wise, and Trac (trac.edgewall.org) is the obvious choice for that.", "date": "2010-02-26 20:27:32", "action": 0, "post": 85}}, {"pk": 109, "model": "server.postrevision", "fields": {"author": 6, "tag_string": "", "title": "A: What is the best way to share scripts between members of a lab?", "content": "This might be useful .\n\n[A Quick Guide to Organizing Computational Biology Projects][1]\n\n\n  [1]: http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1000424", "date": "2010-02-26 20:44:04", "action": 0, "post": 86}}, {"pk": 110, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "sequence protein structure", "title": "Where can I get the secondary structure of a protein?", "content": "As in the title... I have a protein and I would like to know its secundary structure.\nI couldn't find it in uniprot, althought I tought they had annotations for it there.\nIn the end I have used a predictor ([jpred][1]) but there it should be a database somewhere.\n\n\n  [1]: http://www.compbio.dundee.ac.uk/www-jpred", "date": "2010-02-27 09:58:45", "action": 0, "post": 48}}, {"pk": 111, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Using HDF5 to store  bio-data", "content": "There is also a Perl binding to HDF5: PDL::IO::HDF5\n\nhttp://search.cpan.org/~cerney/PDL-IO-HDF5-0.5/\nThis requires the Perl Data Language (PDL) package. The way, data-structures can be handled, sub-ranges of data can be defined  an data can be manipulated is actually very elegant in PDL such that computational code can profit from PDLs vectorized style of writing expressions.\n\nThe same is true for R and the hdf5 package: http://cran.r-project.org/web/packages/hdf5/index.html\n\nCode examples are in the package documentations of both, the R-hdf5 package documentation is quite little though.\n\nBoth of these language bindings might be a very efficient way to read and write HDF5 files.\n\nThere are also APIs in Fortran, Java, Python, Matlab, C, or C++. So it might make sense to select the language and define the type of data you wish to store first. ", "date": "2010-02-27 21:00:56", "action": 0, "post": 87}}, {"pk": 112, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "general", "title": "agile programming for bioinformaticians - any suggestions?", "content": "I am planning to prepare a talk for my workmates, to introduce them the basics of some agile programming methodology, which I think could give us good ideas to improve our working as a team.\n\nMy idea was to take inspiration from [extreme programming][1] and explain the rules I like the most: use of [A7 cards to write tasks][2], [release planning][3] every 3 week, stand-up meeting every day, [Move people around][4], [unit tests first][5], [pair programming][6] (at least introduce the concept), [collective ownership][7].\n\nIt is difficult for me to explain these rules as I don't have much direct experience with, apart for few exceptions, and it is even more difficult because I will have to explain them to people who are not comfortable with programming and with software engineering in general.\nHowever, I also think that I have to prepare this talk early and it will be much more difficult if I wait too much.\n\nDo you have any experience with what I am talking about? Do you have any advice to give me, or can you recommend me a book or a practice that I could explain along with extreme programming?\n\n\n  [1]: http://www.extremeprogramming.org/rules/\n  [2]: http://www.extremeprogramming.org/example/crcsim.html\n  [3]: http://www.extremeprogramming.org/rules/planninggame.html\n  [4]: http://www.extremeprogramming.org/rules/movepeople.html\n  [5]: http://www.extremeprogramming.org/rules/testfirst.html\n  [6]: http://www.extremeprogramming.org/rules/pair.html\n  [7]: http://www.extremeprogramming.org/rules/collective.html", "date": "2010-03-01 13:51:12", "action": 0, "post": 88}}, {"pk": 113, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Agile programming for bioinformaticians - any suggestions?", "content": "\n\nI think the approach is unsuited for individuals who are not comfortable with programming in general. There is a long way to go until someone becomes confident in their abilities. Before that this approach is not only ineffective, it might be even be detrimental.\n\nInstead what helps most is transparency. Everyone needs to write code in a source code repository that can be viewed, commented and verified. People should become familiar with testing, code coverage, and continuous integration. \n\nSomething to read: [Mythical Man Month][1].\n\n  [1]: http://en.wikipedia.org/wiki/The_Mythical_Man-Month", "date": "2010-03-01 14:06:55", "action": 0, "post": 89}}, {"pk": 114, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "sequence biopython python", "title": "Reverse complement with Biopython", "content": "An example that computes the reverse complement of a sequence with [BioPython][1]\n \n    #\n    # Reverse complement example with BioPython\n    #\n    \n    from Bio.Seq import Seq\n    \n    # create a Seq class instance\n    dna = Seq(\"ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\")\n    \n    # original DNA\n    print type(dna)\n    print dna\n    \n    # complement DNA, returns a new sequence\n    print dna.complement()\n    \n    # reverse complement DNA, returns a new sequence\n    print dna.reverse_complement()\n    \n    # note that the original DNA is unchanged\n    print type(dna), dna\n    \n    # currently there is no direct way to just reverse a sequence\n    # we need to do a little extra work\n    \n    data = reversed(dna.tostring())\n    data = ''.join(data)\n    rdna = Seq(data)\n    \n    # reversed sequence\n    print rdna\n\nProduces the following output:\n\n    <class 'Bio.Seq.Seq'>\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC\n    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n    <class 'Bio.Seq.Seq'> ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA\n\n\n  [1]: http://biopython.org/wiki/Main_Page", "date": "2010-03-01 14:26:09", "action": 0, "post": 90}}, {"pk": 115, "model": "server.postrevision", "fields": {"author": 38, "tag_string": "", "title": "A: Agile programming for bioinformaticians - any suggestions?", "content": "I would suggest to have a look at [Scrum][1], too. Certain parts would help not only bioinformations. For example estimating the time expenditure of tasks and the resulting burn down charts can be really helpful to see if something is stuck especially when working together on bigger projects.The daily scrum reports helps to meditate why who is doing what and offers a platform to discuss problems.\n\n\n  [1]: http://en.wikipedia.org/wiki/Scrum_(development)", "date": "2010-03-01 14:41:28", "action": 0, "post": 91}}, {"pk": 116, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "python pygr", "title": "Computing the reverse complement with Pygr", "content": "Computing the reverse complement with the [Pygr][1] bioinformatics framework:\n\n    #\n    # Reverse complement example with pygr\n    #\n    \n    from pygr.sequence import Sequence\n    \n    # create a Sequence class  named bobo\n    dna = Sequence('ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG','bobo')\n    \n    # original DNA\n    print type(dna)\n    print dna\n    \n    # complement DNA, returns a new sequence\n    # ??? - need help here \n    \n    # reverse complement DNA, returns a new sequence\n    print -dna\n    \n    # reverse DNA\n    # ??? - need help here\n    \n    # the original DNA is unchanged\n    print type(dna), dna\n    \n    # get the sequence as a string\n    print str(dna)\n\nProduces the output:\n\n    <class 'pygr.sequence.Sequence'>\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n    <class 'pygr.sequence.Sequence'> ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n\n\n  [1]: http://code.google.com/p/pygr/wiki/PygrDocumentation", "date": "2010-03-01 14:48:25", "action": 0, "post": 92}}, {"pk": 117, "model": "server.postrevision", "fields": {"author": 44, "tag_string": "", "title": "A: Recommend easy to use microarray clustering software", "content": "Possibly related:\nhttp://mmc.gnets.ncsu.edu/", "date": "2010-03-01 14:51:52", "action": 0, "post": 93}}, {"pk": 118, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "sequence biopython python", "title": "Computing the reverse complement with Biopython", "content": "An example that computes the reverse complement of a sequence with [BioPython][1]\n \n    #\n    # Reverse complement example with BioPython\n    #\n    \n    from Bio.Seq import Seq\n    \n    # create a Seq class instance\n    dna = Seq(\"ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\")\n    \n    # original DNA\n    print type(dna)\n    print dna\n    \n    # complement DNA, returns a new sequence\n    print dna.complement()\n    \n    # reverse complement DNA, returns a new sequence\n    print dna.reverse_complement()\n    \n    # note that the original DNA is unchanged\n    print type(dna), dna\n    \n    # currently there is no direct way to just reverse a sequence\n    # we need to do a little extra work\n    \n    data = reversed(dna.tostring())\n    data = ''.join(data)\n    rdna = Seq(data)\n    \n    # reversed sequence\n    print rdna\n\nProduces the following output:\n\n    <class 'Bio.Seq.Seq'>\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC\n    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n    <class 'Bio.Seq.Seq'> ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA\n\n\n  [1]: http://biopython.org/wiki/Main_Page", "date": "2010-03-01 15:03:28", "action": 0, "post": 90}}, {"pk": 119, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "general", "title": "Agile programming for bioinformaticians - any suggestions?", "content": "I am planning to prepare a talk for my workmates, to introduce them the basics of some agile programming methodology, which I think could give us good ideas to improve our working as a team.\n\nMy idea was to take inspiration from [extreme programming][1] and explain the rules I like the most: use of [A7 cards to write tasks][2], [release planning][3] every 3 week, stand-up meeting every day, [Move people around][4], [unit tests first][5], [pair programming][6] (at least introduce the concept), [collective ownership][7].\n\nIt is difficult for me to explain these rules as I don't have much direct experience with, apart for few exceptions, and it is even more difficult because I will have to explain them to people who are not comfortable with programming and with software engineering in general.\nHowever, I also think that I have to prepare this talk early and it will be much more difficult if I wait too much.\n\nDo you have any experience with what I am talking about? Do you have any advice to give me, or can you recommend me a book or a practice that I could explain along with extreme programming?\n\n\n  [1]: http://www.extremeprogramming.org/rules/\n  [2]: http://www.extremeprogramming.org/example/crcsim.html\n  [3]: http://www.extremeprogramming.org/rules/planninggame.html\n  [4]: http://www.extremeprogramming.org/rules/movepeople.html\n  [5]: http://www.extremeprogramming.org/rules/testfirst.html\n  [6]: http://www.extremeprogramming.org/rules/pair.html\n  [7]: http://www.extremeprogramming.org/rules/collective.html", "date": "2010-03-01 15:03:58", "action": 0, "post": 88}}, {"pk": 120, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "python pygr", "title": "Computing the reverse complement with Pygr", "content": "Computing the reverse complement with the [Pygr][1] bioinformatics framework:\n\n    #\n    # Reverse complement example with pygr\n    #\n    \n    from pygr.sequence import Sequence\n    \n    # needs a separate function to reverse strings\n    def rev(it):\n        \"Reverses an interable and returns it as a string\"\n        return ''.join(reversed(it))\n    \n    # original sequence as as string\n    seq = 'ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG'\n    \n    # create a Sequence class  instance named bobo\n    dna = Sequence(seq,'bobo')\n    \n    # sequence class' type and content\n    print type(dna)\n    print dna\n    \n    # the -operator reverse complements the DNA, returns a new sequence\n    print -dna\n    \n    # to reverse the DNA, reverse the input data\n    rdna = Sequence( rev(seq),'bobo')\n    print rdna\n    \n    # to complement the DNA reverse complement, then reverse again\n    cseq = rev(str(-dna))\n    cdna = Sequence(cseq,'bobo')\n\n    print cdna\n\nProduces the output:\n\n    <class 'pygr.sequence.Sequence'>\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA\n    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC\n\n  [1]: http://code.google.com/p/pygr/wiki/PygrDocumentation\n\n", "date": "2010-03-01 16:04:17", "action": 0, "post": 92}}, {"pk": 121, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Computing the reverse and complement of a sequence with Biopython", "content": "Wouldn't it better to have a single question titled 'How to compute the reverse complement with python' and put all the examples as different answers? Otherwise it seems a bit confusing..", "date": "2010-03-01 16:07:15", "action": 0, "post": 94}}, {"pk": 122, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "sequence biopython python", "title": "Computing the reverse and complement of a sequence with Biopython", "content": "An example that computes the reverse complement of a sequence with [BioPython][1]\n\n    #\n    # Reverse complement example with BioPython\n    #\n    \n    from Bio.Seq import Seq\n    \n    # a separate function to reverse strings (or other iterables)\n    def rev(it):\n        \"Reverses an interable and returns it as a string\"\n        return ''.join(reversed(it))\n    \n    # create a Seq class instance\n    dna = Seq(\"ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\")\n    \n    # original DNA\n    print type(dna)\n    print dna\n    \n    # reverse complement DNA, returns a new sequence\n    print dna.reverse_complement()\n    \n    # currently there is no direct way to just reverse a sequence\n    # we need to do a little extra work\n    \n    rseq = rev(str(dna))\n    rdna = Seq(rseq)\n    \n    # reversed sequence\n    print rdna\n    \n    # to complement DNA, returns a new sequence\n    print dna.complement()\n\nProduces the following output:\n\n    <class 'Bio.Seq.Seq'>\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA\n    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC\n\n\n   [1]: http://biopython.org/wiki/Main_Page", "date": "2010-03-01 16:11:52", "action": 0, "post": 90}}, {"pk": 123, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "python pygr", "title": "Computing the reverse and complement of a sequence with Pygr", "content": "Computing the reverse complement with the [Pygr][1] bioinformatics framework:\n\n    #\n    # Reverse complement example with pygr\n    #\n    \n    from pygr.sequence import Sequence\n    \n    # needs a separate function to reverse strings\n    def rev(it):\n        \"Reverses an interable and returns it as a string\"\n        return ''.join(reversed(it))\n    \n    # original sequence as as string\n    seq = 'ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG'\n    \n    # create a Sequence class  instance named bobo\n    dna = Sequence(seq,'bobo')\n    \n    # sequence class' type and content\n    print type(dna)\n    print dna\n    \n    # the -operator reverse complements the DNA, returns a new sequence\n    print -dna\n    \n    # to reverse the DNA, reverse the input data\n    rdna = Sequence( rev(seq),'bobo')\n    print rdna\n    \n    # to complement the DNA reverse complement, then reverse again\n    cseq = rev(str(-dna))\n    cdna = Sequence(cseq,'bobo')\n\n    print cdna\n\nProduces the output:\n\n    <class 'pygr.sequence.Sequence'>\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA\n    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC\n\n  [1]: http://code.google.com/p/pygr/wiki/PygrDocumentation\n\n", "date": "2010-03-01 16:12:20", "action": 0, "post": 92}}, {"pk": 124, "model": "server.postrevision", "fields": {"author": 23, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "The most important thing for me has been keeping a README file at the top of each project directory, where I write down not just *how* to run the scripts, but *why* I wrote them in the first place -- coming back to a project after a several-month lull, it's remarkable difficult to figure out what all the half-finished results mean without detailed notes.\n\nThat said:\n\n - `make` is pretty handy for simple pipelines that need to be re-run a lot\n - I'm also intrigued by [waf][1] and [scons][2], since I use Python a lot\n - If a pipeline only takes a couple of minutes to run, and you only re-run it every few days, coercing it into a build system doesn't really save time overall for that project\n - But once you're used to working with a build system, the threshold where it pays off to use it on a new project drops dramatically\n\n  [1]: http://code.google.com/p/waf/\n  [2]: http://www.scons.org/", "date": "2010-03-01 16:32:26", "action": 0, "post": 95}}, {"pk": 125, "model": "server.postrevision", "fields": {"author": 23, "tag_string": "", "title": "A: Computing the reverse and complement of a sequence with Biopython", "content": "The Bio.Seq module provides two easy ways to get the complement and reverse complement from a sequence:\n\n - If you have a string, use the functions `complement(dna)` and `reverse_complement(dna)`\n - If you have a Seq object, use its methods with the same names: `dna.complement()` and `dna.reverse_complement`\n\nTo reverse a sequence, there is a function in the `Bio.SeqUtils` module called `reverse` which does what you would expect.\n\n---\n\n(Sorry for going meta, but I don't have commenting privileges yet. This can be deleted if the original post is edited.)\n\nAccording to [Meta Stack Overflow][1], if you want to share the answer to a difficult question that's poorly documented elsewhere online, you should post the question as a genuine one, and then submit your own answer separately. In theory, someone else may have an answer that's better than yours, and this allows it to be voted to the top properly.\n\n  [1]: http://meta.stackoverflow.com/questions/17845/etiquette-for-answering-your-own-question", "date": "2010-03-01 16:52:22", "action": 0, "post": 96}}, {"pk": 126, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "", "title": "A: Gene ID conversion tool", "content": "http://idconverter.bioinfo.cnio.es/\n\nIs another possible solution to this, although you might find this is not as up to date as you might like either.", "date": "2010-03-01 17:05:13", "action": 0, "post": 97}}, {"pk": 127, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Gene ID conversion tool", "content": "BioMart has already been mentioned. It can do much more than ID conversion but it is very useful for conversion purposes, it is regularly updated and you can select different genome builds and all kinds of genomic features. It seems to me that you wish to retrieve GeneIDs linked to Affymetrix IDs. To select these attributes in BioMart: go to the [Martview][1] page to start a new BioMart query.\n\nSelect attributes on the attribute page: The Ensembl GeneIDs and Transcript IDs are default. Ensembl GeneID and Affy IDs are under the \"External\" tab. Select your chip there.\nTo limit to those genes which are on the chip, use the Filters->Gene menue. You can limit the genes to those present on various platforms or your favourite set.\n\nThere is an URL button in biomart that allows to retrieve a URL for your query and to pass it on to others. Try this example:\n\n[BioMart URL][2] URL, that should be a good starting point.\n\nIf you are interested in KEGG identifiers (Pathways, Genes), EC-numbers, etc. the  \n\n[KEGG Identifier page][3] could be handy, because the KEGG ids are not in BioMart as far as I know.\n\n\n  [1]: http://www.biomart.org/biomart/martview\n  [2]: http://www.biomart.org/biomart/martview?VIRTUALSCHEMANAME=default&ATTRIBUTES=hsapiens_gene_ensembl.default.feature_page.ensembl_gene_id|hsapiens_gene_ensembl.default.feature_page.ensembl_transcript_id|hsapiens_gene_ensembl.default.feature_page.embl|hsapiens_gene_ensembl.default.feature_page.affy_hg_u133a&FILTERS=hsapiens_gene_ensembl.default.filters.with_affy_hg_u133a.only&VISIBLEPANEL=resultspanel\n  [3]: http://www.genome.jp/kegg/kegg3.html", "date": "2010-03-01 19:51:25", "action": 0, "post": 98}}, {"pk": 128, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "interval query", "title": "Fast interval intersection methodologies", "content": "Most genomic annotations are specified as intervals along the genome. \n\n - [Interval trees][1] have been known to provide an efficient datastructure that allows for very fast overlap querying. \n - [Nested Containment Lists][2] have been proposed as an even faster alternative \n\nProvide code examples in your programming language that demonstrate the use of fast interval querying.\n\n  [1]: http://books.google.com/books?id=NLngYyWFl_YC&lpg=PA311&ots=BwTtEE-jJ9&dq=cormen%20interval%20tree&pg=PA311#v=onepage&q=&f=false\n  [2]: http://bioinformatics.oxfordjournals.org/cgi/content/abstract/btl647v1", "date": "2010-03-01 20:01:20", "action": 0, "post": 99}}, {"pk": 129, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Fast interval intersection methodologies", "content": "The above code requires the either the installation of the [bx python][1] package or alternatively you may just download the [quicksect.py][2] module and place it next to the script itself:\n\n\n    from random import randint, seed\n    \n    # if you can install bx python then uncomment the line below\n    #\n    # from bx.intervals.operations.quicksect import IntervalNode\n    \n    # otherwise just download the quickset module as shown above \n    # and place it in next to your program\n    #\n    from quicksect import IntervalNode\n    \n    # the span of the generated intervals\n    SPAN = 10\n    \n    # the size of the genome\n    SIZE = 5*10**4\n    \n    # the number of intervals\n    N = 10**4\n    \n    def generate(x):\n        \"Generates random interval over a size and span\"\n        lo = randint(10000, SIZE)\n        hi = lo + randint(1, SPAN)\n        return (lo, hi)\n    \n    def find(start, end, tree):\n        \"Returns a list with the overlapping intervals\"\n        out = []\n        tree.intersect( start, end, lambda x: out.append(x) )\n        return [ (x.start, x.end) for x in out ]\n    \n    # use this to force both examples to generate the same data\n    seed(10)\n    \n    # generate 10 thousand random intervals\n    data = map(generate, xrange(N))\n    \n    # generate the intervals to query over\n    query = map(generate, xrange(10))\n    \n    # start the root at the first element\n    start, end = data[0]\n    tree = IntervalNode( start, end )\n    \n    # build an interval tree from the rest of the data\n    for start, end in data[1:]:\n        tree = tree.insert( start, end )\n    \n    for start, end in query:\n        overlap = find(start, end , tree)\n        print '(%s, %s) -> %s' % (start, end, overlap)\n        \n\nProduces the output:\n\n    (41901, 41903) -> [(41894, 41902)]\n    (36981, 36987) -> [(36981, 36984), (36973, 36982), (36978, 36987)]\n    (36338, 36339) -> [(36337, 36347)]\n    (32741, 32748) -> [(32738, 32742)]\n    (49864, 49872) -> [(49859, 49865)]\n    (21475, 21477) -> []\n    (29425, 29428) -> [(29418, 29426), (29419, 29426)]\n    (29590, 29599) -> [(29586, 29595), (29596, 29598)]\n    (12804, 12811) -> [(12806, 12811), (12799, 12806), (12809, 12819)]\n    (30339, 30343) -> [(30336, 30346), (30335, 30345), (30340, 30341)]\n\n  [1]: http://bitbucket.org/james_taylor/bx-python/wiki/Home\n  [2]: http://bitbucket.org/james_taylor/bx-python/raw/ebf9a4b352d3/lib/bx/intervals/operations/quicksect.py", "date": "2010-03-01 20:06:18", "action": 0, "post": 100}}, {"pk": 130, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Fast interval intersection methodologies", "content": "This code example generates 10,000 intervals then queries them for overlapping regions.\n\nThis is a faster solution than the other example, one that now requires the full installation of the [bx-python][1] module. **The data structure is implemented in C** and is at least one order of magnitude faster than the **quicksect.py** module presented in another example.\n\n    from random import randint, seed\n    from bx.intervals.intersection import Intersecter, Interval\n    \n    # the span of the generated intervals\n    SPAN = 10\n    \n    # the size of the genome\n    SIZE = 5*10**4\n    \n    # the number of intervals\n    N = 10**4\n    \n    def generate(x):\n        \"Generates random interval over a size and span\"\n        lo = randint(10000, SIZE)\n        hi = lo + randint(1, SPAN)\n        return (lo, hi)\n    \n    # use this to force both examples to generate the same data\n    seed(10)\n    \n    # generate 10 thousand random intervals\n    data = map(generate, xrange(N))\n    \n    # generate the intervals to query over\n    query = map(generate, xrange(10))\n    \n    # create the interval tree\n    tree = Intersecter()\n    \n    # build an interval tree from the rest of the data\n    for start, end in data:\n        tree.add_interval( Interval(start, end) )\n    \n    # perform the query\n    for start, end in query:\n        overlap = tree.find(start, end)\n        out = [ (x.start, x.end) for x in overlap ]\n        print '(%s, %s) -> %s' % (start, end, out)\n        \nProduces the output:\n\n    (41901, 41903) -> [(41894, 41902)]\n    (36981, 36987) -> [(36973, 36982), (36978, 36987), (36981, 36984)]\n    (36338, 36339) -> [(36337, 36347)]\n    (32741, 32748) -> [(32738, 32742)]\n    (49864, 49872) -> [(49859, 49865)]\n    (21475, 21477) -> []\n    (29425, 29428) -> [(29418, 29426), (29419, 29426)]\n    (29590, 29599) -> [(29586, 29595), (29596, 29598)]\n    (12804, 12811) -> [(12799, 12806), (12806, 12811), (12809, 12819)]\n    (30339, 30343) -> [(30335, 30345), (30336, 30346), (30340, 30341)]\n\n  [1]: http://bitbucket.org/james_taylor/bx-python/overview/\n", "date": "2010-03-01 20:09:49", "action": 0, "post": 101}}, {"pk": 131, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Fast interval intersection methodologies", "content": "This code example generates 10,000 intervals then queries them for overlapping regions. **Requires only the presence of Python.**\n\nThe code below requires the either the installation of the [bx python][1] package or alternatively you may just download the [quicksect.py][2] module and place it next to the script itself:\n\n\n    from random import randint, seed\n    \n    # if you can install bx python then uncomment the line below\n    #\n    # from bx.intervals.operations.quicksect import IntervalNode\n    \n    # otherwise just download the quickset module as shown above \n    # and place it in next to your program\n    #\n    from quicksect import IntervalNode\n    \n    # the span of the generated intervals\n    SPAN = 10\n    \n    # the size of the genome\n    SIZE = 5*10**4\n    \n    # the number of intervals\n    N = 10**4\n    \n    def generate(x):\n        \"Generates random interval over a size and span\"\n        lo = randint(10000, SIZE)\n        hi = lo + randint(1, SPAN)\n        return (lo, hi)\n    \n    def find(start, end, tree):\n        \"Returns a list with the overlapping intervals\"\n        out = []\n        tree.intersect( start, end, lambda x: out.append(x) )\n        return [ (x.start, x.end) for x in out ]\n    \n    # use this to force both examples to generate the same data\n    seed(10)\n    \n    # generate 10 thousand random intervals\n    data = map(generate, xrange(N))\n    \n    # generate the intervals to query over\n    query = map(generate, xrange(10))\n    \n    # start the root at the first element\n    start, end = data[0]\n    tree = IntervalNode( start, end )\n    \n    # build an interval tree from the rest of the data\n    for start, end in data[1:]:\n        tree = tree.insert( start, end )\n    \n    for start, end in query:\n        overlap = find(start, end , tree)\n        print '(%s, %s) -> %s' % (start, end, overlap)\n        \n\nProduces the output:\n\n    (41901, 41903) -> [(41894, 41902)]\n    (36981, 36987) -> [(36981, 36984), (36973, 36982), (36978, 36987)]\n    (36338, 36339) -> [(36337, 36347)]\n    (32741, 32748) -> [(32738, 32742)]\n    (49864, 49872) -> [(49859, 49865)]\n    (21475, 21477) -> []\n    (29425, 29428) -> [(29418, 29426), (29419, 29426)]\n    (29590, 29599) -> [(29586, 29595), (29596, 29598)]\n    (12804, 12811) -> [(12806, 12811), (12799, 12806), (12809, 12819)]\n    (30339, 30343) -> [(30336, 30346), (30335, 30345), (30340, 30341)]\n\n  [1]: http://bitbucket.org/james_taylor/bx-python/wiki/Home\n  [2]: http://bitbucket.org/james_taylor/bx-python/raw/ebf9a4b352d3/lib/bx/intervals/operations/quicksect.py", "date": "2010-03-01 20:13:11", "action": 0, "post": 100}}, {"pk": 132, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Fast interval intersection methodologies", "content": "This code example generates 10,000 intervals then queries them for overlapping regions. **The installation requires a C compiler and Python.**\n\nThis is a faster solution than the other example, one that now requires the full installation of the [bx-python][1] module. **The data structure is implemented in C** and is at least one order of magnitude faster than the **quicksect.py** module presented in another example.\n\n    from random import randint, seed\n    from bx.intervals.intersection import Intersecter, Interval\n    \n    # the span of the generated intervals\n    SPAN = 10\n    \n    # the size of the genome\n    SIZE = 5*10**4\n    \n    # the number of intervals\n    N = 10**4\n    \n    def generate(x):\n        \"Generates random interval over a size and span\"\n        lo = randint(10000, SIZE)\n        hi = lo + randint(1, SPAN)\n        return (lo, hi)\n    \n    # use this to force both examples to generate the same data\n    seed(10)\n    \n    # generate 10 thousand random intervals\n    data = map(generate, xrange(N))\n    \n    # generate the intervals to query over\n    query = map(generate, xrange(10))\n    \n    # create the interval tree\n    tree = Intersecter()\n    \n    # build an interval tree from the rest of the data\n    for start, end in data:\n        tree.add_interval( Interval(start, end) )\n    \n    # perform the query\n    for start, end in query:\n        overlap = tree.find(start, end)\n        out = [ (x.start, x.end) for x in overlap ]\n        print '(%s, %s) -> %s' % (start, end, out)\n        \nProduces the output:\n\n    (41901, 41903) -> [(41894, 41902)]\n    (36981, 36987) -> [(36973, 36982), (36978, 36987), (36981, 36984)]\n    (36338, 36339) -> [(36337, 36347)]\n    (32741, 32748) -> [(32738, 32742)]\n    (49864, 49872) -> [(49859, 49865)]\n    (21475, 21477) -> []\n    (29425, 29428) -> [(29418, 29426), (29419, 29426)]\n    (29590, 29599) -> [(29586, 29595), (29596, 29598)]\n    (12804, 12811) -> [(12799, 12806), (12806, 12811), (12809, 12819)]\n    (30339, 30343) -> [(30335, 30345), (30336, 30346), (30340, 30341)]\n\n  [1]: http://bitbucket.org/james_taylor/bx-python/overview/\n", "date": "2010-03-01 20:16:04", "action": 0, "post": 101}}, {"pk": 133, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "sequence", "title": "How to validate that a sequence only contains letters from a given alphabet?", "content": "How do I verify that a sequence only contains letters from a given alphabet: DNA, RNA, protein?", "date": "2010-03-01 23:47:17", "action": 0, "post": 102}}, {"pk": 134, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "", "title": "A: List all the tools or write a script to validate that a sequence only contains letters from a given alphabet", "content": "Here is an efficient function written in Python:\n\n    dna = set(\"ATGC\")\n    def validate(seq, alphabet=dna):\n        \"Checks that a sequence only contains values from an alphabet\"\n        leftover = set(seq.upper()) - alphabet\n        return not leftover\n    \n    # typical usage below\n    \n    # this will print True\n    print validate('AAAATGCCG')\n    \n    # this will print False\n    print validate('AAANTGCCG')\n    \n    # using it with other alphabets\n    prot = set('ACDEFGHIKLMNPQRSTVWY')\n    print validate(\"mglsdgewql\", alphabet=prot)", "date": "2010-03-01 23:50:05", "action": 0, "post": 103}}, {"pk": 135, "model": "server.postrevision", "fields": {"author": 60, "tag_string": "", "title": "A: Using HDF5 to store  bio-data", "content": "I've been talking a bit with one of the devs behind BioHDF (being at UIUC, up the road from The HDF Group doesn't hurt). I believe a publication is on the way describing it along with some implementation details. ", "date": "2010-03-02 05:22:30", "action": 0, "post": 104}}, {"pk": 136, "model": "server.postrevision", "fields": {"author": 39, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "Since i use Ruby quite often, I have found Rake very useful in creating simple pipelines. Rake has an idea of a task(s) and you can have prerequisites for the tasks, thus create pipelines. See An extension to rake that can be used to build database-backed workflows \u2014 at github http://github.com/jandot/biorake\n\n", "date": "2010-03-02 07:54:01", "action": 0, "post": 105}}, {"pk": 137, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Fast interval intersection methodologies", "content": "An alternative is to use BED files to store data and [BEDTools][1] to calculate the intersection.\n\nThe [BED][2] format is a format used by UCSC and many other projects to generically store annotations on genomes. Sometimes, it is easier to use just plain BED files to store annotations, instead of complex databases or HDF5, and BEDTools make it also faster to access them. Moreover, with BEDFiles you have other advantages, as you can use custom tracks on ucsc or gbrowse and there are other tools that use BED as input.\n\nAnyway, to solve the problem of intersection with BEDTools, you would do:\n    \n`$: intersectBed -a segdups.bed -b exons.bed`\n\n\n  [1]: http://code.google.com/p/bedtools/\n  [2]: http://genome.ucsc.edu/FAQ/FAQformat#format1", "date": "2010-03-02 09:26:39", "action": 0, "post": 106}}, {"pk": 138, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "re Biomake:\n\nIt does look like a great tool but it is unsupported. What you get from Sourceforge is a snapshot with README pointing you to one dialect of Prolog (XSB)only to learn running the examples that project moved to another one (SWI-Prolog). Unless you know Prolog and can fix it Biomake is not functional as I last checked (Jan 2010).  ", "date": "2010-03-02 10:37:07", "action": 0, "post": 107}}, {"pk": 139, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "sequence", "title": "Genome specific database (Gbrowse / Ensembl type)", "content": "I am interested in your opinions about database systems used to store, query and visualize genomic sequence and annotations. I am talking about ca 600-700Mb draft genome with a large number of contigs outside scaffolds. Yep, I know that annotating anything before reaching some quality milestones may be considered pointless, but I want to get the back end (DB) and the pipeline   \nworking way before that.\n\nSo far I started testing Gbrowse (1.70), been impressed by Ensembl as an end-user, and looked at (unsuitable) eye candy GenomeProjector  http://www.g-language.org/GenomeProjector/.\n\nI will appreciate any thoughts about ease of installation/maintenance and integration with annotation tools such as Apollo / Artemis.\n\nThanks\n\ndarked89\n\nPS There is no way top add proper tags (genome annotation database) to this post", "date": "2010-03-02 11:00:20", "action": 0, "post": 108}}, {"pk": 140, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "re Biomake:\n\nIt does look like a great tool but it is unsupported. What you get from Sourceforge is a snapshot with README pointing you to one dialect of Prolog (XSB) only to learn running the examples that project moved to another one (SWI-Prolog). Unless you know Prolog and can fix it Biomake is not functional as I last checked (Jan 2010).  ", "date": "2010-03-02 11:05:54", "action": 0, "post": 107}}, {"pk": 141, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Genome specific database (Gbrowse / Ensembl type)", "content": "This is a really debated topic, whether it is better to store sequences on a database or on simple flat files. I have never had to annotate draft genomes as you so I can't suggest you which is the best approach for you, but I would recommend using flat files, as you will have more support and tools, it will take less time to set it up, and I have the feeling that that is the direction that most projects are taking for the future.\n\nIn case you want to use databases, have a look at [this post][1] and a this type of column type, the [datatype-geometric][2].\n\nIn case you want to try flat files, you will have to study [BED][3], [GFF][4], and maybe [BAM][5] formats, along with [VCF][6] if you have snps. For example, if you BED, you will be able to use [BEDTools][7], which will allow you to merge and work with genomic features and are very fast. You will be surprised to know that GBrowse uses only GFF files to store data, it has no DB backend.\n\nAnother alternative is HDF5, about which you may find some questions here. So, you have a lot of homework here :-)\n\n\n  [1]: http://www.mailund.dk/index.php/2009/01/22/playing-with-spatial-queries-in-mysql/\n  [2]: http://www.postgresql.org/docs/8.1/interactive/datatype-geometric.html\n  [3]: http://genome.ucsc.edu/FAQ/FAQformat.html#format1\n  [4]: http://genome.ucsc.edu/FAQ/FAQformat.html#format3\n  [5]: http://samtools.sourceforge.net/\n  [6]: http://vcftools.sourceforge.net/options.html\n  [7]: http://code.google.com/p/bedtools/", "date": "2010-03-02 12:06:01", "action": 0, "post": 109}}, {"pk": 142, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: Using HDF5 to store  bio-data", "content": "Not BioHDF5 but probably readable and maintained: \n\nHDF5 for Python\nhttp://code.google.com/p/h5py/", "date": "2010-03-02 13:10:29", "action": 0, "post": 110}}, {"pk": 143, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "blast taxonomy", "title": "Taxonomy of blast hits", "content": "Lets have 200k genomic contigs with some (unknown) bacterial contamination. \n\nI blasted (blastn vs nr) all of them, got tabulated output and passed the uniq acc nos ca 5k to Batch Entrez. Since neither my target genome nor bacterias causing contamination are not sequenced, I got a shotgun of results (3000 Eukaryota, 2000 Bacteria, few viruses). \n\nNow for a tricky part: \nwhat I need is:\nsequence_identifier + taxonomic_id(s) + main_tax_group\n\nsomething along the line:\n\nA000001 573 Bacteria\n\nApart from writing a script storing the sequence & taxonomy info into say MySQL, then going through blast top hits output, are there any tools (taverna work flows?) which can do it for me?\n\n \n\n  ", "date": "2010-03-02 15:35:52", "action": 0, "post": 111}}, {"pk": 144, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "blast taxonomy", "title": "Taxonomy of blast hits", "content": "Lets have 200k genomic contigs with some (unknown) bacterial contamination. \n\nI blasted (blastn vs nr) all of them, got tabulated output and passed the uniq acc nos ca 5k to Batch Entrez. Since neither my target genome nor bacterias causing contamination are not sequenced, I got a shotgun of results (3000 Eukaryota, 2000 Bacteria, few viruses). \n\nNow for a tricky part: \nwhat I need is:\nsequence_identifier + taxonomic_id(s) + main_tax_group\n\nsomething along the line:\n\nA000001 573 Bacteria\n\nApart from writing a script storing the sequence & taxonomy info into say MySQL, then going through blast top hits output, are there any tools (taverna work flows?) which can do it for me?\n\n**re Pierre**\n\nPrimary input is text blast output of:\n\n    blastcl3 -p blastn -m 9 -e 0.00001 -b 1 -i frag01 -o out_blastn_frag01\n\nI grep-ed and awk-ed hit acc numbers from second column. Resulting text file (one acc no per line) was feed to Batch Entrez. As far as I can tell there is no way of selecting output in form: \nA000001 573 Bacteria\nThe most parsable output seems to be TinyXML, but then I will download full bacterial genomes / eukaryotic chromosomes worth of sequence which at this stage I do not need.\n\nIdeally instead of two extremes (E.coli K12 + Bacteria) getting a whole taxonomic path:\n\n\n> cellular organisms; Bacteria; Proteobacteria; Gammaproteobacteria;\n> Enterobacteriales; Enterobacteriaceae; Escherichia; Escherichia coli\n\nwill be preferred. That way one can zoom in (select more than just species/strain and  taxonomic Kingdom).\n  \nSo at this moment I am split between using (1) just blast tabulated text output or selecting some Batch Entrez output which then I will be able to combine with (1).", "date": "2010-03-02 16:56:10", "action": 0, "post": 111}}, {"pk": 145, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective", "title": "your favorite bioinformatics blog", "content": "I think that for a professional is very important to follow blogs focused on his own speciality, it is a good way to learn without too much effort and to stay updated. Which bioinformatics-related blogs do you usually read?\n\nnote: there is a [similar question][1] posted on stackoverflow.\n\n\n  [1]: http://stackoverflow.com/questions/2051319/bioinformatics-resources", "date": "2010-03-02 17:25:33", "action": 0, "post": 112}}, {"pk": 146, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "sequence genome annotation database", "title": "Genome specific database (Gbrowse / Ensembl type)", "content": "I am interested in your opinions about database systems used to store, query and visualize genomic sequence and annotations. I am talking about ca 600-700Mb draft genome with a large number of contigs outside scaffolds. Yep, I know that annotating anything before reaching some quality milestones may be considered pointless, but I want to get the back end (DB) and the pipeline   \nworking way before that.\n\nSo far I started testing Gbrowse (1.70), been impressed by Ensembl as an end-user, and looked at (unsuitable) eye candy GenomeProjector  http://www.g-language.org/GenomeProjector/.\n\nI will appreciate any thoughts about ease of installation/maintenance and integration with annotation tools such as Apollo / Artemis.\n\nThanks\n\ndarked89\n\nPS There is no way top add proper tags (genome annotation database) to this post", "date": "2010-03-02 17:40:36", "action": 0, "post": 108}}, {"pk": 147, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective blog off resources", "title": "your favorite bioinformatics blog", "content": "I think that for a professional is very important to follow blogs focused on his own speciality, it is a good way to learn without too much effort and to stay updated. Which bioinformatics-related blogs do you usually read?\n\nnote: there is a [similar question][1] posted on stackoverflow.\n\n\n  [1]: http://stackoverflow.com/questions/2051319/bioinformatics-resources", "date": "2010-03-02 17:41:10", "action": 0, "post": 112}}, {"pk": 148, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "sequence use dna", "title": "How to validate that a sequence only contains letters from a given alphabet?", "content": "How do I verify that a sequence only contains letters from a given alphabet: DNA, RNA, protein?", "date": "2010-03-02 17:42:01", "action": 0, "post": 102}}, {"pk": 149, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "interval query use genomics", "title": "Fast interval intersection methodologies", "content": "Most genomic annotations are specified as intervals along the genome. \n\n - [Interval trees][1] have been known to provide an efficient datastructure that allows for very fast overlap querying. \n - [Nested Containment Lists][2] have been proposed as an even faster alternative \n\nProvide code examples in your programming language that demonstrate the use of fast interval querying.\n\n  [1]: http://books.google.com/books?id=NLngYyWFl_YC&lpg=PA311&ots=BwTtEE-jJ9&dq=cormen%20interval%20tree&pg=PA311#v=onepage&q=&f=false\n  [2]: http://bioinformatics.oxfordjournals.org/cgi/content/abstract/btl647v1", "date": "2010-03-02 17:42:32", "action": 0, "post": 99}}, {"pk": 150, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "python pygr use sequence", "title": "Computing the reverse and complement of a sequence with Pygr", "content": "Computing the reverse complement with the [Pygr][1] bioinformatics framework:\n\n    #\n    # Reverse complement example with pygr\n    #\n    \n    from pygr.sequence import Sequence\n    \n    # needs a separate function to reverse strings\n    def rev(it):\n        \"Reverses an interable and returns it as a string\"\n        return ''.join(reversed(it))\n    \n    # original sequence as as string\n    seq = 'ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG'\n    \n    # create a Sequence class  instance named bobo\n    dna = Sequence(seq,'bobo')\n    \n    # sequence class' type and content\n    print type(dna)\n    print dna\n    \n    # the -operator reverse complements the DNA, returns a new sequence\n    print -dna\n    \n    # to reverse the DNA, reverse the input data\n    rdna = Sequence( rev(seq),'bobo')\n    print rdna\n    \n    # to complement the DNA reverse complement, then reverse again\n    cseq = rev(str(-dna))\n    cdna = Sequence(cseq,'bobo')\n\n    print cdna\n\nProduces the output:\n\n    <class 'pygr.sequence.Sequence'>\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA\n    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC\n\n  [1]: http://code.google.com/p/pygr/wiki/PygrDocumentation\n\n", "date": "2010-03-02 17:43:08", "action": 0, "post": 92}}, {"pk": 151, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "general agile good team", "title": "Agile programming for bioinformaticians - any suggestions?", "content": "I am planning to prepare a talk for my workmates, to introduce them the basics of some agile programming methodology, which I think could give us good ideas to improve our working as a team.\n\nMy idea was to take inspiration from [extreme programming][1] and explain the rules I like the most: use of [A7 cards to write tasks][2], [release planning][3] every 3 week, stand-up meeting every day, [Move people around][4], [unit tests first][5], [pair programming][6] (at least introduce the concept), [collective ownership][7].\n\nIt is difficult for me to explain these rules as I don't have much direct experience with, apart for few exceptions, and it is even more difficult because I will have to explain them to people who are not comfortable with programming and with software engineering in general.\nHowever, I also think that I have to prepare this talk early and it will be much more difficult if I wait too much.\n\nDo you have any experience with what I am talking about? Do you have any advice to give me, or can you recommend me a book or a practice that I could explain along with extreme programming?\n\n\n  [1]: http://www.extremeprogramming.org/rules/\n  [2]: http://www.extremeprogramming.org/example/crcsim.html\n  [3]: http://www.extremeprogramming.org/rules/planninggame.html\n  [4]: http://www.extremeprogramming.org/rules/movepeople.html\n  [5]: http://www.extremeprogramming.org/rules/testfirst.html\n  [6]: http://www.extremeprogramming.org/rules/pair.html\n  [7]: http://www.extremeprogramming.org/rules/collective.html", "date": "2010-03-02 17:44:16", "action": 0, "post": 88}}, {"pk": 152, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "general make pipeline organization", "title": "How to organize a pipeline of small scripts together?", "content": "In bioinformatics it is very common to end up with a lot of small scripts, each one with a different scope - plotting a chart, converting a file into another format, execute small operations - so it is very important to have a good way to clue them together, to define which should be executed before the others and so on.\n\nHow do you deal with the problem? Do you use makefiles, taverna workflows, batch scripts, or any other solution?", "date": "2010-03-02 17:45:01", "action": 0, "post": 79}}, {"pk": 153, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "bed conversion format", "title": "How do I convert an Illumina export file to BED?", "content": "I have some illumina data generated from the latest version of the illumina pipeline (1.6.0) I need to convert my data into BED to view in ucsc genome browser.\n\nThis seems like it should be a fairly common task, however, I am unable to find any scripts to convert my data.", "date": "2010-03-02 17:45:34", "action": 0, "post": 77}}, {"pk": 154, "model": "server.postrevision", "fields": {"author": 44, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "http://biostar.stackexchange.com", "date": "2010-03-02 17:46:19", "action": 0, "post": 113}}, {"pk": 155, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "blast taxonomy", "title": "Taxonomy of blast hits", "content": "Lets have 200k genomic contigs with some (unknown) bacterial contamination. \n\nI blasted (blastn vs nr) all of them, got tabulated output and passed the uniq acc nos ca 5k to Batch Entrez. Since neither my target genome nor bacterias causing contamination are not sequenced, I got a shotgun of results (3000 Eukaryota, 2000 Bacteria, few viruses). \n\nNow for a tricky part: \nwhat I need is:\nsequence_identifier + taxonomic_id(s) + main_tax_group\n\nsomething along the line:\n\nA000001 573 Bacteria\n\nApart from writing a script storing the sequence & taxonomy info into say MySQL, then going through blast top hits output, are there any tools (taverna work flows?) which can do it for me?\n\n**re Pierre**\n\nPrimary input is text blast output of:\n\n    blastcl3 -p blastn -m 9 -e 0.00001 -b 1 -i frag01 -o out_blastn_frag01\n\nI grep-ed and awk-ed hit acc numbers from second column. Resulting text file (one acc no per line) was feed to Batch Entrez. As far as I can tell there is no way of selecting output in form: \nA000001 573 Bacteria\nThe most parsable output seems to be TinyXML, but then I will download full bacterial genomes / eukaryotic chromosomes worth of sequence which at this stage I do not need.\n\nIdeally instead of two extremes (E.coli K12 + Bacteria) getting a whole taxonomic path:\n\n\n> cellular organisms; Bacteria; Proteobacteria; Gammaproteobacteria;\n> Enterobacteriales; Enterobacteriaceae; Escherichia; Escherichia coli\n\nwill be preferred. That way one can zoom in (select more than just species/strain and  taxonomic Kingdom).\n  \nSo at this moment I am split between using (1) just blast tabulated text output or selecting some Batch Entrez output which then I will be able to combine with (1).\n\nre 2\nsingle line which gets squezzed a bit  here:\n\ncontig62836  gi|119525916|gb|CP000508.1|     93.18   44      3       0       1109    1152    262350  262393  2e-06   63.9\n\n\n\nBefore each of the top hits there is blast header with hash sign in front:\n\n\n    # Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score\n\n\nSo simple:\n\n     grep -A 1 Fields out_blastn_frag0* | grep contig | awk '{ print $2}' | awk 'FS=\"|\" {print $4}' | sort | uniq > all_uniq_hits_100302.txt\n\ngives me list off unique accession numbers of my top hits suitable for Batch Entrez.\n\n**re XML:**\nyes, but I tried to avoid too much network traffic. XML for half a million contigs is a lot of data. save for oneliners I am using python. \n\n\n", "date": "2010-03-02 17:50:36", "action": 0, "post": 111}}, {"pk": 156, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Taxonomy of blast hits", "content": "I you want to get the TinySeq XML  *without* getting the sequence, I would create a SAX parser that would only get the value of the **TaxonId** and ignoring the other field (see \"class TinySeqHandler\" in [http://code.google.com/p/lindenb/source/browse/trunk/proj/tinytools/src/org/lindenb/tinytools/TwitterOmics.java][1] for an example). Having the taxonId you can get the full lineage from\n\n    http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=taxonomy&id=YOUR_TAXON_ID&retmode=xml\n\n\n  [1]: http://code.google.com/p/lindenb/source/browse/trunk/proj/tinytools/src/org/lindenb/tinytools/TwitterOmics.java", "date": "2010-03-02 18:02:17", "action": 0, "post": 114}}, {"pk": 157, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Taxonomy of blast hits", "content": "From the description of your input data I guess that you are trying to do a taxonomic classification of sequences in a metagenomics approach. I further assume that you have about 200.000 reads or sequences (or do you alternatively mean assembled contigs of length 200 kB?).\nI am not sure if I completely understand the question, but whatever you do, filtering out the tax ids with your own script might not be the best option. \n \nI assume further you wish to compute a tree of the taxonomic composition of the data in total.\n\n> That way one can zoom in (select more\n> than just species/strain and taxonomic\n> Kingdom)\n\nFor this task you might want to try the [MEGAN][1] (Metagenome Analysis) software. \n\nActually, what you are describing looks very much like one of the publications they have in their publications list:\n\nH. N. Poinar, C. Schwarz, Ji Qi, B. Shapiro, R. D. E. MacPhee, B. Buigues, A. Tikhonov, D. H. Huson, L. P. Tomsho, A. Auch, M. Rampp, W. Miller, S. C. Schuster, [Metagenomics to Paleogenomics: Large-Scale Sequencing of Mammoth DNA][2], Science 311:392-394, 2006\n\nThere is also a [tutorial on setting the right BLAST parameter][3] for use with short reads.\n\nSo in principle, this program could do the job or at least you can have a look at the right parameters for blast. \n\n\n  [1]: http://www-ab.informatik.uni-tuebingen.de/software/megan\n  [2]: http://www.sciencemag.org/cgi/content/abstract/1123360v1\n  [3]: http://www-ab.informatik.uni-tuebingen.de/software/megan/how-to-use-blast", "date": "2010-03-02 18:08:54", "action": 0, "post": 115}}, {"pk": 158, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "mine of course ! :-) [http://plindenbaum.blogspot.com][1]\n\nSee also: Bioinformatics blogs on Nature-blogs: http://blogs.nature.com/blogs?tags=bioinformatics\n\nAnd the life-scientists group on FriendFeed: [http://friendfeed.com/the-life-scientists][2]\n\n\n  [1]: http://plindenbaum.blogspot.com\n  [2]: http://friendfeed.com/the-life-scientists", "date": "2010-03-02 18:10:21", "action": 0, "post": 116}}, {"pk": 159, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "Here is  one that I follow, but I'm interested in adding more blogs to my feed:\n\n - [Blue Collar Bioinformatics][1]\n \n  [1]: http://bcbio.wordpress.com/", "date": "2010-03-02 18:20:20", "action": 0, "post": 117}}, {"pk": 160, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "subjective blog off resources", "title": "Your favorite bioinformatics blog", "content": "I think that for a professional is very important to follow blogs focused on his own speciality, it is a good way to learn without too much effort and to stay updated. Which bioinformatics-related blogs do you usually read?\n\nnote: there is a [similar question][1] posted on stackoverflow.\n\n\n  [1]: http://stackoverflow.com/questions/2051319/bioinformatics-resources", "date": "2010-03-02 18:22:47", "action": 0, "post": 112}}, {"pk": 161, "model": "server.postrevision", "fields": {"author": 52, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "[Very large list of bioinformatics blogs][1] from the now defunct Nodalpoint wiki\n\n\n  [1]: http://web.archive.org/web/20080213153458/wiki.nodalpoint.org/blogs", "date": "2010-03-02 18:35:19", "action": 0, "post": 118}}, {"pk": 162, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "Maybe not The Greatest but these few are covering next gen sequencing:\n\nhttp://www.massgenomics.org/\nhttp://www.fejes.ca/labels/DNA.html\nhttp://omicsomics.blogspot.com/\n\n", "date": "2010-03-02 19:59:25", "action": 0, "post": 119}}, {"pk": 163, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: Where can I get the secondary structure of a protein?", "content": "May be a little bit dated, but let me blow my own trumpet (collection of links):\n\n[Bioinfo_tutorial#Protein_localization_and_structure_prediction](http://openwetware.org/wiki/Wikiomics:Bioinfo_tutorial#Protein_localization_and_structure_prediction)\n", "date": "2010-03-02 20:10:25", "action": 0, "post": 120}}, {"pk": 164, "model": "server.postrevision", "fields": {"author": 6, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "A friend of mine is a very active blogger in bioinformatics. This is his blog site\n\n[Fisheye Perspective][1]\n\n\nHe has also complied a list of bioinformatics and chemo informatics blogs which are very popular. some of you might be interested in it.\n\n[30+ Blogs about Bioinformatics and Chemoinformatics Programming][2] \n\n\n  [1]: http://www.abhishek-tiwari.com/\n  [2]: http://www.abhishek-tiwari.com/2009/02/30-blogs-about-bioinformatics-and.html", "date": "2010-03-02 20:38:44", "action": 0, "post": 121}}, {"pk": 165, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "general subjective os", "title": "Which operating system do you prefer for bioinformatics?", "content": "So, you will probably hate me for asking this question here, as there are lot of forum and blog posts on internet about it and it is also a very subjective question.\n\nHowever, it may be a starting point for a good discussion, if we don't flame... Which operating system do you usually use for your work? Did you install it by yourself, and do you have administrative rights on it, or is there any IT administrator in your lab? ", "date": "2010-03-02 21:16:12", "action": 0, "post": 33}}, {"pk": 166, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective programming languages", "title": "Which programming languages are good to study for bioinformatics?", "content": "This is also a very classic question, however, it can be a very useful discussion for novices which are wishing to work in the bioinformatics field, and have to decide how to organize their time.\nI have seen some surveys on this, for example on bioinformatics.org and on bioinformaticszen, but none of these cases were open discussions.\n\n\nWhich is your favorite programming language in bioinformatics? I actually use very much of Python and R, and hate Perl :-)\n\n\n\n\n\n", "date": "2010-03-02 21:16:36", "action": 0, "post": 34}}, {"pk": 167, "model": "server.postrevision", "fields": {"author": 6, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "I think the emphasis should be more on the way we optimize our program rather than language which we use. I personally use languages based on the kind of problem I am answering.\n\nThis was an interesting paper which I came across some time back although some of the information mentioned in here might sound redundant to some of you but still it's worth a read.\n\n[A Quick Guide for Developing Effective Bioinformatics Programming Skills][1]\n\n\n  [1]: http://www.ploscompbiol.org/article/info:doi%2F10.1371%2Fjournal.pcbi.1000589", "date": "2010-03-02 22:42:11", "action": 0, "post": 122}}, {"pk": 168, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: Finding common motifs in sequences", "content": "You may check out these pages:\n\n[Bioinfo_tutorial#Promoter_prediction](http://openwetware.org/wiki/Wikiomics:Bioinfo_tutorial#Promoter_prediction)\n\n[Wikiomics:Sequence_motifs](http://openwetware.org/wiki/Wikiomics:Sequence_motifs)\n\nThese are ca 2 years old (links may not work etc.) but as a starting point should be OK. \nAlso in unlikely case you did not found it yet: in yeast there has been an extensive motif search study done by Kellis with insane number of citations:\n\n\nNature. 2003 May 15;423(6937):241-54.\n\nKellis M, Patterson N, Endrizzi M, Birren B, Lander ES.\n\n[Sequencing and comparison of yeast species to identify genes and regulatory elements.](http://www.ncbi.nlm.nih.gov/pubmed/12748633)", "date": "2010-03-02 23:29:26", "action": 0, "post": 123}}, {"pk": 169, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "Blogs:\n\n - [programming4scientists.com][1] - tricks for scientists entering the world of programming\n - [mailund on the Internet][2] - nice blog on programming, population genetics, simulations\n - [Open-Bio news][3] - news from the project that hosts bioperl, biopython, etc..\n - [FinchTalk][4] - this one is from a company, but it is interesting and technical worthy of reading it.\n - [Fisheye Perspective][5] - very interesting with news on synthetic biology and else - the author is very active in many bioinformatics communities. note: I suggest you to register to the [feeds][6] directly\n - [88 Proof Synthetic Biology][7]\n - [Learning R][8] - tips to learn R\n - [BioCS][9]\n - [MentalIndigestion][10] \n - [PDB - MOlecule of the Month][11]\n - [The molecule of the Month][12]  - similar style to pdb's, but different authors\n\n\nMoreover, I also find useful to follow the blogs from many bioinformatics services or databases:\n \n - [NCBI][13]'s news\n - [Uniprot][14]'s news\n - [Plos Computational Biology][15]\n - [Gene Ontology][16] news\n\n\n  [1]: http://www.programming4scientists.com/\n  [2]: http://www.mailund.dk/\n  [3]: http://news.open-bio.org/news/\n  [4]: http://www.geospiza.com/finchtalk/\n  [5]: http://www.abhishek-tiwari.com/\n  [6]: http://feeds2.feedburner.com/AbhishekTiwarisBlog\n  [7]: http://88proof.com/synthetic_biology/blog\n  [8]: http://learnr.wordpress.com/\n  [9]: http://blog.mckuhn.de/\n  [10]: http://www.mentalindigestion.net/\n  [11]: http://www.rcsb.org/pdb/motm.do\n  [12]: http://www.chm.bris.ac.uk/motm/motm.htm\n  [13]: http://www.ncbi.nlm.nih.gov/feed/rss.cgi\n  [14]: http://www.uniprot.org/news/?format=rss\n  [15]: http://feeds.plos.org/ploscompbiol/NewArticles\n  [16]: http://go.berkeleybop.org/news4go/rss.xml", "date": "2010-03-03 12:15:23", "action": 0, "post": 124}}, {"pk": 170, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Finding common motifs in sequences", "content": "The first step when looking for conservation of single bases or motives is often a multiple sequence alignment that will align the sequences in a way such that conserved regions are best visible. This can be a first step before using explicit motif finders like MEME. A good way of visualizing multiple alignments is the [sequence-logo][1] that will give a graphical representation of base conservation.\n\nHere is the [wikipedia list of mult.-sequence alignment][2] tools.\n\nI recommend to start with the [EBI web-server of ClustalW][3] though, if that is not enough you can also try MAFFT or T-Coffee.\n\n[Weblogo][4] can generate sequence-logo graphics from the output and also from fasta input directly.\n\nAdvantage of these tools is that you don't need to install them, so good for a first attempt irrespective of using a Mac.  \n\n\n  [1]: http://en.wikipedia.org/wiki/Sequence_logo\n  [2]: http://en.wikipedia.org/wiki/List_of_sequence_alignment_software#Multiple_sequence_alignment\n  [3]: http://www.ebi.ac.uk/Tools/clustalw2/index.html\n  [4]: http://weblogo.threeplusone.com/", "date": "2010-03-03 12:35:31", "action": 0, "post": 125}}, {"pk": 171, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "hdf biohdf hdf storage", "title": "Using HDF5 to store  bio-data", "content": "Hi all,\nhas anobody ever used the [HDF5 API][1] to store some biological data (genotypes...). I know about this [kind of reference][2] (BioHDF...)  but I'm looking for some **source code** I could browse to understand how I can access data faster.\n\nPierre\n\n\nPS: hum, I'm a new user. I'm not allowed to add the following tags: storage database hdf5 source code \n\n  [1]: http://www.hdfgroup.org/HDF5/\n  [2]: http://www.geospiza.com/finchtalk/2008/03/genotyping-with-hdf.html", "date": "2010-03-03 13:38:58", "action": 0, "post": 69}}, {"pk": 172, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "compilation taverna plugin maven workflow", "title": "Looking for a 'Hello world\" plugin for Taverna.", "content": "Hi all,\nI'd like to create a very simple plugin for [Taverna 2.0][1], something very simple like like implementing a 'convertDnaToRna'. There is already some source code that can be found on the net e.g. Egon Willighagen's code at [http://github.com/egonw/cdk-taverna][2] but it requires to know **Maven** and.... I'm too **lazy** :-)\n\nHow can I implement this kind of simple plugin without maven ? ( I *just* want to compile, package & create the right XML config files)\n\n\nThanks !\n\n  [1]: http://www.taverna.org.uk/\n  [2]: http://github.com/egonw/cdk-taverna", "date": "2010-03-03 13:39:44", "action": 0, "post": 76}}, {"pk": 173, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "geneid accession mapping conversion", "title": "Gene ID conversion tool", "content": "Hey,\n\nI was using DAVID (http://david.abcc.ncifcrf.gov/conversion.jsp) to do the gene ID conversion, e.g.conversion between Agilent ID, Genebank accession id and Entrez gene ID, but I found the DAVID database is not updated. Does anyone know a better updataed conversion tool to do this job? Thanks! ", "date": "2010-03-03 14:03:06", "action": 0, "post": 22}}, {"pk": 174, "model": "server.postrevision", "fields": {"author": 63, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "http://manuelcorpas.com/", "date": "2010-03-03 17:17:24", "action": 0, "post": 126}}, {"pk": 175, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "blast taxonomy", "title": "Taxonomy of blast hits", "content": "Lets have 200k genomic contigs with some (unknown) bacterial contamination. \n\nI blasted (blastn vs nr) all of them, got tabulated output and passed the uniq acc nos ca 5k to Batch Entrez. Since neither my target genome nor bacterias causing contamination are not sequenced, I got a shotgun of results (3000 Eukaryota, 2000 Bacteria, few viruses). \n\nNow for a tricky part: \nwhat I need is:\nsequence_identifier + taxonomic_id(s) + main_tax_group\n\nsomething along the line:\n\nA000001 573 Bacteria\n\nApart from writing a script storing the sequence & taxonomy info into say MySQL, then going through blast top hits output, are there any tools (taverna work flows?) which can do it for me?\n\n**re Pierre**\n\nPrimary input is text blast output of:\n\n    blastcl3 -p blastn -m 9 -e 0.00001 -b 1 -i frag01 -o out_blastn_frag01\n\nI grep-ed and awk-ed hit acc numbers from second column. Resulting text file (one acc no per line) was feed to Batch Entrez. As far as I can tell there is no way of selecting output in form: \nA000001 573 Bacteria\nThe most parsable output seems to be TinyXML, but then I will download full bacterial genomes / eukaryotic chromosomes worth of sequence which at this stage I do not need.\n\nIdeally instead of two extremes (E.coli K12 + Bacteria) getting a whole taxonomic path:\n\n\n> cellular organisms; Bacteria; Proteobacteria; Gammaproteobacteria;\n> Enterobacteriales; Enterobacteriaceae; Escherichia; Escherichia coli\n\nwill be preferred. That way one can zoom in (select more than just species/strain and  taxonomic Kingdom).\n  \nSo at this moment I am split between using (1) just blast tabulated text output or selecting some Batch Entrez output which then I will be able to combine with (1).\n\n**re giovanni**\nsingle line which gets squezzed a bit  here:\n\ncontig62836  gi|119525916|gb|CP000508.1|     93.18   44      3       0       1109    1152    262350  262393  2e-06   63.9\n\n\n\nBefore each of the top hits there is blast header with hash sign in front:\n\n\n    # Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score\n\n\nSo simple:\n\n     grep -A 1 Fields out_blastn_frag0* | grep contig | awk '{ print $2}' | awk 'FS=\"|\" {print $4}' | sort | uniq > all_uniq_hits_100302.txt\n\ngives me list off unique accession numbers of my top hits suitable for Batch Entrez.\n\n**re XML:**\nyes, but I tried to avoid too much network traffic. XML for half a million contigs is a lot of data. save for oneliners I am using python. \n\n\n", "date": "2010-03-03 17:19:10", "action": 0, "post": 111}}, {"pk": 176, "model": "server.postrevision", "fields": {"author": 64, "tag_string": "", "title": "A: Using HDF5 to store  bio-data", "content": "This might be useful for you. This code snippet read the Simulation data and manipulate in HDF5. \n<pre>\n*Chnage first 5 includes from \"\" to open and close tags*\n#include \"stdlib.h\"\n#include \"stdio.h\"\n#include \"string.h\"\n#include \"hdf5.h\"\n#include \"hdf5_hl.h\"\n\n#include \"common.h\"\n#include \"hdf5_data.h\"\n#include \"metadata/simulation.h\"\n#include \"metadata/simulation_list.h\"\n\nenum FileIntent\n{\n  READING,\n  WRITING,\n  NEITHER\n};\n\nstruct HDF5Data\n{\n  hid_t file;\n  hid_t group;\n  int ptCreated;\n  hid_t pt;\n  enum FileIntent intent;\n};\n\n/* Iterator function for pulling out existing simulation data.\n * Currently assumes we are only dealing with our own files but could be\n * made smarter to find only groups that contain the required dataspace's.\n */\nstatic herr_t\nrootIterator(hid_t group,const char *name,void *_iter)\n{\n  struct SimulationList* list = (struct SimulationList*)_iter;\n  if (list)\n  {\n    struct Simulation* s = CreateSimulation();\n    simulationSetName(s,name);\n    simulationListAppend(list,s);\n    DestroySimulation(&s);\n    return(0);\n  }\n  return(-1);\n}\n\nstruct HDF5Data* CreateHDF5Data()\n{\n  struct HDF5Data* hdf5 = (struct HDF5Data*)malloc(sizeof(struct HDF5Data));\n  if (hdf5)\n  {\n    hdf5->file = (hid_t)NULL;\n    hdf5->group = (hid_t)NULL;\n    hdf5->pt = (hid_t)NULL;\n    hdf5->ptCreated = 0;\n    hdf5->intent = NEITHER;\n  }\n  return(hdf5);\n}\n\nint DestroyHDF5Data(struct HDF5Data** hdf5)\n{\n  int code = ERR;\n  struct HDF5Data* h5 = *hdf5;\n  if (h5)\n  {\n    if (h5->ptCreated) H5PTclose(h5->pt);\n    if (h5->group > 0) H5Gclose(h5->group);\n    if (h5->file > 0) H5Fclose(h5->file);\n    free(h5);\n    code = OK;\n  }\n  *hdf5 = (struct HDF5Data*)NULL;\n  return(code);\n}\n\nint hdf5DataOpenFileForWriting(struct HDF5Data* hdf5,const char* filename)\n{\n  /* Open the hdf5 file for writing. */\n  int code = ERR;\n  if (hdf5)\n  {\n    hdf5->file =\n      H5Fcreate(filename,H5F_ACC_TRUNC,H5P_DEFAULT,H5P_DEFAULT);\n    if (hdf5->file < 0) code = ERR;\n    else\n    {\n      hdf5->intent = WRITING;\n      code = OK;\n    }\n  }\n  return(code);\n}\n\nint hdf5DataOpenFileForReading(struct HDF5Data* hdf5,const char* filename)\n{\n  /* Open the hdf5 file for writing. */\n  int code = ERR;\n  if (hdf5)\n  {\n    hdf5->file = H5Fopen(filename,H5F_ACC_RDONLY,H5P_DEFAULT);\n    if (hdf5->file < 0) code = ERR;\n    else\n    {\n      hdf5->intent = READING;\n      code = OK;\n    }\n  }\n  return(code);\n}\n\nint hdf5DataSetGroup(struct HDF5Data* hdf5,const char* groupName)\n{\n  int code = ERR;\n  if (hdf5 && (hdf5->file > 0))\n  {\n    if (hdf5->group > 0) H5Gclose(hdf5->group);\n    if (hdf5->ptCreated) H5PTclose(hdf5->pt);\n    hdf5->ptCreated = 0;\n    if (groupName)\n    {\n      if (hdf5->intent == WRITING) hdf5->group =\n        H5Gcreate(hdf5->file,groupName,/*size_hint*/0);\n      else hdf5->group = H5Gopen(hdf5->file,groupName);\n    }\n    code = OK;\n  }\n  return(code);\n}\n\nint hdf5WriteSimulationModelURI(struct HDF5Data* hdf5,const char* uri)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  hsize_t dim[1];\n\n  if ((hdf5 == NULL) || (hdf5->intent != WRITING))\n  {\n    fprintf(stderr,\"Attempting to write to a reading file.\\n\");\n    return(ERR);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  if (uri == NULL)\n  {\n    fprintf(stderr,\"Attempting to write invalid URI to data file.\\n\");\n    return(ERR);\n  }\n  if (strlen(uri) > HDF5_STRING_LENGTH-1)\n  {\n    fprintf(stderr,\n      \"URI too long - fix the hdf5WriteSimulationModelURI code.\\n\");\n    return(ERR);\n  }\n  char* localURI = (char*)calloc(HDF5_STRING_LENGTH,1);\n  strcpy(localURI,uri);\n  /* Make a string data type */\n  datatype = H5Tcopy(H5T_C_S1);\n  /* set the fixed string length */\n  status = H5Tset_size(datatype,HDF5_STRING_LENGTH);\n  /* and we're gonna use C-like null-terminated string */\n  status = H5Tset_strpad(datatype,H5T_STR_NULLTERM);\n  /* Create a simple memory space of the correct size */\n  dim[0] = 1;\n  dataspace = H5Screate_simple(1,dim,NULL);\n  /* and create the dataset to write to */\n  dataset = H5Dcreate(hdf5->group,SIMULATION_MODEL_URI_NAME,datatype,\n    dataspace,H5P_DEFAULT);\n  /* Write the URI to the file */\n  status = H5Dwrite(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,localURI);\n  /* clean up */\n  H5Dclose(dataset);\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  /*H5Fflush(hdf5->file,H5F_SCOPE_GLOBAL);*/\n  free(localURI);\n  return(OK);\n}\n\nint hdf5WriteFieldHeader(struct HDF5Data* hdf5,int N,char* names)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  hsize_t dim[1];\n\n  if ((hdf5 == NULL) || (hdf5->intent != WRITING))\n  {\n    fprintf(stderr,\"Attempting to write to a reading file.\\n\");\n    return(ERR);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  /* Make a string data type */\n  datatype = H5Tcopy(H5T_C_S1);\n  /* set the fixed string length */\n  status = H5Tset_size(datatype,HDF5_STRING_LENGTH);\n  /* and we're gonna use C-like null-terminated strings */\n  status = H5Tset_strpad(datatype,H5T_STR_NULLTERM);\n  /* Create a simple memory space of the correct size */\n  dim[0] = N;\n  dataspace = H5Screate_simple(1,dim,NULL);\n  /* and create the dataset to write to */\n  dataset = H5Dcreate(hdf5->group,FIELD_HEADER_DATA_NAME,datatype,\n    dataspace,H5P_DEFAULT);\n  /* Write the field names to the file */\n  status = H5Dwrite(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,names);\n  /* clean up */\n  H5Dclose(dataset);\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  /*H5Fflush(hdf5->file,H5F_SCOPE_GLOBAL);*/\n  return(OK);\n}\n\nint hdf5WriteData(struct HDF5Data* hdf5,int N,double* data)\n{\n  herr_t status = 0;\n  \n  if ((hdf5 == NULL) || (hdf5->intent != WRITING))\n  {\n    fprintf(stderr,\"Attempting to write to a reading file.\\n\");\n    return(ERR);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  if (!hdf5->ptCreated)\n  {\n    /* create a fixed length packet table in the file */\n    hdf5->pt = H5PTcreate_fl(hdf5->group,DATA_NAME,H5T_NATIVE_DOUBLE,\n      /*chunk size ??*/sizeof(double)*N);\n    hdf5->ptCreated = 1;\n  }\n  if (hdf5->ptCreated)\n  {\n    /* Write a packet to the packet table */\n    status = H5PTappend(hdf5->pt,N,(void*)data);\n  }\n  return(OK);\n}\n\nchar* hdf5ReadSimulationModelURI(struct HDF5Data* hdf5)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  char *uri = (char*)NULL;\n  \n  if ((hdf5 == NULL) || (hdf5->intent != READING))\n  {\n    fprintf(stderr,\"Attempting to read from a writing file.\\n\");\n    return((char*)NULL);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  /* open the dataset */\n  dataset = H5Dopen(hdf5->group,SIMULATION_MODEL_URI_NAME);\n  dataspace = H5Dget_space(dataset);\n  /* get the data type */\n  datatype = H5Dget_type(dataset);\n  /* allocate memory */\n  uri = (char*)malloc(HDF5_STRING_LENGTH);\n  /* read in the data */\n  status = H5Dread(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,uri);\n  if (status < 0)\n  {\n    fprintf(stderr,\"Error getting the dimension of the field header.\\n\");\n    free(uri);\n    H5Sclose(dataspace);\n    H5Tclose(datatype);\n    H5Dclose(dataset);\n    return((char*)NULL);\n  }\n  /* clean up */\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  H5Dclose(dataset);\n  return(uri);\n}\n\nchar** hdf5ReadFieldHeader(struct HDF5Data* hdf5,int* N)\n{\n  herr_t status;\n  hid_t datatype,dataspace,dataset;\n  hsize_t dim[1];\n  char *tmp,*names = (char*)NULL;\n  char** fields = (char**)NULL;\n  int i;\n  \n  if ((hdf5 == NULL) || (hdf5->intent != READING))\n  {\n    fprintf(stderr,\"Attempting to read from a writing file.\\n\");\n    return((char**)NULL);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  /* open the dataset */\n  dataset = H5Dopen(hdf5->group,FIELD_HEADER_DATA_NAME);\n  dataspace = H5Dget_space(dataset);\n  /* get the data type */\n  datatype = H5Dget_type(dataset);\n  /* get the size and allocate memory */\n  status = H5Sget_simple_extent_dims(dataspace,dim,NULL);\n  if (status < 0)\n  {\n    fprintf(stderr,\"Error getting the dimension of the field header.\\n\");\n    H5Sclose(dataspace);\n    H5Tclose(datatype);\n    H5Dclose(dataset);\n    return((char**)NULL);\n  }\n  names = (char*)malloc(HDF5_STRING_LENGTH*dim[0]);\n  /* read in the data */\n  status = H5Dread(dataset,datatype,H5S_ALL,H5S_ALL,H5P_DEFAULT,names);\n  if (status < 0)\n  {\n    fprintf(stderr,\"Error getting the dimension of the field header.\\n\");\n    free(names);\n    H5Sclose(dataspace);\n    H5Tclose(datatype);\n    H5Dclose(dataset);\n    return((char**)NULL);\n  }\n  /* clean up */\n  H5Sclose(dataspace);\n  H5Tclose(datatype);\n  H5Dclose(dataset);\n  /* split up the names */\n  fields = (char**)malloc(sizeof(char*)*dim[0]);\n  tmp = names;\n  for (i=0;i<dim[0];i++)\n  {\n    fields[i] = (char*)malloc(strlen(tmp)+1);\n    strcpy(fields[i],tmp);\n    tmp += HDF5_STRING_LENGTH;\n  }\n  free(names);\n  *N = dim[0];\n  return(fields);\n}\n\ndouble* hdf5ReadData(struct HDF5Data* hdf5,int N)\n{\n  herr_t status = 0;\n  double* data = (double*)malloc(sizeof(double)*N);\n  \n  if ((hdf5 == NULL) || (hdf5->intent != READING))\n  {\n    fprintf(stderr,\"Attempting to read from a writing file.\\n\");\n    return((double*)NULL);\n  }\n  if (hdf5->group <= 0)\n  {\n    fprintf(stderr,\"Missing HDF5 group.\\n\");\n    return(ERR);\n  }\n  if (!hdf5->ptCreated)\n  {\n    /* open the packet table */\n    hdf5->pt = H5PTopen(hdf5->group,DATA_NAME);\n    /* and make sure we're at the start of the table */\n    H5PTcreate_index(hdf5->pt);\n    hdf5->ptCreated = 1;\n  }\n  if (hdf5->ptCreated)\n  {\n    /* get N packets from the packet table */\n    status = H5PTget_next(hdf5->pt,N,(void*)data);\n    if (status<0)\n    {\n      free(data);\n      data = (double*)NULL;\n    }\n  }\n  return(data);\n}\n\nstruct SimulationList* hdf5ReadSimulations(struct HDF5Data* hdf5)\n{\n  struct SimulationList* simulations = (struct SimulationList*)NULL;\n  \n  if ((hdf5 == NULL) || (hdf5->intent != READING))\n  {\n    fprintf(stderr,\"Attempting to read from a writing file.\\n\");\n    return(simulations);\n  }\n  /* look for any groups which are children of the root group */\n  hid_t rootGroup = H5Gopen(hdf5->file,\"/\");\n  if (rootGroup > 0)\n  {\n    simulations = CreateSimulationList();\n    if (H5Giterate(rootGroup,\"/\",NULL,rootIterator,(void*)simulations)\n      != 0) DestroySimulationList(&simulations);\n    H5Gclose(rootGroup);\n  }\n  return(simulations);\n}\n\n</pre>", "date": "2010-03-03 21:18:32", "action": 0, "post": 127}}, {"pk": 177, "model": "server.postrevision", "fields": {"author": 6, "tag_string": "annotation protein", "title": "Pfam based functional annotaion", "content": "I think in one of the [earlier thread][1], Istvan has already asked about the reliability of GO annotation. I was wondering, if any of you have any experience with the functional annotation based upon the [Pfam database][2]. I am looking forward to functionally annotate a large set of peptide library and the easiest way I can think about is to do batch search of those peptides against the Pfam database.In case you guys know a better approach , kindly share it.\n\ncheers\n\n\n  [1]: http://biostar.stackexchange.com/questions/41/how-much-do-you-trust-geneontology\n  [2]: http://pfam.sanger.ac.uk/", "date": "2010-03-04 00:14:24", "action": 0, "post": 128}}, {"pk": 178, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: Pfam based functional annotaion", "content": "My experience with Pfam is limited, but I think relevant to your question.\n\nI work on a human pathogen which has been entirely sequenced and therefore we know quite a bit about what's in it. In particular, I'm interested one pfam group (PF02009) that groups similar proteins from this pathogen.\n\nThe problem I have with the pfam group is that it groups several distinct groups of proteins. These proteins are related, I agree, however, **at the level I'm comparing them (which is in detail)**, I would not jump to the conclusion that these proteins share the same function.\n\nThat brings me to the following comment on your question: looking for functional annotation is very vague. What detail of functional annotation are you looking for?\n\n  * Do you want to know if these peptides belong to groups called \"enzymes\" or \"receptors\" or some kind of basic \"building blocks\", without any more detail?\n  * Do you want to know if these peptides belong to a specific class of enzymes?\n  * Do you want to know if these peptides belong to a specific sub-class of enzymes, going all the way down to the substrate specificity?\n\nAnother question I would have is regarding the length of your peptides. I recall one of my collaborators complaining about the fact that Pfam would not detect fragments that were too short. That was with Pfam2. I don't know how this is with Pfam3 though. So, you'll have to test this.\n\nDepending on the answer to these questions (and many more) you may or may not want to ***only*** use Pfam. But in any case, Pfam could be a good start, if your peptides are not too short.\n\n\nAnother way that might be more relevant to short sequences would be to look at BLAST approaches (PSI- or PHI-BLAST in particular) to find what your peptides match to, and then look at the functional annotation of those hits (including whatever Pfam domains they may contain). I think this method would be more sensitive than the Pfam approach.\n\n", "date": "2010-03-04 08:49:51", "action": 0, "post": 129}}, {"pk": 179, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "annotation protein pfam", "title": "Pfam based functional annotaion", "content": "I think in one of the [earlier thread][1], Istvan has already asked about the reliability of GO annotation. I was wondering, if any of you have any experience with the functional annotation based upon the [Pfam database][2]. I am looking forward to functionally annotate a large set of peptide library and the easiest way I can think about is to do batch search of those peptides against the Pfam database.In case you guys know a better approach , kindly share it.\n\ncheers\n\n\n  [1]: http://biostar.stackexchange.com/questions/41/how-much-do-you-trust-geneontology\n  [2]: http://pfam.sanger.ac.uk/", "date": "2010-03-04 08:52:44", "action": 0, "post": 128}}, {"pk": 180, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "annotation protein pfam protein", "title": "Pfam based functional annotaion", "content": "I think in one of the [earlier thread][1], Istvan has already asked about the reliability of GO annotation. I was wondering, if any of you have any experience with the functional annotation based upon the [Pfam database][2]. I am looking forward to functionally annotate a large set of peptide library and the easiest way I can think about is to do batch search of those peptides against the Pfam database.In case you guys know a better approach , kindly share it.\n\ncheers\n\n\n  [1]: http://biostar.stackexchange.com/questions/41/how-much-do-you-trust-geneontology\n  [2]: http://pfam.sanger.ac.uk/", "date": "2010-03-04 09:29:26", "action": 0, "post": 128}}, {"pk": 181, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "Blogs:\n\n - [programming4scientists.com][1] - tricks for scientists entering the world of programming\n - [mailund on the Internet][2] - nice blog on programming, population genetics, simulations\n - [Open-Bio news][3] - news from the project that hosts bioperl, biopython, etc..\n - [FinchTalk][4] - this one is from a company, but it is interesting and technical worthy of reading it.\n - [Fisheye Perspective][5] - very interesting with news on synthetic biology and else - the author is very active in many bioinformatics communities. note: I suggest you to register to the [feeds][6] directly\n - [88 Proof Synthetic Biology][7]\n - [Learning R][8] - tips to learn R\n - [BioCS][9]\n - [MentalIndigestion][10] \n - [PDB - MOlecule of the Month][11]\n - [The molecule of the Month][12]  - similar style to pdb's, but different authors\n\n\nMoreover, I also find useful to follow the blogs from many bioinformatics services or databases:\n \n - [NCBI][13]'s news\n - [Uniprot][14]'s news\n - [Plos Computational Biology][15]\n - [Gene Ontology][16] news\n - [Ensembl][17] news\n\n\n  [1]: http://www.programming4scientists.com/\n  [2]: http://www.mailund.dk/\n  [3]: http://news.open-bio.org/news/\n  [4]: http://www.geospiza.com/finchtalk/\n  [5]: http://www.abhishek-tiwari.com/\n  [6]: http://feeds2.feedburner.com/AbhishekTiwarisBlog\n  [7]: http://88proof.com/synthetic_biology/blog\n  [8]: http://learnr.wordpress.com/\n  [9]: http://blog.mckuhn.de/\n  [10]: http://www.mentalindigestion.net/\n  [11]: http://www.rcsb.org/pdb/motm.do\n  [12]: http://www.chm.bris.ac.uk/motm/motm.htm\n  [13]: http://www.ncbi.nlm.nih.gov/feed/rss.cgi\n  [14]: http://www.uniprot.org/news/?format=rss\n  [15]: http://feeds.plos.org/ploscompbiol/NewArticles\n  [16]: http://go.berkeleybop.org/news4go/rss.xml\n  [17]: http://www.ensembl.org/common/rss.xml", "date": "2010-03-04 09:50:40", "action": 0, "post": 124}}, {"pk": 182, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "sequencing k", "title": "k-mer based sequencing contamination detection", "content": "In a plant genome project I got a draft assembly (> 500Mbp, >500k contigs). \nA number of contigs is no doubt bacterial in origin. \n\nThere are at least 3 peaks when it comes to GC content (40% - my plant, 50% largest contig, 65-70% another group). \n\nBlastn takes ages, and there is no point of doing it every time we change assembler parameters even slightly. So while rather sooner than later I will have to split 454 sff files into my_plant vs not_my_plant, I will still need a faster method of classifying contigs to not_my_plant group. \n\nIn metagenomics this is often being done by calculating k-mer frequencies, see i.e (not supported anymore) TETRA:  http://www.megx.net/tetra/ (see the manual for the algorithm)\n\nDo you use any program for fast clustering/classification of  sequences from say 150bp to 1Mbp using k-mer frequencies?\n\n", "date": "2010-03-04 11:41:29", "action": 0, "post": 130}}, {"pk": 183, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "Shameless plug for the [bioinformatics subreddit][1] (of which I am a moderator).\n\n\n  [1]: http://www.reddit.com/r/bioinformatics", "date": "2010-03-04 13:51:46", "action": 0, "post": 131}}, {"pk": 184, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "cloud general", "title": "Experiences with cloud computing in bioinformatics", "content": "In the past years cloud computing services such as the [Amazon's Elastic Compute][1] cloud seem to have emerged a recommended alternative for providing high performance computing.\n\nWhat are your experiences when it comes to *bioinformatics in the cloud*?\n\n  [1]: http://aws.amazon.com/ec2/", "date": "2010-03-04 14:08:04", "action": 0, "post": 132}}, {"pk": 185, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Experiences with cloud computing in bioinformatics", "content": "We have been somewhat *early adopters* of cloud computing, having evaluated it for our bioinformatics needs more than two years ago. We are also what you could call *early abandoners*;  after using it for a year we compared it against a the high computing facility' services at our university ([Penn State HPC][1]) and we found it substantially under-performing.\n\nThis is not to say that Cloud Computing is not a fantastic idea, its just that just about all universities and science oriented organizations have far more powerful computing facilities to begin with.\n\nCould computing is probably ideal for satisfying the temporary needs of a small lab with minimal funds and resources as it allows them to perform computations that otherwise would be out of reach. Yet as soon as the lab has continuous computational needs the cloud based solutions become not only more expensive but also a lot less powerful than a comparable \"traditional\" computing services.\n\nI have come up with my own \"rule of thumb\" estimation: *If within an entire year one only needs to run their computers for less than 30% of time then cloud computing may be worth it.* \n\n  [1]: http://gears.aset.psu.edu/hpc/", "date": "2010-03-04 14:24:46", "action": 0, "post": 133}}, {"pk": 186, "model": "server.postrevision", "fields": {"author": 63, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "This article may shed light onto how to organise bioinformatics projects.\nWilliam Stafford Noble. \"A quick guide to organizing computational biology experiments.\" PLoS Computational Biology. 5(7):e1000424, 2009\n\nlink:\nhttp://noble.gs.washington.edu/papers/noble2009quick.html\n\nFor me using git and the directory structure that Bill Noble mentiones in this articles has been a better approach than what I had before.", "date": "2010-03-04 14:30:04", "action": 0, "post": 134}}, {"pk": 187, "model": "server.postrevision", "fields": {"author": 63, "tag_string": "", "title": "A: Experiences with cloud computing in bioinformatics", "content": "Cloud computing is becoming a technology mature enough for its use in genome research experiments. The use of large datasets, its highly demanding algorithms and the need for sudden computational resources, make large-scale sequencing experiments an attractive test-case for cloud computing. So far I have seen cloud computing demonstrated using R (1). However, it remains to be seen a rigorous comparison of its performance using a BLAST (2) search and its ability to cope with ever-increasing databases and open source frameworks such as bioperl (3) or bioconductor (4).\n\nCloud computing claims to be a resource where IT power is delivered over the Internet as you need it, rather than drawn from a desktop computer (5), in a fashion seemingly similar to having your own virtual servers available over the Internet (6). Some of the most important aspects of cloud computing are:\n\n* Software as a Service (SaaS): where you buy a software license for a determined period of time.\n* Utility Computing: storage and virtual servers that IT can access on demand.\n* Web Services.\n\nMy first exposure to cloud computing came of an email from Matt Wood (7), a newly established group leader at the Sanger Institute (8), announcing the Cloud Computing Group (9) in Cambridge, UK. At that point I had no idea of what it meant. When I attended the meeting at Cambridge University\u2019s Centre for Mathematical Sciences (10), to my surprise I found there a very select audience, ranging from the director of IT at Sanger, Phil Butcher (11), one of the Ensembl (12) software coordinators, Glenn Proctor (13), and quite a few local start-up companies.\n\nAmong the presenters, we had Simone Brunozzi, from Amazon\u2019s Cloud Computing (14). I think he had an interesting story to tell: how Amazon, a well known company, is now involved in the business of cloud computing and selling it. Apparently, this technology they sell was developed for Amazon\u2019s own business. Among their main challenges was to be able to address the capricious shopping habits of customers, with orders peaking around Christmas and quite flat the rest of the year. These trends required rapid adaptability of computational resources. The idea of cloud computing fitted well with their business model of e-commerce: you don\u2019t need to care about where your computation is done, the only thing you care about is that you have the needed resources and do not have to pay for them when you don\u2019t need them. One of the things that stroke me about Amazon\u2019s presentation was that they would not tell us the number of processors they had at their disposal.\n\nWhen it comes to using cloud computing for genomics research, prices may be quite expensive when they add up. The bioinformatics field, greatly influenced by the open-source movement, is not likely to rush to join Amazon\u2019s cloud. Private efforts trying to make money out of human genome technology have remained rather unsuccessful to date: think of Celera Genomics or Lion Bioscience. I am skeptical of the bioinformatics community adopting cloud computing unless open source ideals are embraced: i) allowing people to develop and contribute to the technology if and when they want to, ii) allowing total openness in terms of its achievements and pitfalls and iii) making it free to use for everyone. I do not think that making it free does not mean there is no margin for profit. Think of the profitability of free-to-use technologies such as java (15) or MySQL (16), both components of SUN Microsystems\u2019 (17) business.\n\nDespite the promise of potential benefits for the bioinformatics community, the way the cloud is being portrayed does not conform the ideals of free access and openness. Unless these ideals are implemented to some extent, I see it difficult for the cloud to take root in the bioinformatics field and become a new standard platform for genome research.\n\nReferences\n\n1. http://www.r-project.org/\n2. http://blast.ncbi.nlm.nih.gov/Blast.cgi\n3. http://www.bioperl.org/wiki/Main_Page\n4. http://www.bioconductor.org/\n5. http://www.guardian.co.uk/technology/2008/sep/29/cloud.computing.richard.stallman\n6. http://www.infoworld.com/article/08/04/07/15FE-cloud-computing-reality_1.html\n7. http://www.sanger.ac.uk/Users/mw4/\n8. http://www.sanger.ac.uk/\n9. http://cloudcamb.org/\n10. http://www.cms.cam.ac.uk/site/\n11. http://www.yourgenome.org/people/phil_butcher.shtml\n12. http://www.ensembl.org/index.html\n13. http://www.ebi.ac.uk/Information/Staff/person_maintx.php?s_person_id=299\n14. http://aws.amazon.com/ec2/\n15. http://www.java.com/en/\n16 http://www.mysql.com/\n17. http://www.sun.com/\n", "date": "2010-03-04 14:33:33", "action": 0, "post": 135}}, {"pk": 188, "model": "server.postrevision", "fields": {"author": 63, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "Unix, Perl and MySQL are programming skills that you need to master (I can think of people who would also say Java, Javascript, CSS, etc.). The best way to master the art of programming is to spend as much time as possible reading and writing source code. Some people think Perl is doomed. This is not true in the bioinformatics world. In part due to legacy and in part to the flexibility it provides, Perl is still the language of choice for many biohackers. Perl is used to construct 1) the back end of web applications, 2) pipelines and workflows and 3) quick and dirty scripts for parsing and calling other programs.\n\nYou will also need to be familiar with projects like R and Bioconductor, since a lot of the work will involve providing the computational infrastructure for analyzing data. In addition, you\u2019ll need to know about data formats (fasta, sbml, mmcif\u2026), software toolkits and libraries (Paup, Phylip, EMBOSS, BioPerl\u2026), databases (Ensembl, InterPro, PDB, KEGG\u2026), webservers and portals (Pubmed, ISCB).\n\nFinally keep in mind best practices (like refraining from reinventing the wheel), but above all, give yourself the time to enjoy the learning process. Getting to the top usually takes longer than staying at the top; so what\u2019s the point if you haven\u2019t enjoyed the trip?", "date": "2010-03-04 14:36:29", "action": 0, "post": 136}}, {"pk": 189, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "short aligner sequence short", "title": "What methods do you use for short read mapping?", "content": "When it comes to short read mapping there seemingly is no shortage of methods or software to choose from. Yet in practice we found that some published methods did now work at all, others exhibited suboptimal behaviors. \n\n - What short read mappers do you use? \n - How many reads do you need align and what is the size of the genome that you align to? \n - What are the typical computational resources: parallel processes/CPU/memory required for the completion of the task?\n - What is your overall assessment of the procedure: easy, tedious, fun?\n\nNote: we're primarily looking to hear of your first hand, personal experiences with any given tool.\n", "date": "2010-03-04 14:40:30", "action": 0, "post": 137}}, {"pk": 190, "model": "server.postrevision", "fields": {"author": 63, "tag_string": "best places subjective bioinformatics", "title": "What is the best place in the world to do Bioinformatics?", "content": "I guess the best place would need to:\n\n - Have a critical mass of scientists\n - Be a world leading site for its reputation in science\n - Have well known projects\n - Good facilties\n - Good pay/Well funded\n - Leading Technology Provider\n\n ", "date": "2010-03-04 14:54:54", "action": 0, "post": 138}}, {"pk": 191, "model": "server.postrevision", "fields": {"author": 6, "tag_string": "sequencing genomics", "title": "state of computational geomics", "content": "The other day on facebook, I posted this link and some of my friend started discussing about this article. \n\n[It's \"Watson Meets Moore\" as Ion Torrent founder Jonatha Rothberg introduces post-light semiconductor sequencing.][1] \n\n\nfew comments from my friends\n\nKrishna : \"I dont understand this rat race for next gen sequencing. While its true that a cheaper and faster sequencing technology would revolutionalize personal genomics, its more important to develop effective algorithms that could make sense of the zillions of data that would be generated. We do have hundreds of organisms sequenced, but still dont seem to understand a bit of the complexity of the genome!!\"\n\n[Abhishek Tiwari][2]\n@Krishna I could not agree more. People think by commoditizing the genome sequencing some day miracle will happen and we will be able to understand the complexity of Genome. I am afraid we are going to lost in data without any clue what we are looking for. See this in other way, diverting to much funding in these sequencing projects makes it very hard to sustain to bioinformatics research. \n\n\n  [1]: http://bit.ly/9YIW7k\n  [2]: http://biostar.stackexchange.com/users/65/abhishek-tiwari\n\nWe were unison in observation that computational genomics is not at par with it's experimental counter part at the moment. I was wondering what do you guys think about it and how can we make sure that we don't loose the \"interesting information\" coming out of the sequencing projects ?", "date": "2010-03-04 14:57:03", "action": 0, "post": 139}}, {"pk": 192, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: What methods do you use for short read mapping?", "content": "I implemented my personnal suffix-array algorithm ( = **perfect match** ) because **bowtie** was too slow for **my needs**. I wrote about it here : [http://plindenbaum.blogspot.com/2010/01/elementary-school-for-bioinformatics.html][1].\n\nIt aligned all the 60 mers for each side of each SNPs (17E6 * 2 sequences) from dbSNP in about ~12H00.\n\n\n  [1]: http://plindenbaum.blogspot.com/2010/01/elementary-school-for-bioinformatics.html", "date": "2010-03-04 14:58:13", "action": 0, "post": 140}}, {"pk": 193, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: What methods do you use for short read mapping?", "content": "A group in my institute has developed a tool called [GEM][1] for mapping short reads and in general working with next gen sequencing data, like mapping cDNAs, find splicing isoforms, etc... I never used it directly but I have attended some talks on this and it seems convincing. \n\nIn particular, to map short reads you should use the tool [gem_mapper][2].\n\n\n  [1]: http://sourceforge.net/apps/mediawiki/gemlibrary/index.php?title=The_GEM_library\n  [2]:  http://sourceforge.net/apps/mediawiki/gemlibrary/index.php?title=Gem_mapper_man_page", "date": "2010-03-04 14:59:37", "action": 0, "post": 141}}, {"pk": 194, "model": "server.postrevision", "fields": {"author": 63, "tag_string": "best subjective bioinformatics", "title": "What is the best place in the world to do Bioinformatics?", "content": "I guess the best place would need to:\n\n - Have a critical mass of scientists\n - Be a world leading site for its reputation in science\n - Have well known projects\n - Good facilties\n - Good pay/Well funded\n - Leading Technology Provider\n\n ", "date": "2010-03-04 15:07:41", "action": 0, "post": 138}}, {"pk": 195, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "snp genotyping pathways genes mining", "title": "Mapping SNPs to Pathways", "content": "Hi all,\ngiven a set of **SNPs**, what would be your favorite way to find theirs related **pathways**/ **diseases** ?\n\nThanks\n", "date": "2010-03-04 15:08:48", "action": 0, "post": 142}}, {"pk": 196, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: What methods do you use for short read mapping?", "content": "For mapping reads obtained from the [SOLiD platform][1] we use [SHRiMP][2];\n\n - 47 million 50bp long reads in colorspace\n - We are aligning against the human genome, ~ 3 billion bases\n - A typical runtime is 12 hours for every 1 million reads. We split the 47 million reads into about 25 datasets and run them in parallel. SHRiMP's memory use depends on the size of the reads that needs to align: approx 1.6 GB per 1 million reads.\n - Overall we process the entire dataset in about a day\n - We like using the SHRiMP program. It is simple to use, has very clear documentation and no other dependencies. Importantly it easy to teach people how to use it. On the other hand it is probably a slower method than many others.\n\n  [1]: http://www3.appliedbiosystems.com/AB_Home/applicationstechnologies/SOLiD-System-Sequencing-B/index.htm\n  [2]: http://compbio.cs.toronto.edu/shrimp/", "date": "2010-03-04 15:13:53", "action": 0, "post": 143}}, {"pk": 197, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: Experiences with cloud computing in bioinformatics", "content": "We've had a couple of Amazon education grants to try out EC2 here, and the service is very impressive. However, it would be extremely expensive to use it as a long-term replacement for our local grid service (which does have its own limitations, but is at least effectively free at the point of delivery) or clusters (in which a considerable amount of capital has already been invested). I think for the amount of grunt work we do, and particularly for the amount of data that needs to be shunted around, cloud computing is not quite there yet.", "date": "2010-03-04 15:14:13", "action": 0, "post": 144}}, {"pk": 198, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: What is the best place in the world to do Bioinformatics?", "content": "From a UK perspective, Cambridge has to be up there. I'm pretty sure it ticks all of your points, and you can't get much better for density of bioinformaticians than the [Genome Campus][1] in Hinxton.\n\n\n  [1]: http://www.wellcome.ac.uk/Achievements-and-Impact/Initiatives/UK-biomedical-science/Genome-Campus-and-Sanger-Institute/WTD003482.htm", "date": "2010-03-04 15:19:58", "action": 0, "post": 145}}, {"pk": 199, "model": "server.postrevision", "fields": {"author": 63, "tag_string": "", "title": "A: Mapping SNPs to Pathways", "content": "I would use DAS -- Distributed Annotated System to retrieve all genes/phenotypes associated to a specific SNP.\n\nDAS is a webservice for decentralised annotation that provides an esy protocol to retrieve features providing an url.\n\nFor example, retrieve me all OMIM genes in chromosome 18 between base pair 1 and 1000000\n\nhttp://das.sanger.ac.uk/das/ens_36_omim_genes/features?segment=18:1,1000000\n\nMore on DAS [here][1]\n \n\n\n  [1]: http://www.biodas.org/wiki/Main_Page", "date": "2010-03-04 15:20:35", "action": 0, "post": 146}}, {"pk": 200, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "", "title": "A: Looking for a 'Hello world\" plugin for Taverna.", "content": "Pierre, I feel your pain; Maven is not quite my friend either... Taverna is a really modular, and comes with very many dependencies... these are recursively defined and resolved using Maven... I'd love to build a plugin without it too, but never dared setting up such a system myself :)", "date": "2010-03-04 15:22:42", "action": 0, "post": 147}}, {"pk": 201, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "", "title": "A: What is the best way to share scripts between members of a lab?", "content": "I can very much recommend [MyExperiment.org][1]. You can set up a category for a certain class of scripts, as the system has no limitation to Taverna 'scripts' anymore. MyExperiment is a true social services, provides tagging, setting up groups, etc.\n\n\n  [1]: http://www.myexperiment.org/", "date": "2010-03-04 15:25:23", "action": 0, "post": 148}}, {"pk": 202, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "meta bioinformatics", "title": "How far does bioinformatics go?", "content": "Being a metabolomics, and drug discovery dude, I consider myself a bioinformatician (well, I also consider myself a chemist, cheminformatician, statistician, and chemometrician, but that's not relevant to my question).\n\nHowever, some peers see bioinformatics restricted to stuff to do with DNA sequences, that is genomics. So, from a historical and literature perspective, *what is bioinformatics*? Please do back up your answer and argument with citations to primary literature.", "date": "2010-03-04 15:34:11", "action": 0, "post": 149}}, {"pk": 203, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: State of computational genomics", "content": "I think every advance in technology creates new opportunities for those who know computation. ", "date": "2010-03-04 15:36:35", "action": 0, "post": 150}}, {"pk": 204, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "sequencing genomics", "title": "State of computational geomics", "content": "The other day on facebook, I posted this link and some of my friend started discussing about this article. \n\n[It's \"Watson Meets Moore\" as Ion Torrent founder Jonatha Rothberg introduces post-light semiconductor sequencing.][1] \n\n\nfew comments from my friends\n\nKrishna : \"I dont understand this rat race for next gen sequencing. While its true that a cheaper and faster sequencing technology would revolutionalize personal genomics, its more important to develop effective algorithms that could make sense of the zillions of data that would be generated. We do have hundreds of organisms sequenced, but still dont seem to understand a bit of the complexity of the genome!!\"\n\n[Abhishek Tiwari][2]\n@Krishna I could not agree more. People think by commoditizing the genome sequencing some day miracle will happen and we will be able to understand the complexity of Genome. I am afraid we are going to lost in data without any clue what we are looking for. See this in other way, diverting to much funding in these sequencing projects makes it very hard to sustain to bioinformatics research. \n\n\n  [1]: http://bit.ly/9YIW7k\n  [2]: http://biostar.stackexchange.com/users/65/abhishek-tiwari\n\nWe were unison in observation that computational genomics is not at par with it's experimental counter part at the moment. I was wondering what do you guys think about it and how can we make sure that we don't loose the \"interesting information\" coming out of the sequencing projects ?", "date": "2010-03-04 15:38:18", "action": 0, "post": 139}}, {"pk": 205, "model": "server.postrevision", "fields": {"author": 73, "tag_string": "", "title": "A: What methods do you use for short read mapping?", "content": "I have used tophat (which also calls bowtie). It seemed pretty straightforward, I'm not sure I would call it \"fun\", but I think tophat does a good job providing useful output formats. Other people around here use Eland.\n\nI was aligning 60-mer reads - 15-20 million per lane? \n\nThis was to the mouse genome, so about 2.7 gigabases.\n\nI don't know what computational resources were required, but I was running it on a server with 96 gigs of RAM and 16 cpus. Much more than I needed.\n\nI'm actually not sure how long it took per lane, I just set it up and then left it while I worked on other stuff for awhile. ", "date": "2010-03-04 15:54:25", "action": 0, "post": 151}}, {"pk": 206, "model": "server.postrevision", "fields": {"author": 73, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "I have found useful: Perl, MySQL, Unix commands and shell scripts, R, and knowing some web stuff (HTML/php). \n\nIt's good to be familiar with a variety of tools, so you can choose the right one for the problem (and not force a tool to do something it's not really designed for, just because you don't know how to do it any other way).\n\nIf I was starting out, I might consider something like ruby or python instead of perl, but maybe not. There's a lot of code out there already written in perl.", "date": "2010-03-04 16:07:04", "action": 0, "post": 152}}, {"pk": 207, "model": "server.postrevision", "fields": {"author": 73, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "I generally use a simple shell script if I have multiple commands or scripts to run. I also try to make a notes.txt file to remind myself of what I did. Doesn't take long and comes in handy. \n\nThings that you didn't plan to re-use get re-used all the time, in my experience...", "date": "2010-03-04 16:10:28", "action": 0, "post": 153}}, {"pk": 208, "model": "server.postrevision", "fields": {"author": 73, "tag_string": "", "title": "A: How to get the sequence of a genomic region from UCSC?", "content": "Just click \"DNA\" at the top of the screen.", "date": "2010-03-04 16:12:31", "action": 0, "post": 154}}, {"pk": 209, "model": "server.postrevision", "fields": {"author": 73, "tag_string": "", "title": "A: Gene ID conversion tool", "content": "If you have just a few, I just saw someone use the R package [BioIDMapper][1] and it seemed kind of neat. But it's slow.\n\n\n  [1]: http://cran.r-project.org/web/packages/BioIDMapper/", "date": "2010-03-04 16:38:10", "action": 0, "post": 155}}, {"pk": 210, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "meta bioinformatics subjective", "title": "How far does bioinformatics go?", "content": "Being a metabolomics, and drug discovery dude, I consider myself a bioinformatician (well, I also consider myself a chemist, cheminformatician, statistician, and chemometrician, but that's not relevant to my question).\n\nHowever, some peers see bioinformatics restricted to stuff to do with DNA sequences, that is genomics. So, from a historical and literature perspective, *what is bioinformatics*? Please do back up your answer and argument with citations to primary literature.", "date": "2010-03-04 16:38:30", "action": 0, "post": 149}}, {"pk": 211, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "meta bioinformatics", "title": "How far does bioinformatics go?", "content": "Being a metabolomics, and drug discovery dude, I consider myself a bioinformatician (well, I also consider myself a chemist, cheminformatician, statistician, and chemometrician, but that's not relevant to my question).\n\nHowever, some peers see bioinformatics restricted to stuff to do with DNA sequences, that is genomics. So, from a historical and literature perspective, *what is bioinformatics*? Please do back up your answer and argument with citations to primary literature.", "date": "2010-03-04 16:41:33", "action": 0, "post": 149}}, {"pk": 212, "model": "server.postrevision", "fields": {"author": 78, "tag_string": "", "title": "A: Looking for a 'Hello world\" plugin for Taverna.", "content": "Stop being silly and just learn Maven.\n\nIt's not that hard and once you get to know it you'll never want to go back to finding and downloading jars, settings up the classpath, etc..", "date": "2010-03-04 18:59:06", "action": 0, "post": 156}}, {"pk": 213, "model": "server.postrevision", "fields": {"author": 81, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "I find that a healthy knowledge of R & Bioconductor tools has been the most helpful.  In my work I also write a large amount of Python code.  Beyond those, having a strong Unix background - complete with scripts and tools such as sed & awk have been very valuable.  Knowledge of HTML (don't need to be a javascript wiz, just the ability to make basic tables & such) and SQL are also plusses.", "date": "2010-03-04 19:59:41", "action": 0, "post": 157}}, {"pk": 214, "model": "server.postrevision", "fields": {"author": 81, "tag_string": "", "title": "A: Which operating system do you prefer for bioinformatics?", "content": "In my group, all primary computational folks (currently, a new person will be bucking this trend and going with OSX) have linux desktops that they have root access to.  Most of us have a secondary machine which varies between windows & Mac OSX for various side tasks.  Beyond that we have several linux based servers that people use as well (via SSH).  The very few people who do any sort of computational work w/o a linux desktop ssh into these servers to do all of their real work.", "date": "2010-03-04 20:02:58", "action": 0, "post": 158}}, {"pk": 215, "model": "server.postrevision", "fields": {"author": 81, "tag_string": "", "title": "A: Recommend easy to use microarray clustering software", "content": "One thing you might look at is the Broad Institute's <a href=\"https://www.broad.harvard.edu/cancer/software/genepattern/\">genepattern</a> software.  It can be clunky at times but it will do most common tasks in a fairly straightforward fashion.", "date": "2010-03-04 20:04:45", "action": 0, "post": 159}}, {"pk": 216, "model": "server.postrevision", "fields": {"author": 81, "tag_string": "", "title": "A: What is the best way to share scripts between members of a lab?", "content": "I'm the only person in my group who uses software control, other people are averse to it.  What we've ended up with is a by-convention approach within our large NAS block (which everyone mounts).  Any code which is deemed to be generally useful is essentially \"checked in\" to a particular directory tree w/ a designated format for keeping track of versioning, builds (where appropriate), etc.  Code which is specific to a project, dataset, etc is stored in a designated manner within the appropriate directory trees for that project, dataset, etc.", "date": "2010-03-04 20:08:07", "action": 0, "post": 160}}, {"pk": 217, "model": "server.postrevision", "fields": {"author": 83, "tag_string": "biostar", "title": "Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "content": "Hi,\n\nI am trying to implement protein pairwise sequence alignment using \"Global Alignment\" algorithm by 'Needleman -Wunsch'. I am using VB.NET. \n\nI am not clear about how to include 'Blosum62 Matrix' in my source code to do the scoring or to fill the two-dimensional matrix?\n\nI have googled and found that most people suggested to use flat file which contains the standard 'Blosum62 Matrix'. Does it mean that I need to read from this flat file and fill my coded \"Blosum62 Martrix' ?\n\nAlso, the other approach could be is to use some mathematical formula and include it in your programming logic to construct 'Blosum62 Matrix'. But not very sure about this option.\n\nAny ideas or insights are appreciated.\n\nAlso, is there any pesudo algorithm to do the protein pairwise alignment using Global available? I tired to find the basic steps of the alogrithm online but no luck so I am planning to do the same steps as I did for the global pairwise alignment of Nucleotides\n\nThanks.\n", "date": "2010-03-04 20:37:52", "action": 0, "post": 161}}, {"pk": 218, "model": "server.postrevision", "fields": {"author": 84, "tag_string": "multiplealignment alignment dna", "title": "repeat subunit based multiple alignment of DNA", "content": "I want to align over 50 sequences of a polymorphic stretch of promoter DNA. The sequences consist of repeats of selections from 174 incompletely homologous subunits (14-31 subunits per sequence), the subunits are 18-29 bases in length, with a four-part internal structure.  I wish the alignment to be guided by the subunits more than by unstructured primary DNA sequence. Is there any software out there that can do this?\n\nThank you.", "date": "2010-03-04 20:49:12", "action": 0, "post": 162}}, {"pk": 219, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "content": "There are no mathematical formulas for this.\n\nWhat you need is a data structure that you can use to retrieve the score for substitutions that you observe. It could be as simple as as hash map. For example in Python you could initialize it like so:\n\n    blosum = dict()\n    blosum['Ala'] = dict()\n    blosum['Ala']['Ala'] = 4\n    blosum['Ala']['Arg'] = -1\n    blosum['Ala']['Asn'] = -2 \n    ... etc ...\n\nOf course you would not need to initialize it by hand, the information should be read from a file, that way you can load different scoring matrices. Later during alignment when you observe an Ala -> Arg substitution you could retrieve the value as:\n\n    blosum['Ala']['Arg']\n\nUse the corresponding data structure from you programming language. \n\n", "date": "2010-03-04 21:28:09", "action": 0, "post": 163}}, {"pk": 220, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: State of computational genomics", "content": "I agree that there is a bit of lag between the advancement of sequencing technologies (physico-chemical point of view) and the computational requirements to actually take advantage of these advances... \n\nBut is it really a problem?\n\n  - All these technologies have strengths and weaknesses, so it's good that there are different technologies.\n  - The processing of the data will eventually come around to a mature state.\n  - The deluge of data is certainly not delved into yet, but would we even imagine how to do so if the data were not already available?\n  - We are doing science, not selling cars: we need to be at the forefront of any and all advancements and not hold on to old vintage tech just because we \"know\" how to process it (or how to make money with it, e.g. old combustion vs. electrical engines).\n\nAs for your last question, about how to make sure we don't loose the \"interesting information\" coming out of the sequencing projects, well I'd say we aren't loosing anything since the raw data is well preserved in databanks! And concerning future discoveries from that data, you can't loose what you haven't found yet ;)\n\nTo sum up: advances are good, rat-race is good, lots of poorly understood data means we've got lots of work to do! And since I like what I do, I'm happy I won't have to go into another field of research ;)\n\nForward the Foundation!", "date": "2010-03-04 22:10:31", "action": 0, "post": 164}}, {"pk": 221, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "multiplealignment alignment dna", "title": "Repeat subunit based multiple alignment of DNA", "content": "I want to align over 50 sequences of a polymorphic stretch of promoter DNA. The sequences consist of repeats of selections from 174 incompletely homologous subunits (14-31 subunits per sequence), the subunits are 18-29 bases in length, with a four-part internal structure.  I wish the alignment to be guided by the subunits more than by unstructured primary DNA sequence. Is there any software out there that can do this?\n\nThank you.", "date": "2010-03-04 22:37:28", "action": 0, "post": 162}}, {"pk": 222, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "content": "There are no mathematical formulas for this.\n\nWhat you need is a data structure that you can use to retrieve the score for substitutions that you observe. It could be as simple as as hash map. For example in Python you could initialize it like so:\n\n    blosum = dict()\n    blosum['Ala'] = dict()\n    blosum['Ala']['Ala'] = 4\n    blosum['Ala']['Arg'] = -1\n    blosum['Ala']['Asn'] = -2 \n    ... etc ...\n\nOf course you would not need to initialize it by hand, the information should be read from a file, that way you can load different scoring matrices. Later during alignment when you observe an Ala -> Arg substitution you could retrieve the value as:\n\n    blosum['Ala']['Arg']\n\nUse the corresponding data structure from your programming language to build the same construct.\n\n", "date": "2010-03-04 22:39:55", "action": 0, "post": 163}}, {"pk": 223, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "sequencing genomics", "title": "State of computational genomics", "content": "The other day on facebook, I posted this link and some of my friend started discussing about this article. \n\n[It's \"Watson Meets Moore\" as Ion Torrent founder Jonatha Rothberg introduces post-light semiconductor sequencing.][1] \n\n\nfew comments from my friends\n\nKrishna : \"I dont understand this rat race for next gen sequencing. While its true that a cheaper and faster sequencing technology would revolutionalize personal genomics, its more important to develop effective algorithms that could make sense of the zillions of data that would be generated. We do have hundreds of organisms sequenced, but still dont seem to understand a bit of the complexity of the genome!!\"\n\n[Abhishek Tiwari][2]\n@Krishna I could not agree more. People think by commoditizing the genome sequencing some day miracle will happen and we will be able to understand the complexity of Genome. I am afraid we are going to lost in data without any clue what we are looking for. See this in other way, diverting to much funding in these sequencing projects makes it very hard to sustain to bioinformatics research. \n\n\n  [1]: http://bit.ly/9YIW7k\n  [2]: http://biostar.stackexchange.com/users/65/abhishek-tiwari\n\nWe were unison in observation that computational genomics is not at par with it's experimental counter part at the moment. I was wondering what do you guys think about it and how can we make sure that we don't loose the \"interesting information\" coming out of the sequencing projects ?", "date": "2010-03-04 22:45:08", "action": 0, "post": 139}}, {"pk": 224, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: What is the best place in the world to do Bioinformatics?", "content": "One annecdota: when I was looking for a place to start a phd, the first of my criterias to determine where I liked or not a place was the position of the monitors.\n\nI think that at least 90% of the bioinformaticians I have seen working simply sit down like monkeys in front of their monitor. I just don't understand this. I think that a place where somebody takes the time to correct behaviours like these is a good place to work; therefore, for me in the best place of the world to do bioinformatics, seats are comfortable and monitors are positioned at an ergonomic height.\n\nOther than this, I would like to work for the 1000genomes consortium. I don't know what the conditions and the quality of work are, but there is a lot of data there and it would be good to be the among the first persons to use it.", "date": "2010-03-04 22:58:49", "action": 0, "post": 165}}, {"pk": 225, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: How far does bioinformatics go?", "content": "Many people consider that bioinformatics began with the work of [Margaret Dayhoff][1] and the Pam matrixes. She compiled the first collection of protein sequences available at the time, publishing the Atlas of Protein Sequences and Structure, and she developed the first method to give a score to the similarity of two proteins, the PAM matrix.\n\nFor me, bioinformatics is everything that derived from Margaret Dayhoff's work. Compiling data and organizing it, developing tools to compare and handle informations, share the data with other people: if you read her biography you will find everything already there.\n\nAbout the modern bioinformatics, I like to think of it as the science of doing experiments or part of them using computers at least for some steps. I like to think that there is no difference between the work in a wet lab and that in front of computer: when you are planning a bioinformatics project, you also have to think of an hypothesis, on how to verify it and on which tests and controls you will use. This is probably something that many people didn't understand yet, as they think that bioinformatics is just 'writing programs' and the don't even know what a test is and how much time it takes to write a program. \n\n\n  [1]: http://www.answers.com/main/ntquery?s=margaret+dayhoff&gwp=13", "date": "2010-03-04 23:09:59", "action": 0, "post": 166}}, {"pk": 226, "model": "server.postrevision", "fields": {"author": 85, "tag_string": "", "title": "A: Mapping SNPs to Pathways", "content": "Biomart's Martview (http://www.biomart.org/biomart/martview/) will get you from SNP IDs to many gene/protein identifiers.  In a second step, Martview will also get you from gene IDs to GO Biological Process terms, but there are probably better tools that are specifically targeted toward pathways (KEGG, Reactome, WikiPathways, etc.)", "date": "2010-03-04 23:27:54", "action": 0, "post": 167}}, {"pk": 227, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "sequence alignment scoringmatix", "title": "Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "content": "Hi,\n\nI am trying to implement protein pairwise sequence alignment using \"Global Alignment\" algorithm by 'Needleman -Wunsch'. I am using VB.NET. \n\nI am not clear about how to include 'Blosum62 Matrix' in my source code to do the scoring or to fill the two-dimensional matrix?\n\nI have googled and found that most people suggested to use flat file which contains the standard 'Blosum62 Matrix'. Does it mean that I need to read from this flat file and fill my coded \"Blosum62 Martrix' ?\n\nAlso, the other approach could be is to use some mathematical formula and include it in your programming logic to construct 'Blosum62 Matrix'. But not very sure about this option.\n\nAny ideas or insights are appreciated.\n\nAlso, is there any pesudo algorithm to do the protein pairwise alignment using Global available? I tired to find the basic steps of the alogrithm online but no luck so I am planning to do the same steps as I did for the global pairwise alignment of Nucleotides\n\nThanks.\n", "date": "2010-03-05 00:14:06", "action": 0, "post": 161}}, {"pk": 228, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "bioinformatics hardware linux server", "title": "Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "content": "I am looking for an experienced Linux vendors to order a pre-installed CentOS/Ubuntu based webserver to host bioinformatics apps. Any suggestions or recommendations ? ", "date": "2010-03-05 04:20:04", "action": 0, "post": 168}}, {"pk": 229, "model": "server.postrevision", "fields": {"author": 71, "tag_string": "", "title": "A: State of computational genomics", "content": "I don't understand why this is a problem either.  You need to take that next step in data production and there is a lot of innovation going on there, as well as in the computational aspects of primary analysis.  The downstream innovation will happen (and it is based on some work that I am aware of).\n\nThe best innovation comes from rat races.  The market (in this case science, which fundamentally likes choice) will decide who gets to \"win\" and the algorithmic/analytics innovation will follow.", "date": "2010-03-05 04:40:36", "action": 0, "post": 169}}, {"pk": 230, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: What is your experience with the STRING (interactions) database?", "content": "I have used STRING in three projects and I am still using it for large scale [protein-protein interaction][1] data analysis. I have downloaded the data and worked on PPI data of 5 eukaryotic model organisms. I strongly recommend [STRING][2] if you are looking for prokaryotic PPI data or if you working on a global scale of PPI network analysis in any given organism. An exceptional advantage about STRING is that they derive the PPI information from multiple approaches, still every single single interaction is scored using a scoring scheme. This gives a higher advantage to filter specific interactions that you are interested in (for example you can get PPI from human that have a score >0.7 from experimental approach) and thus you can reduce the false positive rate. Another interesting aspect of [STRING][3] is the predicted interactions that are not reported in DIP or [HPRD][4] (If you are looking for literature curated, experimental annotations I strongly recommend HPRD ), this is something really exciting. You may get an interesting connections (not yet proven, though) that can lead you to new biological insights. The STRING team also maintain an interesting [blog][5], with the new releases, code-snippets, API detailes etc. \n\n\n  [1]: http://en.wikipedia.org/wiki/Protein%E2%80%93protein_interaction\n  [2]: http://string.embl.de/\n  [3]: http://string.embl.de/\n  [4]: http://www.hprd.org/\n  [5]: http://string-stitch.blogspot.com/", "date": "2010-03-05 04:48:15", "action": 0, "post": 170}}, {"pk": 231, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: Recommend easy to use microarray clustering software", "content": "I am currently using [Cluster 3.0][1] for clustering and [TreeView][2]. \n\n\n  [1]: http://bonsai.ims.u-tokyo.ac.jp/~mdehoon/software/cluster/software.htm\n  [2]: http://sourceforge.net/projects/jtreeview/", "date": "2010-03-05 04:54:16", "action": 0, "post": 171}}, {"pk": 232, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "", "title": "A: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "content": "Have you looked into the [Ubuntu Amazon EC2 server][1] thing?\n\n\n  [1]: http://www.ubuntu.com/cloud", "date": "2010-03-05 06:53:16", "action": 0, "post": 172}}, {"pk": 233, "model": "server.postrevision", "fields": {"author": 6, "tag_string": "protein structure", "title": "How to charecterize a residue in a protein based on it's ASA", "content": "How can we characterize a residue in a protein as a buried, exposed or intermediate based on it's accessible surface area(ASA) ? \n\nI came across a paper in which they are taking the ratio between the residue's ASA at a particular position to the maximum ASA observed for that residue in the whole protein.Further they apply a cut off on these ratios to characterize a residue as buried , exposed or intermediate. I am not sure about the basis of these cut offs.\n\ncan any one validate or provide a better approach for doing this ?  ", "date": "2010-03-05 09:56:57", "action": 0, "post": 173}}, {"pk": 234, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "content": "[System 76][1] is a vendor that *only* sells \"laptops, desktops, and servers with Ubuntu pre-installed, and is committed to the ideals of open source software.\" You can [compare the servers they sell][2]. They are also a [Ubuntu solution provider][3] so I am sure they can make you a system that fits your needs to a tee.\n\n\n  [1]: http://www.system76.com/\n  [2]: http://www.system76.com/index.php?cPath=29\n  [3]: http://www.ubuntu.com/partners/solutionprovider", "date": "2010-03-05 10:33:25", "action": 0, "post": 174}}, {"pk": 235, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: How far does bioinformatics go?", "content": "Bioinformatics is the field of science in which biology and computer science/information technology merge into a single discipline. The ultimate goal of the field is to enable the discovery of new biological insights as well as to create a global perspective from which unifying principles in biology can be discerned. \n\nListed below are some of the major events in bioinformatics over the last several decades. Most of the events in the list occurred long before the term, \"bioinformatics\", was coined.\n\nI've tagged each entry with either:\n\n - ***(BIO)*** if it was an event which was predominantly important in the field of biology.\n - ***(IT)*** if it was an event which was predominantly important in the field of computer science/information technology\n - ***(BIOINFO)*** if it was an event where biology and computer science/information technology truly merged and we can really speak from bioinformatics.\n\nAs you will notice, it becomes increasingly difficult/subjective to catalogue events with exclusively one tag, so the main point to take away is that in the course of bioinformatics history there has been a constant exchange of ideas between biology, computer science/information technology and bioinformatics.\n\n - **1665**  ***(BIO)*** Robert Hooke published Micrographia, described the cellular structure of cork. He also described microscopic examinations of fossilized plants and animals, comparing their microscopic structure to that of the living organisms they resembled. He argued for an organic origin of fossils, and suggested a plausible mechanism for their formation.\n\n - **1683** ***(BIO)*** Antoni van Leeuwenhoek discovered bacteria.\n\n - **1686** ***(BIO)*** John Ray, John Ray's in his book \"Historia Plantarum\" catalogued and described 18,600 kinds of plants. His book gave the first definition of species based upon common descent.\n\n - **1843** ***(BIO)*** Richard Owen elaborated the distinction of homology and analogy.\n\n - **1864** ***(BIO)*** Ernst Haeckel (H\u00e4ckel) outlined the essential elements of modern zoological classification.\n\n - **1865** ***(BIO)*** Gregory Mendel (1823-1884), Austria,  established the theory of genetic inheritance.\n\n - **1902** ***(BIO)*** The chromosome theory of heredity is proposed by Sutton and Boveri, working independently.\n\n - **1905** ***(BIO)*** The word \"genetics\" is coined by William Bateson.\n\n - **1913** ***(BIO)*** First ever linkage map created by Columbia undergraduate Alfred Sturtevant (working with T.H. Morgan).\n\n - **1930** ***(BIO)*** Tiselius, Uppsala University, Sweden, A new technique, electrophoresis, is introduced by Tiselius for separating proteins in solution. \"The moving-boundary method of studying the electrophoresis of proteins\" (published in Nova Acta Regiae Societatis Scientiarum Upsaliensis, Ser. IV, Vol. 7, No. 4)\n\n - **1946** ***(BIO)*** Genetic material can be transferred laterally between bacterial cells, as shown by Lederberg and Tatum.\n\n - **1951** ***(BIO)*** Pauling and Corey propose the structure for the alpha-helix and beta-sheet (Proc. Natl. Acad. Sci. USA, 27: 205-211, 1951; Proc. Natl. Acad. Sci. USA, 37: 729-740, 1951).\n\n - **1952** ***(BIO)*** Alfred Day Hershey and Martha Chase proved that the DNA alone carries genetic information. This was proved on the basis of their bacteriophage research.\n\n - **1953** ***(BIO)*** Watson and Crick propose the double helix model for DNA based on x-ray data obtained by Franklin and Wilkins (Nature, 171: 737-738, 1953).\n\n - **1954** ***(BIO)*** Perutz's group develop heavy atom methods to solve the phase problem in protein crystallography.\n\n - **1955** ***(BIO)*** The sequence of the first protein to be analyzed, bovine insulin, is announced by F. Sanger.\n\n - **1958** ***(IT)*** The Advanced Research Projects Agency (ARPA) is formed in the US\n\n - **1958** ***(IT)*** The first integrated circuit is constructed by Jack Kilby at Texas Instruments.\n\n - **1961** ***(BIO)*** Sidney Brenner, Fran\u00e7ois Jacob, Matthew Meselson, identify messenger RNA\n\n - **1962** ***(BIO)*** Pauling's theory of molecular evolution\n\n - **1965** ***(BIO)*** Margaret Dayhoff's Atlas of Protein Sequences\n\n - **1968** ***(IT)*** Packet-switching network protocols are presented to ARPA\n\n - **1969** ***(IT)*** The ARPANET is created by linking computers at Stanford, UCSB, The University of Utah and UCLA.\n\n - **1970** ***(BIOINFO)*** The details of the Needleman-Wunsch algorithm for sequence comparison are published.\n\n - **1971** ***(IT)*** Ray Tomlinson (BBN) invents the email program.\n\n - **1972** ***(BIO)*** The first recombinant DNA molecule is created by Paul Berg and his group.\n\n - **1973** ***(IT)*** Robert Metcalfe receives his Ph.D. from Harvard University. His thesis describes Ethernet.\n\n - **1973** ***(BIOINFO)*** The Brookhaven Protein Data Bank is announced (Acta. Cryst. B, 1973, 29: 1746).\n\n - **1974** ***(IT)*** Charles Goldfarb invents SGML (Standardized General Markup Language).\n\n - **1974** ***(IT)*** Vint Cerf and Robert Kahn develop the concept of connecting networks of computers into an \"internet\" and develop the Transmission Control Protocol (TCP).\n\n - **1975** ***(BIO)*** E. M. Southern published the experimental details for the Southern Blot technique of specific sequences of DNA (J. Mol. Biol., 98: 503-517, 1975).\n\n - **1975** ***(IT)*** Microsoft Corporation is founded by Bill Gates and Paul Allen.\n\n - **1975** ***(BIO)*** Two-dimensional electrophoresis, where separation of proteins on SDS polyacrylamide gel is combined with separation according to isoelectric points, is announced by P. H. O'Farrell (J. Biol. Chem., 250: 4007-4021, 1975).\n\n - **1976** ***(IT)*** The Unix-To-Unix Copy Protocol (UUCP) is developed at Bell Labs.\n\n - **1977** ***(BIOINFO)*** Allan Maxam and Walter Gilbert (Harvard) and Frederick Sanger (U.K. Medical Research Council), report methods for sequencing DNA.\n\n - **1977** ***(BIOINFO)*** DNA sequencing and software to analyze it (Staden)\n\n - **1977** ***(BIOINFO)*** The full description of the Brookhaven PDB (http://www.pdb.bnl.gov) is published (Bernstein, F.C.; Koetzle, T.F.; Williams, G.J.B.; Meyer, E.F.; Brice, M.D.; Rodgers, J.R.; Kennard, O.; Shimanouchi, T.; Tasumi, M.J.; J. Mol. Biol., 1977, 112:, 535).\n\n - **1978** ***(IT)*** The first Usenet connection is established between Duke and the University of North Carolina at Chapel Hill by Tom Truscott, Jim Ellis and Steve Bellovin.\n\n - **1980** ***(BIOINFO)*** IntelliGenetics, Inc. founded in California. Their primary product is the IntelliGenetics Suite of programs for DNA and protein sequence analysis.\n\n - **1980** ***(BIO)*** The first complete gene sequence for an organism (FX174) is published. The gene consists of 5,386 base pairs which code nine proteins.\n\n - **1980** ***(BIO)*** W\u00fcthrich et. al. publish paper detailing the use of multi-dimensional NMR for protein structure determination (Kumar, A.; Ernst, R.R.; W\u00fcthrich, K.; Biochem. Biophys. Res. Comm., 1980, 95:, 1).\n\n - **1981** ***(IT)*** IBM introduces its Personal Computer to the market.\n\n - **1981** ***(BIOINFO)*** The Smith-Waterman algorithm for sequence alignment is published.\n\n - **1981** ***(BIO)*** The concept of a sequence motif (Doolittle)\n\n - **1982** ***(BIOINFO)*** GenBank Release 3 made public\n\n - **1982** ***(BIO)*** Genetics Computer Group (GCG) created as a part of the University of Wisconsin of Wisconsin Biotechnology Center. The company's primary product is The Wisconsin Suite of molecular biology tools.\n\n - **1982** ***(BIO)*** Phage lambda genome sequenced\n\n - **1983** ***(IT)*** Name servers are developed at the University of Wisconsin.\n\n - **1983** ***(BIOINFO)*** Sequence database searching algorithm (Wilbur-Lipman)\n\n - **1983** ***(IT)*** The Compact Disk (CD) is launched.\n\n - **1984** ***(IT)*** Jon Postel's Domain Name System (DNS) is placed on-line.\n\n - **1984** ***(IT)*** The Macintosh is announced by Apple Computer.\n\n - **1985** ***(BIOINFO)*** FASTP/FASTN: fast sequence similarity searching algorithm is published.\n\n - **1985** ***(BIO)*** The PCR reaction is described by Kary Mullis and co-workers.\n\n - **1986** ***(IT)*** NSFnet debuts.\n\n - **1986** ***(BIOINFO)*** The SWISS-PROT database is created by the Department of Medical Biochemistry of the University of Geneva and the European Molecular Biology Laboratory (EMBL).\n\n - **1986** ***(BIO)*** The term \"Genomics\" appeared for the first time to describe the scientific discipline of mapping, sequencing, and analyzing genes. The term was coined by Thomas Roderick as a name for the new journal.\n\n - **1987** ***(BIO)*** The physical map of e. coli is published (Y. Kohara, et. al., Cell 51: 319-337).\n\n - **1987** ***(BIO)*** The use of yeast artifical chromosomes (YAC) is described (David T. Burke, et. al., Science, 236: 806-812).\n\n - **1988** ***(IT)*** A new program, an Internet computer virus designed by a student, infects 6,000 military computers in the US.\n\n - **1988** ***(BIOINFO)*** Des Higgins and Paul Sharpe announce the development of CLUSTAL (Higgins, D.G.; Sharp, P.M. Fast and sensitive multiple sequence alignments on a microcomputer. Comput. Appl. Biosci. 1989, 5, 151-153; Higgins, D.G.; Sharp, P.M. CLUSTAL: a package for performing multiple sequence alignment on a microcomputer. Gene 1988, 73, 237-244.)\n\n - **1988** ***(IT)*** EMBnet network for database distribution\n\n - **1988** ***(BIO)*** National Center for Biotechnology Information (NCBI) created at NIH/NLM\n\n - **1988** ***(IT)*** Perl (Practical Extraction Report Language) is released by Larry Wall.\n\n - **1988** ***(BIOINFO)*** The FASTA algorithm for sequence comparison is published by Pearson and Lupman.\n\n - **1988** ***(BIO)*** The Human Genome Initiative is started (Commission on Life Sciences, National Research Council. Mapping and Sequencing the Human Genome, National Academy Press: Washington, D.C.), 1988.\n\n - **1988** ***(BIO)*** The National Center for Biotechnology Information (NCBI) is established at the National Cancer Institute.\n\n - **1990** ***(BIOINFO)*** BLAST: fast sequence similarity searching (Altschul, et. al.) is implemented.\n\n - **1990** ***(IT)*** The HTTP 1.0 specification is published. Tim Berners-Lee publishes the first HTML document.\n\n - **1991** ***(BIO)*** EST: expressed sequence tag sequencing\n\n - **1991** ***(IT)*** Linus Torvalds announces a Unix-Like operating system which later becomes Linux.\n\n - **1991** ***(BIO)*** Myriad Genetics, Inc. is founded in Utah. The company's goal is to lead in the discovery of major common human disease genes and their related pathways. The Company has discovered and sequenced, with its academic collaborators, the following major genes: BRCA1, BRCA2, CHD1, MMAC1, MMSC1, MMSC2, CtIP, p16, p19, and MTS2.\n\n - **1991** ***(BIO)*** The creation and use of expressed sequence tags (ESTs) is described (J. Craig Venter, et. al., Science, 252: 1651-1656).\n\n - **1991** ***(IT)*** The research institute in Geneva (CERN) announces the creation of the protocols which make-up the World Wide Web.\n\n - **1992** ***(BIO)*** Mel Simon and coworkers announce the use of BACs for cloning.\n\n - **1992** ***(BIO)*** The Institute for Genomic Research (TIGR) is established by Craig Venter.\n\n - **1993** ***(BIO)*** Affymetrix begins independent operations in Santa Clara, California\n\n - **1993** ***(BIO)*** Sanger Centre, Hinxton, UK\n\n - **1994** ***(BIOINFO)*** EMBL European Bioinformatics Institute, Hinxton, UK\n\n - **1994** ***(IT)*** Netscape Comminications Corporation founded and releases Navigator, the commercial version of NCSA's Mozilla.\n\n - **1994** ***(BIOINFO)*** The PRINTS database of protein motifs is published by Attwood and Beck.\n\n - **1995** ***(BIO)*** First bacterial genomes completely sequenced\n\n - **1995** ***(IT)*** Microsoft releases version 1.0 of Internet Explorer.\n\n - **1995** ***(IT)*** Sun releases version 1.0 of Java. Sun and Netscape release version 1.0 of JavaScript\n\n - **1995** ***(BIO)*** The Haemophilus influenzea genome (1.8 Mb) is sequenced.\n\n - **1995** ***(BIO)*** The Mycoplasma genitalium genome is sequenced.\n\n - **1995** ***(IT)*** Version 1.0 of Apache is released.\n\n - **1996** ***(BIO)*** Affymetrix produces the first commercial DNA chips.\n\n - **1996** ***(BIO)*** Oxford Molecular Group acquires the MacVector product from Eastman Kodak.\n\n - **1996** ***(BIOINFO)*** Structural Bioinformatics, Inc. founded in San Diego, CA.\n\n - **1996** ***(BIO)*** The Prosite database is reported by Bairoch, et.al.\n\n - **1996** ***(BIO)*** The genome for Saccharomyces cerevisiae (baker's yeast, 12.1 Mb) is sequenced.\n\n - **1996** ***(IT)*** The working draft for XML is released by W3C.\n\n - **1996** ***(BIO)*** Yeast genome completely sequenced\n\n - **1997** ***(BIOINFO)*** LION bioscience AG founded as an integrated genomics company with strong focus on bioinformatics. The company is built from IP out of the European Molecular Biology Laboratory (EMBL), the European Bioinformatics Institute (EBI), the German Cancer Research Center (DKFZ), and the University of Heidelberg.\n\n - **1997** ***(BIOINFO)*** PSI-BLAST\n\n - **1997** ***(BIO)*** The genome for E. coli (4.7 Mbp) is published.\n\n - **1998** ***(BIO)*** Craig Venter forms Celera in Rockville, Maryland.\n\n - **1998** ***(BIOINFO)*** Inpharmatica, a new Genomics and Bioinformatics company, is established by University College London, the Wolfson Institute for Biomedical Research, five leading scientists from major British academic centers and Unibio Limited.\n\n - **1998** ***(BIOINFO)*** The Swiss Institute of Bioinformatics is established as a non-profit foundation.\n\n - **1998** ***(BIO)*** The genomes for Caenorhabditis elegans and baker's yeast are published.\n\n - **1998** ***(BIO)*** Worm (multicellular) genome completely sequenced\n\n - **1998** ***(BIO)*** deCode genetics publishes a paper that described the location of the FET1 gene, which is responsible for familial essential tremor, on chromosome 13 (Nature Genetics).\n\n - **1999** ***(BIO)*** Fly genome completely sequenced\n\n - **1999** ***(BIO)*** deCode genetics maps the gene linked to pre-eclampsia as a locus on chromosome 2p13.\n\n - **2000** ***(BIO)*** Jeong H, Tombor B, Albert R, Oltvai ZN, Barabasi AL. The large-scale organization of metabolic networks. Nature 2000 Oct 5;407(6804):651-4, PubMed\n\n - **2000** ***(BIO)*** The A. thaliana genome (100 Mb) is secquenced.\n\n - **2000** ***(BIO)*** The D. melanogaster genome (180Mb) is secquenced.\n\n - **2000** ***(BIO)*** The genome for Pseudomonas aeruginosa (6.3 Mbp) is published.\n\n - **2001** ***(BIO)*** The human genome (3,000 Mbp) is published.\n\n - **2002** ***(BIO)*** An international sequencing consortium published the full genome sequence of the common house mouse (2.5 Gb). Whitehead Institute researcher Kerstin Lindblad-Toh is the lead author on the paper; her institution lead the project and contributed about half of the sequence. Washington University School of Medicine delivered about 30 percent of the sequence, and created the mouse BAC-based physical map. The Wellcome Trust Sanger Institute in the UK was the third major partner. Other institutes in the International Mouse Genome Sequencing Consortium included the University of California at Santa Cruz, the Institute for Systems Biology, and the University of Geneva.\n\n - **2004** ***(BIO)*** The draft genome sequence of the brown Norway laboratory rat, Rattus norvegicus, was completed by the Rat Genome Sequencing project Consortium. The paper appears in the April 1 edition of Nature.\n\nCompiled from different sources, including: \n\n - A [Short History of Bioinformatics][1], by Allen B. Richon\n - [History of Bioinformatics][2]\n - [Bioinformatics Milestones][3]\n - [History, Origin & Bioinformatics Events][4] \n\n\n  [1]: http://www.netsci.org/Science/Bioinform/feature06.html\n  [2]: http://www.roseindia.net/bioinformatics/history_of_bioinformatics.shtml\n  [3]: http://www.ncbi.nlm.nih.gov/Education/BLASTinfo/milestones.html\n  [4]: http://www.cbclickbank.com/bioinformatics/history.htm", "date": "2010-03-05 12:31:43", "action": 0, "post": 175}}, {"pk": 236, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: Repeat subunit based multiple alignment of DNA", "content": "No idea how to do it exactly but I can think about two routes to investigate:\n\n* LASTZ has something called \"quantum DNA\":\n\nhttp://www.bx.psu.edu/miller_lab/dist/README.lastz-1.02.00/README.lastz-1.02.00.html#fmt_qdna\n\n* instead of using \"linear\" aligner go for graph based ones:\nPOA     http://bioinfo.mbi.ucla.edu/poa/\nAliWABA http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1538870/\n\n", "date": "2010-03-05 12:47:09", "action": 0, "post": 176}}, {"pk": 237, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: Which operating system do you prefer for bioinformatics?", "content": "I have no experience with them, but there are several Linux distributions out there that come preloaded with bioinformatics software.\n\nFor example:\n\n - **[biobuntu][1]** which comes preloaded with amapalign, biococoa, biomode, bioperl, biopython, biosquid, blast2, boxshade, chemtool, clustalw, clustalx, dialign, easychem, fastdnaml, fastlink, garlic, gchempaint, gcubin, gff2aplot, gff2ps, EMBOSS, gmt, gromacs, hmmer, ifeffit, ifrit, imview, kalign, leksbot, libbioruby, meltinggui, mipe, molphy, mozillabiofox, mpqc/support, mummer, muscle, mustang, ncbiepcr, ncbitoolsbin, ncbitoolsx11, njplot, openbabel, perlprimer, phylip, poa, polyxmass, primer3, probcons, proda, pybliographerA, rasmol, readseq, seaview, sibsim4, sigmaalignSimple, sim4, SixpackDisplay, tcoffeeMultiple, tigrglimmerGene, treepuzzleReconstruction, treetool, treeviewxDisplays, viewmol, wise, xbs, xdrawchem and xmakemol\n\n - **[Bio-Linux][2]**  a fully featured, powerful, configurable and easy to maintain bioinformatics workstation. Bio-Linux provides more than 500 bioinformatics programs on an Ubuntu Linux base. There is a graphical menu for bioinformatics programs, as well as easy access to the Bio-Linux bioinformatics documentation system and sample data useful for testing programs. You can also install Bio-Linux packages to handle new generation sequence data types.\n\n - The vision for **[Cloud BioLinux][3]** is to offer a base image of genome analysis resources for cloud computing platforms, such as Amazon EC2.  This Science as a Service model (ScaaS) will allow us to incorporate, develop and optimize life science software as well as supporting data sets on compute clouds.  This project is driven by the observation that commonly-used bioinformatics tools are hard to build and maintain, require high amounts of resources, or just too numerous to choose from.\n\n - **[BioBrew][4]** is a collection of open-source applications for life scientists and an in-house project at Bioinformatics.Org. The BioBrew Roll for Rocks can be used to create Rocks/BioBrew Linux, a distribution customized for both cluster and bioinformatics computing: it automates cluster installation, includes all the HPC software a cluster enthusiast needs, and contains popular bioinformatics applications.\n\n - **[Debian Med][5]** is a \"Debian Pure Blend\" with the aim to develop Debian into an operating system that is particularly well fit for the requirements for medical practice and research. The goal of Debian Med is a complete system for all tasks in medical care which is built completely on free software.\n\n\n  [1]: http://bicmku.in:8082/bioubuntu/\n  [2]: http://nebc.nox.ac.uk/tools/bio-linux/bio-linux-5.0\n  [3]: http://www.cloudbiolinux.com/\n  [4]: http://biobrew.bioinformatics.org/\n  [5]: http://www.debian.org/devel/debian-med/", "date": "2010-03-05 12:56:39", "action": 0, "post": 177}}, {"pk": 238, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "ensembl annotation genes", "title": "I was studying a gene but it disappeared in the latest ensembl release. What should I do now?", "content": "I am studying a set of genes involved in the same pathway, but this week, after looking at the new release of ensembl, I discovered that the gene was removed. What should I do now? There are references to this gene in several articles and the fact that it disappeared intrigues me - to which sequence these articles were referring to? Is it possible that the ensembl's curators have made an error?\n\ncheers", "date": "2010-03-05 13:06:24", "action": 0, "post": 178}}, {"pk": 239, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: I was studying a gene but it disappeared in the latest ensembl release. What should I do now?", "content": "The best course of action would be to contact the people (curators) who made the decision of removing that gene. Keep us posted on what they say, it might be an interesting tidbit about data evolution inside databases ;-0", "date": "2010-03-05 13:15:48", "action": 0, "post": 179}}, {"pk": 240, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: I was studying a gene but it disappeared in the latest ensembl release. What should I do now?", "content": "1. keep on using Ensembl Archive: http://www.ensembl.org/info/website/archives/index.html\n2. there is no general answer to question \"is gene X real one or it is an artifact removed from Ensembl\". \n3. you may check i.e. ESTs if they assemble into sensible transcript /compare few species on the genomic level watching for pseudogenes. \n\n", "date": "2010-03-05 13:21:15", "action": 0, "post": 180}}, {"pk": 241, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "bioinformatics books resources", "title": "Recommend your favorite bioinformatics books", "content": "I am looking for personal experiences and short opinions regarding bioinformatics books. \n\nSo far I have noticed the following trend: most books titled *Bioinformatics with Perl/Python/Java/R* etc end up being introductions into the programming language in question, often  only minor code examples are related to bioinformatics.\n\n**Help us find some good books!**\n\n*PS. If you are willing to write a standalone book review is even better. Please do so by creating a new question titled: \"Provide a book review for X\" then answer it with your own review.*", "date": "2010-03-05 13:30:44", "action": 0, "post": 181}}, {"pk": 242, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "Ok well I think I will just stick to R for now.  I do some work with BioConductor and have the following texts on my desk:\n\nBioinformatics and Computational Biology Solutions Using R and Bioconductor ([http://www.bioconductor.org/docs/mogr/][1]) is a good text to get to grips with common data processing tasks for microarray and proteomics analysis which covers QC, normalisation, one and two colour array data, and downstream data analysis.  It needs an update, some of the example code does not work with more modern BioConductor releases but it is still a useful resource.\n\nBioconductor Case Studies ([http://www.bioconductor.org/pub/biocases/][2]) focuses less on the specifics of the packages and more on the workflows of common bioinformatics analyses, including GSEA, machine learning, pulling data from remote resources, statistical modelling and visualisation.\n\nNeither of these books will teach you R however.  My general R reference is:\n\nR Programming for Bioinformatics [(http://www.bioconductor.org/pub/RBioinf/][3]) which tells you more about R than you probably ever want to (or care) to know.  Whilst it is aimed at a bioinformatics audience it does not skip it's role as a text primarily to teach you how to program in R\n\nIf youre looking for a tome that brings your statistics up to speed instead within the R framework then I have long had a copy of Introductory Statistics With R ([http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20][4]) it's not a long book by any means but will get you used to handling data and applying statistical tests in R.\n\n\n  [1]: http://www.bioconductor.org/docs/mogr/\n  [2]: http://www.bioconductor.org/pub/biocases/\n  [3]: (http://www.bioconductor.org/pub/RBioinf/\n  [4]: http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20", "date": "2010-03-05 13:39:58", "action": 0, "post": 182}}, {"pk": 243, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "bioinformatics books resources", "title": "Recommend your favorite bioinformatics books", "content": "I am looking for personal experiences and short opinions regarding bioinformatics books. \n\nSo far I have noticed the following trend: many books titled *Bioinformatics with Perl/Python/Java/R* etc end up being introductions into the programming language in question, often  only minor code examples are related to bioinformatics.\n\n**Help us find some good books!**\n\n*PS. If you are willing to write a standalone book review is even better. Please do so by creating a new question titled: \"Provide a book review for X\" then answer it with your own review.*", "date": "2010-03-05 13:43:56", "action": 0, "post": 181}}, {"pk": 244, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "Ok well I think I will just stick to R for now.  I do some work with BioConductor and have the following texts on my desk:\n\nBioinformatics and Computational Biology Solutions Using R and Bioconductor ([http://www.bioconductor.org/docs/mogr/][1]) is a good text to get to grips with common data processing tasks for microarray and proteomics analysis which covers QC, normalisation, one and two colour array data, and downstream data analysis.  It needs an update, some of the example code does not work with more modern BioConductor releases but it is still a useful resource.\n\nBioconductor Case Studies ([http://www.bioconductor.org/pub/biocases/][2]) focuses less on the specifics of the packages and more on the workflows of common bioinformatics analyses, including GSEA, machine learning, pulling data from remote resources, statistical modelling and visualisation.   It also benefits from being a more recent release than it's counterpart above.\n\nNeither of these books will teach you R however.  My general R programming reference is:\n\nR Programming for Bioinformatics [(http://www.bioconductor.org/pub/RBioinf/][3]) which tells you more about R than you probably ever want to (or care) to know.  Whilst it is aimed at a bioinformatics audience it does not skip it's role as a text primarily to teach you how to program in R.\n\nIf youre looking for a tome that brings your statistics up to speed instead within the R framework then I have long had a copy of Introductory Statistics With R ([http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20][4]) it's not a long book by any means but will get you used to handling data and applying statistical tests in R.\n\n\n  [1]: http://www.bioconductor.org/docs/mogr/\n  [2]: http://www.bioconductor.org/pub/biocases/\n  [3]: (http://www.bioconductor.org/pub/RBioinf/\n  [4]: http://www.amazon.co.uk/dp/0387790535/?tag=sollc-gb-20", "date": "2010-03-05 13:46:56", "action": 0, "post": 182}}, {"pk": 245, "model": "server.postrevision", "fields": {"author": 78, "tag_string": "protein sequence multiplealignment scoringmatix", "title": "Score protein variants based on frequency of AA in multiple sequence alignment", "content": "For reference, please read this excerpt from  \n**Human non-synonymous SNPs: server and survey**  \nVasily Ramensky, Peer Bork, and Shamil Sunyaev\n\n\n> *Profile analysis of homologous\n> sequences*. The amino acid replacement\n> may be incompatible with the spectrum\n> of substitutions observed at that\n> position in a family of homologous\n> proteins. PolyPhen identifies\n> homologues of the input sequences via\n> a BLAST (23) search of the NRDB\n> database. The set of aligned sequences\n> with sequence identity to the input\n> sequence in the range 30\u00b194%\n> (inclusive) is used by the new version\n> of the PSIC (position-specific\n> independent counts) software (24) to\n> calculate the so-called profile matrix\n> (http://strand.imb.ac.ru/PSIC/).\n> Elements of the matrix (pro- file\n> scores) are logarithmic ratios of the\n> likelihood of a given amino acid\n> occurring at a particular site to the\n> likelihood of this amino acid\n> occurring at any site (background\n> frequency). PolyPhen computes the\n> absolute value of the difference\n> between profile scores of both allelic\n> variants in the polymorphic position.\n> PolyPhen also shows the number of\n> aligned sequences at the query\n> position; this may be used to assess\n> the reliability of profile score\n> calculations.\n\nI'd like to calculate something similar (score variants based on frequency that AA in aligned sequences) to what's mentioned here programmatically, but I can't find any implementation of the above described system.\n\nDoes anyone know of a working implementation of this or something similar, that's available either in code or as a web service?\n\nOr should it is easy enough to implement something like this ourselves?", "date": "2010-03-05 14:37:21", "action": 0, "post": 183}}, {"pk": 246, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "I'll tell an acedote about the book that introduced me to bioinformatics. \n\nLet me preface that I have three big interests in my life: biology, computer science and sailing. The year was around 2000, and I had found the book [The New New Thing : A Silicon Valley Story][1] by [Michael M. Lewis][2]. It was about two of my interests: computer science and sailing.\n\nIt is the biography of [Jim Clark][3], a technology entrepreneur who is about to create his third, separate, billion-dollar company: first Silicon Graphics, then Netscape--and now Healtheon, a startup which he hopes will turn the $1 trillion healthcare industry on its head. But after coming up with the basic idea for Healtheon, securing the initial seed money, and hiring the people to make it happen, Clark concentrated on the building of [Hyperion][4], a sailboat with a 197-foot mast (at the time of her launch, she was the largest sloop ever build and the tallest mast ever built), whose functions are controlled by 25 SGI workstations. As the title implies, Jim Clark is a restless man who was always looking for the *new new thing*, the next big breaktrough. Near the end of the book Michael Lewis tells about one of the new things of Jim Clarks radar, a new emerging field called bioinformatics. \n\nI remember sitting there in my chair, staring at that sentence and thinking \"What! I can combine both biology and computer science!\" From that moment on I was hooked.\n\n*(The book with the ultimate triumvirate, where the three of my interest -biology, computer science and sailing- were combined, came later with the autobiography of  Craig Venter, [A life decoded][5], where he writes about the [Global Ocean Sampling Expedition][6] he undertook with his personal 95-foot sailboat named the Sorcerer II. The expedition sampled water from Halifax, Nova Scotia to the Eastern Tropical Pacific while undertaking a two year circumnavigation. The micro-organisms in the water were sequenced and the results were [published][7], more then doubling the amount of genetic sequences available up to that point.)*\n\n\n  [1]: http://www.nytimes.com/books/99/10/31/reviews/991031.31anderst.html?_r=1\n  [2]: http://en.wikipedia.org/wiki/Michael_Lewis_(author)\n  [3]: http://en.wikipedia.org/wiki/James_H._Clark\n  [4]: http://www.charterworld.com/?sub=yacht-charter&charter=sailing-yacht-hyperion-1095\n  [5]: http://www.nytimes.com/2007/11/11/books/review/Dizikes-t.html\n  [6]: http://www.jcvi.org/cms/research/projects/gos/overview/\n  [7]: http://www.ploscollections.org/article/browseIssue.action?issue=info:doi/10.1371/issue.pcol.v06.i02", "date": "2010-03-05 15:06:55", "action": 0, "post": 184}}, {"pk": 247, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "books book recommendations", "title": "Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "content": "**Bioinformatics Programming Using Python**\n\nPractical Programming for Biological Data\n\nBy [Mitchell L Model][1]\n\n![alt text][2]\n\n\nPublisher:[O'Reilly Media][3]\n\nReleased: December 2009 \n\nPages: 528\n\n*As [asked][4] by moderator [Istvan Albert][5] I made a separate question for this book review, so that the best review can come to the top.*\n\n\n  [1]: http://www.oreillynet.com/pub/au/3752\n  [2]: http://covers.oreilly.com/images/9780596154516/cat.gif\n  [3]: http://oreilly.com/catalog/9780596154516\n  [4]: http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books\n  [5]: http://biostar.stackexchange.com/users/2/istvan-albert", "date": "2010-03-05 15:18:17", "action": 0, "post": 185}}, {"pk": 248, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "blast gff annotation genome bacteria", "title": "merging blastx hits from overlapping bacterial genome segments", "content": "I blastx-ed 1Mbp bacterial genome fragment against NCBI nr database. I have split it into 2000bp fragments with 500bp overlap into a one multiple fasta file (splitter from EMBOSS) \n\n    splitter -sequence my_contig.fa  -size 2000 -overlap 500 \n\nAs on output I picked tabulated blast (-m 9). \n\nNext step was to convert blastx output into gff3. Got that one, with absolute positions (positions in intact contig). \n\nSeems that often one ORF / predicted gene is covered by 2-3 blast hits to the same protein. Hits may or may not overlap. Hence my questions:\n\n1. what are the fragment sizes / overlaps typically used for blastx in such situation?\n2. are there any advantages of improving blast hits, by say merging overlapping segments (e-scores will be invalid), or by using blast2 (blastx mode) and comparing DNA sequence from region of overlapping/almost-touching hits against already detected protein? \n\n", "date": "2010-03-05 15:51:48", "action": 0, "post": 186}}, {"pk": 249, "model": "server.postrevision", "fields": {"author": 87, "tag_string": "genetic map cm", "title": "Compute genetic map", "content": "Dear all,\n\nI would like to get the position in cM for a set of SNPs (SNPs from 1000Genomes Project).\nWhat I have is:\n- list of SNPs with their physical position\n- Genotype (or infered genotype) for each SNP for around 50 individuals\n\nSome of these snps (around 25%) are among the HapMap II SNPs used to compute the genetic map available on HapMap webpage (http://ftp.hapmap.org/recombination/2008-03_rel22_B36/rates).\nBut it is way too little information to think about calculing the cM position for 1000genomes SNPs from HapMap II genetic map, isn't it?\n\nWhat do you suggest?\n\nThanks for your help.\n\nYours truly\nPierre\n \n", "date": "2010-03-05 15:59:48", "action": 0, "post": 187}}, {"pk": 250, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: merging blastx hits from overlapping bacterial genome segments", "content": "Isn't the size of the protein that causes multiple hits? No matter what fragment size or overlap you choose, if two or more fragments cover different sections of the same protein, you'll get mulitple hits.\n\nIf your fragment sizes are too large you'll miss regions, if they are too small you'll get multiple hits. This latter problem does not seem to preclude any downstream analysis, so it may not be worth trying to optimize it away.", "date": "2010-03-05 16:06:14", "action": 0, "post": 188}}, {"pk": 251, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "bioinformatics books resources", "title": "Recommend your favorite bioinformatics books", "content": "I am looking for personal experiences and short opinions regarding bioinformatics books. \n\nSo far I have noticed the following trend: many books titled *Bioinformatics with Perl/Python/Java/R* etc end up being introductions into the programming language in question, often  only minor code examples are related to bioinformatics.\n\n**Help us find some good books!**\n\n*PS. If you are willing to write a standalone book review is even better. Please do so by creating a new question titled: \"Book review for X\" then answer it with your own review.*", "date": "2010-03-05 16:13:38", "action": 0, "post": 181}}, {"pk": 252, "model": "server.postrevision", "fields": {"author": 81, "tag_string": "", "title": "A: Looking for Linux vendors to order a CentOS/Ubuntu based webserver to host bioinformatics apps", "content": "We've been buying our servers from HP via pcconnection.com (don't be fooled by the name), with good success.  All of our desktops have been coming from Penguin Computing.", "date": "2010-03-05 16:53:24", "action": 0, "post": 189}}, {"pk": 253, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "content": "The book assumes no prior programming experience, uses real-world examples with biological data, and uses Python 3 (the programming language's first non-backwards-compatible release).\n\nThe first chapters are about primitive datatypes. At the end of each chapter there is a Tips, Traps and Trackbacks section where you can learn things that make your programming life easier, things that you have to watch out for and the meaning of some representative error messages that you might encounter.\n\nThe next chapter covers control statements and has several extended examples that are useful in the day-to-day work of a bioinformatician, like parsing Genbank files, translating RNA sequences, or constructing a table from a text file. Especially handy are the several templates that explain the general control flow . Suppose for example that you have a text file and that you need to collect all the lines that that meet both a preliminary test and a primary test. Then you just look up the template for **filtered collect of roup of lines** in the book:\n\n    lines = []\n    with open(inputfilename) as file:\n        for line in file:\n            if preliminary-test:\n                flag = preliminary-test(file)\n                lines.append(line)\n    return lines\n\nSubsequent chapters explore object-oriented programming using Classes, pattern matching using regular expressions, fetching pages from the web and displaying webpages, processing HTML and XML and working with relational databases. \n\nThe last chapter introduces displaying data using graphical toolkits and as Scalable Vector Graphics. I have been enthusiastic about the last possibility ever since I read the great article [How to Make a US County Thematic Map Using Free Tools][5] on [FlowingData][6]. It hadn't occurred to me to use this technique in the context of bioinformatics. \n\nI do miss a section on the use of matplotlib or other graphical packages that are often used. Another glaring omission is any reference to BioPython. The auther [states in a mailing list message][2] that this is because there is no Python 3 version of BioPython. \n\nThis book comes a decade after \"[Beginning Perl for Bioinformatics][3]\". Now that we have a good introductory level bioinformatics books in Python, I hope to see (Bio)Python gain strength in the bioinformatics community (a more in-depth description about the tension between Perl and Python can be read in the blog post [Not the Biopythonista I thought I'd be][4])\n\n\n  \n\n\n  [1]: http://flowingdata.com/2009/11/12/how-to-make-a-us-county-thematic-map-using-free-tools/\n  [2]: http://www.mail-archive.com/python-list@python.org/msg273660.html\n  [3]: http://oreilly.com/catalog/9780596000806\n  [4]: http://igotgenes.blogspot.com/2008/08/not-biopythonista-i-thought-id-be.html\n  [5]: http://flowingdata.com/2009/11/12/how-to-make-a-us-county-thematic-map-using-free-tools/\n  [6]: http://flowingdata.com/", "date": "2010-03-05 16:57:17", "action": 0, "post": 190}}, {"pk": 254, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: Experiences with cloud computing in bioinformatics", "content": "Cloud computing is becoming a technology mature enough for its use in genome research experiments. The use of large datasets, its highly demanding algorithms and the need for sudden computational resources, make large-scale sequencing experiments an attractive test-case for cloud computing. So far I have seen cloud computing demonstrated [using R][1]. However, it remains to be seen a rigorous comparison of its performance using a [BLAST search][2] and its ability to cope with ever-increasing databases and open source frameworks such as [bioperl][3] or [bioconductor][4].\n\nCloud computing claims to be [a resource where IT power is delivered over the Internet as you need it, rather than drawn from a desktop computer][5], in a fashion seemingly [similar to having your own virtual servers available over the Internet][6]. Some of the most important aspects of cloud computing are:\n\n* Software as a Service (SaaS): where you buy a software license for a determined period of time.\n* Utility Computing: storage and virtual servers that IT can access on demand.\n* Web Services.\n\nMy first exposure to cloud computing came of an email from [Matt Wood][7], a newly established group leader at the [Sanger Institute][8], announcing the [Cloud Computing Group][9] in Cambridge, UK. At that point I had no idea of what it meant. When I attended the meeting at Cambridge University\u2019s [Centre for Mathematical Sciences][10], to my surprise I found there a very select audience, ranging from the director of IT at Sanger, [Phil Butcher][11], one of the [Ensembl][12] software coordinators, [Glenn Proctor][13], and quite a few local start-up companies.\n\nAmong the presenters, we had Simone Brunozzi, from [Amazon\u2019s Cloud Computing][14]. I think he had an interesting story to tell: how Amazon, a well known company, is now involved in the business of cloud computing and selling it. Apparently, this technology they sell was developed for Amazon\u2019s own business. Among their main challenges was to be able to address the capricious shopping habits of customers, with orders peaking around Christmas and quite flat the rest of the year. These trends required rapid adaptability of computational resources. The idea of cloud computing fitted well with their business model of e-commerce: you don\u2019t need to care about where your computation is done, the only thing you care about is that you have the needed resources and do not have to pay for them when you don\u2019t need them. One of the things that stroke me about Amazon\u2019s presentation was that they would not tell us the number of processors they had at their disposal.\n\nWhen it comes to using cloud computing for genomics research, prices may be quite expensive when they add up. The bioinformatics field, greatly influenced by the open-source movement, is not likely to rush to join Amazon\u2019s cloud. Private efforts trying to make money out of human genome technology have remained rather unsuccessful to date: think of Celera Genomics or Lion Bioscience. I am skeptical of the bioinformatics community adopting cloud computing unless open source ideals are embraced: \n\n - allowing people to develop and contribute to the technology if and when they want to, \n - allowing total openness in terms of its achievements and pitfalls and \n - making it free to use for everyone. \n\nI do not think that making it free does not mean there is no margin for profit. Think of the profitability of free-to-use technologies such as [java][15] or [MySQL][16], both components of [SUN Microsystems][17]\u2019 business.\n\nDespite the promise of potential benefits for the bioinformatics community, the way the cloud is being portrayed does not conform the ideals of free access and openness. Unless these ideals are implemented to some extent, I see it difficult for the cloud to take root in the bioinformatics field and become a new standard platform for genome research.\n\n\n  [1]: http://www.r-project.org/\n  [2]: http://blast.ncbi.nlm.nih.gov/Blast.cgi\n  [3]: http://www.bioperl.org/wiki/Main_Page\n  [4]: http://www.bioconductor.org/\n  [5]: http://www.guardian.co.uk/technology/2008/sep/29/cloud.computing.richard.stallman\n  [6]: http://www.infoworld.com/article/08/04/07/15FE-cloud-computing-reality_1.html\n  [7]: http://www.sanger.ac.uk/Users/mw4/\n  [8]: http://www.sanger.ac.uk/\n  [9]: http://cloudcamb.org/\n  [10]: http://www.cms.cam.ac.uk/site/\n  [11]: http://www.yourgenome.org/people/phil_butcher.shtml\n  [12]: http://www.ensembl.org/index.html\n  [13]: http://www.ebi.ac.uk/Information/Staff/person_maintx.php?s_person_id=299\n  [14]: http://aws.amazon.com/ec2/\n  [15]: http://www.java.com/en/\n  [16]: http://www.mysql.com/\n  [17]: http://www.sun.com/ ", "date": "2010-03-05 17:45:27", "action": 0, "post": 135}}, {"pk": 255, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "content": "I have partially read through this book. It is more software engineering oriented than bioinformatics. I have noticed many typos in the examples.\n\nI think that covering the new Python (3.0) language was a premature undertaking that hurts the value of this book. One must realize that Python 3 is less usable for a bioinformatician as currently few if any of the scientific libraries have been ported to it. Sadly that is not a shortcoming that we can hope to see resolved any time soon.\n\nIt will probably be a decade (if ever!) that we can leave the Python 2 versions behind. ", "date": "2010-03-05 18:47:14", "action": 0, "post": 191}}, {"pk": 256, "model": "server.postrevision", "fields": {"author": 72, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "I think you are spot on with your observation. For some reason most of the recent bioinformatics books, particularly the expensive hardcover ones from CRC and Springer, are written by non-practitioners. By non-practitioners I mean professors who teach statistics, biological science or computer science, as opposed to software developers working in the field of bioinformatics. The result has read like a cross-section of stodgy textbooks and research articles, with little in the way of practical code or analysis strategy. I love technical books but with a couple exceptions (Beginning Perl for Bioinformatics) I have never felt bioinformatics books were worth the money.\n\nI am looking forward to reading Bioinformatics Programming Using Python. I think it will be a good one.\n\nMy reviews:\nStatistical Bioinformatics: with R\nhttp://www.amazon.com/review/R391IS6TF2K3WW/ref=cm_cr_rdp_perm\n\nA Primer of Genome Science, Third Edition\nhttp://www.amazon.com/review/R19MANDXOUZY5R/ref=cm_cr_rdp_perm\n\nR Programming for Bioinformatics\nhttp://www.amazon.com/review/R19FZ31NTXE89O/ref=cm_cr_rdp_perm", "date": "2010-03-05 19:24:00", "action": 0, "post": 192}}, {"pk": 257, "model": "server.postrevision", "fields": {"author": 72, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "I think you are spot on with your observation. For some reason most of the recent bioinformatics books, particularly the expensive hardcover ones from CRC and Springer, are written by non-practitioners. By non-practitioners I mean professors who teach statistics, biological science or computer science, as opposed to software developers working in the field of bioinformatics. The result has read like a cross-section of stodgy textbooks and research articles, with little in the way of practical code or analysis strategy. Others, as you mention, are \"mildly bio-flavored\" introductions to a programming language. I love technical books but with a couple exceptions (Beginning Perl for Bioinformatics) I have never felt bioinformatics books were worth the money.\n\nI am looking forward to reading Bioinformatics Programming Using Python. I think it will be a good one.\n\nMy reviews:\nStatistical Bioinformatics: with R\nhttp://www.amazon.com/review/R391IS6TF2K3WW/ref=cm_cr_rdp_perm\n\nA Primer of Genome Science, Third Edition\nhttp://www.amazon.com/review/R19MANDXOUZY5R/ref=cm_cr_rdp_perm\n\nR Programming for Bioinformatics\nhttp://www.amazon.com/review/R19FZ31NTXE89O/ref=cm_cr_rdp_perm", "date": "2010-03-05 19:29:42", "action": 0, "post": 192}}, {"pk": 258, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "I think you are spot on with your observation. For some reason most of the recent bioinformatics books, particularly the expensive hardcover ones from CRC and Springer, are written by non-practitioners. By non-practitioners I mean professors who teach statistics, biological science or computer science, as opposed to software developers working in the field of bioinformatics. The result has read like a cross-section of stodgy textbooks and research articles, with little in the way of practical code or analysis strategy. Others, as you mention, are \"mildly bio-flavored\" introductions to a programming language. I love technical books but with a couple exceptions (Beginning Perl for Bioinformatics) I have never felt bioinformatics books were worth the money.\n\nI am looking forward to reading Bioinformatics Programming Using Python. I think it will be a good one.\n\nMy reviews:\n\n - [Statistical Bioinformatics: with R][1]\n - [A Primer of Genome Science, Third Edition][2], \n - [R Programming for Bioinformatics][3]\n\n  [1]: http://www.amazon.com/review/R391IS6TF2K3WW/ref=cm_cr_rdp_perm\n  [2]: http://www.amazon.com/review/R19MANDXOUZY5R/ref=cm_cr_rdp_perm\n  [3]: http://www.amazon.com/review/R19FZ31NTXE89O/ref=cm_cr_rdp_perm", "date": "2010-03-05 19:59:39", "action": 0, "post": 192}}, {"pk": 259, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: Which operating system do you prefer for bioinformatics?", "content": "In my Master's in Bioinformatics I used [RedHat][1] 7-8 and  first edition of [Fedora][2], then for the first two years of my PhD I continued with Fedora, then moved to [Ubuntu][3] and For servers to host I used RHEL earlier and now CentOS and Ubuntu server edition. I strongly vote for Ubuntu distro for it's ease of use and strong community presence. \n\n  [1]: http://en.wikipedia.org/wiki/Red_Hat_Linux\n  [2]: http://en.wikipedia.org/wiki/Fedora_%28operating_system%29\n  [3]: http://en.wikipedia.org/wiki/Ubuntu_%28operating_system%29", "date": "2010-03-05 21:58:06", "action": 0, "post": 193}}, {"pk": 260, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Mapping SNPs to Pathways", "content": "There are actually two questions in \n\n> related pathways/ diseases ?\n\nThe first first part can be solved by database queries such as biomart and KEGG, but the second part is about complex studies. Actually, IMHO, a large part of the already known SNPs \nare not connected to disease, they might not even have a phenotype (I would bet >99%) . As far as I understand, the known SNPs are sampled from \"healthy\" individuals and represent a large mix. So it seems likely to assume that they are not easily connected to diseases.\n\nIn short, the answer might be exome sequencing of affected individuals. I found this recent article which I think is really great to answer this question: \n\nNg SB, et al.,\n[Exome sequencing identifies the cause of a mendelian disorder.][1]\nNat Genet. 2010 Jan;42(1):30-5. Epub 2009 Nov 13.\n\nIn short they discovered point mutations common in few affected individuals and subtracted synonymously coding SNPs and already known SNPs until they retained only one gene. \n\n\n  [1]: http://www.ncbi.nlm.nih.gov/pubmed/19915526", "date": "2010-03-05 22:02:46", "action": 0, "post": 194}}, {"pk": 261, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "I would like to recommend the following books to any one who is interested in Bioinformatics (Not in order): \n\n1. [Genes, Proteins and Computers][1] : A concise introduction to the subject, mainly from a biological view point, yet provide a solid understanding of fundamental concepts in biology, computing, algorithm and statistics related to bioinformatics. Must read. \n2. [Bioinformatics by David Mount][2] : A very detailed account of bioinformatics concepts. I think its high time to revise this book. I am looking forward for the next edition. You should have a copy of this if you are Masters' or PhD in Bioinformatics. \n3. [Bioinformatics : Unix/Linux, Data Processing and Programming][3] : This is a cute little book that gives you an edge over Unix, linux, basic data processing and little bit of Perl programming. I appreciate this book for its handy examples. Highly recommend to those who are from biology and interest to get their hands on programming. \n4. [Bioinformatics : Machine learning approaches][4] Machine learning is now an integral part of bioinformatics and bioinformatics is an emerging area for the application of machine learning techniques. For hard-core computer science, here is the real dose of bioinformatics algorithms. One of the first authentic books on bioinformatics algorithms. \n5. [An Introduction to Bioinformatics Algorithms][5] This one is my favorite, especially the pseudocode. Book features extensive content on the algorithms used in bioinforamtics categorized into different group. A unique concept introduced in the book is profile of the authors. If you are really in to bioinformatics algorithms, this should be on your desk. \n\nPS. I have couple of more like [Computational Genome Analysis][6], [Programming Collective Intelligence][7] etc. But they are more of specialized in to different sub-domains of bioinformatics. \n\n\n  [1]: http://www.amazon.com/Bioinformatics-Genes-Proteins-Computers-Advanced/dp/1859960545\n  [2]: http://www.amazon.com/Bioinformatics-Sequence-Analysis-David-Mount/dp/0879696087\n  [3]: http://www.springer.com/life+sciences/bioinformatics/book/978-3-540-21142-6\n  [4]: http://books.google.com/books?id=pxSM7R1sdeQC&dq=Pierre+baldi+%2B+bioinformatics&printsec=frontcover&source=bn&hl=en&ei=IoGRS6uCIJT-NYLA8Z0N&sa=X&oi=book_result&ct=result&resnum=4&ved=0CBUQ6AEwAw#v=onepage&q=&f=false\n  [5]: http://mitpress.mit.edu/catalog/item/default.asp?tid=10337&ttype=2\n  [6]: http://www.amazon.com/Computational-Genome-Analysis-Introduction-Statistics/dp/0387987851\n  [7]: http://oreilly.com/catalog/9780596529321", "date": "2010-03-05 22:19:27", "action": 0, "post": 195}}, {"pk": 262, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: How to charecterize a residue in a protein based on it's ASA", "content": "This depends on the program you use, I have calculated surface accessibility using [PSA from JOY package][1]. Another programs which I have seen frequently in literature is [NACCESS][2]. \n\n  [1]: http://bioinformatics.oxfordjournals.org/cgi/content/short/14/7/617\n  [2]: http://www.bioinf.manchester.ac.uk/naccess/", "date": "2010-03-05 22:29:25", "action": 0, "post": 196}}, {"pk": 263, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "subjective string protein interacti ppi pin", "title": "What is your experience with the STRING (interactions) database?", "content": "STRING is a database of predicted protein-protein interactions at EMBL. It cluster the results from many sources of protein-protein interactions databases, like Mint, etc.., and it also use the informations from KEGG-pathways and reactome, to provide the best annotations for the interactions of a protein.\n\nI am a bit confused from the results that I see there, because when I look at the genes in the pathway I am studying, I see many errors and annotations that I don't understand.\n\nWhat is your experience with STRING? If you want to do me a favor, go there and try to see the interactions annotated for a gene that you know already. Do you see anything weird?", "date": "2010-03-05 22:31:43", "action": 0, "post": 46}}, {"pk": 264, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: k-mer based sequencing contamination detection", "content": "I would recommend R/Bioconductor to do these kinds of analysis even though I personally doubt that this method is precise enough to separate the reads correctly. You can find the function\n`oligonucleotide.frequency` in the `Biostrings` package. The code for the first step would look somewhat like this: \n\n> library(Biostrings)\n\n> reads = read.DNAStringSet(\"yourReads.fas\", format=\"fasta\")\n\n> nf = oligonucleotideFrequency(reads[1:100], width=4)\n\n> hclust(dist(nf)) # do hierarchical clustering of your tetra freq.\n\nThat would be a very simple form of clustering. Then you have all the powerful  \nclassification algorithms built in R available, for example a support vector machine classifier. Create a training and test set of reads from 2 or more sequenced genomes and mix them. Then you will see if it is possible.\n\nBut if you look at your frequencies it might look like this:\n\n           TACG TACT TAGA TAGC TAGG TAGT TATA TATC TATG TATT TCAA TCAC TCAG TCAT TCCA TCCC TCCG TCCT\n      [1,]    0    0    0    0    0    0    0    0    1    0    0    1    2    0    0    4    0    0\n      [2,]    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0\n      [3,]    0    0    0    1    1    1    0    0    0    1    0    0    0    0    0    1    0    0\n      [4,]    0    0    1    1    0    1    0    2    0    0    1    0    2    1    0    0    1    1\n      [5,]    0    1    0    \n\nSo, lots of 0 or 1. Maybe not enough to classify correctly. That's from some 454 reads as an example and it seems that one should try di- and tri- nucleotides as well.\n\nAlternative: blastx on the individual reads and discard only those with good best hit to a bacterium. A few wrong reads should do no big harm, so it is maybe good not to risk to filter out too many beforehand.", "date": "2010-03-05 23:13:37", "action": 0, "post": 197}}, {"pk": 265, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: Where can I get the secondary structure of a protein?", "content": "If it is only one sequence you may try [PSIPRED][1] server. If you need to work on a large sequence dataset, better to install PSIPRED locally. [PSIPRED][2] runs are typically computational intensive. \n\n\n  [1]: http://bioinf4.cs.ucl.ac.uk:3000/psipred/\n  [2]: http://www.ncbi.nlm.nih.gov/pubmed/10869041", "date": "2010-03-05 23:31:04", "action": 0, "post": 198}}, {"pk": 266, "model": "server.postrevision", "fields": {"author": 46, "tag_string": "", "title": "A: Score protein variants based on frequency of AA in multiple sequence alignment", "content": "I'm not sure if I understand you correctly. If you are looking for a webservice that returns the PSIC scoring matrix, why don't you just follow the URL mentioned in the paper's abstract, i.e. http://strand.imb.ac.ru/PSIC/ which leads you to a html form where you can paste your mutliple alignment and returns the PSIC matrix.\nOr did I misunderstand you?\n\n", "date": "2010-03-05 23:38:05", "action": 0, "post": 199}}, {"pk": 267, "model": "server.postrevision", "fields": {"author": 46, "tag_string": "", "title": "A: Pfam based functional annotaion", "content": "You might also consider to blast against Swissprot and transfer residue annotations.", "date": "2010-03-05 23:44:55", "action": 0, "post": 200}}, {"pk": 268, "model": "server.postrevision", "fields": {"author": 89, "tag_string": "cis module prediction high dnase transcription", "title": "Has enhancer and transcription factor binding site prediction already been made redundant?", "content": "ENCODE soon provides DNase I hypersensitivity data for the whole genome in a multitude of different tissues. DNase I hypersensitivity marks genomic positions that are exposed and can hence be used to pinpoint active promoters or enhancers in the studied tissue. DNase I resistant regions, in contrast, mark genomic areas that are protected, e.g. because a transcription factor (TF) is bound. Since the data provides a base-pair resolution, it is possible to \"zoom\" in on the protected areas (== transcription factor binding sites) of the otherwise exposed regions (== enhancers). One can hence identify the shadow-prints on the genome left by the regulatory TFs in a given tissue. To identify which TFs are casting the shadows one could use ChIP-seq (rough binding regions) or Protein Binding Arrays (binding motif).\n\nThe question is: has the *in-silico* prediction of enhancers, binding sites or partners still merit or will we be soon able to look-up the binding events of TFs in the different tissues? ", "date": "2010-03-06 07:43:23", "action": 0, "post": 201}}, {"pk": 269, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: How far does bioinformatics go?", "content": "As much as I agree with the impressive list from BioGeek, I have to say that it is a non-exhaustive, genomics centric list.\n\nIf we look at the first statement he mentions: \"Bioinformatics is the field of science in which biology and computer science/information technology merge into a single discipline.\"\n\nFrom that statement I understand that anything \"biological\" studied using a \"computer\" should have its place in what we call \"Bioinformatics\".\n\nOne perfect example would be all those people working on proteins and not DNA/RNA. I wouldn't say that those are the same field in Bioinformatics, however you may argue that they fit together... As an example of a \"Bioinformatics Center\" that focuses on proteins I would give: [Stockholm Bioinformatics Center][1]\n\nAnother example would be those people trying to understand how molecules diffuse within the cell cytoplasm. That is a lot of computer work that's directly looking at understanding a phenomenon in a biological context. This type of project is bordering on many disciplines and not just biology and informatics, but also physics. Nevertheless, shouldn't that be a \"bioinformatics\" discipline too? In this category I would give the [Biomatter @ MOSAIC ETH Zurich][2]\n\nWhat about Systems Biology (even if they don't want to be called bioinformaticians), shouldn't they be called bioinformaticians too?\n\nAnd finally (although far from exhaustive) I'll give one last example of something I consider bioinformatics: the [E-Cell Project][3] \n\nI hope this answers your question! In my opinion, bioinformatics is NOT only \"genome stuff\" and I would extend it to yourself too ;)\n\n\n  [1]: http://www.sbc.su.se/research/\n  [2]: http://www.biomatter.ethz.ch/Biomatter/Welcome.html\n  [3]: http://www.e-cell.org/ecell/", "date": "2010-03-06 09:11:59", "action": 0, "post": 202}}, {"pk": 270, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: Experiences with cloud computing in bioinformatics", "content": "The J. Craig Venter Institute has released the [JCVI Cloud BioLinux image][1], which *\"enables scientists to quickly provision computation infrastructures supporting bioinformatics using cloud computing platforms such as Amazon EC2 and Eucalyptus.   Upon deployment users will have instant access to a host of software including BLAST, glimmer, hmmer, phylip, rasmol, genespring, clustalw, the Celera Assembler, and the EMBOSS collection of utilities.  JCVI Cloud BioLinux is built on a 64-bit instance of Ubuntu virtual server customized with bioinformatics packages from the BioLinux repository, and will be updated periodically.\"*\n\nThey give as their motivation for releasing this image *\"cloud computing can provide researchers with the ability to perform computations using a practically unlimited pool of virtual machines, without facing the burden of owning or maintaining any hardware infrastructure. (...) This Science as a Service model (ScaaS) will allow JCVI to incorporate, develop and optimize life science software as well as supporting data sets on compute clouds.  This project is driven by the observation that commonly-used bioinformatics tools are hard to build and maintain, require high amounts of resources, or just too numerous to choose from.\"*\n\n\n  [1]: http://www.jcvi.org/cms/research/projects/jcvi-cloud-biolinux/overview/", "date": "2010-03-06 11:04:51", "action": 0, "post": 203}}, {"pk": 271, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Has enhancer and transcription factor binding site prediction already been made redundant?", "content": "I wouldn't venture to hypothesize on what will happen; *making predictions is difficult, especially about the future*.\n\nWhat seems prudent to assume however is that there may be several reasons of why genomic regions are accessible or protected. For example: is it a transcription factor that protects the region or is there some other reason of why the TF will bind to that location to begin with. For example chromatin structure and nucleosome positioning may favor or disfavor certain events.\n\nAny *in-silico* modeling will need to take into account the various mechanisms that may take place.", "date": "2010-03-06 12:48:41", "action": 0, "post": 204}}, {"pk": 272, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "general contact", "title": "How do I contact the moderators or supervisors of this site?", "content": "What options do I have for contacting the individuals responsible for the proper functioning of this site? \n\nHow do I suggest improvements, recommend features or report a problem using this site?", "date": "2010-03-06 13:46:31", "action": 0, "post": 205}}, {"pk": 273, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How do I contact the moderators or supervisors of this site?", "content": "The **BioStar** site will be primarily moderated and regulated by the users who have high reputation. \n\nWe have also created a Google group called [**Biostar-Central**][1] that is intended to be used for administrative purposes. Use this group to suggest improvements, provide feedback or report problems that otherwise would not be appropriate to ask on the main site.\n\nOccasional **BioStar** related announcements will be made public via this group.\n\nThank you,\n\n[Istvan Albert][2]\n\nPS. First posts by new users to this group will be held for moderation. \n\n\n\n  \n\n\n  [1]: http://groups.google.com/group/biostar-central/\n  [2]: http://www.personal.psu.edu/iua1/", "date": "2010-03-06 13:54:52", "action": 0, "post": 206}}, {"pk": 274, "model": "server.postrevision", "fields": {"author": 90, "tag_string": "", "title": "A: How to do quality trimming of SoLid Reads in colour space?", "content": "I know of two quality filtering methods for SOLiD reads, besides the already suggested SAET:\n\n- [A set of tools][1] from [a recent publication][2]\n\n\n- The csfasta_quality_filter.pl script from ABI's [de novo accessory tools package][3]\n\nHaven't actually tried any of them yet, but will do so pretty soon.\n\n  [1]: http://hts.rutgers.edu/filter/\n  [2]: http://bioinformatics.oxfordjournals.org/cgi/content/short/26/6/849?rss=1\n  [3]: http://solidsoftwaretools.com/gf/project/denovo/frs/", "date": "2010-03-06 14:58:53", "action": 0, "post": 207}}, {"pk": 275, "model": "server.postrevision", "fields": {"author": 90, "tag_string": "", "title": "A: How do I map, align, and plot my SOLiD results?", "content": "First of all, you should not convert to base sequence first and then map - you should do the mapping directly on the color-space reads. The short-read mapper will (typically) report the genome matches for you in base sequence format. There are several short read mappers / aligners that handle color space alignment: Bowtie, BFAST, BWA, SHRiMP, PerM and many others including ABI's own mapreads and Bioscope. You can get the mapping output in SAM format, a handy format which contains a lot of information about the alignments and which you can manipulate in Galaxy (via the NGS: SAM tools menu) to get the \"pileup\" of reads in certain regions and so on.  ", "date": "2010-03-06 15:18:14", "action": 0, "post": 208}}, {"pk": 276, "model": "server.postrevision", "fields": {"author": 90, "tag_string": "", "title": "A: How do I map, align, and plot my SOLiD results?", "content": "First of all, you should not convert to base sequence first and then map - you should do the mapping directly on the color-space reads. The short-read mapper will (typically) report the genome matches for you in base sequence format. There are several short read mappers / aligners that handle color space alignment: Bowtie, BFAST, BWA, SHRiMP, PerM and many others including ABI's own mapreads and Bioscope. You can get the mapping output in SAM format, a handy format which contains a lot of information about the alignments and which you can manipulate in Galaxy (via the NGS: SAM tools menu) to get the \"pileup\" of reads in certain regions and so on.  \n\nEdit: I just noticed that Galaxy now features Bowtie mapping for color space.", "date": "2010-03-06 15:33:55", "action": 0, "post": 208}}, {"pk": 277, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Compute genetic map", "content": "I hope I understand your question: The UCSC genome database contains the position in both **base index** and **cM** for the STS. e.g.:\n\n\n    ~> mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -D hg18 -e 'select name,chrom,chromStart,chromEnd,genethonPos from stsMap where genethonPos!=0 limit 2\\G'\n    *************************** 1. row ***************************\n           name: AFM280WE5\n          chrom: chr1\n     chromStart: 3574721\n       chromEnd: 3575045\n    genethonPos: 6.2\n    *************************** 2. row ***************************\n           name: AFM344WE9\n          chrom: chr1\n     chromStart: 4358261\n       chromEnd: 4358654\n    genethonPos: 11.1\n\nSo you can use this STS map as a 'reference' to map your collection of SNP from **bp** to **cM**.\n\n", "date": "2010-03-06 15:42:42", "action": 0, "post": 209}}, {"pk": 278, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: k-mer based sequencing contamination detection", "content": "I would recommend R/Bioconductor to do these kinds of analysis even though I personally doubt that this method is precise enough to separate the reads correctly. You can find the function\n`oligonucleotideFrequency` in the `Biostrings` package. The code for the first step would look somewhat like this: \n\n> library(Biostrings)\n\n> reads = read.DNAStringSet(\"yourReads.fas\", format=\"fasta\")\n\n> nf = oligonucleotideFrequency(reads[1:100], width=4)\n\n> hclust(dist(nf)) # do hierarchical clustering of your tetra freq.\n\nThat would be a very simple form of clustering. Then you have all the powerful  \nclassification algorithms built in R available, for example a support vector machine classifier. Create a training and test set of reads from 2 or more sequenced genomes and mix them. Then you will see if it is possible.\n\nBut if you look at your frequencies it might look like this:\n\n           TACG TACT TAGA TAGC TAGG TAGT TATA TATC TATG TATT TCAA TCAC TCAG TCAT TCCA TCCC TCCG TCCT\n      [1,]    0    0    0    0    0    0    0    0    1    0    0    1    2    0    0    4    0    0\n      [2,]    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0\n      [3,]    0    0    0    1    1    1    0    0    0    1    0    0    0    0    0    1    0    0\n      [4,]    0    0    1    1    0    1    0    2    0    0    1    0    2    1    0    0    1    1\n      [5,]    0    1    0    \n\nSo, lots of 0 or 1. Maybe not enough to classify correctly. That's from some 454 reads as an example and it seems that one should try di- and tri- nucleotides as well.\n\nAlternative: blastx on the individual reads and discard only those with good best hit to a bacterium. A few wrong reads should do no big harm, so it is maybe good not to risk to filter out too many beforehand.", "date": "2010-03-06 16:34:28", "action": 0, "post": 197}}, {"pk": 279, "model": "server.postrevision", "fields": {"author": 91, "tag_string": "", "title": "A: Gene ID conversion tool", "content": "[BridgeDB][1] provides a nice API and REST interface, so you can put ID mapping queries in your scripts.\n\n\n  [1]: http://www.biomedcentral.com/1471-2105/11/5", "date": "2010-03-06 16:42:34", "action": 0, "post": 210}}, {"pk": 280, "model": "server.postrevision", "fields": {"author": 93, "tag_string": "", "title": "A: Where can I get the secondary structure of a protein?", "content": "If you do have the protein structure (PDB file) [link text][1] is also a good option for assigning the secondary structure.\n\n\n  [1]: http://webclu.bio.wzw.tum.de/cgi-bin/stride/stridecgi.py \"Stride\"", "date": "2010-03-06 17:26:09", "action": 0, "post": 211}}, {"pk": 281, "model": "server.postrevision", "fields": {"author": 93, "tag_string": "", "title": "A: How to charecterize a residue in a protein based on it's ASA", "content": "[ASA-view][1] is a server that can help you visualize the burial of each amino acid in your protein\n\n\n  [1]: http://www.netasa.org/asaview/ \"ASA-view\"", "date": "2010-03-06 17:36:39", "action": 0, "post": 212}}, {"pk": 282, "model": "server.postrevision", "fields": {"author": 96, "tag_string": "", "title": "A: Using HDF5 to store  bio-data", "content": "Our [Genomedata][1] system stores multiple tracks of 1-bp resolution genomic data in a HDF5 array. Documentation and full source code is available on that page. It has a Python (PyTables) interface for reading the data. For originally loading it into HDF5, we wrote a C loader for added speed.\n\n\n  [1]: http://noble.gs.washington.edu/proj/genomedata/", "date": "2010-03-06 18:14:16", "action": 0, "post": 213}}, {"pk": 283, "model": "server.postrevision", "fields": {"author": 97, "tag_string": "", "title": "A: Which operating system do you prefer for bioinformatics?", "content": "I have a Mac Pro dual quad core that I use for everything. I use the Mac OS for day to day email, most graphics, browsing, I run a VMWare virtual Windows machine, and I do most analysis in the unix terminal. Windows runs much better on the Mac hardware, Excel is much faster in Window, and I can fileshare between the Windows and Mac systems. So far this has been sufficient for me. If I run into a situation where I need more computing power, I can ssh to a Linux server, but I haven't needed to yet. I configured the machine with 16 GB RAM, leaving slots open to add another 16 if needed. I've been happy with this.", "date": "2010-03-06 18:20:20", "action": 0, "post": 214}}, {"pk": 284, "model": "server.postrevision", "fields": {"author": 98, "tag_string": "assembly unambiguous", "title": "Unambiguous assembly of next-gen fastq reads into fastq contigs?", "content": "Hi,\n\nDoes anybody know of any tool that will produce an unambiguous assembly of next-gen fastq files and give the assembled output back as fastq with consensus/combined scores?\n\nBy unambiguous I mean something like this in abyss:\n\nABYSS -k$k -b0 -t0 -e0 -c0\n\nCheers,\n\nAlbert. ", "date": "2010-03-06 18:22:30", "action": 0, "post": 215}}, {"pk": 285, "model": "server.postrevision", "fields": {"author": 71, "tag_string": "", "title": "A: Which operating system do you prefer for bioinformatics?", "content": "Highly subjective answer of course, but I don't think you can go wrong with Linux at the backend.  In general, you will find a vast variety of software, great community support, better work/$ numbers at scale.  I tend to prefer debian-based distro's (Ubuntu, Debian, etc) but that's a personal choice.  On the front end, I've successfully used IRIX (dating myself), Ubuntu, and OSX.", "date": "2010-03-06 18:33:14", "action": 0, "post": 216}}, {"pk": 286, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "cis module dnase transcription", "title": "Has enhancer and transcription factor binding site prediction already been made redundant?", "content": "ENCODE soon provides DNase I hypersensitivity data for the whole genome in a multitude of different tissues. DNase I hypersensitivity marks genomic positions that are exposed and can hence be used to pinpoint active promoters or enhancers in the studied tissue. DNase I resistant regions, in contrast, mark genomic areas that are protected, e.g. because a transcription factor (TF) is bound. Since the data provides a base-pair resolution, it is possible to \"zoom\" in on the protected areas (== transcription factor binding sites) of the otherwise exposed regions (== enhancers). One can hence identify the shadow-prints on the genome left by the regulatory TFs in a given tissue. To identify which TFs are casting the shadows one could use ChIP-seq (rough binding regions) or Protein Binding Arrays (binding motif).\n\nThe question is: has the *in-silico* prediction of enhancers, binding sites or partners still merit or will we be soon able to look-up the binding events of TFs in the different tissues? ", "date": "2010-03-06 18:39:49", "action": 0, "post": 201}}, {"pk": 287, "model": "server.postrevision", "fields": {"author": 99, "tag_string": "", "title": "A: How to charecterize a residue in a protein based on it's ASA", "content": "yeah, the better answer is not to use surface area to calculate depth. use depth.\nhttp://dx.doi.org/10.1016/j.tibs.2003.09.004", "date": "2010-03-06 19:03:07", "action": 0, "post": 217}}, {"pk": 288, "model": "server.postrevision", "fields": {"author": 91, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "Most of my work is in python, so I use [paver][1], which is similar to makefiles or rake for ruby, but gives you access to all python libraries.\n\n\n  [1]: http://www.blueskyonmars.com/projects/paver/", "date": "2010-03-06 20:38:38", "action": 0, "post": 218}}, {"pk": 289, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "general contact faq", "title": "How do I contact the moderators or supervisors of this site?", "content": "What options do I have for contacting the individuals responsible for the proper functioning of this site? \n\nHow do I suggest improvements, recommend features or report a problem using this site?", "date": "2010-03-06 21:00:23", "action": 0, "post": 205}}, {"pk": 290, "model": "server.postrevision", "fields": {"author": 50, "tag_string": "", "title": "A: Has enhancer and transcription factor binding site prediction already been made redundant?", "content": "I don't work on prediction of transcription factor binding or enhancers so I will just give a very general answer that could apply to any sort of prediction. \n\nI think there is a big difference between observing an event (ex. transcription factor binding to region X) and knowing why you observe it. To put it in another way .. if we can solve protein structures should we still try to predict how a protein might fold ? Prediction  tries to encapsulates our knowledge of the system so I think the answer is that we will never stop trying to predict/model a system even if we can just easily measure it. Until we can model it we don't really know how it works. If you are only interested in knowing where a TF might bind to then the observations are enough but if you want to know **why** a protein with those characteristics is binding to that DNA region then the observations are just the starting point. \n\n", "date": "2010-03-06 23:19:21", "action": 0, "post": 219}}, {"pk": 291, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "", "title": "A: How to organize a pipeline of small scripts together?", "content": "I have done some with [ruffus][1] but have reverted back to using make files.\nRuffus is a nice idea and implemented very nicely, but often, in a pipeline, I just want to overwrite files--since I'm exploring and making lots of changes and mistakes. With rufus, I found I was spending a lot of time tracking down which files had/had not changed. For some reason, it's easier for me to deal with a Makefile, with or without using dependencies. YMMV. I just order the make with steps that come first at the top and add stuff to the bottom as I extend the pipeline. This is very simple, but works well for now. I'm interested to see what other responses are added here. \n\nAs others have mentioned, a README.txt and documentation at the top of the script are a good idea. Also, for any script that takes more than 2 arguments, use a getopt equivalent e.g. [optparse][2] in python).\n\nFinally, extract as much code as possible into tested/test-able libraries.\n\n  [1]: http://wwwfgu.anat.ox.ac.uk/~lg/oss/ruffus/\n  [2]: http://docs.python.org/library/optparse.html", "date": "2010-03-07 03:26:37", "action": 0, "post": 220}}, {"pk": 292, "model": "server.postrevision", "fields": {"author": 26, "tag_string": "", "title": "A: What methods do you use for short read mapping?", "content": "We map the reads from the illumina and SoLid platform by using BWA. http://bio-bwa.sourceforge.net/\n\nFor bacterial genomes, we choses the illumina platform. About 50X coverage of the total reads was obtained against the ~4Mb reference genome. The mapping process took about 1 hour by using 7 cpus.\n\nFor eukaryotic genomes, we choses the SoLid platform. About 25x coverage of the total reads were obtained against the ~500Mb reference genome. The mapping process took about 2 days by using 7 cpus.\n\nGenerally reads mapping by using BWA is reliable. ", "date": "2010-03-07 05:26:39", "action": 0, "post": 221}}, {"pk": 293, "model": "server.postrevision", "fields": {"author": 78, "tag_string": "protein sequence multiplealignment scoringmatix", "title": "Score protein variants based on frequency of AA in multiple sequence alignment", "content": "For reference, please read this excerpt from  \n**Human non-synonymous SNPs: server and survey**  \nVasily Ramensky, Peer Bork, and Shamil Sunyaev\n\n\n> *Profile analysis of homologous\n> sequences*. The amino acid replacement\n> may be incompatible with the spectrum\n> of substitutions observed at that\n> position in a family of homologous\n> proteins. PolyPhen identifies\n> homologues of the input sequences via\n> a BLAST (23) search of the NRDB\n> database. The set of aligned sequences\n> with sequence identity to the input\n> sequence in the range 30\u00b194%\n> (inclusive) is used by the new version\n> of the PSIC (position-specific\n> independent counts) software (24) to\n> calculate the so-called profile matrix\n> (http://strand.imb.ac.ru/PSIC/).\n> Elements of the matrix (pro- file\n> scores) are logarithmic ratios of the\n> likelihood of a given amino acid\n> occurring at a particular site to the\n> likelihood of this amino acid\n> occurring at any site (background\n> frequency). PolyPhen computes the\n> absolute value of the difference\n> between profile scores of both allelic\n> variants in the polymorphic position.\n> PolyPhen also shows the number of\n> aligned sequences at the query\n> position; this may be used to assess\n> the reliability of profile score\n> calculations.\n\nI'd like to calculate something similar (score variants based on frequency that AA in aligned sequences) to what's mentioned here **programmatically**, but I can't find any implementation of the above described system.\n\nDoes anyone know of a working implementation of this or something similar, that's available either in code or as a web service?\n\nOr should it is easy enough to implement something like this ourselves?", "date": "2010-03-07 12:18:39", "action": 0, "post": 183}}, {"pk": 294, "model": "server.postrevision", "fields": {"author": 104, "tag_string": "sequence genome search tool primer", "title": "How to find a 28bp 'primer' sequence in a genome?", "content": "Dumb question I know, but...\n\nWhat tool to use?\n\nI'd like to find forward and reverse primers within an approximate distance of each other... I'd like to accept 1 or two mismatches. The genome is ~1 Gbp. I have ~500 forward reverse pairs to find in the genome.\n\nAny hints appreciated :-)", "date": "2010-03-07 12:53:55", "action": 0, "post": 222}}, {"pk": 295, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: How to find a 28bp 'primer' sequence in a genome?", "content": "I know that many people use the [primer3 software][1] to design primers. There are also two web-interfaces where you can try out the parameters, and there are many of them.\nThe program **[eprimer3][2]** is part of the [EMBOSS tools][3], maybe the best way of getting a command-line executable of primer3.\n\nI didn't see a mismatch parameter though, because for a 'real' PCR-primer to allow for mismatches is a bad idea. I noted the '' in your question, so you might not really be looking for primers. So what is it then? If this is just a piece of sequence then you do not need to bother with uniqueness or melting temperature constraints.\n\n\n  [1]: http://primer3.sourceforge.net/\n  [2]: http://emboss.sourceforge.net/apps/release/6.2/emboss/apps/eprimer3.html\n  [3]: http://emboss.sourceforge.net/", "date": "2010-03-07 13:24:06", "action": 0, "post": 223}}, {"pk": 296, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "", "title": "A: What methods do you use for short read mapping?", "content": "I've only used [bowtie][1], but it seems to be extremely fast and makes use of multiple cores with no extra work on my part. Also, builds an index for the reference sequence which can be re-used after the first build. \n\nThis is mapping to Arabidopsis Thaliana, up to 5 or so Gigs of raw reads, so fastq of 4x that size. Using a pretty standard 8 core machine, it's relatively painless.\n\n  [1]: http://bowtie-bio.sourceforge.net/index.shtml", "date": "2010-03-07 15:20:02", "action": 0, "post": 224}}, {"pk": 297, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "", "title": "A: How to find a 28bp 'primer' sequence in a genome?", "content": "Since you have so few pairs, you could just run them through a read-aligner allowing mismatches, and find pairs that are aligned within X basepairs in the reference genome. \nActually, you could probably even use the paired-end feature of most aligners so that the aligner only find the pairs with nearby matches. For either of those methods, you could use [bowtie][1].\n\nAs far as I know, [primer3][2] does allow gaps and mismatches, so that may also be an option if you just want to see if you have good primers, but you'd probably have to use the command-line version.\n\nor, you could use BLAST and find nearby hits between the pairs.\n\n\n  [1]: http://bowtie-bio.sourceforge.net/index.shtml\n  [2]: http://primer3.sourceforge.net/", "date": "2010-03-07 16:22:36", "action": 0, "post": 225}}, {"pk": 298, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: Has enhancer and transcription factor binding site prediction already been made redundant?", "content": "I agree with Istvan and pedrobeltrao.\n\nI would just add that we should all be careful when we look at the type of experiments that you describe as well as protein structures and many other biochemical experiments.\n\nThey are, most often, ***snapshots*** of what is happening in an ***extremely dynamic*** environment, which is the cell and its components.\n\nWhat holds true at one moment (when the cell was fixed, the proteins extracted or crystalized) is not the whole picture of what's happening or how things look.\n\nI think you'll need more than a few biochemical experiments to ***know*** how the cell really works. Until that day, predictions and modeling will always be useful.", "date": "2010-03-07 19:22:29", "action": 0, "post": 226}}, {"pk": 299, "model": "server.postrevision", "fields": {"author": 87, "tag_string": "", "title": "A: Compute genetic map", "content": "Hey Pierre,\n\nthanks for your answer!\nI already got the genetic map provided by USCS database with STS markers.\nBut my issue remains the same: the density of markers of the available genetic maps (the USCS one or HapMap II one) is much lower than the density of my SNP set. For example I have 4054 SNPs between the 2 STS markers above (in your comment).\n \nTherefore I don't know how to attribute to each SNPs of my set a position in cM  without doing a very important approximation.\n\nAnyway, what do you suggest? To use a rule of three approach to attribute a cM position to my collection's SNPs?\n \nThanks for your advice!\nPierre\n\n\n", "date": "2010-03-08 10:01:03", "action": 0, "post": 227}}, {"pk": 300, "model": "server.postrevision", "fields": {"author": 109, "tag_string": "clustering map", "title": "Hierarchical Clustering, Cluster Heat Maps in Java", "content": "Hello all,\nI am new to this forum and I am glad I found one in Bioinformatics too.\nI hope I can ask this question here.\n**Has anyone been able to generate cluster heatmaps using any library in Java ?**\nI recently got to learn that heatmaps are different from cluster heat maps in just that in the cluster heatmaps there are dendrograms for both genes as well as samples. So essentially Hierarchical clustering (thats what I am working on) is to be performed once on the genes and once on the samples.\nI was looking at JFreechart, JTreeview. In JFreechart I did not find any method to directly get a cluster heat map. And with JTreeview,  it needs 3 input files in particular format like the .CDT file, .gtr file, .atr file. I am curious to know if there is any other direct way to generate these cluster heat maps. \n\nPlease enlighten me\n\nThanks in advance", "date": "2010-03-08 12:57:32", "action": 0, "post": 228}}, {"pk": 301, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Hierarchical Clustering, Cluster Heat Maps in Java", "content": "\nI know that the [Multiexperiment Viewer suite][1] is written in Java. \n\nWhile it is not usually used as a library I think you might be able to import some of its internals in your own code. It is worth a try, as you could get access to numerous other tools as well. \n\n\n  [1]: http://www.tm4.org/mev/", "date": "2010-03-08 13:49:18", "action": 0, "post": 229}}, {"pk": 302, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Computing the reverse and complement of a sequence with Pygr", "content": "This post was not formulated in a question/answer format  therefore will be closed.", "date": "2010-03-08 13:50:54", "action": 0, "post": 230}}, {"pk": 303, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: How to find a 28bp 'primer' sequence in a genome?", "content": "Did not used it myself yet, but there is a new program claiming to be better than primer3:\n\nSee:\nhttp://nar.oxfordjournals.org/cgi/content/abstract/37/13/e95\n\nDownload it from:\nhttp://pythia.sourceforge.net\n\n", "date": "2010-03-08 14:39:24", "action": 0, "post": 231}}, {"pk": 304, "model": "server.postrevision", "fields": {"author": 63, "tag_string": "professional career subjective assessment", "title": "How Important is it to belong to a Professional Society in Computational Biology?", "content": "It is clear that in Computational Biology there are certain organisations, societies and the like, global and regional, that intend to cater the needs for conferences, networking and scientific exchange, proper of any scientific community.\n\nHowever, the benefits of joining a society are still elusive. In an American setting it seems that there is this culture of supporting your own community by joining your society. In Europe it does not seem to have any value attached in one's CV to belong or form part of a society, other than anecdotal. Other regions in the world may be somewhere in between.\n\nI would like to ask people what they think their perception of belonging to a professional society is, whether this should be something that should be encouraged in settings where this is not so valued and what their expectations are.", "date": "2010-03-08 16:54:31", "action": 0, "post": 232}}, {"pk": 305, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How Important is it to belong to a Professional Society in Computational Biology?", "content": "I think the benefits of being in a professional society do not readily lend themselves to quantification. \n\nThe positives are more about personal fulfillment, a sense of belonging, better understanding of the field and building interpersonal relationships that in the end may strongly shape one's future.", "date": "2010-03-08 18:28:21", "action": 0, "post": 233}}, {"pk": 306, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "", "title": "A: How Important is it to belong to a Professional Society in Computational Biology?", "content": "This is a very interesting question.  I think today, and especially in a modern field like bioinformatics, the idea of belonging to a professional society is almost quaint.\n\nHaving once been a bench scientist, the only reasons I could ever ascertain to belonging to a society were that\n\n 1. They might pay your fees to go to a conference if they fund this kind of thing\n 2. You might get reduced conference fees for certain conferences\n 3. You get a little ribbon on your badge to let everyone know at the conference you're a member\n\nCertainly, from my current position - I have never felt that belonging to a professional body distinguished my CV or resume from any other candidate.  As someone who hires, it would not make a jot of difference to me if you were a member of a society or not.\n\nI would go so far as to suggest that even the networking aspects of a society are largely oversold in the wake of the professional relationships I build over Twitter, LinkedIn or FriendFeed.  Whether or not I am a member of a professional organisation would not have any bearing on which conferences I attended, or who I spoke to at them.\n\n", "date": "2010-03-08 21:51:44", "action": 0, "post": 234}}, {"pk": 307, "model": "server.postrevision", "fields": {"author": 115, "tag_string": "", "title": "A: Pfam based functional annotaion", "content": "I think the Pfam approach may return something useful, but you need to be careful about how you interpret your results. Pfam is primarily a tool to assign sequences to protein families. It also does a good job of recognizing functional domains. It provides information about the usual function of the domains/family members- but I do not think it should be viewed as a tool to assign function directly, and I think the Pfam curators would agree with me. It is making an assignment based on sequence similarity, and is inferring structural and functional similarity. These inferences may or may not be correct. You have several risks you need to keep in mind. Two biggies that pop out too me are:\n\n1. Your sequences are all shorter than most protein domains. So you may get false negatives where if you had the full sequence, you might have hit a domain, but because you only have a fragment, the similarity is too weak to produce a hit.\n\n2. You might get false positives because you match a domain but have a few key residues in your sequence mutated, and therefore the protein from which your sequence was derived actually does not perform the function assigned to that domain in Pfam. \n\nYou asked about direct experience. Mine is roughly 5 years old now, but it was that Pfam was one of the best tools to identify functional domains, and was a good way to annotate sequences as long as I kept its limitations in mind. However, I was working with full length sequences, not fragments. My gut instinct is that it will not perform as well on small fragments, but I have no direct experience to back me up- just my knowledge that your fragments are shorter than most domains.\n\nBack when I did function assignment for a living, I considered it very risky to rely on one tool to make an assignment. And I never considered any assignment anything more than a hypothesis that could then be tested in the lab.", "date": "2010-03-08 22:08:45", "action": 0, "post": 235}}, {"pk": 308, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "", "title": "A: How Important is it to belong to a Professional Society in Computational Biology?", "content": "From the practical point of view, I heard when you apply for a green card in US as extraordinary/outstanding scientist, being a member of professional societies gives you some additional \"points\".\n\nAnother example. AACR (The American Association for Cancer Research) became to large, that it accepts papers/posters for a conference only from its members. If you are not, you have to find a full member to be a \"sponsor\" for your paper.\n\nAs for many societies, members usually get early event notices (I get them by e-mail all the time anyway), some free publications (sometime just another junk), fee reduction (do you care if your lab is paying? :). ", "date": "2010-03-08 22:46:36", "action": 0, "post": 236}}, {"pk": 309, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: How Important is it to belong to a Professional Society in Computational Biology?", "content": "The sole benefit that I have gained from my two experiences with society membership was a discounted rate for conference registration.  For the remainder of my subscription, I received no information via email or any other means apart from a reminder to renew (in one case, nothing in the other case).\n\nI'd agree with Daniel, above; the \"informal\" connections that I've made via online social networks have been far more valuable to me than any formal society.", "date": "2010-03-08 23:29:23", "action": 0, "post": 237}}, {"pk": 310, "model": "server.postrevision", "fields": {"author": 89, "tag_string": "gene", "title": "How to determine if a gene is active from expression data", "content": "I have RMA (Robust Multi-Array) scores for the different genes (and their isoforms) on the Affymetrix chip. I want to know which of these genes are \"active\" (or in other words: are likely to produce enough protein products to have an effect). I'm not interested in them being differentially expressed or X-fold over- or under-expressed. All I want is the classification of them being likely \"on\" or \"off\". \n\nSo far I log-transformed (basis 10) the RMA score and centered them (subtracted the median). I called all genes which had a transformed score <0 as being inactive and scores >0 as being active. \n\nDoes anyone have a better methodology ?\n\n", "date": "2010-03-09 02:39:53", "action": 0, "post": 238}}, {"pk": 311, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: How to determine if a gene is active from expression data", "content": "You're right in thinking that your methodology isn't a very good representation of the system. mRNAs (and their protein products) have a huge dynamic range. Some are going to be expressed constantly at extremely low levels, and at the other extremes, you'll have genes that are highly expressed, but only for a short period of time.  Taking the median level as the dividing line between on and off is going to give you huge numbers of false negatives (genes that are actually being transcribed and translated, but that you'll classify as \"off\")\n\nI'd look at what the background noise level is, then run some stats to determine which probes give you signal significantly above that level. Any gene meeting that criteria should probably be considered \"on\". I suspect that may not divide the set as nicely as you'd hope, though.\n\nMaybe if you tell us more about what exactly you're trying to do, we can offer more constructive advice.", "date": "2010-03-09 05:15:16", "action": 0, "post": 239}}, {"pk": 312, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: What methods do you use for short read mapping?", "content": "It's worth noting that a lot of people also use [Novoalign][1]\n\n\n  [1]: http://www.novocraft.com/index.html", "date": "2010-03-09 05:20:42", "action": 0, "post": 240}}, {"pk": 313, "model": "server.postrevision", "fields": {"author": 118, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "I use a combination of things for different purposes, including C, R, Perl and Delphi. For anything to run on windows, whether command-line or with a nice-to-use UI for less technical users, **Delphi** still rocks.", "date": "2010-03-09 12:12:40", "action": 0, "post": 241}}, {"pk": 314, "model": "server.postrevision", "fields": {"author": 118, "tag_string": "", "title": "A: Has enhancer and transcription factor binding site prediction already been made redundant?", "content": "In addition to what's already been said, I'd like to add that even if these data did completely abolish the need to predict TF binding sites (which I'm not entirely sure about), there are still many cases - **and many organisms** - where such data aren't available, implying that there's still a niche for computational approaches.", "date": "2010-03-09 12:59:45", "action": 0, "post": 242}}, {"pk": 315, "model": "server.postrevision", "fields": {"author": 90, "tag_string": "", "title": "A: Has enhancer and transcription factor binding site prediction already been made redundant?", "content": "We still have a long way to go when it comes to enhancer discovery. The fact that a genomic region comes out as DNAse I hypersensitive in a certain tissue does not necessarily mean it is an enhancer region in that tissue. Here, I think the DNAse I hypersensitivity (and FAIRE) data should be regarded as a necessary input to improved enhancer prediction algorithms, rather than something to replace them. (In fact I think there are very few enhancer prediction algorithms out there, so the help is sorely needed!)\n\nSimilarly, I don't think DNAse or FAIRE *in themselves* say much about transcription factor binding, although they can be very informative in combination with knowledge of the TF motif (or so I've heard). ChIP-seq, on the other hand, does give pretty solid information on TF binding which I agree would more or less supersede computational predictions in the relevant tissue in the given organism. As others have pointed out in this thread, though, there are many organisms and/or tissues for which we won't have ChIP-seq within a foreseeable time, and for those cases (and others) we can hopefully use existing ChIP-seq data to refine computational models of TF binding. So I would regard ChIP-seq data as something that helps us refine our understanding of TF binding, including the prediction of binding events in various systems.", "date": "2010-03-09 15:44:54", "action": 0, "post": 243}}, {"pk": 316, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "assembly unambiguous fastq", "title": "Unambiguous assembly of next-gen fastq reads into fastq contigs?", "content": "Hi,\n\nDoes anybody know of any tool that will produce an unambiguous assembly of next-gen fastq files and give the assembled output back as fastq with consensus/combined scores?\n\nBy unambiguous I mean something like this in abyss:\n\nABYSS -k$k -b0 -t0 -e0 -c0\n\nCheers,\n\nAlbert. ", "date": "2010-03-09 17:11:12", "action": 0, "post": 215}}, {"pk": 317, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "Just my two cents and since nobody mentioned yet, I'm using **MATLAB**. Yes, it's commercial and expensive. It might be behind **R/Bioconductor** in amount of contributed algorithms (this is why I sometime have to use R as well). But the environment is very friendly for fast development, figures are great, and making GUIs is pretty easy. Many useful for bioinformatician toolboxes, like Statistics, Bioinformatics, Optimization. Someone may find SimBiology cool (although I haven't used it). As others mentioned **Perl** is still rules for text processing and workflows, although I agree with giovanni on its problems.", "date": "2010-03-09 17:57:12", "action": 0, "post": 244}}, {"pk": 318, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "geneontology enrichment tool", "title": "Tools to find gene ontology term enrichment", "content": "I need to make a recommendation to people working in a wet-lab looking for an easy to use tool that does GO term enrichment determination. For those unfamiliar with the concept it means that given a list of gene names they want to find out which gene ontology terms are present in numbers that are above random chance.\n\nThere is a huge [list here][1] yet a random sampling of the tools mentioned there has lead me to many non-working sites. Other tools seem out of date or just not reliable.\n\nWhat tool do you use to solve this problem?\n\nThanks.\n\n  [1]: http://www.geneontology.org/GO.tools.microarray.shtml", "date": "2010-03-09 18:13:46", "action": 0, "post": 245}}, {"pk": 319, "model": "server.postrevision", "fields": {"author": 57, "tag_string": "", "title": "A: Tools to find gene ontology term enrichment", "content": "I prefer to use DAVID ( http://david.abcc.ncifcrf.gov/ ) but id be interested to hear what other people like.  There are also R packages available through Bioconductor (GOstats; http://www.bioconductor.org/packages/2.3/bioc/html/GOstats.html) that can do enrichment determination, but I am less familiar with those, and you need a good working knowlege of R to use these.\n", "date": "2010-03-09 18:55:53", "action": 0, "post": 246}}, {"pk": 320, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Tools to find gene ontology term enrichment", "content": "You can try one of the tools at [babelomics][1], in particular FatiGO; or as an alternative, you can use the same AmiGO [Term Enrichment tool][2].\n\nHowever, be careful when using GeneOntology: it is a very active and supported project, so they make big enhancements between two releases. If you look at thei bug tracker, there are at least 8-10 changes to geneontology terms every day. So, annotate the version and date of GeneOntology if you want your experiment to be reproducible.\n\n\n  [1]: http://babelomics.bioinfo.cipf.es/\n  [2]: http://amigo.geneontology.org/cgi-bin/amigo/term_enrichment", "date": "2010-03-09 19:35:32", "action": 0, "post": 247}}, {"pk": 321, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: How to determine if a gene is active from expression data", "content": "I would suggest the following question instead of the one you're asking:\n\n**Can you actually determine if a gene is \"active\" (i.e. translated into protein) from [gene] expression data?**\n\nAnd I'll point you towards people who have published papers about it:\n\n  * [Correlation between protein and mRNA abundance in yeast.][1]\n  * [Correlation of mRNA and protein levels: Cell type-specific gene expression of cluster designation antigens in the prostate][2]\n  * [Comparing protein abundance and mRNA expression levels on a genomic scale][3]\n  * [Insights into the relation between mrna and protein expression patterns: ii. Experimental observations in Escherichia coli][4]\n\nThese are just a few papers that seem critical towards such a correlation. That is not to say that there is no good correlation for any gene. But I would be very surprised if you can make a general rule about it without checking in every cell type, tissue type and for every gene to see if such a correlation is or not acceptable.\n\nNow, if you do a Pubmed search for the terms \"[correlation mRNA protein][5]\", you will find many papers that check for such correlations, but mostly for specific genes in specific tissues (often for cancer diagnostics purposes).\n\nIf you do find papers that state such correlations, genome wide using microarray data, I'd be highly suspicious of that paper.\n\nSo, obviously, you can not set \"a\" cut-off for determining this. My personal experience tells me that you can have gene transcription with ***no*** protein expression following it... Unfortunately, I have not published it yet :(\n\n\n  [1]: http://www.ncbi.nlm.nih.gov/pubmed/10022859\n  [2]: http://www.biomedcentral.com/1471-2164/9/246\n  [3]: http://genomebiology.com/2003/4/9/117\n  [4]: http://www3.interscience.wiley.com/journal/106577988/abstract?CRETRY=1&SRETRY=0\n  [5]: http://www.ncbi.nlm.nih.gov/pubmed?term=correlation+mrna+protein", "date": "2010-03-09 20:15:02", "action": 0, "post": 248}}, {"pk": 322, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "gene protein", "title": "How to determine if a gene is active from expression data", "content": "I have RMA (Robust Multi-Array) scores for the different genes (and their isoforms) on the Affymetrix chip. I want to know which of these genes are \"active\" (or in other words: are likely to produce enough protein products to have an effect). I'm not interested in them being differentially expressed or X-fold over- or under-expressed. All I want is the classification of them being likely \"on\" or \"off\". \n\nSo far I log-transformed (basis 10) the RMA score and centered them (subtracted the median). I called all genes which had a transformed score <0 as being inactive and scores >0 as being active. \n\nDoes anyone have a better methodology ?\n\n", "date": "2010-03-09 20:16:00", "action": 0, "post": 238}}, {"pk": 323, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: Hierarchical Clustering, Cluster Heat Maps in Java", "content": "[GenePilot][1]\u2122 is a Java-based Analysis suite, which provides a MicroArray Analysis capabilities. \n\nYou can export your results as Cluster Heatmaps. They give the following example of a local heatmap of the currently selected cluster along with the top dendigram (if applicable), column information, average thumbnail, row info and Gene Ontology Information (if applicable):\n\n![alt text][2]\n\n\n  [1]: http://www.genepilot.com/index.html\n  [2]: http://www.genepilot.com/assets/gifs/HC_Select_right.gif", "date": "2010-03-09 22:41:33", "action": 0, "post": 249}}, {"pk": 324, "model": "server.postrevision", "fields": {"author": 89, "tag_string": "", "title": "A: Tools to find gene ontology term enrichment", "content": "Another option is GONOME (http://gonome.imb.uq.edu.au/), which finds the over- and under-represented\nGO terms for a given set of genomic positions.", "date": "2010-03-09 23:15:00", "action": 0, "post": 250}}, {"pk": 325, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "metabolomics metabolite cheminformatics java opensource", "title": "What open source Java library can I use to query online, free databases in which pathways a metabolite is participating?", "content": "What opensource Java solutions are available to query online pathway databases like [KEGG][1] (or [BioMeta][2]), [MACiE][3] and [Brenda][4] for the pathways a certain metabolite is available, for example, based on the [InChI][5]? Preferably, the library would have a good data model for the pathway information, possibly [SMBL][6] or [RDF][7]-based. What would the code look like to make such a query?\n\n\n  [1]: http://www.genome.jp/kegg/\n  [2]: http://biometa.cmbi.ru.nl/\n  [3]: http://www.ebi.ac.uk/thornton-srv/databases/MACiE/\n  [4]: http://www.brenda-enzymes.org/\n  [5]: http://en.wikipedia.org/wiki/International_Chemical_Identifier\n  [6]: http://sbml.org/\n  [7]: http://en.wikipedia.org/wiki/Resource_description_framework", "date": "2010-03-10 11:57:11", "action": 0, "post": 251}}, {"pk": 326, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: What open source Java library can I use to query online, free databases in which pathways a metabolite is participating?", "content": "There is no explicit Brenda Java-API I know of, but kegg provides [a jar-file][1] which I recommend you ***don't*** use. \nThere is a solution anyhow, I have never used MACiE btw.\nBoth database provide a standard compliant web-services interface over SOAP messages.\nWeb-services are a standardized way of language and system independent programmatic communication. \n\n[KEGG soap: http://www.genome.jp/kegg/soap/][2]\n\n[Brenda SOAP: http://www.brenda-enzymes.org/soap/][3]\n\nBoth services have a [WSDL file][4] to describe the interface.\n\nThis description can be used to automatically generate client code using for example [Axis2 a free open-source][5] implementation of the [SOAP protocol][6]. IMHO this is the way to go.\nSo you will use Axis2 wsdl2code (or the Axis2 Eclipse-plugin) to generate exactly the free-open-source Java API you need.\n\n\n  [1]: http://www.genome.jp/kegg/soap/support/keggapi.jar\n  [2]: http://www.genome.jp/kegg/soap/\n  [3]: http://www.brenda-enzymes.org/soap/\n  [4]: http://en.wikipedia.org/wiki/Web_Services_Description_Language\n  [5]: http://ws.apache.org/axis2/\n  [6]: http://en.wikipedia.org/wiki/SOAP", "date": "2010-03-10 15:48:37", "action": 0, "post": 252}}, {"pk": 327, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "", "title": "A: Tools to find gene ontology term enrichment", "content": "it's very much in progress, but a colleague and I (mostly him) have been working on this for python:\nhttp://github.com/tanghaibao/goatools/\n\nit has a command-line script to find terms that are enriched in a study group. it reports p-value for various multiple testing corrections as well as the false discovery rate.\n\nIt can also be used to plot the DAG of a particular GO term. ", "date": "2010-03-10 16:24:01", "action": 0, "post": 253}}, {"pk": 328, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: What open source Java library can I use to query online, free databases in which pathways a metabolite is participating?", "content": "There is no explicit Brenda Java-API I know of, but kegg provides [a jar-file][1] which I recommend you ***don't*** use. \nThere is a solution anyhow, I have never used MACiE btw.\nBoth database provide a standard compliant web-services interface over SOAP messages.\nWeb-services are a standardized way of language and system independent programmatic communication. \n\n[KEGG soap: http://www.genome.jp/kegg/soap/][2]\n\n[Brenda SOAP: http://www.brenda-enzymes.org/soap/][3]\n\nBoth services have a [WSDL file][4] to describe the interface.\n\nThis description can be used to automatically generate client code using for example [Axis2 a free open-source][5] implementation of the [SOAP protocol][6]. IMHO this is the way to go.\nSo you will use Axis2 wsdl2code (or the Axis2 Eclipse-plugin) to generate exactly the free-open-source Java API you need.\n\n\n----------\n A little edit and some issues from myself after having a look at the KEGG soap interface:\n\nAs often, KEGG is a bit misbehaving, so what I answered above is the theory, it is true *in principle*, but....\n\n1. The databinding (mapping of xml-schema types to Java types) that seems to work is\n**xmlbeans**. The **adb** databinding gives an error. This is due to non-standard use of some\nstructures in the wsdl. \n\n2. Below is some source code demonstrating how an axis2 interface with xmlbeans data binding can be used. The only glitch is I cannot tell, how to set or read the *ArrayOfstring*. This glitch is IMHO KEGG's fault because they did only test with Axis1.\n\n3. Alternatives if nobody knows a better solution, try Axis1 with [the jar-file][7] from KEGG or try the [Brenda WSDL][8].\n\nExample use of Axis2/xmlbeans generated classes. The principle is the same for Brenda:\n\n  \n\n     package keggtest;\n            \n       import java.rmi.RemoteException;\n            \n       import kegg.soap.ArrayOfstring;\n       import kegg.soap.GetPathwaysByGenesDocument;\n       import kegg.soap.GetPathwaysByGenesResponseDocument;\n       import kegg.soap.KEGGStub;\n       import kegg.soap.GetPathwaysByGenesDocument.GetPathwaysByGenes;\n            \n       import org.apache.axis2.AxisFault;\n    \n    public class keggclient {\n    \n    \t/**\n    \t * @param args\n    \t */\n    \tpublic static void main(String[] args) {\n    \n    \t\ttry {\n    \t\t\tKEGGStub stub = new KEGGStub(\"http://soap.genome.jp/KEGG.wsdl\");\n    \n    \t\t\tGetPathwaysByGenes getPathwaysByGenes = GetPathwaysByGenes.Factory\n    \t\t\t\t\t.newInstance();\n    \t\t\tArrayOfstring genesIdList = ArrayOfstring.Factory.newInstance();\n    \t\t\t// add items to ArrayOfstring, but how?\n    \t\t\tgetPathwaysByGenes.setGenesIdList(genesIdList);\n    \t\t\tGetPathwaysByGenesDocument get_pathways_by_genes = GetPathwaysByGenesDocument.Factory\n    \t\t\t\t\t.newInstance();\n    \t\t\tget_pathways_by_genes.setGetPathwaysByGenes(getPathwaysByGenes);\n    \t\t\ttry {\n    \t\t\t\tGetPathwaysByGenesResponseDocument res = stub\n    \t\t\t\t\t\t.get_pathways_by_genes(get_pathways_by_genes);\n    \t\t\t\tSystem.err.println(res.getGetPathwaysByGenesResponse()\n    \t\t\t\t\t\t.getReturn());\n    \t\t\t} catch (RemoteException e) {\n    \t\t\t\t// TODO Auto-generated catch block\n    \t\t\t\te.printStackTrace();\n    \t\t\t}\n    \n    \t\t} catch (AxisFault e) {\n    \t\t\t// TODO Auto-generated catch block\n    \n    \t\t\te.printStackTrace();\n    \t\t}\n    \n    \t}\n    }\n\n\n  [1]: http://www.genome.jp/kegg/soap/support/keggapi.jar\n  [2]: http://www.genome.jp/kegg/soap/\n  [3]: http://www.brenda-enzymes.org/soap/\n  [4]: http://en.wikipedia.org/wiki/Web_Services_Description_Language\n  [5]: http://ws.apache.org/axis2/\n  [6]: http://en.wikipedia.org/wiki/SOAP\n  [7]: http://www.genome.jp/kegg/soap/support/keggapi.jar\n  [8]: http://www.brenda-enzymes.org/soap/brenda.wsdl", "date": "2010-03-10 20:50:20", "action": 0, "post": 252}}, {"pk": 329, "model": "server.postrevision", "fields": {"author": 23, "tag_string": "", "title": "A: Pfam based functional annotaion", "content": "This review article may be helpful or at least interesting to you:\n\n[\"Automated protein function prediction -- the genomic challenge\"][1] (Friedberg 2006)\n\nHere's a relevant excerpt:\n\n> Pfam is arguably the database of choice for those seeking order within the protein sequence universe. [...] As we shall see, Pfam annotation is used by function prediction programs, either by directly querying Pfam or by using umbrella databases that include Pfam information such as InterPro. SMART, CDD, and PRODOM are other databases consisting of multiple alignments of protein domains. All these databases have proteins arranged in homologous clusters, which, when possible, are annotated. These databases are often deferred to when producing homology-based annotation transfers. It should be emphasized that the use of these databases for homology transfer should be done with caution, as they annotate proteins on a domain level. A multi-domain query aligned to Pfam, for example, should be carefully checked for mis-annotations due to domain shuffling, as mentioned eariler. Also, the 'granularity' of these databases varies. For example, a single Pfam family may contain several proteins which perform the same enzymatic reaction on different substrates.\n\n  [1]: http://bib.oxfordjournals.org/cgi/content/full/7/3/225", "date": "2010-03-10 21:05:39", "action": 0, "post": 254}}, {"pk": 330, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: What open source Java library can I use to query online, free databases in which pathways a metabolite is participating?", "content": "There is no explicit Brenda Java-API I know of, but kegg provides [a jar-file][1] which I recommend you ***don't*** use. \nThere is a solution anyhow, I have never used MACiE btw.\nBoth database provide a standard compliant web-services interface over SOAP messages.\nWeb-services are a standardized way of language and system independent programmatic communication. \n\n[KEGG soap: http://www.genome.jp/kegg/soap/][2]\n\n[Brenda SOAP: http://www.brenda-enzymes.org/soap/][3]\n\nBoth services have a [WSDL file][4] to describe the interface.\n\nThis description can be used to automatically generate client code using for example [Axis2 a free open-source][5] implementation of the [SOAP protocol][6]. IMHO this is the way to go.\nSo you will use Axis2 wsdl2code (or the Axis2 Eclipse-plugin) to generate exactly the free-open-source Java API you need.\n\n\n----------\n A little edit and some issues from myself after having a look at the KEGG soap interface:\n\nAs often, KEGG is a bit misbehaving, so what I answered above is the theory, it is true *in principle*, but....\n\n1. The databinding (mapping of xml-schema types to Java types) that seems to work is\n**xmlbeans**. The **adb** databinding gives an error. This is due to non-standard use of some\nstructures in the wsdl. \n\n2. Below is some source code demonstrating how an axis2 interface with xmlbeans data binding can be used. The only glitch is I cannot tell, how to set or read the *ArrayOfstring*. This glitch is IMHO KEGG's fault because they did only test with Axis1.\n\n3. Alternatives if nobody knows a better solution, try Axis1 with [the jar-file][7] from KEGG or try the [Brenda WSDL][8].\n\nExample use of Axis2/xmlbeans generated classes. The principle is the same for Brenda:\n\n  \n\n     package keggtest;\n            \n       import java.rmi.RemoteException;\n            \n       import kegg.soap.ArrayOfstring;\n       import kegg.soap.GetPathwaysByGenesDocument;\n       import kegg.soap.GetPathwaysByGenesResponseDocument;\n       import kegg.soap.KEGGStub;\n       import kegg.soap.GetPathwaysByGenesDocument.GetPathwaysByGenes;\n            \n       import org.apache.axis2.AxisFault;\n    \n    public class keggclient {\n    \n    \t/**\n    \t * @param args\n    \t */\n    \tpublic static void main(String[] args) {\n    \n    \t\ttry {\n    \t\t\tKEGGStub stub = new KEGGStub(\"http://soap.genome.jp/KEGG.wsdl\");\n    \n    \t\t\tGetPathwaysByGenes getPathwaysByGenes = GetPathwaysByGenes.Factory\n    \t\t\t\t\t.newInstance();\n    \t\t\tArrayOfstring genesIdList = ArrayOfstring.Factory.newInstance();\n    \t\t\t// add items to ArrayOfstring, but how?\n    \t\t\tgetPathwaysByGenes.setGenesIdList(genesIdList);\n    \t\t\tGetPathwaysByGenesDocument get_pathways_by_genes = GetPathwaysByGenesDocument.Factory\n    \t\t\t\t\t.newInstance();\n    \t\t\tget_pathways_by_genes.setGetPathwaysByGenes(getPathwaysByGenes);\n    \t\t\ttry {\n    \t\t\t\tGetPathwaysByGenesResponseDocument res = stub\n    \t\t\t\t\t\t.get_pathways_by_genes(get_pathways_by_genes);\n    \t\t\t\tSystem.err.println(res.getGetPathwaysByGenesResponse()\n    \t\t\t\t\t\t.getReturn());\n    \t\t\t} catch (RemoteException e) {\n    \t\t\t\t// TODO Auto-generated catch block\n    \t\t\t\te.printStackTrace();\n    \t\t\t}\n    \n    \t\t} catch (AxisFault e) {\n    \t\t\t// TODO Auto-generated catch block\n    \n    \t\t\te.printStackTrace();\n    \t\t}\n    \n    \t}\n    }\n\n\n----------\nAnd another edit, after trying the Brenda WSDL with axis2 wsdl2code, the result is not \nvery promising:\n...\nSEVERE: The binding operation getKeggPathway is RPC/literal. The message parts for this operation must use the type attribute as specificed by WS-I Basic Profile specification (4.4.1).  Message part, ecNumber, violatesthis rule.  Please remove the element attribute and use the type attribute.\n...\n\nSo, if somebody has a better answer, including asking the service providers to adhere to standards. Apologies for testing after answering.... \n\n\n\n\n\n  [1]: http://www.genome.jp/kegg/soap/support/keggapi.jar\n  [2]: http://www.genome.jp/kegg/soap/\n  [3]: http://www.brenda-enzymes.org/soap/\n  [4]: http://en.wikipedia.org/wiki/Web_Services_Description_Language\n  [5]: http://ws.apache.org/axis2/\n  [6]: http://en.wikipedia.org/wiki/SOAP\n  [7]: http://www.genome.jp/kegg/soap/support/keggapi.jar\n  [8]: http://www.brenda-enzymes.org/soap/brenda.wsdl", "date": "2010-03-10 21:12:15", "action": 0, "post": 252}}, {"pk": 331, "model": "server.postrevision", "fields": {"author": 72, "tag_string": "base phred fastq bustard", "title": "How can a base-called position be \"unknown\" but have a non-minimal score?", "content": "Let's say I extract something like this from a qseq or FASTQ file\n\n    TTCAGATGTTCATATGCGGATCGGCGCTGGGCCCACGAGATCTAGCAGAGCTCGT.GGGACCACGACCACCGACCC\n    a`bbbbbbaabbab`ab^`bVa^^bab^[``bba^`]_Ya^`_`^^_Xa\\_KYTYD[PY^Y_^[P[V_BBBBBBBB\n\nSo the dot is like an N - it can't call the base. So if I look at the FASTQ scores in integer format I would expect that position to have a minimal score. But in fact its score is 'D' or 4, not great but some other called bases at the tail end are 'B' or 2. What gives?", "date": "2010-03-10 21:26:16", "action": 0, "post": 255}}, {"pk": 332, "model": "server.postrevision", "fields": {"author": 120, "tag_string": "sequencing dna", "title": "If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "content": "I have a plate of colonies to sequence.  I pick 2 colonies and sequence each in Fwd and Rev directions.   I get back a single bp difference between the 2 strands.  2 bp have an T, two have a C.   How should I call this base?  Can I call it a Y (C or T) and leave it at that, or do I need to sequence another colony to be sure? \n", "date": "2010-03-10 23:46:35", "action": 0, "post": 256}}, {"pk": 333, "model": "server.postrevision", "fields": {"author": 121, "tag_string": "", "title": "A: How to determine if a gene is active from expression data", "content": "Sounds like your trying to find genes which actually switch from on-to-off (or vice-versa) based on cell-type, condition, etc.  Not all genes have this type of behavior ... some are graded (like a dimer switch).  There are numerous papers that discuss techniques for finding genes which have \"bi-modal\" expression patterns.  Since they are a mixture of two expressions patterns it is likely that they have \"on\" and \"off\" pattern.\n\nThis article explain the technique and includes Matlab code that should do the whole thing for you.\n\n[Human and mouse switch-like genes share common transcriptional regulatory mechanisms for bimodality.][1]\n\n\n  [1]: http://www.ncbi.nlm.nih.gov/pubmed/19105848", "date": "2010-03-11 01:09:56", "action": 0, "post": 257}}, {"pk": 334, "model": "server.postrevision", "fields": {"author": 121, "tag_string": "python geneid conversion", "title": "Programatic technique for gene-name/id conversion", "content": "Does anyone know of a good gene-id conversion tool written in Python.  I've come across numerous webtools but I'd like something a little more automated.  I have the knowledge/ability to do it myself I was just wondering if there was something already out there.  There's no point in re-inventing the wheel each time.\n\nThanks in advance", "date": "2010-03-11 01:27:26", "action": 0, "post": 258}}, {"pk": 335, "model": "server.postrevision", "fields": {"author": 121, "tag_string": "", "title": "A: Experiences with cloud computing in bioinformatics", "content": "I've started using [PiCloud][1].  It is a super simple library for Python that facilitates running your code in the cloud.  The client will copy your interpreter's state and then run the code on their Amazon EC2 cluster.  They then charge you based on your program's run time.  They're currently doing beta trials so its actually free (for now).\n\nThe only disadvantage is that they abstract everything away from you ... so its actually impossible to run on your own Amazon EC2 cluster.  Its also virtually impossible to run anything that's not Python.\n\nBut overall I've found it really easy to implement some of my algorithms using their client.\n\n\n  [1]: http://www.picloud.com/", "date": "2010-03-11 01:50:51", "action": 0, "post": 259}}, {"pk": 336, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Programatic technique for gene-name/id conversion", "content": "You could automate the access to the website with Python ;-)", "date": "2010-03-11 03:36:20", "action": 0, "post": 260}}, {"pk": 337, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How can a base-called position be \"unknown\" but have a non-minimal score?", "content": "I recall a situation where one of our students (Gue-Su Chang) tracked down a few undocumented behaviors in the Illumina pipeline. Basically once the basecalling is done there are additional filters applied during post-processing to handle a few odd cases. This might be on of those, the score D refers to the original call, but  later that gets overridden by another step. I know that's pretty vague. Long story short: I think the score does not apply here.\n ", "date": "2010-03-11 03:59:56", "action": 0, "post": 261}}, {"pk": 338, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Unambiguous assembly of next-gen fastq reads into fastq contigs?", "content": "I think combining the quality score is not the intended use case for the p-values. The quality scores refer to the probability of a basecall being incorrect. So during assembly it is an important information. \n\nBut once the reads are assembled if we were to keep it, it would need to reflect not just the chance of one base being wrong but that for an entire overlap to occur by chance. That is a different quantity than the original.\n\nThis is just an opinion, I could be wrong.\n", "date": "2010-03-11 04:16:58", "action": 0, "post": 262}}, {"pk": 339, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "content": "There are lots of factors to consider here:\n\n1) What do the quality scores tell you about the base call at that position?\n\n2) How deep is your coverage?  If you've got 1x coverage, it's possible that you may be seeing a miscalled base. If you're taking consensus from 30x coverage, it's much less likely.\n\n3) You're sequencing from a population. It's completely possible that within this population there are individuals with both alleles that you're describing, right?", "date": "2010-03-11 05:03:27", "action": 0, "post": 263}}, {"pk": 340, "model": "server.postrevision", "fields": {"author": 118, "tag_string": "", "title": "A: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "content": "As chrisamiller says, it depends on the details of what you're trying to do. **The question is whether what you're seeing is variation due to technical error or due to biological variation.** \n\nHowever, without any additional information, if you've essentially only got 2 reads per sequence with contradicting information at a given position, you can't really call the base with any degree of certainty. In this case, the use of an ambiguity base call (i.e. Y instead of C or T) would be justified, in my view.", "date": "2010-03-11 05:42:31", "action": 0, "post": 264}}, {"pk": 341, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: If I have 4 sequence runs, 2 in each direction, 1 bp is different, on each, should I resequence?", "content": "I agree with chrisamiller and PhiS. I'll just add that it also ***greatly depends on what you will do with your sequence***.\n\nI understand from your question that:\n\n  * You have picked only 2 [bacterial] colonies for sequencing\n  * These colonies result from the cloning of a PCR product (?)\n  * They were sequenced using Sanger sequencing\n\n[NOTE: when describing your problem it is very important to give these kind of details, so please correct me if my assumptions are wrong.]\n\nI am guessing that:\n\n  * You might want to check that the sequence is correct (maybe verifying that your qPCR product is correct)?\n  * You might be cloning a gene (or fragment thereof) in order to express a protein?\n\n[NOTE: here again, these kind of details are crucial in determining if you can accept an ambiguous base or not. Please add a comment or edit your post if it is yet another purpose]\n\nFinally, as Istvan has asked, you need to be clear as to what the difference is: are you looking at a different base call ***between the two sequenced colonies*** or ***between the forward and reverse sequencing events***?\n\nIf it is the first (i.e. difference between the two colonies) then you need to check the quality of the call at that base (quality scores if you have them, or look at the chromatogram to see if there's a mistake or a double pic etc.). If they are good quality, then you probably have at least these two different variants of the sequence you're targeting.\n\nIf it is the second (i.e. difference between the forward and reverse) then you should also look at the quality in each read. If they are bad quality, sequence again. If they are good quality, then I'm scratching my head making a funny face. Start over from scratch.\n\nNow to your question about leaving it ambiguous or not: \n\n  * If you just wanted to check that the sequence is \"fairly\" OK, then fine, leave it as a Y.\n  * If you're checking the amplicon of a qPCR event, then it is crucial to know if you have only one sequence or two different ones (even if it's a SNP). This will change your interpretation.\n  * If you want to express a protein from this sequence, then you need to check if the difference (T or C) changes the resulting protein sequence: if yes, you need to choose the correct clone. If not, you can go with either.\n\n", "date": "2010-03-11 08:39:15", "action": 0, "post": 265}}, {"pk": 342, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: Programatic technique for gene-name/id conversion", "content": "Writing a small tool to automate access to the website/service is pretty simple. Here's a method I wrote for the UniProt ID mapping service:\n\n    import urllib\n    import urllib2\n    \n    def uniprot_mapping(fromtype, totype, identifier):\n        base = 'http://www.uniprot.org'\n        tool = 'mapping'\n        params = {'from':fromtype,\n                    'to':totype,\n                    'format':'tab',\n                    'query':identifier,\n        }\n        data = urllib.urlencode(params)\n        url = base+'/'+tool+'?'+data\n        response = urllib2.urlopen(url)\n        return response.read()\n\nIt's not extensively tested, but should work. You can find a list of fromtypes and totypes here: [http://www.uniprot.org/faq/28#id_mapping_examples][1]\n\n\n  [1]: http://www.uniprot.org/faq/28#id_mapping_examples", "date": "2010-03-11 11:03:45", "action": 0, "post": 266}}, {"pk": 343, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: Tools to find gene ontology term enrichment", "content": "The [BiNGO plugin][1] for [Cytoscape][2] will allow you to determine term enrichment in a Cytoscape network. It's quite a neat tool.\n\n\n  [1]: http://www.psb.ugent.be/cbd/papers/BiNGO/\n  [2]: http://www.cytoscape.org/", "date": "2010-03-11 11:19:47", "action": 0, "post": 267}}, {"pk": 344, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "geneontology enrichment tool go", "title": "Tools to find gene ontology term enrichment", "content": "I need to make a recommendation to people working in a wet-lab looking for an easy to use tool that does GO term enrichment determination. For those unfamiliar with the concept it means that given a list of gene names they want to find out which gene ontology terms are present in numbers that are above random chance.\n\nThere is a huge [list here][1] yet a random sampling of the tools mentioned there has lead me to many non-working sites. Other tools seem out of date or just not reliable.\n\nWhat tool do you use to solve this problem?\n\nThanks.\n\n  [1]: http://www.geneontology.org/GO.tools.microarray.shtml", "date": "2010-03-11 18:04:52", "action": 0, "post": 245}}, {"pk": 345, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "podcast subjective recommendations", "title": "Appropriate podcasts for a bioinformatician?", "content": "What podcasts are the bioinformaticians here listening to that tie in with their work?  \n\nThe most relevant podcast that I know of (the currently even more irregular than normal) [Coast to Coast Bio Podcast][1] is still in my list of podcasts.\n\nFor programming related topics I still find the [StackOverflow podcast][2] an interesting and engaging listen.\n\nWhilst at one point or another I subscribed to both [Nature][3] and [Science][4] podcasts for general science I no longer do so.\n\nWhat podcasts might I be missing out on that other people are enjoying related to their work?\n\n\n  [1]: http://www.c2cbio.com/\n  [2]: http://blog.stackoverflow.com/category/podcasts/\n  [3]: http://www.nature.com/nature/podcast/\n  [4]: http://www.sciencemag.org/about/podcast.dtl", "date": "2010-03-12 09:52:17", "action": 0, "post": 268}}, {"pk": 346, "model": "server.postrevision", "fields": {"author": 89, "tag_string": "", "title": "A: Appropriate podcasts for a bioinformatician?", "content": "That is a great question. I am not aware of any podcast or vodcast(video) that specifically cover  bioinformatics topics so far.\nBut there are other services that provide bioinformatics content in a audio-visual form:\n\nhttp://www.scivee.tv/\n\nhttp://videolectures.net/Top/Computer_Science/Bioinformatics/\n\nhttp://www.bioscreencast.com/\n\n", "date": "2010-03-12 11:47:06", "action": 0, "post": 269}}, {"pk": 347, "model": "server.postrevision", "fields": {"author": 89, "tag_string": "podcast subjective recommendations vodcast", "title": "Appropriate podcasts for a bioinformatician?", "content": "What podcasts are the bioinformaticians here listening to that tie in with their work?  \n\nThe most relevant podcast that I know of (the currently even more irregular than normal) [Coast to Coast Bio Podcast][1] is still in my list of podcasts.\n\nFor programming related topics I still find the [StackOverflow podcast][2] an interesting and engaging listen.\n\nWhilst at one point or another I subscribed to both [Nature][3] and [Science][4] podcasts for general science I no longer do so.\n\nWhat podcasts might I be missing out on that other people are enjoying related to their work?\n\n\n  [1]: http://www.c2cbio.com/\n  [2]: http://blog.stackoverflow.com/category/podcasts/\n  [3]: http://www.nature.com/nature/podcast/\n  [4]: http://www.sciencemag.org/about/podcast.dtl", "date": "2010-03-12 11:47:29", "action": 0, "post": 268}}, {"pk": 348, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: Appropriate podcasts for a bioinformatician?", "content": "Related, but not bioinformatics, BBC podcasts:\n\n - Material World - popsci http://www.bbc.co.uk/podcasts/series/material/\n - More or Less - statistics etc. http://www.bbc.co.uk/podcasts/series/moreorless\n\nBoth have very good presenters, and make for an entertaining listen.", "date": "2010-03-12 11:55:57", "action": 0, "post": 270}}, {"pk": 349, "model": "server.postrevision", "fields": {"author": 124, "tag_string": "rna alignment trna", "title": "How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "content": "(Sorry for the long header)\n\nHello all.\n\nI wish to have a FASTA file (or similar) of a tRNA sequences that are aligned.\n\nHere is an example of a FASTA file I would like to align:\n\nhttp://gtrnadb.ucsc.edu/Aero_pern/aerPer1-tRNAs.fa\n\nHere is how the sequence would look aligned:\n\nhttp://gtrnadb.ucsc.edu/Aero_pern/Aero_pern-align.html\n\nIt uses a software called COVE, which can be found here:\n\nhttp://selab.janelia.org/software.html\n\nAnd it is said to do it by doing: \"Structural alignments are generated by aligning tRNA sequences against domain-specific tRNA covariance models with the use of COVE.\"\n\nWhich leads me to my questions:\n\n1. Where might I find the \"domain-specific tRNA\" to run the COVE model with ?\n2. How can I do this on windows ?\n3. Is there a better way to do this alignment ?\n\n\nThis is my first question, and I am very new to bioinformatics, so I am sorry if I am missing something very basic, or am asking something to which not many people would know to answer.\n\nThanks in advance,\n\nTal\n", "date": "2010-03-12 13:58:39", "action": 0, "post": 271}}, {"pk": 350, "model": "server.postrevision", "fields": {"author": 118, "tag_string": "alignment trna sequence", "title": "How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "content": "(Sorry for the long header)\n\nHello all.\n\nI wish to have a FASTA file (or similar) of a tRNA sequences that are aligned.\n\nHere is an example of a FASTA file I would like to align:\n\nhttp://gtrnadb.ucsc.edu/Aero_pern/aerPer1-tRNAs.fa\n\nHere is how the sequence would look aligned:\n\nhttp://gtrnadb.ucsc.edu/Aero_pern/Aero_pern-align.html\n\nIt uses a software called COVE, which can be found here:\n\nhttp://selab.janelia.org/software.html\n\nAnd it is said to do it by doing: \"Structural alignments are generated by aligning tRNA sequences against domain-specific tRNA covariance models with the use of COVE.\"\n\nWhich leads me to my questions:\n\n1. Where might I find the \"domain-specific tRNA\" to run the COVE model with ?\n2. How can I do this on windows ?\n3. Is there a better way to do this alignment ?\n\n\nThis is my first question, and I am very new to bioinformatics, so I am sorry if I am missing something very basic, or am asking something to which not many people would know to answer.\n\nThanks in advance,\n\nTal\n", "date": "2010-03-12 14:15:23", "action": 0, "post": 271}}, {"pk": 351, "model": "server.postrevision", "fields": {"author": 90, "tag_string": "", "title": "A: Appropriate podcasts for a bioinformatician?", "content": "I enjoy [Futures in Biotech][1], which is about life science in general but does touch on bioinformatics sometimes.\n\n\n  [1]: http://twit.tv/FIB", "date": "2010-03-12 14:17:58", "action": 0, "post": 272}}, {"pk": 352, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "content": " 1. The site is a little short on information but it gave me the impression that it will build the covariance model from the multiple sequence alignment itself. Try contacting the author for more information.\n 2. You can compile cove on Windows under [Cygwin][1], I just gave it a try and compiled it with no problem.\n\n\n  [1]: http://www.cygwin.com/", "date": "2010-03-12 15:51:14", "action": 0, "post": 273}}, {"pk": 353, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: Appropriate podcasts for a bioinformatician?", "content": "It's not bioinformatic-specific, but <a href=\"http://www.wnyc.org/shows/radiolab/\">RadioLab</a> is a great science show. I especially like listening on days when I'm frustrated with my work - it helps me remember why I have a passion for science.", "date": "2010-03-12 16:23:51", "action": 0, "post": 274}}, {"pk": 354, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "content": "I had a quick look into the documentation of the software. If you donwload and unpack the soucecode archive, there is a Guide.tex file that can be compiled with Latex, you could look into this. So, to answer your questions partially without trying anything myself: \n \n1. Where do I find the covariance Models to run COVE with? As Istvan said: you have to make them yourself. From the manual:\nUsing these programs, you can:\n - generate new models, by training them on example sequences (covet) ....\n\n2. See Istvan's answer\n3. Possibly not:\n\n    The tRNA identification program  tRNAscan-SE is based on a tRNA CM and COVE  (Lowe and Eddy, 1997). \n\nAnd this program is still state-of-the art in tRNA discovery. If you want to look at RNAs in general an learn about their structure then [Rfam][1]/Infernal is nice.\n\nIf you are interested in RNA structure and visualization the [BiBiServ RNA-Studio][2] are an interesting resource.\n\n\n  [1]: http://rfam.janelia.org/\n  [2]: http://bibiserv.techfak.uni-bielefeld.de/bibi/Tools_RNA_Studio.html", "date": "2010-03-12 16:24:10", "action": 0, "post": 275}}, {"pk": 355, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: How to perform tRNA sequence alignment (against a domain-specific tRNA covariance models) with COVE (or Infernal) on windows ?", "content": "There is a recent review:\n\nComputational analysis of tRNA identity\nFEBS Letters, Volume 584, Issue 2, Pages 325-333\n\nD. Ardell\n\nhttp://dx.doi.org/10.1016/j.febslet.2009.11.084\n\nYou may check if COVE is your only option. ", "date": "2010-03-12 16:31:28", "action": 0, "post": 276}}, {"pk": 356, "model": "server.postrevision", "fields": {"author": 52, "tag_string": "blast gff format", "title": "How to convert BLAST results to GFF", "content": "I'd like to visualise the results of a BLAST search in a genome browser. Is there a simple way to get the results in GFF format without having to write a parser myself?", "date": "2010-03-12 17:04:23", "action": 0, "post": 277}}, {"pk": 357, "model": "server.postrevision", "fields": {"author": 52, "tag_string": "", "title": "A: Appropriate podcasts for a bioinformatician?", "content": "I like [The Changelog][1]. It highlights interesting and useful open source software with a slight ruby slant.\n\n\n  [1]: http://thechangelog.com/", "date": "2010-03-12 17:07:53", "action": 0, "post": 278}}, {"pk": 358, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How to convert BLAST results to GFF", "content": "I found this via google: http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl\n\nelse I would save my blast result as **XML** and transform it to GFF with with a (should be) simple **XSLT** stylesheet.\n\n", "date": "2010-03-12 17:18:08", "action": 0, "post": 279}}, {"pk": 359, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: How to convert BLAST results to GFF", "content": "Have you tried these scripts: http://gmod.org/wiki/Load_BLAST_Into_Chado, http://www.bioperl.org/pipermail/bioperl-l/2002-November/010223.html ??\n\nmaybe the [PSL][1] format is better to represent an alignment. You can also look at the [BED][2] format so later you can play with [BedTools][3]\n\n\n  [1]: http://genome.ucsc.edu/FAQ/FAQformat.html#format2\n  [2]: http://genome.ucsc.edu/FAQ/FAQformat.html#format1\n  [3]: http://code.google.com/p/bedtools/", "date": "2010-03-12 17:29:05", "action": 0, "post": 280}}, {"pk": 360, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How to convert BLAST results to GFF", "content": "I found this via google: http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl\n\nelse I would save my blast result as **XML** and transform it to GFF with with a (should be) simple **XSLT** stylesheet. As an example, you can have a look at my 'old' stylesheet blast2svg: http://code.google.com/p/lindenb/source/browse/trunk/src/xsl/blast2svg.xsl\nPierre\n\n", "date": "2010-03-12 17:29:14", "action": 0, "post": 279}}, {"pk": 361, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: How to convert BLAST results to GFF", "content": "Start with tabulated blast output myfile.blast.out. Then check two-liners from:\n\nhttp://bergman-lab.blogspot.com/2009/12/ncbi-blast-tabular-output-format-fields.html\n\nFew lines tooutput proper gff are missing, but you may either go for minimalistic gff or try to encode everything in column 9. Also you may try validating your gff3 here:\n\nhttp://modencode.oicr.on.ca/cgi-bin/validate_gff3_online\n\n", "date": "2010-03-12 18:12:04", "action": 0, "post": 281}}, {"pk": 362, "model": "server.postrevision", "fields": {"author": 121, "tag_string": "", "title": "A: Programatic technique for gene-name/id conversion", "content": "In case anyone comes by this later I've made a simple python module for doing this sort of converting.  You can find it on GitHub: http://github.com/JudoWill/IDConverter\n\nFeel free make comments and provide suggestions.", "date": "2010-03-13 04:51:33", "action": 0, "post": 282}}, {"pk": 363, "model": "server.postrevision", "fields": {"author": 30, "tag_string": "career subjective", "title": "What do you consider the most trivial and the most challenging tasks in your particular field of work?", "content": "To clarify, I am a biochemist, trained in molecular evolution since undergrad and I changed my particular field of work to large scale phylogenetic analysis in the grad school. \n\nSo, to me, building and interpreting a phylogenetic tree from a family of genes can be considered a trivial task in my subfield (actually, this should be be trivial to any people with a background in biology), but to integrate functional data and increase the scale of the analysis to whole genomes and dozen/hundreds of species would be a little more challenging. \n\nI am really curious since bioinformatics and computational biology has had a fast growing in the last years, many paradigms have changed in what is trivial and what is challenging in his many subfields. ", "date": "2010-03-13 15:46:57", "action": 0, "post": 283}}, {"pk": 364, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "content": "**Challenging**:\n\n - Using other's code\n - understanding why a technology/paper/language/db is worth looking/testing\n - understanding theoretical papers\n - making my code reusable\n - being my own learning mentor\n - working with 'big-data'\n - (...)\n\n**Trivial**:\n\n  - working with 'big-data' :-)\n  - Using SQL/C/C++/Java/etc... etc...\n  - using some common resources related to by field (dbsnp...)\n  - Parsing data\n  - sharing\n  - (...)", "date": "2010-03-13 16:41:18", "action": 0, "post": 284}}, {"pk": 365, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "content": "Off the top of my head:\n\n**Challenging and frustrating:**  \n\n - Sifting through the avalanche of new\n   papers and tools to find ones that\n   are immediately relevant  \n\n**Challenging and interesting:**  \n\n - Given whole-genome assays, deciding which\n   of the hundreds of mutations are\n   important and potentially causative\n -  Integrating results from assays that\n   provide different insights and\n   potentially conflicting information.\n - writing code using a parallel (or map/reduce) paradigm, so that it won't take years to run\n\n**Trivial, but tedious:**  \n\n - constantly munging data files from one poorly defined format to another\n", "date": "2010-03-13 17:33:54", "action": 0, "post": 285}}, {"pk": 366, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: How to convert BLAST results to GFF", "content": "\n>  http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl\n\nYou can use the script Pierre found swith a slight modification, actually it is a bit crude and does no real error checking but it works. The error is it does not work if the blast file has a header like this:\n\n    # BLASTN 2.2.21 [Jun-14-2009]\n    # Query: 16383 sequences\n    # Database: genomedata/GenomeOfDeath.fas\n    # Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score\n    GeneOfDeath  GenomeOfDeath  100.00  295     0       0       1       295     152626  152920  4e-168   585\n\n\nSo, one should filter out lines beginning with \"#\" and it does no harm to skip lines which \nare empty or contain only white spaces.\n\nSo edit the file Blast2Gff.pl: in line 149 add:\n\n     next if (/^\\#/ || /^\\s*$/); # filter comments and empty lines\n\nSuch that this part looks like below, than try again.\n\n    while (<BLASTIN>)\n    {\n\n      next if (/^\\#/ || /^\\s*$/); # filter comments and empty lines\n\n\t$HitNum++;\n   \n\tmy ($QryId, $SubId, $PID, $Len, \n\t    $MisMatch, $GapOpen, \n\t    $QStart,$QEnd, $SStart, $SEnd,\n\t    $EVal, $BitScore) = split(/\\t/);\n\n\n\n\n", "date": "2010-03-13 20:46:52", "action": 0, "post": 286}}, {"pk": 367, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: How to convert BLAST results to GFF", "content": ">  http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl\n\nYou can use the script Pierre found swith a slight modification, actually it is a bit crude and does no real error checking but it works. The error is it does not work if the blast file has a header like this:\n\n    # BLASTN 2.2.21 [Jun-14-2009]\n    # Query: 16383 sequences\n    # Database: genomedata/GenomeOfDeath.fas\n    # Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score\n    GeneOfDeath  GenomeOfDeath  100.00  295     0       0       1       295     152626  152920  4e-168   585\n\n\nSo, one should filter out lines beginning with \"#\" and it does no harm to skip lines which \nare empty or contain only white spaces.\n\nSo edit the file Blast2Gff.pl: in line 149 add:\n\n     next if (/^\\#/ || /^\\s*$/); # filter comments and empty lines\n\nSuch that this part looks like below, then try again.\n\n    while (<BLASTIN>)\n    {\n\n      next if (/^\\#/ || /^\\s*$/); # filter comments and empty lines\n\n\t$HitNum++;\n   \n\tmy ($QryId, $SubId, $PID, $Len, \n\t    $MisMatch, $GapOpen, \n\t    $QStart,$QEnd, $SStart, $SEnd,\n\t    $EVal, $BitScore) = split(/\\t/);\n\n\n\n\n", "date": "2010-03-13 20:55:45", "action": 0, "post": 286}}, {"pk": 368, "model": "server.postrevision", "fields": {"author": 130, "tag_string": "gene function database redundancy", "title": "A resource to identify functionally redundant genes", "content": "Can anybody point me to a resource that provides information on functionally redundant genes? I have been pointed towards the use of GOA (http://www.ebi.ac.uk/GOA/) as one approach. Would this provide sufficient 'resolution' to identify functionally equivalent genes? My thinking is that if two genes share the same GO term and the GO term is a leaf node, that might be useful. \n\nAny pointers would be appreciated", "date": "2010-03-14 16:26:35", "action": 0, "post": 287}}, {"pk": 369, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: A resource to identify functionally redundant genes", "content": "What exactly do you mean by functional redundancy? \n\n- Two proteins may both metabolize some sugar, but send different products down different pathways. Are they redundant?\n- Two different pathways can be used to produce the same end product from some metabolite.  Are all of the genes in these two pathways redundant? \n- What about proteins that have multiple functions? How do you handle _partial_ redundancy?\n\nMy take:  \nThere are no solid and complete answers to these questions at this point, but I think you could justify using GO terms of a certain depth, as you suggest. Just justify your assumptions, acknowledge that any such attempt is going to be full of errors and omissions, and be careful about  drawing too many hard conclusions from the results.", "date": "2010-03-14 16:38:32", "action": 0, "post": 288}}, {"pk": 370, "model": "server.postrevision", "fields": {"author": 134, "tag_string": "", "title": "A: Appropriate podcasts for a bioinformatician?", "content": "From the same people as Futures in Biotech: [Floss weekly][1]. About free & open software, they had an [episode][2] on Bioperl a while ago.\n\n\n  [1]: http://twit.tv/FLOSS\n  [2]: http://twit.tv/floss96", "date": "2010-03-15 00:32:45", "action": 0, "post": 289}}, {"pk": 371, "model": "server.postrevision", "fields": {"author": 135, "tag_string": "blast c mpi sequence", "title": "Performing BLAST/SmithWaterman searches directly from my application", "content": "*Bringing in my questions from [stackoverflow][1]:*\n\n\n\nI'm working on a small application and thinking about integrating BLAST or other local alignment searches into my application. My searching has only brought up programs, which need to be installed and called as an external program.\n\nIs there a way short of me implementing it from scratch? Any pre-made library perhaps?\n\n\n  [1]: http://stackoverflow.com/questions/1432467/performing-blast-smithwaterman-searches-directly-from-my-application", "date": "2010-03-15 07:11:09", "action": 0, "post": 290}}, {"pk": 372, "model": "server.postrevision", "fields": {"author": 135, "tag_string": "", "title": "A: Performing BLAST/SmithWaterman searches directly from my application", "content": "I found the [NCBI C++ Toolkit][1] to be quite useful.\n\n\n  [1]: http://www.ncbi.nlm.nih.gov/IEB/ToolBox/CPP_DOC/", "date": "2010-03-15 07:12:01", "action": 0, "post": 291}}, {"pk": 373, "model": "server.postrevision", "fields": {"author": 118, "tag_string": "", "title": "A: Performing BLAST/SmithWaterman searches directly from my application", "content": "Also the [SeqAn][1] C++ library may be useful to some.\n\n\n  [1]: http://www.seqan.de/ ", "date": "2010-03-15 12:12:24", "action": 0, "post": 292}}, {"pk": 374, "model": "server.postrevision", "fields": {"author": 137, "tag_string": "", "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "content": "These are the big challenge(s) for me:\n \n 1. Ask the relevant questions and find/develop the proper/satisfactory solutions to obtain meaningful results.\n 2. Determine what is relevant (what really matters).\n 3. Understand what and why is proper, merely sufficient or unsatisfactory.\n 4. Interpret the results without bias and preconceptions.\n \n\n \n\n\n", "date": "2010-03-15 15:02:35", "action": 0, "post": 293}}, {"pk": 375, "model": "server.postrevision", "fields": {"author": 34, "tag_string": "", "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "content": "**Trivial**\n\n - Creating lists of genes that might be of interest in a given system\n - Integrating several experiments with one kind of data\n - Talking with people in my own sub-disciplines of biology\n - Thinking of cool experiments to do\n\n**Challenging**\n\n - Determining which genes in a list are important for a process and integrating those genes in to current domain-specific understanding in a meaningful way\n - Integrating several experiments across totally different kinds of data\n - Talking with people in other sub-disciplines of biology and actually understanding each other well enough to collaborate effectively\n - Thinking of the most important and useful questions to ask\n - Getting funding", "date": "2010-03-15 16:56:44", "action": 0, "post": 294}}, {"pk": 376, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "content": "\n\nMost challenging: processing contradictory information and identifying the credible evidence.\n", "date": "2010-03-15 18:45:16", "action": 0, "post": 295}}, {"pk": 377, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "job career", "title": "Where to advertise or find bioinformatics jobs", "content": "What do you recommend as the most appropriate site to advertise (or look for) bioinformatics related job openings.", "date": "2010-03-15 18:57:44", "action": 0, "post": 296}}, {"pk": 378, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "I think it is easier to look at the home pages of the laboratories that work in a topic of your interest and ask; however, there are a few generic places:\n\n - [Nature Jobs][1], for example [these][2]\n - [Linked In][3], in particular groups like [Bioinformatics Geeks][4] or [Bioinformatics Computing][5]\n\n\n  [1]: http://www.nature.com/naturejobs/index.html\n  [2]: http://www.nature.com/naturejobs/science/searches/13075465-all-bioinformatics-jobs#search-results\n  [3]: http://www.linkedin.com/\n  [4]: http://www.linkedin.com/groups?gid=65325&trk=anetsrch_name&goback=%2Egdr_1268681143545_1\n  [5]: http://www.linkedin.com/groups?gid=96837&trk=anetsrch_name&goback=%2Egdr_1268681143545_1", "date": "2010-03-15 19:27:51", "action": 0, "post": 297}}, {"pk": 379, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": " * Biojobs on FriendFeed: http://friendfeed.com/biojobs\n * The (French) Bioinfo mailing list (but many international positions) http://listes.sfbi.fr/wws/info/bioinfo\n * http://www.nature.com/naturejobs/index.html (nature jobs)\n * some yahoo pipes .e.g. http://pipes.yahoo.com/pipes/search?q=bioinformatics+job&x=0&y=0\n * (...)", "date": "2010-03-15 19:52:48", "action": 0, "post": 298}}, {"pk": 380, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": " 1. Some companies do not longer publish\n    their vacancies in newspapers but\n    instead use their own vacancy\n    web-site. This is helpful and\n    up-to-date (well, should be), but\n    the counterside is that there's no\n    longer a central place where you can\n    find all actual vacant jobs. So if\n    you are searching for a job you have\n    to check out a score of websites on\n    a regular base. To make this\n    somewhat easier the [Geneyous\n    JobReport][1] has been set up.\n    \n    The  JobReport checks the vacancy\n    pages of several (mostly Dutch)\n    companies and institutes on a\n    regular base on keywords like\n    genomics, bio-informatician,\n    genetics, scientific programmer and\n    more, including Dutch translations.\n    \n    The results are placed in a grid and\n    arrows indicate if the number of\n    keywords has\n    increased/decreased/remained stable\n    the last month.\n\n 2. [AcademicTransfer][2] is the joint job board of Dutch universities, university medical centers and research institutions. Use this website to search jobs, career opportunities and trends in the Dutch and international academic job market.\n\n\n  [1]: http://www.geneyous.nl/jobreport/\n  [2]: http://www.academictransfer.com/search_results/?q=bioinformatics&find=Search&phd_position=", "date": "2010-03-15 20:20:37", "action": 0, "post": 299}}, {"pk": 381, "model": "server.postrevision", "fields": {"author": 67, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": " 1. Some companies do not longer publish\n    their vacancies in newspapers but\n    instead use their own vacancy\n    web-site. This is helpful and\n    up-to-date (well, should be), but\n    the counterside is that there's no\n    longer a central place where you can\n    find all actual vacant jobs. So if\n    you are searching for a job you have\n    to check out a score of websites on\n    a regular base. To make this\n    somewhat easier the [Geneyous\n    JobReport][1] has been set up.\n    \n    The  JobReport checks the vacancy\n    pages of several (mostly Dutch)\n    companies and institutes on a\n    regular base on keywords like\n    genomics, bio-informatician,\n    genetics, scientific programmer and\n    more, including Dutch translations.\n    \n    The results are placed in a grid and\n    arrows indicate if the number of\n    keywords has\n    increased/decreased/remained stable\n    the last month.\n\n 2. [AcademicTransfer][2] is the joint job board of Dutch universities, university medical centers and research institutions. Use this website to search jobs, career opportunities and trends in the Dutch and international academic job market.\n\n 3. The [Bioinformatics Organization Career Center][3]\n\n\n\n  [1]: http://www.geneyous.nl/jobreport/\n  [2]: http://www.academictransfer.com/search_results/?q=bioinformatics&find=Search&phd_position=\n  [3]: http://www.bioinformatics.org/jobs/\n  [4]: http://www.bioinformatics.fr/jobs.php", "date": "2010-03-15 20:29:59", "action": 0, "post": 299}}, {"pk": 382, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "You can also checked http://www.bioinformatics.fr/jobs.php\nWhen I have the time I also try to compile jobs from several sources like jobs.ac.uk, bioinformatics.org, listbioinfo (see Pierre post), iscb.org or biospace.com", "date": "2010-03-15 21:50:36", "action": 0, "post": 300}}, {"pk": 383, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "", "title": "A: Mapping SNPs to Pathways", "content": "Pierre,\n\nAs soon as you get the Entrez gene Id related to your SNPs you can query KEGG or WikiPathways that should provide Entrez gene Ids related to a given pathway.\nThe good think with this two websites is that with some SVG you can customized the graphic view of the pathways in order to highlight genes that have the SNPs.\nHope this helps.\n\nFred", "date": "2010-03-15 22:14:03", "action": 0, "post": 301}}, {"pk": 384, "model": "server.postrevision", "fields": {"author": 142, "tag_string": "biopython blast", "title": "Compare two protein sequences using local BLAST", "content": "Hi,\n\nI have been given a task to compare the all the protein sequences of a strain of campylobacter with a strain of E.coli. I would like to do this locally using Biopython and the inbuilt Blast tools. However, I'm stuck on how to program this and what tools I should be using. If anybodu could point in the right direction, I would be thankful!\n\nCheers", "date": "2010-03-15 23:24:58", "action": 0, "post": 302}}, {"pk": 385, "model": "server.postrevision", "fields": {"author": 142, "tag_string": "biopython blast", "title": "Compare two protein sequences using local BLAST", "content": "Hi,\n\nI have been given a task to compare the all the protein sequences of a strain of campylobacter with a strain of E.coli. I would like to do this locally using Biopython and the inbuilt Blast tools. However, I'm stuck on how to program this and what tools I should be using. If anybody could point me in the right direction, I would be thankful!\n\nCheers", "date": "2010-03-16 00:05:48", "action": 0, "post": 302}}, {"pk": 386, "model": "server.postrevision", "fields": {"author": 34, "tag_string": "", "title": "A: Mapping SNPs to Pathways", "content": "I haven't used it myself, but [GRAIL][1] was built for this sort of problem in GWAS. It looks pretty impressive from what I've seen.\n\n\n  [1]: http://www.broadinstitute.org/mpg/grail/", "date": "2010-03-16 00:07:51", "action": 0, "post": 303}}, {"pk": 387, "model": "server.postrevision", "fields": {"author": 121, "tag_string": "", "title": "A: Compare two protein sequences using local BLAST", "content": "The BLAST section of the BioPython module is not terribly well documented.  The relevant section is [here][1].  Before starting you'll need to create a local BLAST database ... To my knowledge there is no way to do this directly through BioPython (but you could use the Subprocess module to automate the commandline if you really wanted too) ... The documentation for the BLAST tool is on the NCBI website [here][2].  You'll obviously need to download the whole genome sequences ... I suggest using the NCBI FTP site, I can never seem to find the right link in the normal webportal.\n\nOnce you have all of the relevant downloads and databases created you'll simply need to run the BLAST query in a loop that processes all of the data.  Something like this should work (I don't have the required data to test this but it should get you 95% of the way there.)\n\n    from Bio.Blast.Applications import NcbiblastxCommandline\n    from Bio.Blast import NCBIXML\n    from Bio import SeqIO\n    import subprocess\n    \n    SOURCE_FASTA = '/path/to/source/seq.fasta'\n    DATABASE = 'databsename' #should be in the path but YMMV\n    \n    with open(SOURCE_FASTA) as inhandle:\n    \tfor seq in SeqIO.parse(handle, 'fasta'):\n    \t\twith open('scratch.fasta', 'w') as outhandle:\n    \t\t\t#write a scratch file\n    \t\t\tSeqIO.write(seq, outhandle, 'fasta')\n    \t\t\n    \t\t#create the commandline string\n    \t\tcline = NcbiblastxCommandline(query='scratch.fasta', \n                        db=DATABASE, evalue=0.001, outfmt=5, out=\"scratch.xml\")\n    \t\t\n    \t\t#actually run BLAST\n    \t\treturn_code = subprocess.call(str(cline))\n    \t\t\n    \t\tif return_code == 0:\n    \t\t\t#if it was successful then process it\n    \t\t\twith open('scratch.xml') as xmlhandle:\n    \t\t\t\tblast_record = NCBIXML.read(xmlhandle)\n    \t\t\t\t\n    \t\t\t\tdo_something_with_results(blast_record)\n\t\t\t\t\n\t\t\nHope that helps.\n\n  [1]: http://www.biopython.org/DIST/docs/tutorial/Tutorial.html#htoc77\n  [2]: ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/user_manual.pdf", "date": "2010-03-16 04:34:58", "action": 0, "post": 304}}, {"pk": 388, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "", "title": "A: Compare two protein sequences using local BLAST", "content": "hi, if you're having trouble, maybe it'd be wiser to do the simplest analysis--just do an all-vs-all blastp directly using the command-line-interface to blast. For example use E.coli as the subject and the other species as the query and a command like:\n\n    $ formatdb -p T -i ecoli.fa\n    $ blastall -d ecoli.fa -i other.fa -p blastn -m 8 -e 0.01 -o ecoli_other.blast\n\nUsing the -m 8 option, you can parse the tab-delimited blast file with few lines of code. This assumes you have the protein fasta files in hand--the are probably available from ncbi or your favorite yeast genome repository.", "date": "2010-03-16 04:36:10", "action": 0, "post": 305}}, {"pk": 389, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "BioPlanet is quite active, for both advertising and searching: http://www.bioplanet.com/planetforums/forumdisplay.php?fid=1.\n\nIn Australia I use the jobs portal Seek - http://www.seek.com.au/ - I'm sure other countries have a similar website.\n\nAdvertising?  Twitter, with the hash tags #bioinformatics #jobs.", "date": "2010-03-16 06:21:11", "action": 0, "post": 306}}, {"pk": 390, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: Compare two protein sequences using local BLAST", "content": "If the genomes are public, someone may have done this analysis for you, or there may be a web-based tool to do the job.\n\nFor example, here is a genome comparison tool at the JCVI/CMR - http://cmr.jcvi.org/cgi-bin/CMR/shared/MakeFrontPages.cgi?page=circular_display.\n\nThe JGI Integrated Microbial Genome system is also very good - http://img.jgi.doe.gov. It allows you to select multiple genomes for various comparative analyses.  I believe they may even have all versus all data buried away in their FTP archive somewhere.  However, take some time to get used to the site - it has quite a steep learning curve.", "date": "2010-03-16 07:07:24", "action": 0, "post": 307}}, {"pk": 391, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "genome analysis integrated ngs", "title": "Looking for refernces to Cell lines/samples with full Integrated Genome Analysis", "content": "Hello,\n\nI am looking for genome (from cell lines or patient samples) that have been fully characterized thanks to the Next Generation Sequencing (NGS) methods.\nI already know the following instances:\n\n - [NCI-H209 cell line][1]\n   \n  \n - [22 Human Glioblastoma Multiforme   \n   samples][2]\n\n   \n  \n\n - [a first Acute Myeloid Leukaemia with minimal maturation \n   (AML-M1) sample][3]\n\n   \n   \n\n - [a second Acute Myeloid Leukaemia with minimal maturation\n   (AML-M1) sample][4]\n\nSo if you know other papers/ressources I would be glad if you could share it with others.\n\nThanks in advance,\n\nFred\n\n  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08629.html\n  [2]: http://www.sciencemag.org/cgi/content/full/321/5897/1807\n  [3]: http://www.nature.com/nature/journal/v456/n7218/full/nature07485.html\n  [4]: http://content.nejm.org/cgi/content/full/361/11/1058", "date": "2010-03-16 08:39:42", "action": 0, "post": 308}}, {"pk": 392, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "In the UK, pretty much every academic job is listed on http://www.jobs.ac.uk/ - they have good mechanisms for filtering the stream.\n\nThe New Scientist is a good place to find openings too - http://www.newscientistjobs.com/jobs/default.aspx\n\nAs for advertising... I agree with Neil - Twitter + hash tags.\n\n", "date": "2010-03-16 08:52:17", "action": 0, "post": 309}}, {"pk": 393, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "genome analysis integrated ngs", "title": "Looking for references to Cell lines/samples with full Integrated Genome Analysis", "content": "Hello,\n\nI am looking for genome (from cell lines or patient samples) that have been fully characterized thanks to the Next Generation Sequencing (NGS) methods.\nI already know the following instances:\n\n - [NCI-H209 cell line][1]\n   \n  \n - [22 Human Glioblastoma Multiforme   \n   samples][2]\n\n   \n  \n\n - [a first Acute Myeloid Leukaemia with minimal maturation \n   (AML-M1) sample][3]\n\n   \n   \n\n - [a second Acute Myeloid Leukaemia with minimal maturation\n   (AML-M1) sample][4]\n\nSo if you know other papers/ressources I would be glad if you could share it with others.\n\nThanks in advance,\n\nFred\n\n  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08629.html\n  [2]: http://www.sciencemag.org/cgi/content/full/321/5897/1807\n  [3]: http://www.nature.com/nature/journal/v456/n7218/full/nature07485.html\n  [4]: http://content.nejm.org/cgi/content/full/361/11/1058", "date": "2010-03-16 08:54:43", "action": 0, "post": 308}}, {"pk": 394, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective agile sturdy team development", "title": "Which software development technique is used in your lab? ", "content": "On this page of the [software carpentry manual][1] you can find a brief introduction to different software development techniques, including agile and sturdy ones. \n\nWhich of these development model is closer to the one you use on your lab? How do you work together with your teammates?\n\nnote: If you are interested, I can provide you with more documents to describe the different development techniques.\n\n\n  [1]: http://software-carpentry.org/lifecycle.html", "date": "2010-03-16 10:09:33", "action": 0, "post": 310}}, {"pk": 395, "model": "server.postrevision", "fields": {"author": 144, "tag_string": "recommandation books", "title": "How to get started in bioinformatics?", "content": "I am a Software Engineering student (with decent background in biology) and would like to explore the field of bioinformatics. I am completely new to the field and would like some pointers on where and how to get started.\n\n - Is there any book I should read?  \n - Any interesting online resources?\n - Any interesting blogs / online communities (apart from this one)?\n - What are some of the interesting problems bioinformatics is trying to solve?\n\nAny advice or insight about this industry would be appreciated.", "date": "2010-03-16 10:47:33", "action": 0, "post": 311}}, {"pk": 396, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "", "title": "A: How to get started in bioinformatics?", "content": "I am pretty sure Google can help you with getting started. I have seen questions like yours many times, like so many others before you, you have no idea where to start.\n\nHowever, like all those before you, you make a classical mistake: you forget to formulate what you really like to do. Never ask others what you should do (with your life). Instead, use Google to read up on topic, look around at (Open Source) bioinformatics tools, possibly get additional non-IT education, and decide for yourself what domain question you have. Only then you should start asking around how to proceed.\n\nThe reason underlying this, is that those reading your question, like me, have no clue about your background, your interested, while at the same time, there is so many interesting things to do. You basically ask us what is the answer to the world, but I am pretty sure 42 is not the answer you are looking for.\n\nSo, first do some research yourself, pick a topic yourself, formulate questions you have on that topic that Google, Wikipedia, your university courses do not tell you, and then pose those questions.", "date": "2010-03-16 11:02:00", "action": 0, "post": 312}}, {"pk": 397, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "recommendations books", "title": "How to get started in bioinformatics?", "content": "I am a Software Engineering student (with decent background in biology) and would like to explore the field of bioinformatics. I am completely new to the field and would like some pointers on where and how to get started.\n\n - Is there any book I should read?  \n - Any interesting online resources?\n - Any interesting blogs / online communities (apart from this one)?\n - What are some of the interesting problems bioinformatics is trying to solve?\n\nAny advice or insight about this industry would be appreciated.", "date": "2010-03-16 11:09:42", "action": 0, "post": 311}}, {"pk": 398, "model": "server.postrevision", "fields": {"author": 135, "tag_string": "", "title": "A: How to get started in bioinformatics?", "content": "Does your university offer bioinformatics courses? It might be a better place to start asking there...\n\nBooks: can't really recommend any. There are too many different sub-fields in bioinformatics\n\nOnline: depends what you're interested in, again.\n\nBlogs: not really, I think. If you find any good ones, let me know.\n\nThere seem to be two opposing sides to bioinformatics currently:\n\n - those who studied microbiology and use bioinformatics as a tool (maybe even cobble some scripts together)\n - those who come from the software engineering side and build tools according to these standards.\n\nProblems in bioinformatics:\n\n - sequence analysis, including sequence matching/searching (BLAST et al.), also databases\n - image processing (electron microscopy analysis, microarrays)\n - structure prediction (protein structure, see Folding@Home and others)\n\nMany of these include high performance computing, so you might want to learn stuff about that.\n\nYour question is rather broad. How did you find out about bioinformatics? What made you interested in this field?\n", "date": "2010-03-16 11:28:50", "action": 0, "post": 313}}, {"pk": 399, "model": "server.postrevision", "fields": {"author": 145, "tag_string": "", "title": "A: Compare two protein sequences using local BLAST", "content": "And Will, your example seems overly complicated. Why not just give the multiple query input FASTA file directly to BLAST?\n\nAlso, satsurae - do you have to use BLAST? If the data set is not too big, you could use EMBOSS needleall to do a full Needleman-Wunsch alignment - although this may not offer the statistics you may want.\nhttp://emboss.sourceforge.net/apps/release/6.2/emboss/apps/needleall.html\n\n", "date": "2010-03-16 11:34:46", "action": 0, "post": 314}}, {"pk": 400, "model": "server.postrevision", "fields": {"author": 145, "tag_string": "", "title": "A: Computing the reverse and complement of a sequence with Biopython", "content": "If you want to reverse a string in Python, you can use a slice with a step of minus one -1,\n\n    rev_str = str[::-1]\n\nIt should not surprise you that you can do the same with a Biopython Seq object:\n\n    rev_seq = seq[::-1]\n\nI guess the Biopython Tutorial you be more explicit but it does cover reversing a sequence like this.\n", "date": "2010-03-16 11:39:30", "action": 0, "post": 315}}, {"pk": 401, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: How to get started in bioinformatics?", "content": "Well, I will answer by redirecting you to other topics :-) :\n\n**Is there any book I should read?**\n\n - Biostar - [recommend your favorite bioinformatics books][1]\n\n**Any interesting online resources?**\n\n - Biostar - [appropriate podcasts for a bioinformatician][2]\n\n**Any interesting blogs / online communities (apart from this one)?**\n\n - Biostar - [your favorite bioinformatics blog][3]\n\n**What are some of the interesting problems bioinformatics is trying to solve?**\n\n - Biostar - [How far does bioinformatics go][4]\n\n\n  [1]: http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books\n  [2]: http://biostar.stackexchange.com/questions/268/appropriate-podcasts-for-a-bioinformatician\n  [3]: http://biostar.stackexchange.com/questions/112/your-favorite-bioinformatics-blog\n  [4]: http://biostar.stackexchange.com/questions/149/how-far-does-bioinformatics-go", "date": "2010-03-16 12:01:15", "action": 0, "post": 316}}, {"pk": 402, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Which software development technique is used in your lab? ", "content": "As I've always worked alone on my sources, I've heavily used the [Cowboy Coding][1] and the [confessional debugging][2] techniques :-)\n\n\n  [1]: http://en.wikipedia.org/wiki/Cowboy_coding\n  [2]: http://en.wiktionary.org/wiki/confessional_debugging", "date": "2010-03-16 12:17:31", "action": 0, "post": 317}}, {"pk": 403, "model": "server.postrevision", "fields": {"author": 130, "tag_string": "", "title": "A: Which software development technique is used in your lab? ", "content": "think it, code it :)", "date": "2010-03-16 12:25:31", "action": 0, "post": 318}}, {"pk": 404, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "content": "I think the most trivial is also the most challenging:  fetching and pre-processing the data in the first place, before you even do any analysis with it.  I'd say 80% of my time is spent searching, fetching, parsing, munging and storing data, 20% is analysis and conclusions.", "date": "2010-03-16 12:39:50", "action": 0, "post": 319}}, {"pk": 405, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "I've been doing bioinformatics for 10 years or so and have never read a book on the subject. I learned (and still learn, every day) on the job, almost entirely from online resources.\n\nI think many bioinformaticians of a \"certain age\" learned in this way:  they are often former bench biologists who gave up lab work and taught themselves programming.  These days there are undergraduate courses (!), so I imagine more people use textbooks.  It's just that I don't know of any, nor have I ever needed to use one.", "date": "2010-03-16 12:47:39", "action": 0, "post": 320}}, {"pk": 406, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: Compare two protein sequences using local BLAST", "content": "The others have answered your question!\n\nI just want to make a suggestion, if you are interested in visually comparing the two genomes, I highly recommend the [Artemis][1] and [ACT (Artemis Comparison Tool)][2] from the Sanger institute.\n\nIf you have the full genome, then you can easily visualize all the reading frames. With ACT, you use the two genome sequences (or one genome and a fasta file of genes/proteins or even two gene/protein fasta files) as well as a \"comparison file\", which is a blast output file.\n\nIt is very useful for annotation and curation!\n\n\n  [1]: http://www.sanger.ac.uk/resources/software/artemis/\n  [2]: http://www.sanger.ac.uk/resources/software/act/", "date": "2010-03-16 13:02:14", "action": 0, "post": 321}}, {"pk": 407, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "content": "From a support perspective, the biggest challenge of my day-to-day work (rather than grand scientific challenges) remains convincing wet biologists of the inappropriateness of Excel and Word as data exchange formats.\n\nScientifically speaking, data integration is probably the biggest technical challenge. Making disparate experiments comparable, and databases compatible would make life significantly easier.", "date": "2010-03-16 13:47:22", "action": 0, "post": 322}}, {"pk": 408, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "genome analysis integrated ngs", "title": "Which human cell line/sample genomes have been already sequenced completely?", "content": "Hello,\n\nI am looking for genome (from cell lines or patient samples) that have been fully characterized thanks to the Next Generation Sequencing (NGS) methods.\nI already know the following instances:\n\n - [NCI-H209 cell line][1]\n   \n  \n - [22 Human Glioblastoma Multiforme   \n   samples][2]\n\n   \n  \n\n - [a first Acute Myeloid Leukaemia with minimal maturation \n   (AML-M1) sample][3]\n\n   \n   \n\n - [a second Acute Myeloid Leukaemia with minimal maturation\n   (AML-M1) sample][4]\n\nSo if you know other papers/ressources I would be glad if you could share it with others.\n\nThanks in advance,\n\nFred\n\n  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08629.html\n  [2]: http://www.sciencemag.org/cgi/content/full/321/5897/1807\n  [3]: http://www.nature.com/nature/journal/v456/n7218/full/nature07485.html\n  [4]: http://content.nejm.org/cgi/content/full/361/11/1058", "date": "2010-03-16 13:58:05", "action": 0, "post": 308}}, {"pk": 409, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "", "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "content": "From a support perspective, the biggest challenge of my day-to-day work (rather than grand scientific challenges) remains convincing wet-lab biologists of the inappropriateness of Excel and Word as data exchange formats.\n\nScientifically speaking, data integration is probably the biggest technical challenge. Making disparate experiments comparable, and databases compatible would make life significantly easier.", "date": "2010-03-16 14:08:55", "action": 0, "post": 322}}, {"pk": 410, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "genome analysis integrated ngs", "title": "Which human tumor cell line/sample genomes have been already sequenced completely?", "content": "Hello,\n\nI am looking for genome (from cell lines or patient samples) that have been fully characterized thanks to the Next Generation Sequencing (NGS) methods.\nI already know the following instances:\n\n - [NCI-H209 cell line][1]\n   \n  \n - [22 Human Glioblastoma Multiforme   \n   samples][2]\n\n   \n  \n\n - [a first Acute Myeloid Leukaemia with minimal maturation \n   (AML-M1) sample][3]\n\n   \n   \n\n - [a second Acute Myeloid Leukaemia with minimal maturation\n   (AML-M1) sample][4]\n\nSo if you know other papers/ressources I would be glad if you could share it with others.\n\nThanks in advance,\n\nFred\n\n  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08629.html\n  [2]: http://www.sciencemag.org/cgi/content/full/321/5897/1807\n  [3]: http://www.nature.com/nature/journal/v456/n7218/full/nature07485.html\n  [4]: http://content.nejm.org/cgi/content/full/361/11/1058", "date": "2010-03-16 14:11:20", "action": 0, "post": 308}}, {"pk": 411, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "recommendations books blog", "title": "How to get started in bioinformatics?", "content": "I am a Software Engineering student (with decent background in biology) and would like to explore the field of bioinformatics. I am completely new to the field and would like some pointers on where and how to get started.\n\n - Is there any book I should read?  \n - Any interesting online resources?\n - Any interesting blogs / online communities (apart from this one)?\n - What are some of the interesting problems bioinformatics is trying to solve?\n\nAny advice or insight about this industry would be appreciated.", "date": "2010-03-16 14:24:07", "action": 0, "post": 311}}, {"pk": 412, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "", "title": "A: Which human tumor cell line/sample genomes have been already sequenced completely?", "content": " - [COLO-829 cell line][1]\n\n\n  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08658.html", "date": "2010-03-16 14:26:13", "action": 0, "post": 323}}, {"pk": 413, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "", "title": "A: Which human tumor cell line/sample genomes have been already sequenced completely?", "content": " - [COLO-829 cell line][1]\n - [96 human glioblastoma samples][2]\n\n\n  [1]: http://www.nature.com/nature/journal/v463/n7278/full/nature08658.html\n  [2]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2671642/?tool=pubmed", "date": "2010-03-16 14:48:02", "action": 0, "post": 323}}, {"pk": 414, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "", "title": "A: Compare two protein sequences using local BLAST", "content": "hi, if you're having trouble, maybe it'd be wiser to do the simplest analysis--just do an all-vs-all blastp directly using the command-line-interface to blast. For example use E.coli as the subject and the other species as the query and a command like:\n\n    $ formatdb -p T -i ecoli.fa\n    $ blastall -d ecoli.fa -i other.fa -p blastn -m 8 -e 0.01 -o ecoli_other.blast\n\nUsing the -m 8 option, you can parse the tab-delimited blast file with few lines of code. This assumes you have the protein fasta files in hand--the are probably available from ncbi or your favorite bacteria genome repository.", "date": "2010-03-16 15:28:48", "action": 0, "post": 305}}, {"pk": 415, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: Which software development technique is used in your lab? ", "content": "Question 1: With my collaborators, we use agile.\n\nQuestion 2: (if I've understood correctly the \"how do you work together with your teammates?\") Our team members have very different roles and it is mainly one person actually coding. So we don't need to share code etc. When it comes to the communication part, we rely on different tools:\n\n  * [Google Wave][1]\n  * Our personal Wiki\n  * We've been testing [Yammer][2]\n  * [SVN][3]\n  * Skype\n  * Email\n\nAnd most importantly, whenever we can, face to face brainstorming with a white board.\n\n\n  [1]: http://wave.google.com/\n  [2]: http://www.yammer.com/\n  [3]: http://subversion.tigris.org/", "date": "2010-03-16 15:31:11", "action": 0, "post": 324}}, {"pk": 416, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "", "title": "A: Which human tumor cell line/sample genomes have been already sequenced completely?", "content": "There were recently a paper from Nelson's lab at UCLA on full sequencing of U87 GBM cell line.\n\nClarck et al, U87MG Decoded: The Genomic Sequence of a Cytogenetically Aberrant Human Cancer Cell Line, PLoS, 2010.\n\nhttp://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000832\n", "date": "2010-03-16 16:54:25", "action": 0, "post": 325}}, {"pk": 417, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "", "title": "A: Which human tumor cell line/sample genomes have been already sequenced completely?", "content": "There were recently a paper from Nelson's lab at UCLA on full sequencing of U87 GBM cell line.\n\nClark et al, U87MG Decoded: The Genomic Sequence of a Cytogenetically Aberrant Human Cancer Cell Line, PLoS Genetics, 2010.\n\nhttp://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000832\n", "date": "2010-03-16 16:59:31", "action": 0, "post": 325}}, {"pk": 418, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "", "title": "A: Which software development technique is used in your lab? ", "content": "We are using [37signals][1]' [Basecamp][2] and [Backpack][3] to exchange data, results, ideas and other staff. It's not free, but not so expensive. As for codes, we usually have individual projects. All techniques as in Pierre's answer. :)\n\n\n  [1]: http://37signals.com\n  [2]: http://basecamphq.com\n  [3]: http://backpackit.com", "date": "2010-03-16 20:36:45", "action": 0, "post": 326}}, {"pk": 419, "model": "server.postrevision", "fields": {"author": 146, "tag_string": "microarray image", "title": "Convert microarray quantization in image", "content": "How can I convert the microarray quantization mathematically elaborated in the corresponding image? I need to see the image of the mathematic changes in the microarray quantization.  ", "date": "2010-03-16 20:56:46", "action": 0, "post": 327}}, {"pk": 420, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "fpga hpc", "title": "Hardware resources for HPC in Bioinformatics", "content": "Greetings everybody,\n\nWe're planning to build a very powerful computing machine to serve bioinformatics application here at HCFMUSP. I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions like Pico Computing FPGA cards, CLCbio Cube and TimeLogic DeCypher.\n\nDoes anybody have some experience with these cards? Do they scale well? Are they worth the trouble?\n\n\nCheers,\nDaniel", "date": "2010-03-16 22:46:17", "action": 0, "post": 328}}, {"pk": 421, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "fpga hpc", "title": "Hardware resources for HPC in Bioinformatics", "content": "Greetings everybody,\n\nWe're planning to build a very powerful computing machine to serve bioinformatics application here at HCFMUSP. I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions like Pico Computing FPGA cards, CLCbio Cube and TimeLogic DeCypher.\n\nDoes anybody have some experience with these cards? Do they scale well? Are they worth the trouble?\n\n\nCheers,\nDaniel\n\nP.S.: There are a lot of open source recipes on how to implement aligners and related on FPGAs. That's why I'm very interested in this topic.", "date": "2010-03-16 22:55:37", "action": 0, "post": 328}}, {"pk": 422, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "", "title": "A: What do you consider the most trivial and the most challenging tasks in your particular field of work?", "content": "My main work deals with simulations and modelling in population genetics (for several different purposes). Data are essential to validade both.\n\n**Trivial**:\n\n - Gathering HUGE amounts of data (I do\n   love NGS!); \n - Parsing/converting these\n   data to a usable condition;\n - Extracting the population genetics\n   parameters estimates from it;\n\n**Challenging**:\n\n - Knowing when to stop gathering HUGE\n   amounts of data (I still love NGS!);\n - Curating data <-- The real challenge;\n\nFor a population geneticist these are trully happy times. Finally we have (possibly) enough data to validate some fundamental models and theories. But, as a great philosopher said - \"With great power comes great responsibility\". So, carefully curated data is the great challenge from now on, IMHO.\n\nThat's all, dudes.", "date": "2010-03-16 23:18:06", "action": 0, "post": 329}}, {"pk": 423, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "Most of my sparse experience with bioinformatics came with the necessity to extract some statistics from sequence data. So, most books I can recommend deal with statistical and algorithmic approaches to biological data. \n\n- **An Introduction to Bioinformatics Algorithms** Neil C. Jones and Pavel A. Pevzner\n\n- **Statistical Methods in Bioinformatics** Warren J. Ewens, Gregory R. Grant\n\n- **Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison** David Sankoff, Joseph Kruskal\n\n- **Bioinformatics and Computational Biology Solutions Using R and Bioconductor** Robert Gentleman, Vincent Carey, Wolfgang Huber, Rafael Irizarry, Sandrine Dudoit\n\nJones and Pavel are accomplished mathematicians and bioinformaticians. Their work with repeats is a must have reference. Ewens's book will become a classic. He is already a foremost figure in population genetics, both in theory and experiment. Sankoff's book still is the most important reference in sequence aligment. Unfortunatelly, these books are somewhat mind bending. They rely heavily on mathematical concepts. But, as far as I know, bioinformatics theory is indeed mathematically and algorithmically challenging.\n\nAnd the last book is a very broad practical introduction to bioinformatics of array data.  Good for relaxing . . .\n\nCheers !\n", "date": "2010-03-16 23:54:18", "action": 0, "post": 330}}, {"pk": 424, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "", "title": "A: Which software development technique is used in your lab? ", "content": "As the number of good programmers in natural sciences is relatively low as compared to other programming projects, I think it is good to pick a model that suites the team. In these situations, I do not think coding style matters too much (write unit tests first or last, ...).\n\nI am involved in two large chem- and bioinformatics projects: [Bioclipse][1] and the [CDK][2]. There is a bit of overlap in developers, but still both projects use different development models. Both development teams are scattered around the internet.\n\nBut what does matter very much is communication. This makes the following components important:\n\n - choose a version control system: I would recommend Git; it does require some training, but there is plenty of information, and we all have good education to start with.\n - choose a bug track system and make this your main development communication channel: it works independent of individual developers' time lines.\n - have mailing lists to discuss issues in more detail, ask for advice, etc\n - choose coding standards: these can be small and large, and are aimed at removing getting annoyed to much about others coding styles\n - put persons in charge and have them take responsibility over the code\n\nThe CDK even adds to this that code is reviewed before it gets into the main version. Git makes it very easy to developed in such a distributed way (not just in location, but also in time). The person in charge is the gate keeper and decides how and when code gets incorporated into the main version, and ensures everyone lives up to coding and project standards.\n\nWikis, blogs, waves, etc are useful for documenting things. More important is to add proper documentation to the source code.\n\n  [1]: http://www.bioclipse.net\n  [2]: http://cdk.sf.net", "date": "2010-03-17 06:52:10", "action": 0, "post": 331}}, {"pk": 425, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "", "title": "A: How to get started in bioinformatics?", "content": "*Note: the below answer is meant to be constructive.* The best way to start in any field is just to listen, learn, and do something. By actually doing something, you best show your intentions, and you get more people listening to your questions.\n\nI am pretty sure Google can help you with getting started, and otherwise have a look around at this forum for topics you like. I have seen questions like yours many times, like so many others before you, you have no idea where to start.\n\nHowever, like all those before you, you make a classical mistake: you forget to formulate what you really like to do. Never ask others what you should do (with your life). Instead, use Google to read up on topic, look around at (Open Source) bioinformatics tools, possibly get additional non-IT education, and decide for yourself what domain question you have. Only then you should start asking around how to proceed.\n\nThe reason underlying this, is that those reading your question, like me, have no clue about your background, your interested, while at the same time, there is so many interesting things to do. You basically ask us what is the answer to the world, but I am pretty sure 42 is not the answer you are looking for.\n\nSo, first do some research yourself, pick a topic yourself, formulate questions you have on that topic that Google, Wikipedia, your university courses do not tell you, and then pose those questions.", "date": "2010-03-17 07:45:22", "action": 0, "post": 312}}, {"pk": 426, "model": "server.postrevision", "fields": {"author": 148, "tag_string": "", "title": "A: I was studying a gene but it disappeared in the latest ensembl release. What should I do now?", "content": "Do inform Ensembl via helpdesk@ensembl.org; if it is an error then the Havana curators can put this back in. Send them the ENSG number from the previous release, or the protein sequence, or a page from the archive site. If they think it should have been removed, they will give you a good reason.", "date": "2010-03-17 08:40:50", "action": 0, "post": 332}}, {"pk": 427, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "<p>You can also checked [http://www.bioinformatics.fr/jobs.php][1] with a dedicated RSS feed.</p>\n<p>When I have the time I also try to compile jobs from other sources like :</p>\n\n - [jobs.ac.uk][2] \n - [bioinformatics.org][3]\n - [listbioinfo][4] (see Pierre post)\n - [iscb.org][5] \n - [biospace.com][6]\n\n\n  [1]: http://www.bioinformatics.fr/jobs.php\n  [2]: http://www.jobs.ac.uk/cgi-bin/search.cgi?keywords=bioinformatics&x=0&y=0\n  [3]: http://www.bioinformatics.org/jobs/\n  [4]: http://listes.sfbi.fr/wws/info/bioinfo\n  [5]: http://www.iscb.org/iscb-careers\n  [6]: http://www.biospace.com/search_results_jobs.aspx?SearchWord=%25%25&TheLocation=%25%25", "date": "2010-03-17 10:39:37", "action": 0, "post": 300}}, {"pk": 428, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "fpga hpc reconfigurable", "title": "Hardware resources for HPC in Bioinformatics", "content": "Greetings everybody,\n\nWe're planning to build a very powerful computing machine to serve bioinformatics application here at HCFMUSP. I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions using FPGA cards like these ones:\n\n[CLCbio Cube][1]\n\n[TimeLogic DeCypher][2]\n\n[Pico Computing E-FPGA][3]\n\n\nFor the people who never heard of FPGA I do suggest to check out Wikipedia on these topics:\n\n[Field Programmable Gate Array][4]\n[Reconfigurable Computing][5]\n\nThere are several possible implementations of important algorithms in bioinformatics in those plataforms. This is  just one example:\n\n[160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)][6]\n\n\nDoes anybody have some experience with these cards? Do they scale well? Are they worth the trouble?\n\n\nCheers,\nDaniel\n\n\n  [1]: http://www.clcbio.com/index.php?id=616\n  [2]: http://www.timelogic.com/decypher_intro.html\n  [3]: http://www.picocomputing.com/e_series.html\n  [4]: http://en.wikipedia.org/wiki/Fpga\n  [5]: http://en.wikipedia.org/wiki/Reconfigurable_computing\n  [6]: http://www.biomedcentral.com/1471-2105/8/185", "date": "2010-03-17 11:59:54", "action": 0, "post": 328}}, {"pk": 429, "model": "server.postrevision", "fields": {"author": 135, "tag_string": "", "title": "A: Hardware resources for HPC in Bioinformatics", "content": "From what I've read, FPGAs are fine, but expensive. Have you looked into other, more readily available (and easier to program, mostly) architectures? I'm thinking of GPUs (CUDA, OpenCL), and Cell B.E. chips (in Playstation 3, programmable via C/C++ and also via OpenCL)?", "date": "2010-03-17 12:15:03", "action": 0, "post": 333}}, {"pk": 430, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "fpga hpc reconfigurable", "title": "Hardware resources for HPC in Bioinformatics", "content": "Greetings everybody,\n\nWe're planning to build a very powerful computing machine to serve bioinformatics application here at [HCFMUSP][7](check my profile). I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions using FPGA cards like these ones:\n\n[CLCbio Cube][1]\n\n[TimeLogic DeCypher][2]\n\n[Pico Computing E-FPGA][3]\n\n\nFor the people who never heard of FPGA I do suggest to check out Wikipedia on these topics:\n\n[Field Programmable Gate Array][4]\n[Reconfigurable Computing][5]\n\nThere are several possible implementations of important algorithms in bioinformatics in those plataforms. This is  just one example:\n\n[160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)][6]\n\n\nDoes anybody have some experience with these cards? Do they scale well? Are they worth the trouble?\n\n\nCheers,\nDaniel\n\n\n  [1]: http://www.clcbio.com/index.php?id=616\n  [2]: http://www.timelogic.com/decypher_intro.html\n  [3]: http://www.picocomputing.com/e_series.html\n  [4]: http://en.wikipedia.org/wiki/Fpga\n  [5]: http://en.wikipedia.org/wiki/Reconfigurable_computing\n  [6]: http://www.biomedcentral.com/1471-2105/8/185\n  [7]: http://www.hcnet.usp.br/", "date": "2010-03-17 13:38:36", "action": 0, "post": 328}}, {"pk": 431, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "microarray annotation affymetrix", "title": "Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "content": "Is it possible for two different Affymetrix probe set IDs to have common annotations to a single gene ? I am looking for the concept behind Affy probe set IDs. Any literature or links ? ", "date": "2010-03-17 16:51:43", "action": 0, "post": 334}}, {"pk": 432, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "I used to check Biojobs at FriendFeed,  [Bioinformatics.org][1]  and [Bioinformatics.fr][2] \n\n\n  [1]: http://www.bioinformatics.org/jobs/?show=archives\n  [2]: http://bioinformatics.fr/jobs.php", "date": "2010-03-17 16:55:23", "action": 0, "post": 335}}, {"pk": 433, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "", "title": "A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "content": "Different probesets are certainly capable of mapping to the same gene on the standard Affymetrix GeneChip platform.\n\nGroups of probes are combined into probesets and multiple probesets *MAY* exist for a gene\n\nNetAffx is the Affymetrix clearing house of Affymetrix probe ID info : [http://www.affymetrix.com/analysis/index.affx][1]\n\nYou might be interested in the BrainArray Custom CDFs which reannotate and regroup Affymetrix probes and probesets which are kept more up to date [http://brainarray.mbni.med.umich.edu/Brainarray/Database/CustomCDF/genomic_curated_CDF.asp][2] They also have tools for mapping probesets between chips/species [http://brainarray.mbni.med.umich.edu/Brainarray/Database/ProbeMatchDB/ncbi_probmatch_para_step1.asp][3]\n\nAnd interestingly a resource I have only just found called [ADAPT][4] which \"describes the many-to-many relationships between Affymetrix\u2122 probesets transcripts and genes, by directly mapping every probe against publicly available mRNAs/cDNA sequences from RefSeq and Ensembl.\"\n\n\n  [1]: http://www.affymetrix.com/analysis/index.affx\n  [2]: http://brainarray.mbni.med.umich.edu/Brainarray/Database/CustomCDF/genomic_curated_CDF.asp\n  [3]: http://brainarray.mbni.med.umich.edu/Brainarray/Database/ProbeMatchDB/ncbi_probmatch_para_step1.asp\n  [4]: http://bioinformatics.picr.man.ac.uk/adapt/Welcome.adapt", "date": "2010-03-17 17:00:00", "action": 0, "post": 336}}, {"pk": 434, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "microarray annotation affymetrix probeset", "title": "Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "content": "Is it possible for two different Affymetrix probe set IDs to have common annotations to a single gene ? I am looking for the concept behind Affy probe set IDs. Any literature or links ? ", "date": "2010-03-17 17:01:00", "action": 0, "post": 334}}, {"pk": 435, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "", "title": "A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "content": "Yes, many probe sets associated with the same gene.\n\nHere is the technical documentation from Affymetrix on probe set design:\n\n[Transcript Assignment for NetAffx\u2122 Annotations][1]\n\n\n  [1]: https://www.affymetrix.com/support/technical/whitepapers/Transcript_Assignment_whitepaper.pdf", "date": "2010-03-17 17:02:19", "action": 0, "post": 337}}, {"pk": 436, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: Hardware resources for HPC in Bioinformatics", "content": "All depends how diverse will be the applications running on this beast. If the end users are from DNA sequencing, NMR, mass spec to crystallography and the total number o applications is say 50+ it is unlikely you will be able to support it not even on FPGAs but even with CUDAs. Either something installs / compiles (almost) out of the box or you may have to drop it. Software authors will be of no help when it comes to porting it (and possibly a bunch of libs they depend on) to a new platform they do not even have in house. \n\n\nOn the other hand whenever problem is restricted to one domain, FPGAs are great. I used SORCERER for protein mass spec and DeCypher for blast searches.   \n\nAnyway, have fun with new beasts, whatever they will be :-)", "date": "2010-03-17 18:00:23", "action": 0, "post": 338}}, {"pk": 437, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: Hardware resources for HPC in Bioinformatics", "content": "All depends how diverse will be the applications running on this beast. If the end users are from DNA sequencing, NMR, mass spec to crystallography and the total number o applications is say 50+ it is unlikely you will be able to support it not even on FPGAs but even with CUDAs. Either something installs / compiles (almost) out of the box or you may have to drop it. Software authors will be of no help when it comes to porting it (and possibly a bunch of libs they depend on) to a new platform they do not even have in house. \n\n\nOn the other hand whenever problem is restricted to one domain, FPGAs are great. I used SORCERER for protein mass spec and DeCypher for blast searches.   \n\nAnyway, have fun with new servers, whatever they will be :-)", "date": "2010-03-17 18:11:11", "action": 0, "post": 338}}, {"pk": 438, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: A resource to identify functionally redundant genes", "content": "Just want to clarify : Are you looking for Orthologs/Paralogs of knockdown genes ? If yes, I support Dave Bridges comments, you could try a bi-directional blast searches. If you are looking for large number of genes from a well annotated genome, you may look for database that reports orthologs. I have used orthologs from Inparanoid for fly genome.  ", "date": "2010-03-17 20:51:53", "action": 0, "post": 339}}, {"pk": 439, "model": "server.postrevision", "fields": {"author": 115, "tag_string": "", "title": "A: A resource to identify functionally redundant genes", "content": "Have you looked at the COGS database at the NCBI? \nhttp://www.ncbi.nlm.nih.gov/COG/\n\nI'm not sure how current it is these days, and if the human coverage would be sufficient for your needs, but when I used to do structure-function work, I found it useful.\n\nGiven what you said in your response to Chris, I suspect you're going to be mostly looking at signaling proteins, so the EC numbers probably won't help you. But if you do find yourself looking at an enzyme that isn't a phosphatase or a kinase, EC numbers might help. In that case, MetaCyc might also be useful:\nhttp://metacyc.org/\n\nMy gut instinct on this one, though, is that you're going to get at best a 90% solution, and you'll have to do that last 10% by hand, using literature.", "date": "2010-03-17 21:03:20", "action": 0, "post": 340}}, {"pk": 440, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "", "title": "A: A resource to identify functionally redundant genes", "content": "<p>If you are looking for genes that encode proteins that could play the same role in a pathway, then you can parse the XML files provided by KEGG Pathays Database.</p>\n\n<p>For instance let's take the mTOR signaling pathway. You can see that at some step of the pathway several proteins (genes) can be involved like it is the case for AKT1 in green : There is the number 3 because you can have either AKT1, AKT2 or AKT3.</p>\n\n![alt text][1]\n\n<p>So by parsing the related XML file (hsa04150.xml) you can easily get the related Entrez geneid 207, 2008, 1000 that are enclosed in the following XML part:</p>\n\n        <entry id=\"33\" name=\"hsa:10000 hsa:207 hsa:208\" type=\"gene\" link=\"http://www.genome.jp/dbget-bin/www_bget?hsa+10000+207+208\">\n        <graphics name=\"AKT3...\" fgcolor=\"#000000\" bgcolor=\"#BFFFBF\"\n             type=\"rectangle\" x=\"339\" y=\"291\" width=\"45\" height=\"17\"/>\n        </entry>\n\n<p>In this pathway there are other instances like this one. (when there is a number at the upper left side of the protein).</p>\n\n<p>So may be it could be a way to identify functionally redundant genes.</p>\n\nHope this helps.\n\nFred\n\n\n  [1]: http://www.bioinformatics.fr/images/tutorials/mTOR_KEGG.gif", "date": "2010-03-17 21:22:29", "action": 0, "post": 341}}, {"pk": 441, "model": "server.postrevision", "fields": {"author": 115, "tag_string": "", "title": "A: Which software development technique is used in your lab? ", "content": "To put my answer in context: I work in industry. I've worked in both small biotechs and large pharmas. I am not the coder on the projects I work on- these days, I'm the project manager. Earlier in my career, I was the \"translator\" between the scientists and the programmers (that job has had many different titles, and was rarely my sole job function).\n\nI have found various permutations of agile programming to be the most successful. The one exception to this has been when I've worked on projects in the more heavily regulated drug development (vs. drug discovery) arena. In those cases, the internal processes have often required a waterfall-like process. For awhile, I specialized a bit in fitting the agile-like development approach favored by my programmers into the waterfall process required by corporate policy.", "date": "2010-03-17 21:52:53", "action": 0, "post": 342}}, {"pk": 442, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: How to get started in bioinformatics?", "content": "I think the best way is to get in to a lab for a rotation project / part-time project depending on your schedule and work on a live project. You may either help the group to code something, they can help you to get familiarize with some common bioinformatics tools and approaches. I think this will be the best way. \n\nIf you can work on your own, pick your language (Perl, Python, Java, Ruby) send a mail to respective bio* mailing list. You will definitely get a small project. You can help the open source community and also get to understand the field and its generic requirements. \n\nGo ahead, Future is Open, Bioinformatics is Open. All the best ! ", "date": "2010-03-17 21:55:59", "action": 0, "post": 343}}, {"pk": 443, "model": "server.postrevision", "fields": {"author": 72, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "A lot of universities and companies never post to national boards and their websites do not get spidered. When I was looking for my first bioinformatics job I collected a list of every job board of every major university I could find and checked each one daily.\n\nHere is my list (some of these might have moved by now)\n\nhttp://www.bioplanet.com/planetforums/viewthread.php?tid=2644", "date": "2010-03-18 00:24:55", "action": 0, "post": 344}}, {"pk": 444, "model": "server.postrevision", "fields": {"author": 71, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "Don't forget to network.  Many of my jobs have been found because I knew someone who pointed me to it or approached me about it.", "date": "2010-03-18 01:54:11", "action": 0, "post": 345}}, {"pk": 445, "model": "server.postrevision", "fields": {"author": 71, "tag_string": "", "title": "A: Which software development technique is used in your lab? ", "content": "Like Melanie, I've worked in industry as a programmer, as a product manager, etc.  In my experience, an iterative, \"agile\" (without getting dogmatic about what agile means) works way better than the waterfall models.  In a research driven environment with constant change, incomplete requirements and needs, I would argue it's the only good way. \n\nThe other key point, don't go for all the features you can, since chances are you will need to re-implement parts anyway.\n\n(Disclaimer - I don't work in science these days)", "date": "2010-03-18 02:03:54", "action": 0, "post": 346}}, {"pk": 446, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "", "title": "A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "content": "<p>Yes of course it is possible. For instance you have the probeset 203074_at from HG-U133 Plus 2 that is associated to ANXA8, ANXA8L1 and ANXA8L2.</p>\n\n<p>In our team, for all the probe sets of the HG-U133 Plus 2 we are performing Blast sequence alignment between the 11 probes of a probset against all mRNAs from Ensembl and Refseq in order to associate them to the right transcript(s).</p>\n\n<p>And for additional information, please find below some interesting reading suggestions  concerning the mapping between the affymetrix probe sets and the mRNAs</p>\n\n 1. [Alternative mapping of probes to genes for Affymetrix chips][1]\n 2. [A sequence-based identification of the genes detected by probesets on the Affymetrix U133 plus 2.0 array][2]\n 3. [Evolving gene/transcript definitions significantly alter the interpretation of GeneChip data][3]\n 4. [Detecting false expression signals\n    in    high-density oligonucleotide\n    arrays    by an in silico\n    approach][4]\n\n\n  \n\n\n  [1]: http://www.biomedcentral.com/1471-2105/5/111\n  [2]: http://www.ncbi.nlm.nih.gov/pubmed/15722477\n  [3]: http://www.ncbi.nlm.nih.gov/pubmed/16284200\n  [4]: http://www.ncbi.nlm.nih.gov/pubmed/15718097", "date": "2010-03-18 07:58:22", "action": 0, "post": 347}}, {"pk": 447, "model": "server.postrevision", "fields": {"author": 98, "tag_string": "chip distance profiles", "title": "distance measure between chip-seq peak set profiles", "content": "Is there any tool that will tell me how different/similar two chip-seq peak sets are in two different parts of the genome? For example, if I have a ~10Kb region in the genome with a series of peaks and another ~10Kb region in the genome with another set of peaks from the same experiment, can I calculate a distance measure between these two peak set profiles with any available tool?", "date": "2010-03-18 10:02:35", "action": 0, "post": 348}}, {"pk": 448, "model": "server.postrevision", "fields": {"author": 37, "tag_string": "licensing general software", "title": "What license do you use when you release code and data?", "content": "Do you aim to make your resources as widely available and reusable as possible? \n\nConversely, do you try to protect the investment of time and resources that went into producing the IP?\n\nThe choice of license can be a tricky thing, and getting it wrong can cause considerable problems for you, and for others attempting to build on your work.\n\nThings to consider:\n\n[ISCB Discussion report on software sharing][1]\n\n[Ontology licensing][2]\n\n[Attribution vs Citation][3]\n\n\n\n\n  [1]: http://iscb-discussion.blogspot.com/2008/03/iscb-member-feedback-sought-on-revised.html\n  [2]: http://themindwobbles.wordpress.com/2009/11/12/science-commons-provide-a-list-of-considerations-for-researchers-looking-to-license-their-ontology/\n  [3]: http://peanutbutter.wordpress.com/2009/07/10/attribution-vs-citation-do-you-know-the-difference/", "date": "2010-03-18 10:06:47", "action": 0, "post": 349}}, {"pk": 449, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: What license do you use when you release code and data?", "content": "my code ( http://code.google.com/p/lindenb/ ) is released under **GNU General Public License v2** but frankly,  the characteristics of all the available licenses are just vague for me. I just want a license that would say: \n> use my code as much as you want but \n> tell me if you're doing something\n> interesting with it, cite my work if an article is published, and remember me if\n> you're getting millionaire.\n", "date": "2010-03-18 10:59:10", "action": 0, "post": 350}}, {"pk": 450, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: What license do you use when you release code and data?", "content": "Most of the time I don't care about the license, I just forget to include it in the files; however, I didn't publish anything important yet apart from some scripts on github.\n\nIf I want to use a license, I choose GNU GPL2, but just because it is the only one that I know more or less how it works. \n\nFor slides and written material I pay more attention, I always use a [Creative Commons][1] license, usually [commercial work/free to share][2] \n\n\n  [1]: http://creativecommons.org/\n  [2]: http://creativecommons.org/licenses/by/3.0/us/", "date": "2010-03-18 11:21:20", "action": 0, "post": 351}}, {"pk": 451, "model": "server.postrevision", "fields": {"author": 137, "tag_string": "", "title": "A: What license do you use when you release code and data?", "content": "I prefer BSD-style license over GPL because I am a bit aware of the problems of using GPLed code in corporate setting. For example a software project **might** catch wind because it is inside some corporate codebase (i.e. has users) even if they do not have technically have to release the modified sources.", "date": "2010-03-18 12:10:10", "action": 0, "post": 352}}, {"pk": 452, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: What license do you use when you release code and data?", "content": "One important consideration is that of the support that made the software possible. When someone's work is supported by public grants (aka taxpayers) both ethical considerations and probably the law requires that the software be made available with few strings attached.\n \nThe fundamental differences between the Open Source licenses can be found in the conditions specifying the licensing of derived work based on the software. Some licenses do not impose any conditions: MIT, BSD; others strictly mandate that any type of derived work must be licensed the same conditions as the original work GPL. \n\nI have been on various sides of software licensing, but now I think that each situation is unique thus no general rule or recommendation applies to all situations.", "date": "2010-03-18 13:26:46", "action": 0, "post": 353}}, {"pk": 453, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "", "title": "A: What license do you use when you release code and data?", "content": "Without getting into a licensing discussion: I prefer to use the most permissive licenses like MIT/BSD instead of GPL. The bottom line is being I never want the license to be a reason for people *not* to use my code--though I can see the reasons why some libraries choose different licenses.", "date": "2010-03-18 14:28:46", "action": 0, "post": 354}}, {"pk": 454, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: distance measure between chip-seq peak set profiles", "content": "Hi,\n\nthis is a problem that I am actively investigating. I have come up with a potential (homegrown) approach but it has has not been fully vetted, so keep that in mind. It builds on the following assumptions\n\n 1. We assume that the  position of each peak is defined independently of the rest\n 2. Within one peak the distribution of the reads is governed by a reasonably normal distribution\n\nThus if we could detect each peak, find the corresponding peak in the other dataset,  extract only the reads that correspond to both of the these peaks, then we can run a statistical test to detect differences between these distributions. \n\nThe results will characterize each peak individually rather than the entire shape. These differences may manifest themselves as a difference in the mean or variance of peaks. (the first indicating a shift of the peak, the other is a change in occupancy). For example below are the results from a script that I wrote that compares peaks around TSS for two experiments:\n\n![alt text][1]\n\nThe upper panel shows the original peaks, the lower panel shows the underlying read distributions, the little boxes below show the shift and p-values respectively.\nThe interpretation is that the last 2 peaks show a statistically significant shift in the mean value of 10bp and +20 bp respectively.\n\nI do have a tool that does this pretty automatically but since I am not fully convinced of its correctness it is not yet publicly available.\n\nNot so long ago I was advised that this is a problem can be thought of a time series analysis but have not yet looked into this possibility. That is something to also investigate.\n\n\n  [1]: http://atlas.bx.psu.edu/_images/genie-compare.png", "date": "2010-03-18 14:40:57", "action": 0, "post": 355}}, {"pk": 455, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: distance measure between chip-seq peak set profiles", "content": "Hi,\n\nthis is a problem that I am actively investigating. I have come up with a potential (homegrown) approach but it has has not been fully vetted, so keep that in mind. It builds on the following assumptions\n\n 1. We assume that the  position of each peak is defined independently of the rest\n 2. Within one peak the distribution of the reads is governed by a reasonably normal distribution\n\nThus if we could detect each peak, find the corresponding peak in the other dataset,  extract only the reads that correspond to both of the these peaks, then we can run a statistical test to detect differences between these distributions. \n\nThe results will characterize each peak individually rather than the entire shape. These differences may manifest themselves as a difference in the mean or variance of peaks. (the first indicating a shift of the peak, the other is a change in occupancy). For example below are the results from a script that I wrote that compares peaks around TSS for two experiments:\n\n![alt text][1]\n\nThe upper panel shows the original peaks, the lower panel shows the underlying read distributions, the little boxes below show the shift and p-values respectively.\nThe interpretation is that the last 2 peaks show a statistically significant shift in the mean value of 10bp and +20 bp respectively.\n\nI do have a tool that does this pretty automatically but since I am not yet convinced of the correctness of the approach as a whole it is not yet publicly available.\n\nNot so long ago I was advised that this is a problem can be thought of a time series analysis but have not yet looked into this possibility. That is something to also investigate.\n\n\n  [1]: http://atlas.bx.psu.edu/_images/genie-compare.png", "date": "2010-03-18 14:48:21", "action": 0, "post": 355}}, {"pk": 456, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: What license do you use when you release code and data?", "content": "Most of the times I don't care about the license, I just forget to include it in the files; however, I didn't publish anything important yet apart from some scripts on github.\n\nIf I want to use a license, I choose GNU GPL2, but just because it is the only one that I know more or less how it works. \n\nFor slides and written material I pay more attention, I always use a [Creative Commons][1] license, usually [commercial work/free to share][2] \n\n\n  [1]: http://creativecommons.org/\n  [2]: http://creativecommons.org/licenses/by/3.0/us/", "date": "2010-03-18 16:46:12", "action": 0, "post": 351}}, {"pk": 457, "model": "server.postrevision", "fields": {"author": 137, "tag_string": "", "title": "A: distance measure between chip-seq peak set profiles", "content": "Looking only at the beautiful plots and not knowing what they really mean it seems to me that the a homegrown approach is unnecessary because after normalization you end up with two probability mass functions. There are multiple distance measures on probability distributions, but the Jensen-Shannon divergence seems (to me) to be most useful here because it can be generalized to multiple reads and has a probabilistic interpretation (the probability that the two runs represent samples drawn from the same background distribution) \n\nsee: \n\nEl-Yaniv, R., Fine, S. & Tishby, N. Agnostic classification of Markovian sequences. In Advances in Neural Information Processing (NIPS-97  (1997).\n\n\n", "date": "2010-03-18 19:54:45", "action": 0, "post": 356}}, {"pk": 458, "model": "server.postrevision", "fields": {"author": 120, "tag_string": "r gene symbol", "title": "Is there a package/function in R where I can load in a whole genome, and then say e.g. get.gene.sequence (input_genome, \"gene_symbol\")", "content": "Is there a package in R where I can load in a whole genome, and then say e.g. get.gene.sequence (input_genome, \"gene_symbol\"), or another tool that you'd use for this job?", "date": "2010-03-18 20:33:35", "action": 0, "post": 357}}, {"pk": 459, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "r gene symbol", "title": "How do I access and query entire genome sequences with R", "content": "Is there a package in R where I can load in a whole genome, and then say e.g. get.gene.sequence (input_genome, \"gene_symbol\"), or another tool that you'd use for this job?", "date": "2010-03-18 20:45:19", "action": 0, "post": 357}}, {"pk": 460, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "", "title": "A: How to find a 28bp 'primer' sequence in a genome?", "content": "[EDIT]\nJust saw [this][1] today (http://www.biomedcentral.com/1471-2105/11/143) which could be another piece of software to check out. I didnt read it carefully, but it looks like it builds on primer3.\n[/EDIT]\n\n\nSince you have so few pairs, you could just run them through a read-aligner allowing mismatches, and find pairs that are aligned within X basepairs in the reference genome. \nActually, you could probably even use the paired-end feature of most aligners so that the aligner only find the pairs with nearby matches. For either of those methods, you could use [bowtie][2].\n\nAs far as I know, [primer3][3] does allow gaps and mismatches, so that may also be an option if you just want to see if you have good primers, but you'd probably have to use the command-line version.\n\nor, you could use BLAST and find nearby hits between the pairs.\n\n\n  [1]: http://www.biomedcentral.com/1471-2105/11/143\n  [2]: http://bowtie-bio.sourceforge.net/index.shtml\n  [3]: http://primer3.sourceforge.net/", "date": "2010-03-18 21:30:55", "action": 0, "post": 225}}, {"pk": 461, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: How do I access and query entire genome sequences with R", "content": "Fasta files are pretty easy to manipulate using the seqinR package, if you've got the memory to handle it.  (~4GB for chr1)\n\n    library(seqinr)\n    seq = read.fasta(\"chr1.fa\",seqtype=\"DNA\")\n    geneSeq = seq[[1]][geneStart:geneStop]\n    \nThere's probably a better way to do it, but this may get you started.", "date": "2010-03-18 21:37:45", "action": 0, "post": 358}}, {"pk": 462, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How do I access and query entire genome sequences with R", "content": "Ok, here is my java solution. It only uses some *remote* resources (the anonymous mysql server and the DAS server of the UCSC). My piece of code takes a list of refGene as its arguments and only prints the genes/geneomic-sequences to stdout but one could imagine it would store a pair(name,sequence) in memory.\n\n\n\n    import java.sql.Connection;\n    import java.sql.DriverManager;\n    import java.sql.PreparedStatement;\n    import java.sql.ResultSet;\n    \n    import javax.xml.parsers.SAXParser;\n    import javax.xml.parsers.SAXParserFactory;\n    \n    import org.xml.sax.Attributes;\n    import org.xml.sax.SAXException;\n    import org.xml.sax.helpers.DefaultHandler;\n    \n    public class Gene2Seq\n    \t{\n    \tprivate static class DASHandler\n    \t\textends DefaultHandler\n    \t\t{\n    \t\tprivate boolean inDNA=false;\n    \t\t@Override\n    \t\tpublic void startElement(String uri, String localName, String qName,\n    \t\t\t\tAttributes attributes) throws SAXException\n    \t\t\t{\n    \t\t\tinDNA=(qName.equals(\"DNA\"));\n    \t\t\t}\n    \t\t@Override\n    \t\tpublic void endElement(String uri, String localName, String qName)\n    \t\t\t\tthrows SAXException\n    \t\t\t{\n    \t\t\tinDNA=false;\n    \t\t\t}\n    \t\t@Override\n    \t\tpublic void characters(char[] ch, int start, int length)\n    \t\t\t\tthrows SAXException\n    \t\t\t{\n    \t\t\tif(inDNA) System.out.print(new String(ch, start, length).replace(\"\\n\", \"\"));\n    \t\t\t}\n    \t\t}\n    \t\n    \tpublic static void main(String[] args) throws Throwable\n    \t\t{\n    \t\t//put the JDBC driver for mysql in the $CLASSPATH\n    \t\tClass.forName(\"com.mysql.jdbc.Driver\");\n    \t\tConnection con = DriverManager.getConnection(\n    \t\t\t\t\"jdbc:mysql://genome-mysql.cse.ucsc.edu/hg19\",\n    \t\t\t\t\"genome\", \"\"\n    \t\t\t\t);\n    \t\tSAXParserFactory f=SAXParserFactory.newInstance();\n    \t\tSAXParser parser=f.newSAXParser();\n    \t\tPreparedStatement pstmt=con.prepareStatement(\n    \t\t\t\t\"select name,chrom,txStart,txEnd from refGene where name2=?\"\n    \t\t\t\t);\n    \t\tfor(String name: args)\n    \t\t\t{\n    \t\t\tpstmt.setString(1, name);\n    \t\t\tResultSet row=pstmt.executeQuery();\n    \t\t\twhile(row.next())\n    \t\t\t\t{\n    \t\t\t\tSystem.out.println(\">\"+row.getString(1)+\"|\"+row.getString(2)+\":\"+row.getInt(3)+\"-\"+row.getInt(4));\n    \t\t\t\tparser.parse(\n    \t\t\t\t\t\t\"http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=\"+row.getString(2)+\":\"+(row.getInt(3)+1)+\",\"+(row.getInt(4)+1),\n    \t\t\t\t\t\tnew DASHandler());\n    \t\t\t\tSystem.out.println();\n    \t\t\t\t}\n    \t\t\trow.close();\n    \t\t\t}\n    \t\t\n    \t\tpstmt.close();\n    \t\tcon.close();\n    \t\t}\n    \t}\n\n\noutput with **EIF4G1**:\n\n\n\n    >NM_004953|chr3:184038262-184053145\n    agatgggctgaaagtggaactcaaggggtttctggcacctacctacctgcttcccgctggggggtggggagttggcccag....\n    >NM_182917|chr3:184032970-184053145\n    tcctcgacggccgccgcccgcctggccttttagggcctgactcccgcccttcctggcctacactcctgggcggcggcagg....\n    >NM_198241|chr3:184032355-184053145\n    gaagcggtggccgccgagcgggatctgtgcggggagccggaaatggt....\n\n\n", "date": "2010-03-18 21:47:46", "action": 0, "post": 359}}, {"pk": 463, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: How do I access and query entire genome sequences with R", "content": "\nseqinR ([http://cran.r-project.org/web/packages/seqinr/index.html][1]) is a good option for R.\n\nIf you don't need the whole genome locally, you can fetch sequences from Ensembl using biomaRt ([http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html][2]):\n\n    library(biomaRt)\n    ensembl <- useMart(\"ensembl\",dataset=\"hsapiens_gene_ensembl\")\n    seq     <- getSequence(id = \"A2M\", type=\"hgnc_symbol\", mart = ensembl, seqType = \"transcript_exon_intron\")\n\n\nI would also consider one of the Bio* libraries ([http://www.open-bio.org/wiki/Projects][3]) for sequence retrieval and manipulation.\n\n\n  [1]: http://cran.r-project.org/web/packages/seqinr/index.html\n  [2]: http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html\n  [3]: http://www.open-bio.org/wiki/Projects", "date": "2010-03-18 22:33:25", "action": 0, "post": 360}}, {"pk": 464, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: How do I access and query entire genome sequences with R", "content": "R has gotten a lot of sequence handling and searching routines recently that make it a good choice also for sequence analysis in bioinformatics.\n\nHave a look at the [BSGenome package in BioConductor][1]. It is meant to hold the genome sequence and allow fast sequence searches in the genome sequence. It *does not* contain real genome annotations though. There are readymade packages for a bunch of eukaryote genomes you can download, but of course your organism has to be in the list. This can be used together with the [BioStrings][2] package that allows for fast sequence searches and manipulation. \n\nIt could be a good team with biomaRt (already mentioned, I really recommend this) if you want further local sequence processing or if you already have the gene start/end coordinates, or alternatively transfer the coordinates only and cut these out of the BSGenome.\n\n\n  [1]: http://www.bioconductor.org/packages/2.5/bioc/html/BSgenome.html\n  [2]: http://www.bioconductor.org/packages/2.5/bioc/html/Biostrings.html", "date": "2010-03-19 09:19:43", "action": 0, "post": 361}}, {"pk": 465, "model": "server.postrevision", "fields": {"author": 137, "tag_string": "", "title": "A: What license do you use when you release code and data?", "content": "I prefer BSD-style license over GPL because I am a bit aware of the problems of using GPLed code in corporate setting. For example a software project **might** catch wind because it is inside some corporate codebase (i.e. has users) even if they do not technically have to release the modified sources.", "date": "2010-03-19 11:57:06", "action": 0, "post": 352}}, {"pk": 466, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "biomart wsdl soap java webservice", "title": "Anyone using \"Biomart + Java Web Services\" ?", "content": "Hi all,\nThanks to [Neil][1], I've discovered that **Biomart** is not just a HTML front-end but it can also be invoked as a [web service][2].\n\nSo, I played with java and the following webservice: http://www.ensembl.org/biomart/martwsdl .\n\n${jAVA_HOME}/bin/**wsimport**  http://www.ensembl.org/biomart/martwsdl\n\nwas called to generate the java sources from the **WSDL** file and I also wrote the following client:\n\n    import org.ensembl._80.martservicesoap.*;\n    \n    public class BioMartClient\n     {\n     public static void  main(String args[]) throws Exception\n      {\n      BioMartSoapService service=new BioMartSoapService();\n      MartServiceSoap martsoap= service.getBioMartSoapPort();\n      for(Mart mart: martsoap.getRegistry())\n       {\n       System.out.println(mart.getName());\n       }\n      }\n     }\n\nbut the program throwed the following exception when it invokes **getRegistry**():\n\n    Exception in thread \"main\" com.sun.xml.internal.ws.server.UnsupportedMediaException: Unsupported Content-Type: text/html; charset=utf-8 Supported ones are: [text/xml]\n            at com.sun.xml.internal.ws.encoding.StreamSOAPCodec.decode(StreamSOAPCodec.java:284)\n    (...)\n            at $Proxy30.getRegistry(Unknown Source)\n            at BioMartClient.main(BioMartClient.java:9)\n\n\nI also tested a few more BioMart servers: Sometimes *getRegistry* just returns an empty list (http://www.biomart.org/biomart/martwsdl ), sometimes the path *martwsdl* does not exist ( http://www.wormbase.org/biomart/martwsdl ), etc...\n\nIn the end I didn't find any server containing some data that could be processed via the SOAP protocol.\n\nIs it a known issue ? Am I missing something ? Is there a functional BioMart+SOAP server anywhere ?\n\nThanks,\n\n\n\n  [1]: http://biostar.stackexchange.com/questions/357\n  [2]: http://www.biomart.org/martservice.html", "date": "2010-03-19 13:49:39", "action": 0, "post": 362}}, {"pk": 467, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: Repeat subunit based multiple alignment of DNA", "content": "No idea how to do it exactly but I can think about two routes to investigate:\n\n* LASTZ has something called \"quantum DNA\":\n\nhttp://www.bx.psu.edu/miller_lab/dist/README.lastz-1.02.00/README.lastz-1.02.00.html#fmt_qdna\n\n* instead of using \"linear\" aligner go for graph based ones:\n\n POA     http://bioinfo.mbi.ucla.edu/poa/\n\n AliWABA http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1538870/\n\n", "date": "2010-03-19 14:27:47", "action": 0, "post": 176}}, {"pk": 468, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "visualization genome plotting", "title": "What tools/libraries do you use to visualize genomic feature data?", "content": "Given some genomic data in a well-known format (e.g. GFF) with gene models, what tool(s) do you use to visualize that data. \nWhat tools allow you to add your own tracks of data easily? \nI'm interested in both desktop and web-based tools--with preference to those that are customizable via some kind of API.", "date": "2010-03-19 15:14:27", "action": 0, "post": 363}}, {"pk": 469, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: What tools/libraries do you use to visualize genomic feature data?", "content": "I'm using the well-known UCSC Genome Browser http://genome.ucsc.edu/goldenPath/help/customTrack.html\n\nI also wrote an experimental implementation of [Jan Aerts' LocusTree][1] based on BerkeleyDB (see http://plindenbaum.blogspot.com/2009/11/java-implementation-of-jan-aerts.html )\n\n![LocusTree][2]\n\n\n  [1]: http://saaientist.blogspot.com/2009/04/locustree-searching-genomic-loci.html\n  [2]: http://4.media.tumblr.com/tumblr_kt8yz0W4AP1qznaooo1_400.jpg", "date": "2010-03-19 15:24:07", "action": 0, "post": 364}}, {"pk": 470, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Anyone using \"Biomart + Java Web Services\" ?", "content": "Hi Pierre,\n\nactually it would surprise me if there were no problems. This reminds me of some experiences I encountered when I tried to use the highly appraised standardized SOAP web-services world (actually I wanted to ask a question about user's experiences with bioinfo services but didn't get that far). So, it is a bit like the famous [radio yerevan][1], \"In principle it's standardized, but everyone has different standards.\"\n\nHowever, and not to just bash the providers, I can remember that we had successfully accessed biomart SOAP web-services with [SoapUI][2]. That tool is great for testing and building messages. Alternatively try a different SOAP stack like Axis2 to generate the binding.\n\nI might give it a try and generate a simple Axis2 client, then I will edit and provide the \njava code. So long there could be something wrong with the way you are trying to use the library. Also, Biomart is sensitive to the exact workflow of service calls.\n\nThis is what I just tried in soapui:\nconnect to: http://www.biomart.org/biomart/martwsdl\nthen call \"getRegistry\" as you did with the following message:\n  \n      <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:mar=\"http://www.biomart.org:80/MartServiceSoap\">\n    \n       <soapenv:Header/>\n    \n       <soapenv:Body>\n    \n          <mar:getRegistry/>\n       </soapenv:Body>\n    </soapenv:Envelope>\n\nThen you will get this response, which looks very much ok.\n\n    <soap:Envelope soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <getRegistryResponse xmlns=\"http://www.biomart.org:80/MartServiceSoap\">\n             <mart>\n                <name xsi:type=\"xsd:string\">ensembl</name>\n                <displayName xsi:type=\"xsd:string\">ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database xsi:type=\"xsd:string\">ensembl_mart_57</database>\n                <host xsi:type=\"xsd:string\">www.biomart.org</host>\n                <path xsi:type=\"xsd:string\">/biomart/martservice</path>\n                <port xsi:type=\"xsd:string\">80</port>\n                <visible xsi:type=\"xsd:int\">1</visible>\n                <default xsi:type=\"xsd:int\">1</default>\n                <serverVirtualSchema xsi:type=\"xsd:string\">default</serverVirtualSchema>\n                <includeDatasets xsi:type=\"xsd:string\"/>\n                <martUser xsi:type=\"xsd:string\"/>\n                <redirect xsi:nil=\"true\" xsi:type=\"xsd:int\"/>\n             </mart>\n\n\n\n\n\n\n  [1]: http://en.wikipedia.org/wiki/Radio_Yerevan\n  [2]: http://www.soapui.org/\n\n\n\n\n\n\n\n\n\n", "date": "2010-03-19 15:46:08", "action": 0, "post": 365}}, {"pk": 471, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: What tools/libraries do you use to visualize genomic feature data?", "content": "For desktop level genome visualization the [Integrated Genome Browser][1] is a very nice tool.\n\nPS. Web based tool authors always tend to over-complicate things (that includes me too ;-) ), maybe it is accidental complexity, maybe it is avoidable. I wish I knew. There is a server side, there is a client side, state needs to be saved between interactions and that turns  into a disconnect that needs to be bridged.\n\n\n  [1]: http://www.bioviz.org/igb/", "date": "2010-03-19 16:08:53", "action": 0, "post": 366}}, {"pk": 472, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: What tools/libraries do you use to visualize genomic feature data?", "content": "I'll put in a plug for  [Genboree](http://genboree.org/java-bin/login.jsp), which my lab develops.  It's essentially a genome browser with personalized databases/wikis, access control, and integration with Galaxy.  It can import UCSC tracks and you can add any data that maps to genomic coordinates. It also has a [REST API](http://genboree.org/java-bin/showHelp.jsp?topic=restAPIOverview) that's fairly new.\n\nSince I do a lot of copy-number work, I do quite a bit of sanity-check visualization with R, often just using simple tweaks of the plot command, but sometimes pulling in packages to help.", "date": "2010-03-19 16:44:35", "action": 0, "post": 367}}, {"pk": 473, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: What tools/libraries do you use to visualize genomic feature data?", "content": "For desktop level genome visualization the [Integrated Genome Browser][1] is a very nice tool.\n\n  [1]: http://www.bioviz.org/igb/", "date": "2010-03-19 17:18:34", "action": 0, "post": 366}}, {"pk": 474, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Anyone using \"Biomart + Java Web Services\" ?", "content": "Hi Pierre,\n\nactually it would surprise me if there were no problems. This reminds me of some experiences I encountered when I tried to use the highly appraised standardized SOAP web-services world (actually I wanted to ask a question about user's experiences with bioinfo services but didn't get that far). So, it is a bit like the famous [radio yerevan][1], \"In principle it's standardized, but everyone has different standards.\"\n\nHowever, and not to just bash the providers, I can remember that we had successfully accessed biomart SOAP web-services with [SoapUI][2]. That tool is great for testing and building messages. Alternatively try a different SOAP stack like Axis2 to generate the binding.\n\nI might give it a try and generate a simple Axis2 client, then I will edit and provide the \njava code. So long there could be something wrong with the way you are trying to use the library. Also, Biomart is sensitive to the exact workflow of service calls.\n\nThis is what I just tried in soapui:\nwith SoapUI load the wsdl at: http://www.biomart.org/biomart/martwsdl\nWith other tools (eg curl, see comments), send the xml-message below to the \nservice endpoint address: http://www.biomart.org/biomart/martsoap\n\nthen call \"getRegistry\" as you did with the following message:\n  \n      <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:mar=\"http://www.biomart.org:80/MartServiceSoap\">\n    \n       <soapenv:Header/>\n    \n       <soapenv:Body>\n    \n          <mar:getRegistry/>\n       </soapenv:Body>\n    </soapenv:Envelope>\n\nThen you will get this response, which looks very much ok.\n\n    <soap:Envelope soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <getRegistryResponse xmlns=\"http://www.biomart.org:80/MartServiceSoap\">\n             <mart>\n                <name xsi:type=\"xsd:string\">ensembl</name>\n                <displayName xsi:type=\"xsd:string\">ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database xsi:type=\"xsd:string\">ensembl_mart_57</database>\n                <host xsi:type=\"xsd:string\">www.biomart.org</host>\n                <path xsi:type=\"xsd:string\">/biomart/martservice</path>\n                <port xsi:type=\"xsd:string\">80</port>\n                <visible xsi:type=\"xsd:int\">1</visible>\n                <default xsi:type=\"xsd:int\">1</default>\n                <serverVirtualSchema xsi:type=\"xsd:string\">default</serverVirtualSchema>\n                <includeDatasets xsi:type=\"xsd:string\"/>\n                <martUser xsi:type=\"xsd:string\"/>\n                <redirect xsi:nil=\"true\" xsi:type=\"xsd:int\"/>\n             </mart>\n\n\n\n\n\n\n  [1]: http://en.wikipedia.org/wiki/Radio_Yerevan\n  [2]: http://www.soapui.org/\n\n\n\n\n\n\n\n\n\n", "date": "2010-03-19 17:18:42", "action": 0, "post": 365}}, {"pk": 475, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: What tools/libraries do you use to visualize genomic feature data?", "content": "I'll put in a plug for  [Genboree](http://genboree.org/java-bin/login.jsp), which my lab develops.  It's essentially a genome browser with personalized databases/wikis, access control, and integration with Galaxy.  It can import UCSC tracks and you can add any data that maps to genomic coordinates. It also has a [REST API](http://genboree.org/java-bin/showHelp.jsp?topic=restAPIOverview) that's fairly new.\n\nSince I do a lot of copy-number work, I also do quite a bit of sanity-check visualization with R, often just using simple tweaks of the plot command, but sometimes pulling in packages to help.", "date": "2010-03-19 17:22:51", "action": 0, "post": 367}}, {"pk": 476, "model": "server.postrevision", "fields": {"author": 119, "tag_string": "", "title": "A: What tools/libraries do you use to visualize genomic feature data?", "content": "I like the Broad's IGV: [http://www.broadinstitute.org/igv/][1] for genome browsing. It handles lots of common data formats, including SAM/BAM files if you're dealing with NGS-scale datasets. Apparently you can talk to it it via http, but you can't say anything very complicated: [http://www.broadinstitute.org/igv/PortCommands][2]\n\n  [1]: http://www.broadinstitute.org/igv/\n  [2]: http://www.broadinstitute.org/igv/PortCommands\n", "date": "2010-03-19 17:51:58", "action": 0, "post": 368}}, {"pk": 477, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Repeat subunit based multiple alignment of DNA", "content": "As tagged correctly, this is a multiple sequence alignment problem, so pairwise/database alignment tools (BLAST or maybe B/LASTZ as mentioned above) are not an option. \nSo well understood tools such as [ClustalW][1], or T-Coffe, or DIALIGN, might already do the job. Try low gap extension/opening costs. I would try a well-known algorithm and try the more 'esoteric' stuff later on, and only if that doesn't give good results.\n\nBetter than ClustalW maybe in your case\n[Dialign][2]: It uses no gap-costs. \n\n> This approach can be used for both global and local alignment, but it is particularly successful in situations where sequences share only local  homologies. (From the BiBiServ description)\n\nThis seems to fit your case quite well.\n\nAnother possibility would be to mask out the portions of each sequence that is a priori known to be less conserved. That requires to have knowledge about each sequence and to manually design a mask. Or even a vector of base-specific weights, but I don't know any MSA tool that takes such input. If you find one, please post it here :)\n\n\n\n\n  [1]: http://www.ebi.ac.uk/Tools/clustalw2/\n  [2]: http://bibiserv.techfak.uni-bielefeld.de/dialign/", "date": "2010-03-19 18:25:34", "action": 0, "post": 369}}, {"pk": 478, "model": "server.postrevision", "fields": {"author": 25, "tag_string": "", "title": "A: What tools/libraries do you use to visualize genomic feature data?", "content": "I use [Artemis][1] and [ACT][2] from the Sanger Institute. The former is a genome viewer and annotation tool. The latter is used for comparing genomes.\n\nHowever, I'm not sure that there's an API for it...\n\n\n  [1]: http://www.sanger.ac.uk/resources/software/artemis/\n  [2]: http://www.sanger.ac.uk/resources/software/act/", "date": "2010-03-19 20:51:09", "action": 0, "post": 370}}, {"pk": 479, "model": "server.postrevision", "fields": {"author": 89, "tag_string": "", "title": "A: What tools/libraries do you use to visualize genomic feature data?", "content": "A bit different from the linear browsers listed above is the genome visualization tool [circos][1]. It can plot a wide range of different data types onto the radially displayed chromosomes. Everything can be customized and is quite easy to use. \n\n![alt text][2]\n\n\n  [1]: http://mkweb.bcgsc.ca/circos/\n  [2]: http://mkweb.bcgsc.ca/circos/tutorial_images/100px/tutorial-05-05.png", "date": "2010-03-19 21:56:40", "action": 0, "post": 371}}, {"pk": 480, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Anyone using \"Biomart + Java Web Services\" ?", "content": "Edit:\n**Conclusion: It does not work and is unlikely to work without changing the service.**\n\nTesting bioinformatics web-services can sometimes be a frustrating experience. It looks as if all the specs of interoperability are not worth the (white-) papers they are printed on.\nI actually have had very little success in connecting to perl, SOAP-lite based web-services like BioMart, Kegg, etc.  \n\nActually, I tried to use a generated Axis2 client and got an exception.\nThen, I tried to validate the response message in SoapUI from BioMart, and it does not validate!\n\n    line 4: Expected element 'mart' instead of 'mart@http://www.biomart.org:80/MartServiceSoap' here in element getRegistryResponse@http://www.biomart.org:80/MartServiceSoap\n\nSo it's very unlikely that this is going to work at all, except with perl and SOAP::Lite. There are too many tiny glitches involved. To clean up this mess I intend to contact the Bimart developers and ask them to change their interface. In fact, it seems that nobody has tested that yet with Java, otherwise somebody would have noticed that it does not work. \n\nMaybe, you wish to join me in this effort?\n\n\n----------\n\n\nHi Pierre,\n\nactually it would surprise me if there were no problems. This reminds me of some experiences I encountered when I tried to use the highly appraised standardized SOAP web-services world (actually I wanted to ask a question about user's experiences with bioinfo services but didn't get that far). So, it is a bit like the famous [radio yerevan][1], \"In principle it's standardized, but everyone has different standards.\"\n\nHowever, and not to just bash the providers, I can remember that we had successfully accessed biomart SOAP web-services with [SoapUI][2]. That tool is great for testing and building messages. Alternatively try a different SOAP stack like Axis2 to generate the binding.\n\nI might give it a try and generate a simple Axis2 client, then I will edit and provide the \njava code. So long there could be something wrong with the way you are trying to use the library. Also, Biomart is sensitive to the exact workflow of service calls.\n\nThis is what I just tried in soapui:\nwith SoapUI load the wsdl at: http://www.biomart.org/biomart/martwsdl\nWith other tools (eg curl, see comments), send the xml-message below to the \nservice endpoint address: http://www.biomart.org/biomart/martsoap\n\nthen call \"getRegistry\" as you did with the following message:\n  \n      <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:mar=\"http://www.biomart.org:80/MartServiceSoap\">\n    \n       <soapenv:Header/>\n    \n       <soapenv:Body>\n    \n          <mar:getRegistry/>\n       </soapenv:Body>\n    </soapenv:Envelope>\n\nThen you will get this response, which looks very much ok.\n\n    <soap:Envelope soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <getRegistryResponse xmlns=\"http://www.biomart.org:80/MartServiceSoap\">\n             <mart>\n                <name xsi:type=\"xsd:string\">ensembl</name>\n                <displayName xsi:type=\"xsd:string\">ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database xsi:type=\"xsd:string\">ensembl_mart_57</database>\n                <host xsi:type=\"xsd:string\">www.biomart.org</host>\n                <path xsi:type=\"xsd:string\">/biomart/martservice</path>\n                <port xsi:type=\"xsd:string\">80</port>\n                <visible xsi:type=\"xsd:int\">1</visible>\n                <default xsi:type=\"xsd:int\">1</default>\n                <serverVirtualSchema xsi:type=\"xsd:string\">default</serverVirtualSchema>\n                <includeDatasets xsi:type=\"xsd:string\"/>\n                <martUser xsi:type=\"xsd:string\"/>\n                <redirect xsi:nil=\"true\" xsi:type=\"xsd:int\"/>\n             </mart>\n\n\n\n\n\n\n  [1]: http://en.wikipedia.org/wiki/Radio_Yerevan\n  [2]: http://www.soapui.org/\n\n\n\n\n\n\n\n\n\n", "date": "2010-03-19 22:36:03", "action": 0, "post": 365}}, {"pk": 481, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: What tools/libraries do you use to visualize genomic feature data?", "content": "It's interesting to see votes for the IGV; I've looked at it only recently and it does look very promising as a desktop viewer.\n\nI'm a long-time user of the [Generic Genome Browser][1], a Bioperl-based web application. It is extremely customizable and can act as both DAS server and client. Be prepared to spend quite a bit of time \"munging\" your GFF files into shape and working on the config file to get the desired results.\n\nI also like Bioperl's [Bio::Graphics][2] as a way to take simple text files (including GFF) and quickly generate very attractive plots.  There's a similar, but less extensive [Ruby library][3] too.\n\nI've recently tried [GenomeGraphs][4], an R Bioconductor package. It fetches annotations from Ensembl and plots them as tracks. It's a good way to overlay quantitative data onto genomic features:  here is a [sample plot][5].\n\n\n  [1]: http://gmod.org/wiki/Gbrowse\n  [2]: http://bioperl.org/wiki/HOWTO:Graphics\n  [3]: http://bio-graphics.rubyforge.org/\n  [4]: http://www.bioconductor.org/packages/release/bioc/html/GenomeGraphs.html\n  [5]: http://twitpic.com/19350x", "date": "2010-03-19 23:16:11", "action": 0, "post": 372}}, {"pk": 482, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "", "title": "A: What license do you use when you release code and data?", "content": "Regarding Open Data, these require different licenses. I recommend reading the [Panton Principles][1].\n\n\n  [1]: http://pantonprinciples.org/", "date": "2010-03-20 08:22:48", "action": 0, "post": 373}}, {"pk": 483, "model": "server.postrevision", "fields": {"author": 153, "tag_string": "", "title": "A: Where can I get the secondary structure of a protein?", "content": "If you want to obtain domains as well as the annotations that come along, you can do it locally with an RPS-BALST. Here for example to obtain Pfam annotations :\n> rpsblast -i \".$InputPath.\"/\".$item.\" -d ~/Bioinfo/cdd/Pfam -e 0.000000000001 -o \".$elemt[0].\"_Pfam.rpsblast -T T -m 7\n\n- i = the input path\n- d = the database path\n- e = the e-value cut-off value\n- o = the output name\n- T T and -m 7 = to have the output in XML format\n\nYou can download all the databases fromm CDD http://www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtml.\n You'll obtain external source databases like Pfam, SMART, COG, PRK, TIGRFAM. ", "date": "2010-03-20 11:37:31", "action": 0, "post": 374}}, {"pk": 484, "model": "server.postrevision", "fields": {"author": 153, "tag_string": "swissprot dna protein embl genbank", "title": "How to retrive the DNA sequence from a list of EMBL and GeneID", "content": "Hi everyone,\n\nAs input files, I use swissprot files. \nI have a perl script which parses all the `enter code here`files to retieve all the EMBL ids and GeneID from the DR features line for each protein.\nI would like to know if there's an automatic way to retrieve all the corresponding DNA squences for each protein on the list. Thanks for your help.\n\nBest,\n\nKirsley\n\n", "date": "2010-03-20 12:24:42", "action": 0, "post": 375}}, {"pk": 485, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How to retrive the DNA sequence from a list of EMBL and GeneID", "content": "from a geneid you can get the information as XML from the NCBI  with **EFetch**. e.g. for GeneId=2.\n\nhttp://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=gene&id=2&retmode=xml\n\nand you can then get the accession of each RNA sequence under: `(...)/Gene-commentary_products/Gene-commentary/Gene-commentary_type[@value='mRNA']/Gene-commentary_accession` (use XSLT/XPATH to extract this information)\n\nand for each accession you get the DNA sequence  with EFetch.\n\nhttp://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nucleotide&id=NM_000014&rettype=fasta&retmode=xml\n\n", "date": "2010-03-20 12:51:20", "action": 0, "post": 376}}, {"pk": 486, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: How to retrive the DNA sequence from a list of EMBL and GeneID", "content": "Yes there is if your organism is in Ensembl - [BioMart][1].  Here is how you'd use the web interface, assuming that you want human sequences:\n\n 1. Go to BioMart and click MARTVIEW\n 2. Select database = Ensembl Genes 57\n 3. Select dataset = Homo sapiens genes\n 4. Click \"Filters\" to the left and open the \"Gene\" selection\n 5. From the dropdown box, select the IDs that you want to use (e.g. UniProt/TrEMBL)\n 6. Either paste your list in the box or upload the file\n 7. Click \"Attributes\" to the left, select the \"Sequences\" radio button and open the \"Sequences\" tab\n 8. Select what type of sequence (e.g. unspliced transcript)\n 9. Click \"Results\" (in menu bar, top-left of page)\n\nThis will return the first 10 sequences. You can download the rest as a file. There is also programmatic access to Ensembl:  Perl API, biomaRt for R Bioconductor.\n\nIf this doesn't work for you, the [Bioperl][2] library should be able to retrieve sequences given IDs.\n\n\n  [1]: http://www.biomart.org\n  [2]: http://www.bioperl.org", "date": "2010-03-20 13:02:12", "action": 0, "post": 377}}, {"pk": 487, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "chromosome ideogram plotting", "title": "Drawing chromosome ideogams with data", "content": "What software do you use to draw chromosomes with G-banding pattern and plot data alongside each chromosome? I'm interested in different kind of plots - lines, points, bars, etc - and high customization.\n\nI have used [coloredChromosomes.pl][1] and [chromosomeplot][2] in MATLAB, but there are not enough features. What would you recommend to try?\n\n\n  [1]: http://users.comcen.com.au/~journals/ojb/ojbideofreesample2003/ojbideofreesample2003.htm\n  [2]: http://www.mathworks.com/access/helpdesk/help/toolbox/bioinfo/ref/chromosomeplot.html", "date": "2010-03-20 15:12:06", "action": 0, "post": 378}}, {"pk": 488, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Drawing chromosome ideogams with data", "content": "I found this bookmark in my del.icio.us \n\n> \"Idiographica: a general-purpose web\n> application to build idiograms\n> on-demand for human, mouse and rat\"\n\n doi:10.1093/bioinformatics/btm455 \n\nhttp://www.ncrna.org/idiographica/\n\n![idiographica][1]\n\nThere is also [gff2ps][2] \n\nOr you can use the **custom tracks** in the [UCSC genome Browser][3].\n\n\n  [1]: http://www.ncrna.org/idiographica/image/idiogram_sample1s\n  [2]: http://genome.crg.es/software/gfftools/GFF2PS.html\n  [3]: http://genome.ucsc.edu/goldenPath/help/customTrack.html", "date": "2010-03-20 15:35:11", "action": 0, "post": 379}}, {"pk": 489, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "chromosome ideogram plotting", "title": "Drawing chromosome ideogams with data", "content": "What software do you use to draw chromosomes with G-banding pattern and plot data alongside each chromosome? I'm interested in different kind of plots - lines, points, bars, etc - and high customization.\n\nI have used [coloredChromosomes.pl][1] and [chromosomeplot][2] in MATLAB, but there are not enough features. What would you recommend to try?\n\n**UPDATE**:\nI need something like this:\n![chromosome plot example][3]\n\n\n  [1]: http://users.comcen.com.au/~journals/ojb/ojbideofreesample2003/ojbideofreesample2003.htm\n  [2]: http://www.mathworks.com/access/helpdesk/help/toolbox/bioinfo/ref/chromosomeplot.html\n  [3]: http://img233.imageshack.us/img233/6805/chrexample.jpg \"chromosome plot example\"", "date": "2010-03-20 16:10:27", "action": 0, "post": 378}}, {"pk": 490, "model": "server.postrevision", "fields": {"author": 72, "tag_string": "", "title": "A: Drawing chromosome ideogams with data", "content": "Circos is very popular these days\nhttp://mkweb.bcgsc.ca/circos/", "date": "2010-03-20 17:35:00", "action": 0, "post": 380}}, {"pk": 491, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "", "title": "A: Drawing chromosome ideogams with data", "content": "You can try [Flash GViewer][1].\n<p>I found it so nice that I tried to do a SVG version of it but not enough spare time to finish it.</p>\n\n\n  [1]: http://gmod.org/wiki/Flashgviewer/", "date": "2010-03-20 23:07:51", "action": 0, "post": 381}}, {"pk": 492, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "You can also checked [http://www.bioinformatics.fr/jobs.php][1] with a dedicated RSS feed.</p>\n<p>When I have the time I also try to compile jobs from other sources like :</p>\n\n - [jobs.ac.uk][2] \n - [bioinformatics.org][3]\n - [listbioinfo][4] (see Pierre post)\n - [iscb.org][5] \n - [biospace.com][6]\n\n\n  [1]: http://www.bioinformatics.fr/jobs.php\n  [2]: http://www.jobs.ac.uk/cgi-bin/search.cgi?keywords=bioinformatics&x=0&y=0\n  [3]: http://www.bioinformatics.org/jobs/\n  [4]: http://listes.sfbi.fr/wws/info/bioinfo\n  [5]: http://www.iscb.org/iscb-careers\n  [6]: http://www.biospace.com/search_results_jobs.aspx?SearchWord=%25%25&TheLocation=%25%25", "date": "2010-03-20 23:10:36", "action": 0, "post": 300}}, {"pk": 493, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Anyone using \"Biomart + Java Web Services\" ?", "content": "Edit:\n**Conclusion: It does not work and is unlikely to work without changing the service.**\n\n**In the meantime, I would like to ask everyone who has similar experiences with non-functional SOAP/REST web-services, non-parsable WSDLS, non-validating XML-messages or other problems with service interoperability not to give up, but to report to the providers, to challenge them to improve the interoperability!**\n\nThose experiencing similar problems with  BioMart can for example report to: mart-dev@ebi.ac.uk\n\nTesting bioinformatics web-services can sometimes be a frustrating experience. It looks as if all the specs of interoperability are not worth the (white-) papers they are printed on.\nI actually have had very little success in connecting to perl, SOAP-lite based web-services like BioMart, Kegg, etc.  \n\nActually, I tried to use a generated Axis2 client and got an exception.\nThen, I tried to validate the response message in SoapUI from BioMart, and it does not validate!\n\n    line 4: Expected element 'mart' instead of 'mart@http://www.biomart.org:80/MartServiceSoap' here in element getRegistryResponse@http://www.biomart.org:80/MartServiceSoap\n\nSo it's very unlikely that this is going to work at all, except with perl and SOAP::Lite. There are too many tiny glitches involved. To clean up this mess I intend to contact the Bimart developers and ask them to change their interface. In fact, it seems that nobody has tested that yet with Java, otherwise somebody would have noticed that it does not work. \n\nMaybe, you wish to join me in this effort?\n\n\n----------\n\n\nHi Pierre,\n\nactually it would surprise me if there were no problems. This reminds me of some experiences I encountered when I tried to use the highly appraised standardized SOAP web-services world (actually I wanted to ask a question about user's experiences with bioinfo services but didn't get that far). So, it is a bit like the famous [radio yerevan][1], \"In principle it's standardized, but everyone has different standards.\"\n\nHowever, and not to just bash the providers, I can remember that we had successfully accessed biomart SOAP web-services with [SoapUI][2]. That tool is great for testing and building messages. Alternatively try a different SOAP stack like Axis2 to generate the binding.\n\nI might give it a try and generate a simple Axis2 client, then I will edit and provide the \njava code. So long there could be something wrong with the way you are trying to use the library. Also, Biomart is sensitive to the exact workflow of service calls.\n\nThis is what I just tried in soapui:\nwith SoapUI load the wsdl at: http://www.biomart.org/biomart/martwsdl\nWith other tools (eg curl, see comments), send the xml-message below to the \nservice endpoint address: http://www.biomart.org/biomart/martsoap\n\nthen call \"getRegistry\" as you did with the following message:\n  \n      <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:mar=\"http://www.biomart.org:80/MartServiceSoap\">\n    \n       <soapenv:Header/>\n    \n       <soapenv:Body>\n    \n          <mar:getRegistry/>\n       </soapenv:Body>\n    </soapenv:Envelope>\n\nThen you will get this response, which looks very much ok.\n\n    <soap:Envelope soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <getRegistryResponse xmlns=\"http://www.biomart.org:80/MartServiceSoap\">\n             <mart>\n                <name xsi:type=\"xsd:string\">ensembl</name>\n                <displayName xsi:type=\"xsd:string\">ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database xsi:type=\"xsd:string\">ensembl_mart_57</database>\n                <host xsi:type=\"xsd:string\">www.biomart.org</host>\n                <path xsi:type=\"xsd:string\">/biomart/martservice</path>\n                <port xsi:type=\"xsd:string\">80</port>\n                <visible xsi:type=\"xsd:int\">1</visible>\n                <default xsi:type=\"xsd:int\">1</default>\n                <serverVirtualSchema xsi:type=\"xsd:string\">default</serverVirtualSchema>\n                <includeDatasets xsi:type=\"xsd:string\"/>\n                <martUser xsi:type=\"xsd:string\"/>\n                <redirect xsi:nil=\"true\" xsi:type=\"xsd:int\"/>\n             </mart>\n\n\n\n\n\n\n  [1]: http://en.wikipedia.org/wiki/Radio_Yerevan\n  [2]: http://www.soapui.org/\n\n\n\n\n\n\n\n\n\n", "date": "2010-03-21 11:17:33", "action": 0, "post": 365}}, {"pk": 494, "model": "server.postrevision", "fields": {"author": 153, "tag_string": "", "title": "A: How to retrive the DNA sequence from a list of EMBL and GeneID", "content": "Thanks for your answers! I could not try with BioMart as my organism is not present on Ensembl. I forgot to precise that I am working on Chlamydiales.", "date": "2010-03-21 13:21:00", "action": 0, "post": 382}}, {"pk": 495, "model": "server.postrevision", "fields": {"author": 94, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "I guess a follow on to this question is \"What are the best sites to advertise informatics jobs when you are on a limited budget.\"  My system includes posting on:\n\n - **[LinkedIn][1]** - Free when you post via your status profile and groups.\n - **[Nature Jobs][2]** - Free\n - **[GenomeWeb][3]** - Free\n - **[Bioinformatics(dot)org][4]** - $75 / year professional membership needed\n - **[Craigslist][5]** - Free in most cities and a great way to find local candidates if you are in a bigger biotech city (DC, Boston, SD)\n - **[ISCB][6]** - Free if you are a member, which is like 100 bucks.\n - **[Dice.com][7]** - Expensive, but targeted. Geared more to technology professionals, have found several great SE and sys admin candidates here.\n\nThen, use sites like Twitter, FriendFeed, LinkedIn, Facebook, etc to spread thew word about the availability of these positions, and point candidates to your website.  I use [Wufoo][8] to generate applications, track candidates via the reports, etc.\n\nI find all of these are great ways to find entry-mid level candidates. \n\nThere is no substitute for trusted referrals or candidates from your existing network of professionals.\n\nOf course these are all great sites to search for a new job as well, that why I use them. ;-)\n\n\n  [1]: http://www.linkedin.com/\n  [2]: http://www.nature.com/naturejobs/index.html\n  [3]: http://www.genomeweb.com/jobs\n  [4]: http://www.genomeweb.com/jobs\n  [5]: http://washingtondc.craigslist.org/sci/\n  [6]: http://www.iscb.org/iscb-careers\n  [7]: http://www.dice.com/\n  [8]: http://Wufoo.com", "date": "2010-03-21 16:42:53", "action": 0, "post": 383}}, {"pk": 496, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Anyone using \"Biomart + Java Web Services\" ?", "content": "Hi again,\n\nI was finally able to edit the received message such that it can be validated. The biomart reponse semed to completely screw up namespaces and they use [XML-schema instance][1]. :o)\nIf you look at that w3c site you see that they say this should never be used.\nSo compare the valid edited reponse massage with the real (but shortened) output.\nThe next step is to make the maintainers have their service send valid XML\n\nHere is the edited and schema-valid response, only the first mart given:\n\n\n    <soap:Envelope \n    soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" \n    \n    xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" \n    xmlns:tns=\"http://www.biomart.org:80/MartServiceSoap\"\n    xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <tns:getRegistryResponse>\n             <mart>\n                <name>ensembl</name>\n                <displayName>ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database>ensembl_mart_57</database>\n                <host>www.biomart.org</host>\n                <path>/biomart/martservice</path>\n                <port>80</port>\n                <visible>1</visible>\n                <default>1</default>\n                <serverVirtualSchema>default</serverVirtualSchema>\n                <includeDatasets/>\n                <martUser/>\n                <redirect>1</redirect>\n             </mart>\n           \n          </tns:getRegistryResponse>\n       </soap:Body>\n    </soap:Envelope>\n\nAnd compare this with the original response:\n\n    <soap:Envelope soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"     \n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n    xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" \n    xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <getRegistryResponse xmlns=\"http://www.biomart.org:80/MartServiceSoap\">\n             <mart>\n                <name xsi:type=\"xsd:string\">ensembl</name>\n                <displayName xsi:type=\"xsd:string\">ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database xsi:type=\"xsd:string\">ensembl_mart_57</database>\n                <host xsi:type=\"xsd:string\">www.biomart.org</host>\n                <path xsi:type=\"xsd:string\">/biomart/martservice</path>\n                <port xsi:type=\"xsd:string\">80</port>\n                <visible xsi:type=\"xsd:int\">1</visible>\n                <default xsi:type=\"xsd:int\">1</default>\n                <serverVirtualSchema xsi:type=\"xsd:string\">default</serverVirtualSchema>\n                <includeDatasets xsi:type=\"xsd:string\"/>\n                <martUser xsi:type=\"xsd:string\"/>\n                <redirect xsi:nil=\"true\" xsi:type=\"xsd:int\"/>\n             </mart>\n          </getRegistryResponse>\n       </soap:Body>\n    </soap:Envelope>\n\n\n  [1]: http://www.w3.org/2001/XMLSchema-instance\n\n", "date": "2010-03-21 21:00:25", "action": 0, "post": 384}}, {"pk": 497, "model": "server.postrevision", "fields": {"author": 157, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "Hi, \n\nI like this thread: begins as a troll, ends with nice advices\n\n  ---jmf", "date": "2010-03-22 08:21:22", "action": 0, "post": 385}}, {"pk": 498, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Anyone using \"Biomart + Java Web Services\" ?", "content": "Hi again,\n\nI was finally able to edit the received message such that it can be validated. The biomart reponse semed to screw up namespace definitions and they use [XML-schema instance][1]. :o)\n\nThe schema instance definitions had no obvious use and did not validate. So I just removed them. \n\nIf you look at that w3c site you see that W3C says this should never be used.\nSo compare the valid edited reponse massage with the real (but shortened) output.\nThe next step is to make the maintainers have their service send valid XML\n\nHere is the edited and schema-valid response, only the first mart given:\n\n\n    <soap:Envelope \n    soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" \n    \n    xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" \n    xmlns:tns=\"http://www.biomart.org:80/MartServiceSoap\"\n    xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <tns:getRegistryResponse>\n             <mart>\n                <name>ensembl</name>\n                <displayName>ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database>ensembl_mart_57</database>\n                <host>www.biomart.org</host>\n                <path>/biomart/martservice</path>\n                <port>80</port>\n                <visible>1</visible>\n                <default>1</default>\n                <serverVirtualSchema>default</serverVirtualSchema>\n                <includeDatasets/>\n                <martUser/>\n                <redirect>1</redirect>\n             </mart>\n           \n          </tns:getRegistryResponse>\n       </soap:Body>\n    </soap:Envelope>\n\nAnd compare this with the original response:\n\n    <soap:Envelope soap:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"     \n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n    xmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" \n    xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" \n    xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n       <soap:Body>\n          <getRegistryResponse xmlns=\"http://www.biomart.org:80/MartServiceSoap\">\n             <mart>\n                <name xsi:type=\"xsd:string\">ensembl</name>\n                <displayName xsi:type=\"xsd:string\">ENSEMBL GENES 57 (SANGER UK)</displayName>\n                <database xsi:type=\"xsd:string\">ensembl_mart_57</database>\n                <host xsi:type=\"xsd:string\">www.biomart.org</host>\n                <path xsi:type=\"xsd:string\">/biomart/martservice</path>\n                <port xsi:type=\"xsd:string\">80</port>\n                <visible xsi:type=\"xsd:int\">1</visible>\n                <default xsi:type=\"xsd:int\">1</default>\n                <serverVirtualSchema xsi:type=\"xsd:string\">default</serverVirtualSchema>\n                <includeDatasets xsi:type=\"xsd:string\"/>\n                <martUser xsi:type=\"xsd:string\"/>\n                <redirect xsi:nil=\"true\" xsi:type=\"xsd:int\"/>\n             </mart>\n          </getRegistryResponse>\n       </soap:Body>\n    </soap:Envelope>\n\n\n  [1]: http://www.w3.org/2001/XMLSchema-instance\n\n", "date": "2010-03-22 10:29:25", "action": 0, "post": 384}}, {"pk": 499, "model": "server.postrevision", "fields": {"author": 160, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "Hi !\nBriefly, I use R/Bioconductor, combined with PHP and MySQL. PHP can encapsulate programmes/scripts from other languages, such as Perl and Java, and can easly manage webapps by URL. Also nice for UI and run on Linux/MacOSX/Window$.\n", "date": "2010-03-22 10:30:55", "action": 0, "post": 386}}, {"pk": 500, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "microarray data methods", "title": "What are the most reliable normalization method for microarrays?", "content": "Hi people,\n\nI've just attended a seminar focused on microarray data, essentially given by experimentalists. It was somewhat shocking that they were unable to agree on what methods to use for data normalization (and why). So, you can imagine what happened in further steps . . .\n\nHence, I'm wondering about a list of the most reliable methods for data normalization. Not a plain list of methods. A list explaing why a given method is reliable (or why someone should use it). Who wants to contribute?", "date": "2010-03-22 11:34:06", "action": 0, "post": 387}}, {"pk": 501, "model": "server.postrevision", "fields": {"author": 159, "tag_string": "what bioinformatics", "title": "How do you explain what you do to the guy on the street or your mum?", "content": "Ok, I realise that some of you work on a genome campus or your mum may be a Nobel prize winner, but, given a socially average situation, how do you explain your work, and for a 50 point bonus, how do you feel as you do it?", "date": "2010-03-22 11:59:39", "action": 0, "post": 388}}, {"pk": 502, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How do you explain what you do to the guy on the street or your mum?", "content": "I tell them: \"there must [be a page on wikipedia][1] about it\".\n\n\n  [1]: http://en.wikipedia.org/wiki/Bioinformatics", "date": "2010-03-22 12:04:48", "action": 0, "post": 389}}, {"pk": 503, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: How do you explain what you do to the guy on the street or your mum?", "content": "I go to the streets and stop all the people I encounter, and I explain them what I do in my lab, so I accumulate a lot of experience and become better at explaining things :-)\n\nSeriously, if you want to be able to explain your project to other people, you have to be able to explain it to your workmates first.. so I prepare a seminar every once in a while and I try to be active at group meetings. In my first year of phd I was able to prepare a seminar every month (as a mean), I also went to python meetings etc..\n\nNon peer-review journals like The Scientist or Scientific American can give you good examples on how to translate a complex scientific experiment in a language that is easy to understand for everybody.\n\nAnother way to improve comes from the fact that I use a lot of A7 papers to take notes, so I constantly have to reduce my tasks to short phrases. However, it would take too long to explain this system better here..\n\nI think that in general, if you want to improve your communications skills, you have to practice a lot, there is no other way to do it. ", "date": "2010-03-22 12:20:32", "action": 0, "post": 390}}, {"pk": 504, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "torrent bioinformatics data", "title": "How do I import data from a torrent into a BioPerl, R, Bioclipse, or Taverna application?", "content": "While [BioTorrent][1] is still rather unpopulated, I quite like the idea of having such torrents seeded by university IT or library departments. Now, I want to analyze the data, so the question is, how can the data be used directly in my workflow system ([BioPerl][2] or [R][3] scripts, [Taverna][4] or [Bioclipse][5] workflows)?\n\nAre there libraries in a suitable programming language to download torrents automatically, without human interaction?\n\n  [1]: http://www.biotorrents.net/browse.php?page=1\n  [2]: http://www.bioperl.org/\n  [3]: http://www.r-project.org/\n  [4]: http://taverna.sf.net\n  [5]: http://bioclipse.net", "date": "2010-03-22 13:03:12", "action": 0, "post": 391}}, {"pk": 505, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: What are the most reliable normalization methods for microarrays?", "content": "I recommend that you visit PubMed, enter \"microarray (normalisation OR normalization) as a query, select some of the review articles and have a good read. Then, armed with appropriate keywords (RMA, GCRMA, MAS), head to Google and obtain some more opinions.\n\nIt is not so surprising that people cannot agree on methods. A normalisation method is just a statistical model that tries to explain what happens when probes meet gene chips. Different models have different assumptions. Some of these are: how to distinguish within-array effects from between-array effects?  Are mismatch probes ever useful?  (RMA says no, because MM probes often, in fact, match).  How is \"background\" distributed across a chip?\n\nExperiments also vary. Which of your experiments are comparable? Should you even be comparing, say, samples prepared last week and frozen to samples freshly-prepared today? If you do want to compare, you can only hope that each set will show some characteristic (batch effect) for which you can correct. \n\nHow do you conclude that a method is \"right\", or \"better\"?  You might try to validate using another experimental method, such as real-time PCR. Or you might conduct \"spike-in\" experiments, where you know what the \"true positives\" should be, then see how well each method picks them out.  That's the approach taken in [this paper][1].  Or, you might try several methods on your own favourite dataset. Of course, someone else will then try them on their favourite dataset - and reach totally opposite conclusions!  Or you might just ask \"what do most people do?\"\n\nThat's the long answer. The short answer: RMA ;-)\n\n  [1]: http://nar.oxfordjournals.org/cgi/content/full/31/4/e15", "date": "2010-03-22 13:18:01", "action": 0, "post": 392}}, {"pk": 506, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: What are the most reliable normalization methods for microarrays?", "content": "The lack of reproducibility in microarray methods is well known problem. In my opinion the reasons for this go way beyond the choice of normalization and are primarily caused by biological and experimental variability. Some are convinced that one method must be substantially better than the other, but I suspect that is because that particular method worked well for them under some specific circumstances. \n\nI read studies that demonstrated that the upper 50% percent (the strongest signals) were recovered identically across just about all methodologies, whereas the bottom half contained a different subset for each method. So maybe the best strategy is to be more strict with the results, beyond what the original estimate of the significance is - of course it could be that this approach removes the genes of interest.\n\n\nThat's the long answer. The short answer: the best normalization is the one you understand the best. \n\n;-)\n", "date": "2010-03-22 13:19:59", "action": 0, "post": 393}}, {"pk": 507, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: How do I import data from a torrent into a BioPerl, R, Bioclipse, or Taverna application?", "content": "I don't think there is an R library for torrents. I have tried searching [here][1] and on [CRAN][2], but there is nothing.\n\nPerl, on the other side, has [many libraries][3] for downloading torrents. Python [supports torrents][4] as well.\n\nOnce you have chosen a library, just write a script to download the torrent and to give a return signal when it is finished. \n\nHowever, I would object on the reproducibility of using data downloaded with a torrent: what would you do if the torrent disappears or is modified after you have used it? How do you take into account the version of the data?\nMoreover, consider that scientific databases have to release their data often, and every release would require a different torrent to be seed. That would make it more difficult to control and keep.\n\n\n\n  [1]: http://www.rseek.org/?cx=010923144343702598753%3Aboaz1reyxd4&q=torrent&sa=Search+functions%2C+lists%2C+and+more&cof=FORID%3A11&siteurl=www.rseek.org%2F%3Fq%3Dtorrent#467\n  [2]: http://cran.r-project.org/\n  [3]: http://search.cpan.org/search?query=torrent&mode=all\n  [4]: http://pypi.python.org/pypi?%3Aaction=search&term=torrent&submit=search", "date": "2010-03-22 13:45:56", "action": 0, "post": 394}}, {"pk": 508, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: How do you explain what you do to the guy on the street or your mum?", "content": "I totally think that science communication should be a required course in every PhD program, and that you should have to practice these explanations until you can do them in your sleep. Scientists are their own best advocates, and we need to start acting like it. \n\nYou need to be able to explain your work at several different depths. It's just as important to accurately gauge the interest and experience of your audience, so you can choose the appropriate spiel. That's the really tricky part.  Some of the tools you need are:\n\nFor non-scientists:\n\n- The layperson's 15-second elevator pitch: For the cocktail party or the new acquaintance who asks what you do. They should walk away understanding that you do science and that your work is trying to make the world a better place. (\"better cancer treatments\", \"new malaria drugs\")\n\n- The follow-up 2-minute overview if they ask for more details  Still very high level, abstract, focused on where you're trying to get with your research. (\"understanding XYZ part of disease ABC by looking at things through a microscope\", \"figuring out how the brain stores memories by sticking people in cool scanners\")\n\n- The full explanation. For the non-scientists who really want to wrap their head around what you do. Keep in mind that these people may not have taken a science course since high school.  Avoid jargon and acronyms, and make sure that at the end, you leave them with the big picture idea of what you're trying to accomplish and how that will advance humanity.\n\nFor scientists:\n\n- The scientists's elevator pitch. For people who you'll meet around your campus or at conferences. You may even need two or three of these, for use in different venues.  (At a focused conference, you'll be more specific and jargon-ythan at a departmental retreat)\n\n- The two-minute casual conversation.  This one is tricky, because you need to read the person you're talking to in a very short time.  Do they know what RMA is? What about ERBB2? What's their background, and how can I look at my problem from their angle, so as to best couch my answer in terms they'll understand?\n\n- The 5, 15, and 30 minute presentations, often with slides or a poster. You should get drilled in these during your graduate school career, and if you didn't, there's no time like the present to start practicing.\n\n", "date": "2010-03-22 14:28:56", "action": 0, "post": 395}}, {"pk": 509, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "microarray data methods", "title": "What are the most reliable normalization methods for microarrays?", "content": "Hi people,\n\nI've just attended a seminar focused on microarray data, essentially given by experimentalists. It was somewhat shocking that they were unable to agree on what methods to use for data normalization (and why). So, you can imagine what happened in further steps . . .\n\nHence, I'm wondering about a list of the most reliable methods for data normalization. Not a plain list of methods. A list explaing why a given method is reliable (or why someone should use it). Who wants to contribute?", "date": "2010-03-22 14:45:10", "action": 0, "post": 387}}, {"pk": 510, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "", "title": "A: What tools/libraries do you use to visualize genomic feature data?", "content": "thanks for all the replies so far. i just want to add a couple i've found:\nAnnoj with a nice demo here: http://neomorph.salk.edu/epigenome/epigenome.html\nseems to be a pretty nice web-interface and i've been able to get my own annotations drawn. it may be an abandoned project, and i wasn't able to find the javascript source (only the packed/minified version).\n\nalso [genometools][1] wraps cairo to allow simple drawing of regions: here's the image from their home page. ![alt text][2] And they have bindings to a variety of scripting languages.\n\n  [1]: http://genometools.org\n  [2]: http://genometools.org/images/annotation.png", "date": "2010-03-22 15:16:13", "action": 0, "post": 396}}, {"pk": 511, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: How do you explain what you do to the guy on the street or your mum?", "content": "My opening line: \"I work at the intersection between computers and biology\". \n\nOften there is no need to say anything more. If the person looks for more detailed answer I talk about assembling a whole book from a huge pile of randomly torn out sentences (DNA assembly). \n\nThen one can go with finding \"interesting paragraphs\", \"repeated, mostly boring parts\", etc. Works for non-scientist (at least that\u015b my impression...).\n\nIn short: if possible, find analogy everyone can somehow relate to. \nYou get minus points for anything sounding too technical.  \n \n  \n ", "date": "2010-03-22 15:43:48", "action": 0, "post": 397}}, {"pk": 512, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "job career general", "title": "What different bioinformatics positions mean?", "content": "I went to several sites to look for a new position (thanks to recent [question][1]). With not much experience in bioinformatics market I'm confused with a lot of different positions. Some positions I understand but not everything. Some looks like just called differently for companies, academy or government. I tried to put here all I could find. Can somebody approximately sort them let's say by salary or level of responsibility? Which positions requires Ph.D. degree? Any systematic description would be very useful.\n\n - Bioinformatics Internship\n - Bioinformatics Postdoc \n - Bioinformatics Analyst (I, II, III) \n - Senior Bioinformatics Analyst \n - Bioinformatics Analyst Programmer (I, II, III)\n - Bioinformatics Developer Senior\n - Bioinformatics Developer\n - Bioinformatician (I, II, III)\n - Bioinformatics Expert \n - Bioinformatics Systems Administrator \n - Bioinformatics Research Fellow \n - Bioinformatics Research Assistant \n - Bioinformatics Research Associate \n - Bioinformatics Scientist (Researcher) \n - Bioinformatics Senior (Staff) Scientist\n - Bioinformatics Project Manager\n - Director (Head) of Bioinformatics\n\n  [1]: http://biostar.stackexchange.com/questions/296/where-to-advertise-or-find-bioinformatics-jobs", "date": "2010-03-22 15:48:32", "action": 0, "post": 398}}, {"pk": 513, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "sequence alignment scoringmatrix", "title": "Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "content": "Hi,\n\nI am trying to implement protein pairwise sequence alignment using \"Global Alignment\" algorithm by 'Needleman -Wunsch'. I am using VB.NET. \n\nI am not clear about how to include 'Blosum62 Matrix' in my source code to do the scoring or to fill the two-dimensional matrix?\n\nI have googled and found that most people suggested to use flat file which contains the standard 'Blosum62 Matrix'. Does it mean that I need to read from this flat file and fill my coded \"Blosum62 Martrix' ?\n\nAlso, the other approach could be is to use some mathematical formula and include it in your programming logic to construct 'Blosum62 Matrix'. But not very sure about this option.\n\nAny ideas or insights are appreciated.\n\nAlso, is there any pesudo algorithm to do the protein pairwise alignment using Global available? I tired to find the basic steps of the alogrithm online but no luck so I am planning to do the same steps as I did for the global pairwise alignment of Nucleotides\n\nThanks.\n", "date": "2010-03-22 16:12:52", "action": 0, "post": 161}}, {"pk": 514, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: How do you explain what you do to the guy on the street or your mum?", "content": "I use these simple facts : I work on data from human genome project, and explain that its one of the biggest scientific achievement ever. I use that data to analyze proteins involved in X diseases. We are trying to understand these proteins and its various aspects related to disease using computer programs, database, software etc. I will clarify that I won't do any wet lab experiments, instead I use computers for the experiments and we call it as dry lab. This used to work for me most of the time. \n", "date": "2010-03-22 16:48:47", "action": 0, "post": 399}}, {"pk": 515, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: How do you explain what you do to the guy on the street or your mum?", "content": "My opening line: \"I work at the intersection between computers and biology\". \n\nOften there is no need to say anything more. If the person looks for more detailed answer I talk about assembling a whole book from a huge pile of randomly torn out sentences (DNA assembly). \n\nThen one can go with finding \"interesting paragraphs\", \"repeated, mostly boring parts\", etc. Works for non-scientist (at least that my impression...).\n\nIn short: if possible, find analogy everyone can somehow relate to. \nYou get minus points for anything sounding too technical.  \n \n  \n ", "date": "2010-03-22 16:49:23", "action": 0, "post": 397}}, {"pk": 516, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: What do different bioinformatics positions mean?", "content": "I think most of positions will have a brief, yet concise description that will explain the necessary qualification required for a particular position. I think the requirement depends on the nature of positions and there is no specific /systematic rule applies for different category of positions. ", "date": "2010-03-22 17:01:04", "action": 0, "post": 400}}, {"pk": 517, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "what bioinformatics not related", "title": "How do you explain what you do to the guy on the street or your mum?", "content": "Ok, I realise that some of you work on a genome campus or your mum may be a Nobel prize winner, but, given a socially average situation, how do you explain your work, and for a 50 point bonus, how do you feel as you do it?", "date": "2010-03-22 17:25:16", "action": 0, "post": 388}}, {"pk": 518, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: How do you explain what you do to the guy on the street or your mum?", "content": "I totally think that science communication should be a required course in every PhD program, and that you should have to practice these explanations until you can do them in your sleep. Scientists are their own best advocates, and we need to start acting like it. \n\nYou need to be able to explain your work at several different depths. It's just as important to accurately gauge the interest and experience of your audience, so you can choose the appropriate spiel. That's the really tricky part.  Some of the tools you need are:\n\nFor non-scientists:\n\n- The layperson's 15-second elevator pitch: For the cocktail party or the new acquaintance who asks what you do. They should walk away understanding that you do science and that your work is trying to make the world a better place. (\"better cancer treatments\", \"new malaria drugs\")\n\n- The follow-up 2-minute overview if they ask for more details  Still very high level, abstract, focused on where you're trying to get with your research. (\"understanding XYZ part of disease ABC by looking at things through a microscope\", \"figuring out how the brain stores memories by sticking people in cool scanners\")\n\n- The full explanation. For the non-scientists who really want to wrap their head around what you do. Keep in mind that these people may not have taken a science course since high school.  Avoid jargon and acronyms, and make sure that at the end, you leave them with the big picture idea of what you're trying to accomplish and how that will advance humanity.\n\nFor scientists:\n\n- The scientists's elevator pitch. For people who you'll meet around your campus or at conferences. You may even need two or three of these, for use in different venues.  (At a focused conference, you'll be more specific and jargon-ythan at a departmental retreat)\n\n- The two-minute casual conversation.  This one is tricky, because you need to read the person you're talking to in a very short time.  Do they know what RMA is? What about ERBB2? What's their background, and how can I look at my problem from their angle, so as to best couch my answer in terms they'll understand?\n\n- The 5, 15, and 30 minute presentations, often with slides or a poster. You should get drilled in these during your graduate school career, and if you didn't, there's no time like the present to start practicing.\n\n\nOnce you get these down, practice the final element, which is being enthusiastic about your work. After all, you probably think that what you\u2019re researching is one of the coolest and most important things ever. If that comes across to your audience, they\u2019ll be engaged and interested too.\n\n", "date": "2010-03-22 17:27:40", "action": 0, "post": 395}}, {"pk": 519, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "content": "sorry, I'm only speaking 'java' here.\n\nI would create an interface ScoreMatrix:\n\n    public interface ScoreMatrix\n         {\n         public int getScore(char aa1,char aa2);\n         }\n\nthat would be used by your AlignmentTool\n\n    public interface AlignmentTool\n         {\n         public void setScoreMatrix(ScoreMatrix m);\n         public ScoreMatrix getScoreMatrix();\n         public void align(String seq1,String seq);\n         (...)\n         }\n\nand Blosum62 would be an implementation of ScoreMatrix\n\n    public class Blosum62 implements ScoreMatrix\n        {\n        public int getScore(char aa1,char aa2) \n            {\n            switch(upper(aa1))\n              {\n              (...)\n               {\n               case 'A' :\n               switch(upper(aa2))\n                 {\n                 (...)\n                 case 'A': return 98;\n                 (...)\n                 }\n              }\n            }\n        }\n\n\n", "date": "2010-03-22 17:34:19", "action": 0, "post": 401}}, {"pk": 520, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "job career general not related", "title": "What different bioinformatics positions mean?", "content": "I went to several sites to look for a new position (thanks to recent [question][1]). With not much experience in bioinformatics market I'm confused with a lot of different positions. Some positions I understand but not everything. Some looks like just called differently for companies, academy or government. I tried to put here all I could find. Can somebody approximately sort them let's say by salary or level of responsibility? Which positions requires Ph.D. degree? Any systematic description would be very useful.\n\n - Bioinformatics Internship\n - Bioinformatics Postdoc \n - Bioinformatics Analyst (I, II, III) \n - Senior Bioinformatics Analyst \n - Bioinformatics Analyst Programmer (I, II, III)\n - Bioinformatics Developer Senior\n - Bioinformatics Developer\n - Bioinformatician (I, II, III)\n - Bioinformatics Expert \n - Bioinformatics Systems Administrator \n - Bioinformatics Research Fellow \n - Bioinformatics Research Assistant \n - Bioinformatics Research Associate \n - Bioinformatics Scientist (Researcher) \n - Bioinformatics Senior (Staff) Scientist\n - Bioinformatics Project Manager\n - Director (Head) of Bioinformatics\n\n  [1]: http://biostar.stackexchange.com/questions/296/where-to-advertise-or-find-bioinformatics-jobs", "date": "2010-03-22 17:35:20", "action": 0, "post": 398}}, {"pk": 521, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "protein sequence multiplealignment scoringmatrix", "title": "Score protein variants based on frequency of AA in multiple sequence alignment", "content": "For reference, please read this excerpt from  \n**Human non-synonymous SNPs: server and survey**  \nVasily Ramensky, Peer Bork, and Shamil Sunyaev\n\n\n> *Profile analysis of homologous\n> sequences*. The amino acid replacement\n> may be incompatible with the spectrum\n> of substitutions observed at that\n> position in a family of homologous\n> proteins. PolyPhen identifies\n> homologues of the input sequences via\n> a BLAST (23) search of the NRDB\n> database. The set of aligned sequences\n> with sequence identity to the input\n> sequence in the range 30\u00b194%\n> (inclusive) is used by the new version\n> of the PSIC (position-specific\n> independent counts) software (24) to\n> calculate the so-called profile matrix\n> (http://strand.imb.ac.ru/PSIC/).\n> Elements of the matrix (pro- file\n> scores) are logarithmic ratios of the\n> likelihood of a given amino acid\n> occurring at a particular site to the\n> likelihood of this amino acid\n> occurring at any site (background\n> frequency). PolyPhen computes the\n> absolute value of the difference\n> between profile scores of both allelic\n> variants in the polymorphic position.\n> PolyPhen also shows the number of\n> aligned sequences at the query\n> position; this may be used to assess\n> the reliability of profile score\n> calculations.\n\nI'd like to calculate something similar (score variants based on frequency that AA in aligned sequences) to what's mentioned here **programmatically**, but I can't find any implementation of the above described system.\n\nDoes anyone know of a working implementation of this or something similar, that's available either in code or as a web service?\n\nOr should it is easy enough to implement something like this ourselves?", "date": "2010-03-22 17:35:22", "action": 0, "post": 183}}, {"pk": 522, "model": "server.postrevision", "fields": {"author": 163, "tag_string": "phylogeny software visualization", "title": "What phylogeny viewing software do you use?", "content": "There are numerous phylogeny viewing programs available, which ones do people use most often? Are there features (e.g., visualisations, data formats, size of tree that can be displayed, annotation) that people feel existing software lack?\n\nI'll declare an interest. I'm the author of http://taxonomy.zoology.gla.ac.uk/rod/treeview.html, which is beginning to show its age. There are some other great tools around, so I'm trying to gauge whether TreeView should be allowed to die gracefully, of whether I should invest time in developing it further (see http://darwin.zoology.gla.ac.uk/~rpage/treeviewx/ ).", "date": "2010-03-22 18:00:18", "action": 0, "post": 402}}, {"pk": 523, "model": "server.postrevision", "fields": {"author": 127, "tag_string": "literature bioinformatics python", "title": "How difficult/reliable is it to programmatically (python) look up and download papers?", "content": "I know that it is possible to write a script that attempts to use the ezproxy that most universities use to download papers directly using some search query. I have seen a perl implementation of this but was looking for something a bit cleaner and hopefully in python.\n\nI don't mind having the script only be able to work within a university network, but it would have to be able to check if the paper is accessible via the current IP or such. Not sure how feasible this is, thus my question...", "date": "2010-03-22 18:01:27", "action": 0, "post": 403}}, {"pk": 524, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How difficult/reliable is it to programmatically (python) look up and download papers?", "content": "Sorry Ricardo, not python but the following codes contain some snippets that might be useful to find  the PDF from a doi/pmid...\n\n - http://code.google.com/p/pdfetch/\n - http://bio-geeks.com/?p=749\n\nAnd my version using java...\n\n - http://plindenbaum.blogspot.com/2009/11/my-pdfs-anywhere.html\n", "date": "2010-03-22 18:11:29", "action": 0, "post": 404}}, {"pk": 525, "model": "server.postrevision", "fields": {"author": 85, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "oddly enough, craigslist has been successful for us in the past...", "date": "2010-03-22 18:14:50", "action": 0, "post": 405}}, {"pk": 526, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: How difficult/reliable is it to programmatically (python) look up and download papers?", "content": "Have you tried this [py-ezproxy][1]?\n\nThe script that you have seen in perl may have been written with the Mechanize library. In case, you can look at [Mechanize][2] in python, which is the reimplementation in python of the same concept. Anyway, you can use mechanize to connect to the internet using a proxy and do waht you are asking for.\n\n\n  [1]: http://bitbucket.org/dgc/py-ezproxy/overview/\n  [2]: http://pypi.python.org/pypi/mechanize/0.1.11", "date": "2010-03-22 18:15:19", "action": 0, "post": 406}}, {"pk": 527, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: What phylogeny viewing software do you use?", "content": "I am not too much into this, but I have used: [jalview][1], [seaview][2], [mega][3] (on linux throught wine).\n\nAll of these are not specifically developed for visualizing trees, however they have the ability to do so and for my needs it is enough.\n\n\n  [1]: http://www.jalview.org/examples/examples4.html\n  [2]: http://pbil.univ-lyon1.fr/binaries/seaview-tree.png\n  [3]: http://www.megasoftware.net/overview.html", "date": "2010-03-22 18:34:52", "action": 0, "post": 407}}, {"pk": 528, "model": "server.postrevision", "fields": {"author": 115, "tag_string": "", "title": "A: What do different bioinformatics positions mean?", "content": "In general, positions labeled as \"analyst\" will be applying tools other people have created. Positions labeled as \"developer\" will be writing new tools. However, you shouldn't count on that, as sometimes job titles are written by people with no idea about bioinformatics. I'd expect the Bioinformatics Systems Administrator to be responsible for keeping the tools and the computers the tools run on up and running.\n\nResearch assistants and associates are usually BS/MS level jobs. Scientist jobs usually require a PhD. But neither of these rules is absolute.\n\nA project manager is responsible for putting together the project schedule and keeping the project on track. Whether a PhD is required or not is quite variable, and will usually correlate with whether the project manager is also expected to be the technical lead on the project.\n\nThe Director/Head of Bioinformatics is a management job. In a larger company, this person probably has almost no time for direct involvement in projects. In a smaller company, he/she is probably still hands on at least some of the time.\n\nSalaries are all over the place. About all I'd hazard to guess there is that the Director is making the most money, but even that is not a sure bet.", "date": "2010-03-22 18:43:31", "action": 0, "post": 408}}, {"pk": 529, "model": "server.postrevision", "fields": {"author": 118, "tag_string": "", "title": "A: What phylogeny viewing software do you use?", "content": "I usually do use [TreeView][1]. While it may not be particularly new, I think it's stood the test of time well.\n\n\n  [1]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html", "date": "2010-03-22 18:47:42", "action": 0, "post": 409}}, {"pk": 530, "model": "server.postrevision", "fields": {"author": 118, "tag_string": "", "title": "A: What phylogeny viewing software do you use?", "content": "I usually do use [TreeView][1]. While it may not be particularly new, I think it's stood the test of time well. I've also used [Mesquite][2] and some other tools, but I always find myself coming back to TreeView per default. \n\nAmong my colleagues, many also use TreeView, so I am sure that if you did put in the effort to update/enhance TreeView, there'd be many who would greatly appreciate it.\n\nLast, but not least: THANK YOU for having produced this gem!\n\n\n  [1]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html\n  [2]: http://mesquiteproject.org/mesquite/mesquite.html", "date": "2010-03-22 18:54:20", "action": 0, "post": 409}}, {"pk": 531, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: What phylogeny viewing software do you use?", "content": "Try : [Phyfi][1] for quick trees or [iTOL][2] if you need that super cool phylogeny tree figure for your next publication. I have used [TreeView][3] and [MEGA][4] earlier. You may take a look at the list of The Phylogeny Tree Drawing / Plotting program from Phylip [page][5]. \n\n\n  [1]: http://cgi-www.daimi.au.dk/cgi-chili/phyfi/go\n  [2]: http://itol.embl.de/\n  [3]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html\n  [4]: http://www.megasoftware.net/\n  [5]: http://evolution.genetics.washington.edu/phylip/software.html#Plotting", "date": "2010-03-22 19:21:19", "action": 0, "post": 410}}, {"pk": 532, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: What phylogeny viewing software do you use?", "content": "Tried Phyfi][1] for quick trees or [iTOL][2] if you need that super cool phylogeny tree figure for your next publication. I have used [TreeView][3] and [MEGA][4] earlier. You may take a look at the list of The Phylogeny Tree Drawing / Plotting program from Phylip [page][5]. \n\n\n  [1]: http://cgi-www.daimi.au.dk/cgi-chili/phyfi/go\n  [2]: http://itol.embl.de/\n  [3]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html\n  [4]: http://www.megasoftware.net/\n  [5]: http://evolution.genetics.washington.edu/phylip/software.html#Plotting", "date": "2010-03-22 19:35:11", "action": 0, "post": 410}}, {"pk": 533, "model": "server.postrevision", "fields": {"author": 52, "tag_string": "", "title": "A: What phylogeny viewing software do you use?", "content": "I like [FigTree][1] because it allows me to play with the tree a little bit to mark-up the regions I'm interested in, unfortunately it's Mac OSX only though. [Scriptree][2] also seems quite good.\n\nWith the availability of larger sequencing data sets I'd like to see tree viewers be able to help distill a phylogenetic tree down to the points of interest. I'd like to be able to use colours and branch grouping to highlight to the reader what I think is relevent.\n\n[1]: http://tree.bio.ed.ac.uk/software/figtree/\n[2]: http://atgc.lirmm.fr/scriptree/\n", "date": "2010-03-22 19:48:02", "action": 0, "post": 411}}, {"pk": 534, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "", "title": "A: What phylogeny viewing software do you use?", "content": "I normally use FigTree for a quick and flexible look on phylogenetic data. For small datasets, PHYLIP DRAWTREE or TreeView are enough. But, for printing I really look for some adequate LaTeX package, commonly PSTricks. It's cumbersome but it works and is beautifull, fully customizable. For large trees, some scripting is necessary. But, now there is [E.T.E.][1] which is quite handy.\n\nI'm happy to see Rod Page in this forum. Your books on phylogenetics and molecular evolution are part of my everyday life. I do appreciate the effort !!!\n\n\n  [1]: http://ete.cgenomics.org/", "date": "2010-03-22 20:10:13", "action": 0, "post": 412}}, {"pk": 535, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "snp data human annotation", "title": "How to map a SNP to a gene around +/- 60KB ? ", "content": "I am looking at a bunch of SNPs. Some of them are part of genes, but other are not. I am interested to look up +60KB or -60KB of those SNPs to get details about some nearby genes. Please share your experience in dealing with such a situation or thoughts on any methods that can do this. Thanks in advance. ", "date": "2010-03-22 20:42:28", "action": 0, "post": 413}}, {"pk": 536, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Drawing chromosome ideogams with data", "content": "The [GenomeGraphs package in Bioconductor][1] allows to draw (human) chromosome ideograms with R. The package can be used to depict genome tracks of coverage, microarray measurements and genes together with the ideograms. \nSee the [user guide][2] for an overview of different types of graphics. For the ideogram, the example looks like this (from the [GenomeGraphs paper][3]):\n\n![Example][4]\n\n![alt text][5]\n\nHere is the code that makes something like this (from the user guide):\n\n    library(GenomeGraphs)\n    library(biomaRt)\n    data(\"exampleData\", package = \"GenomeGraphs\")\n    mart <- useMart(\"ensembl\", dataset = \"hsapiens_gene_ensembl\")\n    minbase <- 180292097\n    maxbase <- 180492096\n    genesplus <- makeGeneRegion(start = minbase,\n                                end = maxbase, strand = \"+\", chromosome = \"3\",\n                                biomart = mart)\n    genesmin <- makeGeneRegion(start = minbase,\n                               end = maxbase, strand = \"-\", chromosome = \"3\",\n                               biomart = mart)\n    seg <- makeSegmentation(segStart, segEnd,\n                            segments, dp = DisplayPars(color = \"black\",\n                                        lwd = 2, lty = \"solid\"))\n    cop <- makeGenericArray(intensity = cn,\n                            probeStart = probestart, segmentation = seg,\n                            dp = DisplayPars(size = 3, color = \"seagreen\",\n                              type = \"dot\"))\n    ideog <- makeIdeogram(chromosome = 3)\n    expres <- makeGenericArray(intensity = intensity,\n                               probeStart = exonProbePos,\n                               dp = DisplayPars(color = \"darkred\",\n                                 type = \"point\"))\n    genomeAxis <- makeGenomeAxis(add53 = TRUE,\n                                 add35 = TRUE)\n    gdPlot(list(a = ideog, b = expres, c = cop,\n                d = genesplus, e = genomeAxis, f = genesmin),\n           minBase = minbase, maxBase = maxbase,\n           labelCex = 2)\n\n\n  [1]: http://bioconductor.org/packages/2.5/bioc/html/GenomeGraphs.html\n  [2]: http://bioconductor.org/packages/2.5/bioc/vignettes/GenomeGraphs/inst/doc/GenomeGraphs.pdf\n  [3]: http://www.biomedcentral.com/1471-2105/10/2/abstract/\n  [4]: http://www.biomedcentral.com/1471-2105/10/2/figure/F1\n  [5]: http://www.biomedcentral.com/content/download/figures/1471-2105-10-2-1.PDF", "date": "2010-03-22 20:53:49", "action": 0, "post": 414}}, {"pk": 537, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "Good to have a strong background in general programming concepts. Choice of languags depends on the nature of your projects. In general a mixed bag of programming skills in domains like scripting (take your pick : Perl, Python, Ruby), Web(Lot of JScript, CSS, Perl / PHP), Databases (MySQL, PgSQL), statistics(Mostly R / Matlab) with c / C++ / Java will be an excellent combination. \n\n", "date": "2010-03-22 20:53:55", "action": 0, "post": 415}}, {"pk": 538, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Drawing chromosome ideogams with data", "content": "The [GenomeGraphs package in Bioconductor][1] allows to draw (human) chromosome ideograms with R. The package can be used to depict genome tracks of coverage, microarray measurements and genes together with the ideograms. \nSee the [user guide][2] for an overview of different types of graphics. For the ideogram, the example looks like this (from the [GenomeGraphs paper][3]): [Example][4]\n\n\nHere is the code that makes something like this (from the user guide):\n\n    library(GenomeGraphs)\n    library(biomaRt)\n    data(\"exampleData\", package = \"GenomeGraphs\")\n    mart <- useMart(\"ensembl\", dataset = \"hsapiens_gene_ensembl\")\n    minbase <- 180292097\n    maxbase <- 180492096\n    genesplus <- makeGeneRegion(start = minbase,\n                                end = maxbase, strand = \"+\", chromosome = \"3\",\n                                biomart = mart)\n    genesmin <- makeGeneRegion(start = minbase,\n                               end = maxbase, strand = \"-\", chromosome = \"3\",\n                               biomart = mart)\n    seg <- makeSegmentation(segStart, segEnd,\n                            segments, dp = DisplayPars(color = \"black\",\n                                        lwd = 2, lty = \"solid\"))\n    cop <- makeGenericArray(intensity = cn,\n                            probeStart = probestart, segmentation = seg,\n                            dp = DisplayPars(size = 3, color = \"seagreen\",\n                              type = \"dot\"))\n    ideog <- makeIdeogram(chromosome = 3)\n    expres <- makeGenericArray(intensity = intensity,\n                               probeStart = exonProbePos,\n                               dp = DisplayPars(color = \"darkred\",\n                                 type = \"point\"))\n    genomeAxis <- makeGenomeAxis(add53 = TRUE,\n                                 add35 = TRUE)\n    gdPlot(list(a = ideog, b = expres, c = cop,\n                d = genesplus, e = genomeAxis, f = genesmin),\n           minBase = minbase, maxBase = maxbase,\n           labelCex = 2)\n\n\n  [1]: http://bioconductor.org/packages/2.5/bioc/html/GenomeGraphs.html\n  [2]: http://bioconductor.org/packages/2.5/bioc/vignettes/GenomeGraphs/inst/doc/GenomeGraphs.pdf\n  [3]: http://www.biomedcentral.com/1471-2105/10/2/abstract/\n  [4]: http://www.biomedcentral.com/1471-2105/10/2/figure/F1\n  [5]: http://www.biomedcentral.com/content/download/figures/1471-2105-10-2-1.PDF", "date": "2010-03-22 20:59:12", "action": 0, "post": 414}}, {"pk": 539, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "", "title": "A: How to map a SNP to a gene around +/- 60KB ? ", "content": "I downloaded refFlat table from UCSC Genome Browser, which contains gene symbols and their genomic locations. Then mapped SNPs to genes. I did it in MATLAB, but can be done with any language.", "date": "2010-03-22 21:00:53", "action": 0, "post": 416}}, {"pk": 540, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Drawing chromosome ideogams with data", "content": "The [GenomeGraphs package in Bioconductor][1] allows to draw (human) chromosome ideograms with R. The package can be used to depict genome tracks of coverage, microarray measurements and genes together with the ideograms. \nSee the [user guide][2] for an overview of different types of graphics. For the ideogram, the example looks like this (also in the [GenomeGraphs paper][3]): \n\n![Example][4]\n\n\nHere is the code that makes something like this (from the user guide):\n\n    library(GenomeGraphs)\n    library(biomaRt)\n    data(\"exampleData\", package = \"GenomeGraphs\")\n    mart <- useMart(\"ensembl\", dataset = \"hsapiens_gene_ensembl\")\n    minbase <- 180292097\n    maxbase <- 180492096\n    genesplus <- makeGeneRegion(start = minbase,\n                                end = maxbase, strand = \"+\", chromosome = \"3\",\n                                biomart = mart)\n    genesmin <- makeGeneRegion(start = minbase,\n                               end = maxbase, strand = \"-\", chromosome = \"3\",\n                               biomart = mart)\n    seg <- makeSegmentation(segStart, segEnd,\n                            segments, dp = DisplayPars(color = \"black\",\n                                        lwd = 2, lty = \"solid\"))\n    cop <- makeGenericArray(intensity = cn,\n                            probeStart = probestart, segmentation = seg,\n                            dp = DisplayPars(size = 3, color = \"seagreen\",\n                              type = \"dot\"))\n    ideog <- makeIdeogram(chromosome = 3)\n    expres <- makeGenericArray(intensity = intensity,\n                               probeStart = exonProbePos,\n                               dp = DisplayPars(color = \"darkred\",\n                                 type = \"point\"))\n    genomeAxis <- makeGenomeAxis(add53 = TRUE,\n                                 add35 = TRUE)\n    gdPlot(list(a = ideog, b = expres, c = cop,\n                d = genesplus, e = genomeAxis, f = genesmin),\n           minBase = minbase, maxBase = maxbase,\n           labelCex = 2)\n\n\n  [1]: http://bioconductor.org/packages/2.5/bioc/html/GenomeGraphs.html\n  [2]: http://bioconductor.org/packages/2.5/bioc/vignettes/GenomeGraphs/inst/doc/GenomeGraphs.pdf\n  [3]: http://www.biomedcentral.com/1471-2105/10/2/abstract/\n  [4]: http://www.bccs.uni.no/~mdo041/rplots/ideog.png\n  [5]: http://www.biomedcentral.com/content/download/figures/1471-2105-10-2-1.PDF", "date": "2010-03-22 21:10:36", "action": 0, "post": 414}}, {"pk": 541, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "", "title": "A: How to map a SNP to a gene around +/- 60KB ? ", "content": "I downloaded refFlat table from UCSC Genome Browser, which contains gene symbols and their genomic locations. Then mapped SNPs to genes. I did it in MATLAB, but can be done with any language.\n\nYou can also try a Perl script [here][1].\n\n\n  [1]: http://www.medicine.tcd.ie/neuropsychiatric-genetics/bioinformatics-biostatistics/software/", "date": "2010-03-22 21:13:50", "action": 0, "post": 416}}, {"pk": 542, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "", "title": "A: How to map a SNP to a gene around +/- 60KB ? ", "content": "I downloaded refFlat table from UCSC Genome Browser, which contains gene symbols and their genomic locations. Then mapped SNPs to genes. I did it in MATLAB, but can be done with any language.\n\nYou can also try a Perl script from [here][1].\n\n\n  [1]: http://www.medicine.tcd.ie/neuropsychiatric-genetics/bioinformatics-biostatistics/software/", "date": "2010-03-22 21:21:41", "action": 0, "post": 416}}, {"pk": 543, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: What phylogeny viewing software do you use?", "content": "Tried Phyfi][1] for quick trees or [iTOL][2] whenever I need that super cool phylogeny tree figure for a publication. I have used [TreeView][3] and [MEGA][4] earlier. Tried couple of programs from the list of The Phylogeny Tree Drawing / Plotting program from Phylip [page][5]. \n\n\n  [1]: http://cgi-www.daimi.au.dk/cgi-chili/phyfi/go\n  [2]: http://itol.embl.de/\n  [3]: http://taxonomy.zoology.gla.ac.uk/rod/treeview.html\n  [4]: http://www.megasoftware.net/\n  [5]: http://evolution.genetics.washington.edu/phylip/software.html#Plotting", "date": "2010-03-22 21:23:53", "action": 0, "post": 410}}, {"pk": 544, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: How to map a SNP to a gene around +/- 60KB ? ", "content": "No need to program this. This can be done as a BioMart query in MartView:\n\n[rs8 with 60000 bases up/donw-flanks][1]\n\nI just checked it works with that size flanks. The result is a FASTA file. \n\nOn the other hand, if you have a SNP position it could be easier to simply search for the genes directly in the genome annotation. Get a genome annotation as a tab separated file from e.g. BioMart and search for the genes with start/stop positons within this range.\n\n\n\n  [1]: http://www.biomart.org/biomart/martview?VIRTUALSCHEMANAME=default&ATTRIBUTES=hsapiens_snp.default.sequences.chr_name|hsapiens_snp.default.sequences.chrom_start|hsapiens_snp.default.sequences.refsnp_id|hsapiens_snp.default.sequences.allele|hsapiens_snp.default.sequences.snp|hsapiens_snp.default.sequences.downstream_flank.\"60000\"|hsapiens_snp.default.sequences.upstream_flank.\"60000\"&FILTERS=hsapiens_snp.default.filters.refsnp.\"rs8\"&VISIBLEPANEL=resultspanel", "date": "2010-03-22 21:28:48", "action": 0, "post": 417}}, {"pk": 545, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How to map a SNP to a gene around +/- 60KB ? ", "content": "Using the **UCSC mysql server**:\n\n    ~> mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A -D hg19 -e '\n    select\n     K.proteinID,\n     K.name,\n     S.name,\n     S.avHet,\n     S.chrom,\n     S.chromStart,\n     K.txStart,\n     K.txEnd\n    from snp130 as S\n    left join knownGene as K on\n     (S.chrom=K.chrom and not(K.txEnd+60000<S.chromStart or S.chromEnd+60000<K.txStart))\n    where\n     S.name in (\"rs25\",\"rs100\",\"rs75\",\"rs9876\",\"rs101\")'\n\nresult:\n\n    +-----------+------------+--------+----------+-------+------------+----------+----------+\n    | proteinID | name       | name   | avHet    | chrom | chromStart | txStart  | txEnd    |\n    +-----------+------------+--------+----------+-------+------------+----------+----------+\n    | NULL      | NULL       | rs100  |        0 | chr7  |   24438348 |     NULL |     NULL |\n    | NULL      | NULL       | rs101  |        0 | chr7  |   24438147 |     NULL |     NULL |\n    | NP_056019 | uc003ssf.3 | rs25   | 0.499586 | chr7  |   11584141 | 11414172 | 11871824 |\n    | NP_056019 | uc003ssf.3 | rs75   | 0.241967 | chr7  |   11613691 | 11414172 | 11871824 |\n    | B2RNV1    | uc003tnv.2 | rs9876 | 0.426096 | chr7  |   47315290 | 47314752 | 47579199 |\n    | B2RNV1    | uc003tnw.2 | rs9876 | 0.426096 | chr7  |   47315290 | 47314752 | 47621742 |\n    +-----------+------------+--------+----------+-------+------------+----------+----------+", "date": "2010-03-22 21:44:47", "action": 0, "post": 418}}, {"pk": 546, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: How to map a SNP to a gene around +/- 60KB ? ", "content": "You can do it with UCSC or biomart as described in the other answers; however, if you are going to work a lot with snps, I suggest you to have a look at [plink][1].\n\nplink is a nice C program with many options to work with snps and genotypes, extract reports and even calculate basic statistics. To use it to check whether your snps are within 60Kb of a gene, follow the instructions [here][2].\n\n\n  [1]: http://pngu.mgh.harvard.edu/~purcell/plink\n  [2]: http://pngu.mgh.harvard.edu/~purcell/plink/grep.shtml", "date": "2010-03-22 23:18:20", "action": 0, "post": 419}}, {"pk": 547, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "phylogeny software visualization feedback", "title": "What phylogeny viewing software do you use?", "content": "There are numerous phylogeny viewing programs available, which ones do people use most often? Are there features (e.g., visualisations, data formats, size of tree that can be displayed, annotation) that people feel existing software lack?\n\nI'll declare an interest. I'm the author of http://taxonomy.zoology.gla.ac.uk/rod/treeview.html, which is beginning to show its age. There are some other great tools around, so I'm trying to gauge whether TreeView should be allowed to die gracefully, of whether I should invest time in developing it further (see http://darwin.zoology.gla.ac.uk/~rpage/treeviewx/ ).", "date": "2010-03-23 01:58:09", "action": 0, "post": 402}}, {"pk": 548, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Drawing chromosome ideogams with data", "content": "The [GenomeGraphs package in Bioconductor][1] allows to draw (human) chromosome ideograms with R. The package can be used to depict genome tracks of coverage, microarray measurements and genes together with the ideograms. \nSee the [user guide][2] for an overview of different types of graphics. For the ideogram, the example looks like this (also in the [GenomeGraphs paper][3]): \n\n![Example][4]\n\n\nHere is the code that makes something like this (from the user guide):\n\n    library(GenomeGraphs)\n    library(biomaRt)\n    data(\"exampleData\", package = \"GenomeGraphs\")\n    mart <- useMart(\"ensembl\", dataset = \"hsapiens_gene_ensembl\")\n    minbase <- 180292097\n    maxbase <- 180492096\n    genesplus <- makeGeneRegion(start = minbase,\n                                end = maxbase, strand = \"+\", chromosome = \"3\",\n                                biomart = mart)\n    genesmin <- makeGeneRegion(start = minbase,\n                               end = maxbase, strand = \"-\", chromosome = \"3\",\n                               biomart = mart)\n    seg <- makeSegmentation(segStart, segEnd,\n                            segments, dp = DisplayPars(color = \"black\",\n                                        lwd = 2, lty = \"solid\"))\n    cop <- makeGenericArray(intensity = cn,\n                            probeStart = probestart, segmentation = seg,\n                            dp = DisplayPars(size = 3, color = \"seagreen\",\n                              type = \"dot\"))\n    ideog <- makeIdeogram(chromosome = 3)\n    expres <- makeGenericArray(intensity = intensity,\n                               probeStart = exonProbePos,\n                               dp = DisplayPars(color = \"darkred\",\n                                 type = \"point\"))\n    genomeAxis <- makeGenomeAxis(add53 = TRUE,\n                                 add35 = TRUE)\n    gdPlot(list(a = ideog, b = expres, c = cop,\n                d = genesplus, e = genomeAxis, f = genesmin),\n           minBase = minbase, maxBase = maxbase,\n           labelCex = 2)\n\nEdit: It supports multiple ideograms in one plot like this:\n\n     ideog <- makeIdeogram(chromosome = 1)\n     ideog2 <- makeIdeogram(chromosome = 2)\n     ideog3 <- makeIdeogram(chromosome = 3)\n     ideog4 <- makeIdeogram(chromosome = 4)\n     gdPlot(list(\"1\"= ideog, \"2\" = ideog2, \"3\" =ideog3, \"4\"=ideog4 ), \n     minBase = minbase, maxBase = maxbase)\n\nIf you plot data below the chromosomes using a base track, \ntake care of the `minbase, maxbase` parameters because the chromosomes have different length!\n\n\n  [1]: http://bioconductor.org/packages/2.5/bioc/html/GenomeGraphs.html\n  [2]: http://bioconductor.org/packages/2.5/bioc/vignettes/GenomeGraphs/inst/doc/GenomeGraphs.pdf\n  [3]: http://www.biomedcentral.com/1471-2105/10/2/abstract/\n  [4]: http://www.bccs.uni.no/~mdo041/rplots/ideog.png\n  [5]: http://www.biomedcentral.com/content/download/figures/1471-2105-10-2-1.PDF", "date": "2010-03-23 08:50:20", "action": 0, "post": 414}}, {"pk": 549, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "webservice bioinformatics soap rest subjective", "title": "What is your experience with bioinformatics webservices?", "content": "[Web-services][1] using SOAP or REST style are becoming more and more popular in also bioinformatics. The [Embrace Registry][2] and [BioCatalogue][3] are registries which provide a good overview of publicly available bioinformatics services. They aim at making services easier to describe and find. It is also often heard that web-services provide a platform- and language-independent interface to databases and computation. Furthermore, web-services can be [composed into complex-workflows][4], [used for data-integration,][5] automated user-interface and API-generation, that's at least the theory. How does the reality look for you?\n\nDo you use  SOAP/REST/.NET services in bioinformatics,\nand what are your experiences with the different services and service providers?\n\nMain aspects I am interested in are motivated by my own recent (and very mixed) experiences:\n\n - Did you encounter interoperability or language-dependence problems?\n - How did the providers react?\n - What would make you replace local scripts and tools by web-services?\n\n\n  [1]: http://en.wikipedia.org/wiki/Web_service\n  [2]: http://www.embraceregistry.net/\n  [3]: http://www.biocatalogue.org/\n  [4]: http://www.ncbi.nlm.nih.gov/pubmed/16845108\n  [5]: http://www.ncbi.nlm.nih.gov/pubmed/18056132", "date": "2010-03-23 10:30:26", "action": 0, "post": 420}}, {"pk": 550, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "microarray data methods models", "title": "What are the most reliable normalization methods for microarrays?", "content": "Hi people,\n\nI've just attended a seminar focused on microarray data, essentially given by experimentalists. It was somewhat shocking that they were unable to agree on what methods to use for data normalization (and why). So, you can imagine what happened in further steps . . .\n\nHence, I'm wondering about a list of the most reliable methods for data normalization. Not a plain list of methods/models. A list explaing why a given method/model is reliable (or why someone should use it). \n\nJust to avoid some confusions, in this context [reliability][1] acquires its statistical meaning.\n\nThis question is relevant just because the most popular normalization procedures depends on statistical models to address probe-level, background-level, etc., variation/correlation. For example, RMA and fRMA uses a linear model. \n\nSo, given the number of microarray plataforms and designs, reliability is of utmost importance. \n\n\n\n  [1]: http://en.wikipedia.org/wiki/Reliability_%28statistics%29", "date": "2010-03-23 11:44:40", "action": 0, "post": 387}}, {"pk": 551, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: What are the most reliable normalization methods for microarrays?", "content": "Following this definition, all deterministic methods are 100% reliable, because they always reproduce the same result when repeated. Reliability is - of course - important for measurements, but data-transformations are not measurements. There are some statistics (not normalization methods I know of) for example those involving the\nEM-algorithms or k-means clustering.  \n\nSo, my advise: check if the methods are deterministic, then they are reliable by definition. This question of reliability is for sure relevant for the measurement techniques such as microarrays, qPCR, RNA-seq, but it is totally solved for normalization (say: ALL methods are deterministic/reliable). If you are looking for a problem to solve in normalization this is definitely not right place. ", "date": "2010-03-23 12:01:54", "action": 0, "post": 421}}, {"pk": 552, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: What are the most reliable normalization methods for microarrays?", "content": "Following this definition, all deterministic methods are 100% reliable, because they always reproduce the same result when repeated. Reliability is - of course - important for measurements, but data-transformations are not measurements. There are some statistics (not normalization methods I know of) for example those involving the\nEM-algorithms or k-means clustering.  \n\nSo, my advise: check if the methods are deterministic, then they are reliable by definition. This question of reliability is for sure relevant for the measurement techniques such as microarrays, qPCR, RNA-seq, but it is totally solved for normalization (say: ALL methods are deterministic/reliable). If you are looking for a problem to solve in normalization this is definitely not the right place.\n\nBTW.: one can easily assess the reliability. If you want to check RMA, loess-normalization, mean or quantile normalization, just run it on the same input data say 1000 times and look at the results.\nBTW2.: RMA  because mentioned (robust multichip average) is not (only) normalization, it comprizes background subtraction, quantile normalization (a totally deterministic method), and intensity sumarization. \n ", "date": "2010-03-23 12:19:06", "action": 0, "post": 421}}, {"pk": 553, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: What is your experience with bioinformatics webservices?", "content": " - SOAP/WSDL is great for generating the code for reading/writing the structured information.\n - It is very easy to implement a SOAP server and its client with a few annotations with the Java API ( [my experience][1] )\n - I've tested a few SOAP services from the Biocatalogue. Many times it uses an old deprecated format. e.g.:\n\n     wsimport http://www.pdb.org/pdb/services/pdbws?wsdl\n\n    [WARNING] src-resolve: Cannot resolve the name 'soapenc:Array' to a(n) 'type definition' component.\n      line 10 of http://www.pdb.org/pdb/services/pdbws?wsdl#types?schema1\n\n    [ERROR] undefined simple or complex type 'soapenc:Array'\n      line 10 of http://www.pdb.org/pdb/services/pdbws?wsdl\n\n - the WSDL generated with JAVA are missing some documentation (what is this method? how should I use it ?)\n - I also played successfully with some WS at the EBI (  [my experience with intact][2] ) but here the message returned was 'just' a tab delimited line that had to be splitted/parsed again by the client :-)\n\n - (...)\n\n  [1]: http://plindenbaum.blogspot.com/2009/05/webservicesjaxws-for-snp-glassfish.html\n  [2]: http://plindenbaum.blogspot.com/2008/10/ebiintact-web-service-api-my-notebook.html", "date": "2010-03-23 12:20:21", "action": 0, "post": 422}}, {"pk": 554, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: What are the most reliable normalization methods for microarrays?", "content": "Following this definition, all deterministic methods are 100% reliable, because they always reproduce the same result when repeated. Reliability is - of course - important for measurements, but data-transformations are not measurements. There are some statistics (not normalization methods I know of) for example those involving the\nEM-algorithms or k-means clustering.  \n\nSo, my advise: check if the methods are deterministic, then they are reliable by definition. This question of reliability is for sure relevant for the measurement techniques such as microarrays, qPCR, RNA-seq, but it is totally solved for normalization (say: ALL methods are deterministic/reliable). If you are looking for a problem to solve in normalization this is definitely not the right place.\n\nBTW.: one can easily assess the reliability. If you want to check RMA, loess-normalization, mean or quantile normalization, just run it on the same input data say 1000 times and look at the results.\nBTW2.: RMA  because mentioned (robust multichip average) is not (only) normalization, it comprizes background subtraction, quantile normalization (a totally deterministic method), and intensity sumarization. \n\nEdit: Just to restrict the above said again. There are some reliability issues with normalization. I just saw a message on bioconductor noticing differences in the analysis using GCRMA on windows/linux. As said, most normalization and summary methods are deterministic as long as data and methods stay the same. However, there can be variations on the probe level, even when using the same array design. The most common source of such events is that the array annotation and thereby the probe-level groups and their assignments to genes are changed. \n\nThis is sort of a \"pseudo-(un)reliabilty\" because if all parameters are the same, the results are the same. But the annotations are frequently changed and the annotation updates are mostly included automagically without the user noticing the difference. This is specifically true for the Affy platform.\n\n\n ", "date": "2010-03-23 13:01:06", "action": 0, "post": 421}}, {"pk": 555, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: What is your experience with bioinformatics webservices?", "content": "I feel somewhat embarrassed to admit that I know very little about these web-services. I knew that they existed but never saw examples of actual use cases performed with  them. When simply reading about a service they feel a little complicated, imposing a cognitive overhead that may not obviously pay off in long term.\n\nBut I have learned a number of neat tricks here on this site on how to access various resources, and I plan to put those to use. I find cookbook like approaches: *this is how we do X or Y with a bioservice* as being the most effective method of demonstrating their value.", "date": "2010-03-23 13:23:52", "action": 0, "post": 423}}, {"pk": 556, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: What is your experience with bioinformatics webservices?", "content": "I feel somewhat embarrassed to admit that I know very little about these web-services. I knew that they existed but never saw examples of actual use cases performed with  them. When simply reading about a service they feel a little complicated, imposing a cognitive overhead that may not obviously pay off in long term.\n\nBut I have learned a number of neat tricks here on this site on how to access various resources, and I plan to put those to use. I find cookbook like approaches: *this is how we do X or Y with a bioservice* as being the most effective method of demonstrating their value.\n\nEdit (forgot to answer this):\n\n - What would make you replace local scripts and tools by web-services?\n\nFor me the first priority is that the simplicity of the overall solution. What is the added complexity of one approach versus the other, and weighing that against overall goals.\n ", "date": "2010-03-23 13:34:43", "action": 0, "post": 423}}, {"pk": 557, "model": "server.postrevision", "fields": {"author": 72, "tag_string": "", "title": "A: What is your experience with bioinformatics webservices?", "content": "I have used the Stanford HIVdb web service, which is a fantastic tool for identifying drug resistant mutations in HIV sequences. Fortunately, they provide the entire client-side base code in both Perl and Java, otherwise it might have been too onerous to deal with. I think this is absolutely critical to getting any traction if you intend to roll out a web service like this.\n\nI believe our group was the first to submit pyrosequencing data to this service, which meant they received tens of thousands of hits from us instead of a just a few. Still, it was able to deal with the increased load over a weekend.\n\n* Did you encounter interoperability or language-dependence problems?\n * Yes their Perl client did not work after a certain version. Fortunately they provided a Java client which continued to work.\n\n\n* How did the providers react?\n     * Very well. They were very helpful.\n\n\n* What would make you replace local scripts and tools by web-services?\n\n   * Because I work in industry now it\n   would be difficult for me to get the\n   use of these services blessed by the\n   powers that be without a security\n   framework in place (https?). There also appears to be a lot more available on the human side than for plants.\n\nI would say SOAP is losing the popularity contest to REST, not because of a lack of merits, but because only Pierre Lindenbaum understands how to use SOAP. Seriously though, I think SOAP was/is too complex or intimidating for most end-users to wrap their head around even though it is a more powerful framework.\n\nAnother factor that I think will be in REST's favor is the proliferation of modern web frameworks like Rails and Grails that make it easy to develop RESTy interfaces which serve both human and robot clients with the flip of a switch.", "date": "2010-03-23 14:04:31", "action": 0, "post": 424}}, {"pk": 558, "model": "server.postrevision", "fields": {"author": 165, "tag_string": "sequence submission ncbi public accession", "title": "When is the best time to submit sequences to public databases like NCBI?", "content": "I have always left the submission of sequences to NCBI to the very last minute, i.e. just before submitting a manuscript for review and on occasion, I have left it until I have known that the paper is accepted. In your opinion when is the best time to submit? As soon as you have quality checked the sequences? Once the manuscript is ready for submission? After the manuscript has been accepted?\nIt would be great to get a general feel of when people tend to submit there sequences.", "date": "2010-03-23 14:37:58", "action": 0, "post": 425}}, {"pk": 559, "model": "server.postrevision", "fields": {"author": 118, "tag_string": "", "title": "A: When is the best time to submit sequences to public databases like NCBI?", "content": "In the past, I've mostly done it like you, but with the current wealth of sequence data, I guess the relative value of sequences is going down. Therefore, I don't see any reason per se to wait until the paper is submitted/accepted. *Unless* of course you have something that gives you an advantage over your competition (if applicable) that you don't want them to see before your publication is out. \n\nNote that you can also submit sequences and specify a release date, so it's not necessarily true that sequences become publically available as soon as they're submitted.\n\nIn my personal view, the advantage to submitting as early as possible is that you've got it out of the way sooner.\n\n", "date": "2010-03-23 16:06:48", "action": 0, "post": 426}}, {"pk": 560, "model": "server.postrevision", "fields": {"author": 85, "tag_string": "gwas gene", "title": "How to find all GWAS studies that a given gene has been implicated in?", "content": "dbGaP seems to be a primary data repository, but it doesn't store results on the level of genes (or as far as I can tell, even genomic regions).", "date": "2010-03-23 18:35:41", "action": 0, "post": 427}}, {"pk": 561, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: How to find all GWAS studies that a given gene has been implicated in?", "content": "AFAIK, [dbGAP][1] is one of the official resource for GWAS studies. A mere gene search may not fetch the exact details about the studies. Dataset from large scale GWAS studies are not available under public access due to sensitive genotype and phenotype data from patients. You have to write to individual investigators to get access to the data. Usually this data will be available only after the Embargo Release date. This is usually after 1year of the submission of the data. I think once you have access to the dataset, you will able to get the p-values of the SNPs genotyped in the whole study with the de-identified case/control phenotypes. These SNPs may need further mapping to get the details about the genes. \n\nI am looking forward for other comments to know if there is any public resource that provides GWAS data. \n\n\n  [1]: http://www.ncbi.nlm.nih.gov/gap", "date": "2010-03-23 19:01:57", "action": 0, "post": 428}}, {"pk": 562, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "gwas gene genome", "title": "How to find all GWAS studies that a given gene has been implicated in?", "content": "dbGaP seems to be a primary data repository, but it doesn't store results on the level of genes (or as far as I can tell, even genomic regions).", "date": "2010-03-23 19:12:23", "action": 0, "post": 427}}, {"pk": 563, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "chromosome ideogram plotting visualization", "title": "Drawing chromosome ideogams with data", "content": "What software do you use to draw chromosomes with G-banding pattern and plot data alongside each chromosome? I'm interested in different kind of plots - lines, points, bars, etc - and high customization.\n\nI have used [coloredChromosomes.pl][1] and [chromosomeplot][2] in MATLAB, but there are not enough features. What would you recommend to try?\n\n**UPDATE**:\nI need something like this:\n![chromosome plot example][3]\n\n\n  [1]: http://users.comcen.com.au/~journals/ojb/ojbideofreesample2003/ojbideofreesample2003.htm\n  [2]: http://www.mathworks.com/access/helpdesk/help/toolbox/bioinfo/ref/chromosomeplot.html\n  [3]: http://img233.imageshack.us/img233/6805/chrexample.jpg \"chromosome plot example\"", "date": "2010-03-23 19:12:57", "action": 0, "post": 378}}, {"pk": 564, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: How to find all GWAS studies that a given gene has been implicated in?", "content": "AFAIK, [dbGAP][1] is one of the official resource for GWAS studies. A mere gene search may not fetch the exact details about the studies. Dataset from large scale GWAS studies are not available under public access due to sensitive genotype and phenotype data from patients. You have to write to individual investigators to get access to the data. Usually this data will be available only after the Embargo Release date. This is usually after 1year of the submission of the data. I think once you have access to the dataset, you will able to get the p-values of the SNPs genotyped in the whole study with the de-identified case/control and their phenotypes. These SNPs may need further mapping to get the details about the genes. \n\nI am looking forward for other comments to know if there is any public resource that provides GWAS data. \n\n\n  [1]: http://www.ncbi.nlm.nih.gov/gap", "date": "2010-03-23 19:22:07", "action": 0, "post": 428}}, {"pk": 565, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "taverna plone virtual", "title": "Tips on how to set up a virtual workbench for bioinformatics", "content": "Greetings again,\n\nI want to build a virtual workbench for a medical community. I'm thinking in a solution in the spirit of the Taverna project. Every user shoud be able to construct its own workflow from a set of in-house tools, submit and retrive data, etc. The data are somewhat sigilous. Applications will be critical in a near future.\n\nThe most important point is: the community is large and the bioinformaticians are very few. If we could set up a service for common tasks (alignment, phylogeny, GO annotation retrieval, etc.) our life would be so much happier (and we could focus on bioinformatics research again) !!! \n\nI aware only of Taverna and Plone4Bio. Is there other server-like virtual benches? Did someone already test them? Extensively?", "date": "2010-03-23 20:02:14", "action": 0, "post": 429}}, {"pk": 566, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Tips on how to set up a virtual online workbench for bioinformatics", "content": "Some workflow engines. Some of them (like Mobyle or Galaxy) are hosted on a web server.\n\nMobyle: http://mobyle.pasteur.fr\n\nGalaxy: http://main.g2.bx.psu.edu/\n\nOrange: http://www.ailab.si/orange/\n\nKNime: http://knime.org/\n\nWildfire: http://wildfire.bii.a-star.edu.sg/index.php\n\nUgene: http://ugene.unipro.ru/index.html\n\nKepler: https://kepler-project.org/\n\n(...)", "date": "2010-03-23 20:19:11", "action": 0, "post": 430}}, {"pk": 567, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "fpga hpc reconfigurable", "title": "Hardware resources for HPC in Bioinformatics", "content": "Greetings everybody,\n\nWe're planning to build a very powerful computing machine to serve bioinformatics application here at [HCFMUSP][7] (check my profile). I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions using FPGA cards like these ones:\n\n[CLCbio Cube][1]\n\n[TimeLogic DeCypher][2]\n\n[Pico Computing E-FPGA][3]\n\n\nFor the people who never heard of FPGA I do suggest to check out Wikipedia on these topics:\n\n[Field Programmable Gate Array][4]\n[Reconfigurable Computing][5]\n\nThere are several possible implementations of important algorithms in bioinformatics in those plataforms. This is  just one example:\n\n[160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)][6]\n\n\nDoes anybody have some experience with these cards? Do they scale well? Are they worth the trouble?\n\n\nCheers,\nDaniel\n\n\n  [1]: http://www.clcbio.com/index.php?id=616\n  [2]: http://www.timelogic.com/decypher_intro.html\n  [3]: http://www.picocomputing.com/e_series.html\n  [4]: http://en.wikipedia.org/wiki/Fpga\n  [5]: http://en.wikipedia.org/wiki/Reconfigurable_computing\n  [6]: http://www.biomedcentral.com/1471-2105/8/185\n  [7]: http://www.hcnet.usp.br/", "date": "2010-03-23 20:27:02", "action": 0, "post": 328}}, {"pk": 568, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "taverna plone online", "title": "Tips on how to set up a virtual online workbench for bioinformatics", "content": "Greetings again,\n\nI want to build a virtual workbench on a bunch of Linux servers (VM allowed) for a medical community. I'm thinking in a solution in the spirit of the Taverna project (server version). Every user shoud be able to construct its own online virtual workflow from a set of in-house tools, submit and retrive data, etc. \n\nThe data are somewhat sigilous. Applications will be critical in a near future. So, I can't use elsewhere servers/services.\n\nThe most important point is: the community is large and the bioinformaticians are very few. If we could set up a customizable online service for common tasks (alignment, phylogeny, GO annotation retrieval, etc.) our life would be so much happier (and we could focus on bioinformatics research again) !!! \n\nI aware only of Taverna and Plone4Bio. Is there other server-like virtual benches? Did someone already test them? Extensively?", "date": "2010-03-23 20:41:47", "action": 0, "post": 429}}, {"pk": 569, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "", "title": "A: Tips on how to set up a virtual online workbench for bioinformatics", "content": "Plenty of people have tried this before for other communities\n\nCARMEN for neuroinformatics: [http://carmen.org.uk][1]\n\nBIRN (Biomedical Informatics Reseatch Network) [http://www.birncommunity.org/][2]\n\nNUGO (via the NuGO Black Box or NBX) [http://www.nugo.org/nbx][3]\n\nThis is not a trivial problem and can be attacked with varying levels of complexity.  You would do well to look at how other people have attempted to solve the problem.  It's not just an issue of providing the services, or a workflow handler, but also opens up serious consideration of how you provide authentication and security for data and resources.\n\n\n  [1]: http://carmen.org.uk\n  [2]: http://www.birncommunity.org/\n  [3]: http://www.nugo.org/nbx", "date": "2010-03-23 21:15:24", "action": 0, "post": 431}}, {"pk": 570, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "taverna plone online workflow", "title": "Tips on how to set up a virtual online workbench for bioinformatics", "content": "Greetings again,\n\nI want to build a virtual workbench on a bunch of Linux servers (VM allowed) for a medical community. I'm thinking in a solution in the spirit of the Taverna project (server version). Every user shoud be able to construct its own online virtual workflow from a set of in-house tools, submit and retrive data, etc. \n\nThe data are somewhat sigilous. Applications will be critical in a near future. So, I can't use elsewhere servers/services.\n\nThe most important point is: the community is large and the bioinformaticians are very few. If we could set up a customizable online service for common tasks (alignment, phylogeny, GO annotation retrieval, etc.) our life would be so much happier (and we could focus on bioinformatics research again) !!! \n\nI aware only of Taverna and Plone4Bio. Is there other server-like virtual benches? Did someone already test them? Extensively?", "date": "2010-03-23 21:16:57", "action": 0, "post": 429}}, {"pk": 571, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "", "title": "A: What license do you use when you release code and data?", "content": "Currently GPL, but if you are developing as part of your job you should probably check to see if your employer has a policy on it.", "date": "2010-03-23 23:07:27", "action": 0, "post": 432}}, {"pk": 572, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "", "title": "A: Is it possible for two different Affymetrix probe set ID to have common annotations to same gene ? ", "content": "As previously stated in some of the excellent answers above it is not just possible, but common.\n\nWe have our own system for 'validating' the mappings between affy probesets and transcripts.\n\n 1. Align all of the probes to the genome sequence\n 2. Count the number of transcripts that each probe-set is associated with and how many probes hit for each.\n 3. Exclude probe-sets that map to more than one gene with a significant number of their probes (promiscuous).\n 4. Quality score the probe-sets against actual transcribed sequence (some probes do not actually hit exonic or UTR sequences) and exclude those that fall below a threshold.\n\nRecently I have worked most with the Affymetrix Drosophila 2.0 chip-set and we find about 5% of probe-sets to be unreliable. Most fail because they are promiscuous i.e. one probe-set maps to more than one gene/transcript.\n\n", "date": "2010-03-23 23:32:24", "action": 0, "post": 433}}, {"pk": 573, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "", "title": "A: What is your experience with bioinformatics webservices?", "content": "I always very much liked the idea of webservices, and the several standards have mixed goals and features. I quite like the idea of [SOAP][1]. The SOAP standard practically settled for XML, but there are alternatives, like SOAP over [XMPP][2].\n\nThe standard has been complex and large, resulting in many partial implementations. This makes the SOAP practically difficult to use, and resulting in best practices, effectively reducing the size of the standard, so that libraries can focus on that subset. [WSDL][3] is one additional standard required by most of those best practices.\n\nMoreover, those incomplete libraries are often mutually incompatible, which has prominently been the case for Axis1/Axis2. However, some SOAP services could be properly accessed by the first and not the latter and the other way around. Try setting up a client that supports services that require both versions.\n\nREST is much simpler, but does not offer the standardized discovery, and any service may use a different design.\n\n**Disclaimer**: we developed an XMPP alternative that supports asynchronous web services recently, doi:[10.1186/1471-2105-10-279][4].\n\n\n  [1]: http://www.w3.org/TR/soap/\n  [2]: http://xmpp.org/\n  [3]: http://www.w3.org/TR/wsdl\n  [4]: http://www.biomedcentral.com/1471-2105/10/279", "date": "2010-03-24 07:17:10", "action": 0, "post": 434}}, {"pk": 574, "model": "server.postrevision", "fields": {"author": 135, "tag_string": "call papers conferences research", "title": "Is there a site where call for papers and conferences are listed in one place?", "content": "Is there an easy way to find out about current calls for papers and conferences? I find it incredibly frustrating every time I find an interesting conference announcement and see that the call for papers deadline expired the day before, or is too soon to prepare a paper for submission. Is there a global collection of bioinformatics related conferences somewhere?", "date": "2010-03-24 08:42:29", "action": 0, "post": 435}}, {"pk": 575, "model": "server.postrevision", "fields": {"author": 171, "tag_string": "", "title": "A: How do I access and query entire genome sequences with R", "content": "Hello,\nconcerning the seqinR package I would also consider the \"query\" function which allows you to \nquery various databases as  EMBL, GenBank, Uniprot, some Ensembl genomes and others databases structured under ACNUC ([http://pbil.univ-lyon1.fr/databases/acnuc/acnuc.html][1]) .\n\n>library(seqinr)\n\nTo check which databases are available, type:\n\n>choosebank(infobank=TRUE)\n\n\nFor example if you want to query the ensembl human genome for sequences in which the field hgnc is a2m :\n\n> choosebank(\"human\")\n\n> query(\"mylist\",\"k=hgnc:a2m\")\n\nNote that in the case of Ensembl, cross-references may be used as keywords:\n \nFor example in the selected sequence, the annotations are\n\n> S12_1.PE362                  \n> Location/Qualifiers    (length=4425\n> bp) FT   CDS            \n> join(complement(9268360..9268445),complement(9265956..9266139),\n> FT                  \n> complement(9264973..9265132),complement(9264755..9264807),\n> FT                  \n> complement(9262910..9262930),complement(9262463..9262631),\n> FT                  \n> complement(9261917..9262001),complement(9260120..9260240),\n> FT                  \n> complement(9259087..9259201),complement(9258832..9258941),\n> FT                  \n> complement(9256835..9256996),complement(9254043..9254270),\n> FT                  \n> complement(9253740..9253803),complement(9251977..9252119),\n> FT                  \n> complement(9251203..9251352),complement(9248135..9248296),\n> FT                  \n> complement(9247569..9247680),complement(9246061..9246175),\n> FT                  \n> complement(9243797..9244025),complement(9242952..9243078),\n> FT                  \n> complement(9242498..9242619),complement(9241796..9241847),\n> FT                  \n> complement(9232690..9232773),complement(9232235..9232411),\n> FT                  \n> complement(9231840..9231927),complement(9230297..9230453),\n> FT                  \n> complement(9229942..9230016),complement(9229352..9229532),\n> FT                  \n> complement(9227156..9227379),complement(9225249..9225467),\n> FT                  \n> complement(9224955..9225082),complement(9223084..9223174),\n> FT                  \n> complement(9222341..9222409),complement(9221336..9221438),\n> FT                  \n> complement(9220779..9220820),complement(9220419..9220435))\n> FT                  \n> /gene=\"ENSG00000175899\" FT            \n> /protein_id=\"ENSP00000323929\" FT      \n> /note=\"transcript_id=ENST00000318602\"\n> FT                  \n> /db_xref=\"HGNC:A2M\" FT                \n> /db_xref=\"UCSC:uc001qvk.1\" FT         \n> /db_xref=\"CCDS:CCDS44827.1\" FT        \n> /db_xref=\"HPA:CAB017621\" FT           \n> /db_xref=\"HPA:CAB017621\" FT           \n> /db_xref=\"HPA:HPA002265\" FT           \n> /db_xref=\"HPA:HPA002265\" FT           \n> /db_xref=\"WikiGene:A2M\" FT            \n> /db_xref=\"Uniprot/SWISSPROT:A2MG_HUMAN\"\n> FT                  \n> /db_xref=\"RefSeq_peptide:NP_000005.2\"\n> FT                  \n> /db_xref=\"RefSeq_dna:NM_000014.4\" FT  \n> /db_xref=\"Uniprot/SPTREMBL:C9J773_HUMAN\"\n> FT                  \n> /db_xref=\"Uniprot/SPTREMBL:Q9BQ22_HUMAN\"\n> FT                  \n> /db_xref=\"EntrezGene:A2M\" FT          \n> /db_xref=\"EMBL:AB209614\" FT           \n> /db_xref=\"EMBL:AC007436\" FT           \n> /db_xref=\"EMBL:AF109189\" FT           \n> /db_xref=\"EMBL:AF349032\" FT           \n> /db_xref=\"EMBL:AF349033\" FT           \n> /db_xref=\"EMBL:AY591530\" FT           \n> /db_xref=\"EMBL:BC026246\" FT           \n> /db_xref=\"EMBL:BC040071\" FT           \n> /db_xref=\"EMBL:CR749334\" FT           \n> /db_xref=\"EMBL:M11313\"\n\n \"HGNC:A2M\", \"UCSC:uc001qvk.1\",\"CCDS:CCDS44827.1\",\"HPA:CAB017621\",etc.\n are keywords which may be used to retrieve the sequence \n\nNow to check the sequence list ( in this case there is only 1 sequence in the list) :\n\n> mylist$req\n\n\n[[1]]\n          name         length          frame         ncbicg \n\"HS12_1.PE362\"         \"4425\"            \"0\"            \"1\" \n\n\nto get the sequence data:\n\n>seq<-sapply(mylist$req[1:1],getSequence, as.string = FALSE)  \n\n\nto save  data in fasta format:\n\n>write.fasta(sequences=seq,names=\"my_sequence\" , file.out = \"myseq.fasta\")\n\n\nYou can get as well  whole chromsome sequences, extract data in  several formats, extract fragments of sequences, translate into protein.\n\nYou may find more  information on  the seqinR page here  http://seqinr.r-forge.r-project.org/ \n\nI hope this may  help  you\n\n\nSimon\n\n\n  [1]: http://pbil.univ-lyon1.fr/databases/acnuc/acnuc.html", "date": "2010-03-24 09:09:02", "action": 0, "post": 436}}, {"pk": 576, "model": "server.postrevision", "fields": {"author": 170, "tag_string": "", "title": "A: Drawing chromosome ideogams with data", "content": "The quantsmooth Bioconductor package also has chromosome plotting functionality in the prepareGenomeplot(), paintCytobands() functions\n\nSome Examples\n![Digital Karyogram][1]\n\n\n![Copynumber plots][2]\n\n\n  [1]: http://imgur.com/8DsW5.png\n  [2]: http://imgur.com/a0AWz.png", "date": "2010-03-24 09:53:57", "action": 0, "post": 437}}, {"pk": 577, "model": "server.postrevision", "fields": {"author": 170, "tag_string": "", "title": "A: Drawing chromosome ideogams with data", "content": "The quantsmooth Bioconductor package also has chromosome plotting functionality in the prepareGenomeplot(), paintCytobands() functions\n\nSome Examples\n![Digital Karyogram][1]\n\n\n![Copynumber plots][2]\n\n\nEDIT:\nThe code for these plots is quite involved, and depends a lot on the genomic data.\n\nA quick example leads to the following plot\n\n    # prepareGenomePlot example\n    library(quantsmooth)\n    # construct genomic positions\n    CHR<-sample(22,40,replace=TRUE)  # Chromosomes\n    MapInfo<-lengthChromosome(CHR,\"bases\")*runif(length(CHR)) # position on chromosome\n    chrompos<-prepareGenomePlot(data.frame(CHR,MapInfo),paintCytobands = TRUE, organism=\"hsa\")\n    # Chrompos returns a matrix with the positions of the elements on the plot\n    # You can use all kinds of base graphics functions to annotate the chromosomes\n    points(chrompos[,2],chrompos[,1]+0.1,pch=\"x\",col=\"red\")\n    # Show connection between 3rd and 4th element\n    segments(chrompos[3,2],chrompos[3,1],chrompos[4,2],chrompos[4,1],col=\"blue\",lwd=2)\n\n![PrepareGenomePlot Example][3]\n\n\n  [1]: http://imgur.com/8DsW5.png\n  [2]: http://imgur.com/a0AWz.png\n  [3]: http://imgur.com/RscFr.png", "date": "2010-03-24 11:28:15", "action": 0, "post": 437}}, {"pk": 578, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "", "title": "A: Is there a site where call for papers and conferences are listed in one place?", "content": "At the risk of sounding slightly daft - no, not that I know of.\n\nI personally get my information about upcoming conferences from the mailing lists I subscribe to where every upcoming barely relevant call for papers is spammed liberally across half a dozen of them at a time, ensuring that there is no way for me to not know about their existence!\n\n[http://www.bioinformatics.org/][1] however do seem to have lots of CfP's on their news front page.\n\n\n  [1]: http://www.bioinformatics.org/", "date": "2010-03-24 11:35:32", "action": 0, "post": 438}}, {"pk": 579, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "", "title": "A: Is there a site where call for papers and conferences are listed in one place?", "content": "There is no centralized place to this end. But, there are a few very important hubs, though. These are very important:\n\n[Genetics Society Meetings][1]\n[ISCB Meetings][2]\n\nIEEE has some interesting meetings too.\n\nTo avoid deadline frustation, I recommend you to follow this societies closely (use their RSS, Twitter or mail lists). Many conferences just spike out suddenly and have very short time windows (at least in South America). And always be prepared. Keep your preprints in good shape. Life will be much easier and a lot more funnier.\n\n\n  [1]: http://www.genetics.org.uk/page/3190/External-meetings.html\n  [2]: http://www.iscb.org/iscb-conferences", "date": "2010-03-24 11:45:01", "action": 0, "post": 439}}, {"pk": 580, "model": "server.postrevision", "fields": {"author": 170, "tag_string": "", "title": "A: Drawing chromosome ideogams with data", "content": "The quantsmooth Bioconductor package also has chromosome plotting functionality in the prepareGenomeplot(), paintCytobands() functions\n\nSome Examples\n![Digital Karyogram][1]\n\n\n![Copynumber plots][2]\n\n\nEDIT:\nThe code for these plots is quite involved, and depends a lot on the genomic data.\n\nThe supplementary data for Genome Res. 2007 17: 368-376, doi:10.1101/gr.5686107 contains the data and script to produce the figures for the paper, which also contain some of these ideograms\n\nA quick example leads to the following plot\n\n    # prepareGenomePlot example\n    library(quantsmooth)\n    # construct genomic positions\n    CHR<-sample(22,40,replace=TRUE)  # Chromosomes\n    MapInfo<-lengthChromosome(CHR,\"bases\")*runif(length(CHR)) # position on chromosome\n    chrompos<-prepareGenomePlot(data.frame(CHR,MapInfo),paintCytobands = TRUE, organism=\"hsa\")\n    # Chrompos returns a matrix with the positions of the elements on the plot\n    # You can use all kinds of base graphics functions to annotate the chromosomes\n    points(chrompos[,2],chrompos[,1]+0.1,pch=\"x\",col=\"red\")\n    # Show connection between 3rd and 4th element\n    segments(chrompos[3,2],chrompos[3,1],chrompos[4,2],chrompos[4,1],col=\"blue\",lwd=2)\n\n![PrepareGenomePlot Example][3]\n\n\n  [1]: http://imgur.com/8DsW5.png\n  [2]: http://imgur.com/a0AWz.png\n  [3]: http://imgur.com/RscFr.png", "date": "2010-03-24 11:58:41", "action": 0, "post": 437}}, {"pk": 581, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "", "title": "A: How difficult/reliable is it to programmatically (python) look up and download papers?", "content": "We have certainly written scripts using Mechanize for this in the past which picked up ~85-90% of articles for which PDFs were available. This trawled around looking for links, forwards etc.. to PDFs.\n\nSo you could go that way, but I wonder if you might want to take a look at Pubget http://pubget.com/. I haven't had a close look, but they have an API that you might be able to use to do the hard work for you. As I say I don't know how good the return rate is with this.", "date": "2010-03-24 12:26:41", "action": 0, "post": 440}}, {"pk": 582, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "hpc r parallel cran", "title": "Which R packages, if any, are best for high performance computing ?", "content": "I have started running R jobs on a high performance compute cluster, but inevitably find that I am just performing array jobs which are ultimately not taking advantage of true parallelism, although they do speed up the experiment.\n\nI would like to start writing some parallel code in R where parallelized functions are available and wondered what people's experiences of this are and what packages you would recommend ?", "date": "2010-03-24 12:39:46", "action": 0, "post": 441}}, {"pk": 583, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: Which R packages, if any, are best for parallel computing ?", "content": "I know of two, but have not used either:\n\n 1. [R/parallel \u2013 speeding up bioinformatics analysis with R][1]\n 2. [The gputools package enables GPU computing in R][2]\n\nSee also [CRAN Task View: High-Performance and Parallel Computing with R][3].\n\n\n  [1]: http://www.biomedcentral.com/1471-2105/9/390\n  [2]: http://bioinformatics.oxfordjournals.org/cgi/content/abstract/26/1/134\n  [3]: http://cran.r-project.org/web/views/HighPerformanceComputing.html", "date": "2010-03-24 12:49:25", "action": 0, "post": 442}}, {"pk": 584, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "hpc r parallel cran", "title": "Which R packages, if any, are best for parallel computing ?", "content": "I have started running R jobs on a high performance compute cluster, but inevitably find that I am just performing array jobs which are ultimately not taking advantage of true parallelism, although they do speed up the experiment.\n\nI would like to start writing some parallel code in R where parallelized functions are available and wondered what people's experiences of this are and what packages you would recommend ?", "date": "2010-03-24 13:15:10", "action": 0, "post": 441}}, {"pk": 585, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "", "title": "A: Which R packages, if any, are best for parallel computing ?", "content": "Maybe this question is best suited for stackoverflow.\nHave a look at [this discussion][1] and follow [this search][2].\n\n\n  [1]: http://stackoverflow.com/questions/1395309/how-to-make-r-use-all-processors\n  [2]: http://stackoverflow.com/search?q=[r]+parallel", "date": "2010-03-24 13:29:32", "action": 0, "post": 443}}, {"pk": 586, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "", "title": "A: Which R packages, if any, are best for parallel computing ?", "content": "Have you looked at REvolution R?\n\n[http://www.revolution-computing.com/][1]\n\nsudo apt-get install revolution-r \n\nwill get you up and running in Ubuntu in no time.\n\n\"REvolution R runs many computationally-intensive programs faster, especially on multiprocessor systems. REvolution R is built with high-performance compilers and linked with computational libraries that take advantage of multiple processors simultaneously to reduce the time to complete many common mathematical operations. You do not need to modify your code to benefit from these optimizations. \"\n\n\n  [1]: http://www.revolution-computing.com/", "date": "2010-03-24 13:33:26", "action": 0, "post": 444}}, {"pk": 587, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Which R packages, if any, are best for parallel computing ?", "content": "Fundamentally the most important element of parallel computing revolves around requirement of *inter-process communication*. \n\nThere are many problems that require no such communication and thus can be simply be parallelized by splitting the input data into chunks and running multiple instances of the program in question. I don't personally consider this \"parallel\" computing but others call it as such. Many of the solutions you'll find for R are handy convenience functions for starting up R as new processes then collecting the results of their run. \n\nThe *true parallel* computing revolves around the ability to quickly exchange data across different parallel processes. These are necessary when one process needs some results computed in a different process. Most of the time this requires specialized libraries or computing models and is not something that I would recommend one to undertake as a side project. \n\nThere are some libraries written to take advantage of multiple cores. This is called *implicit parallelism*. In this case while the original may be a single threaded program, some internal functions are able to perform over multiple cores. \n\nYour primary course of action is to identify whether the problem that you wish to parallelize can be partitioned just by its input data and/or whether the functionality that you need is available via implicit parallelism. If so you have many straightforward solutions. If not then the solution will be a lot more complicated.\n", "date": "2010-03-24 13:53:06", "action": 0, "post": 445}}, {"pk": 588, "model": "server.postrevision", "fields": {"author": 175, "tag_string": "", "title": "A: When is the best time to submit sequences to public databases like NCBI?", "content": "how about the issue of patenting after submitting the data? will there be any complications since these data are already in public domain", "date": "2010-03-24 14:22:41", "action": 0, "post": 446}}, {"pk": 589, "model": "server.postrevision", "fields": {"author": 73, "tag_string": "", "title": "A: Tools to find gene ontology term enrichment", "content": "[GOrilla][1] makes nice pictures.\n\n\n  [1]: http://cbl-gorilla.cs.technion.ac.il/", "date": "2010-03-24 14:37:13", "action": 0, "post": 447}}, {"pk": 590, "model": "server.postrevision", "fields": {"author": 176, "tag_string": "", "title": "A: Which R packages, if any, are best for parallel computing ?", "content": "If you know a little python or are interested in learning, you can use the mpi4py and rpy packages. The first one provides access to the MPI library for parallel computing very simply and the second allows you to use R from within your python program. With both you can do a lot ...", "date": "2010-03-24 14:44:20", "action": 0, "post": 448}}, {"pk": 591, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "", "title": "A: Tools to find gene ontology term enrichment", "content": "Like several of the others I also recommend DAVID to wet lab biologists. It is well maintained, but you should check the version on the particular species annotation(s) they are currently using as it it sometimes not the latest.\n\nThey use a variant of the Fisher exact statistic for their p-value calculations called the EASE score which they wrote up in a paper a few years back http://www.ncbi.nlm.nih.gov/pubmed/14519205 which is more conservative that the standard.", "date": "2010-03-24 14:51:19", "action": 0, "post": 449}}, {"pk": 592, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: Is there a site where call for papers and conferences are listed in one place?", "content": "Just heard of [ResearchRaven][1] : A Place to Announce Upcoming Meetings and Calls for Papers. \n\n\n  [1]: http://www.researchraven.com/", "date": "2010-03-24 15:45:11", "action": 0, "post": 450}}, {"pk": 593, "model": "server.postrevision", "fields": {"author": 178, "tag_string": "college project", "title": "Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "content": "This is more of a general question as I am new to this site.  I teach at a community college and am trying to determine some projects that 1st year and 2nd year biology students could do.  Ideally, the project would be able to be continuous as 1. the turnover rate for the students would be pretty quick and 2. this couldn't be research done at universities.  \n\nOne thought I had involved the periodical cicadas.  These cicadas have life cycles where they are underground for either 13 or 17 years.  As a result, there are different populations of cicadas that are genetically isolated from each other.  One population will come out in 2011, another one in 2013 etc. etc.  When the populations emerge varies from state to state.  \n\nWould there be any value to sequencing these different populations?  What type of analysis would I do for each one?  There are a lot of details to be figured out and I would have to write a grant to get some equipment. I would also partner with a local university to see if I could use some of their equipment. Before I start trying to figure out the smaller details though, I just wanted some feedback to see if this would be worthwhile and what are some other details I may not have thought of.\n\nThe only other idea I had was sequencing some fungi as this area has not gotten a lot of attention.  Any ideas or comments are welcome.  Thank you!  ", "date": "2010-03-24 16:00:03", "action": 0, "post": 451}}, {"pk": 594, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: Which R packages, if any, are best for parallel computing ?", "content": "I'm dealing with some of the same problems right now - trying to adapt an R package to multi-core machines. I've had some luck using the [multicore/doMC](http://cran.r-project.org/web/packages/doMC/index.html) and [foreach](http://cran.r-project.org/web/packages/foreach/index.html) packages. They essentially take a for loop and parcel out the iterations to multiple cores. This is essentially splitting the input data, not the more implicit parallelism, but seems to work fairly well. This approach  doesn't solve the problem of splitting jobs among multiple cluster nodes, though.\n\nI also looked at R/parallel, but had major problems getting it to work. Lots of cryptic error messages and failure in simple cases that looked just like the vignettes.  I can't recommend it.", "date": "2010-03-24 16:07:09", "action": 0, "post": 452}}, {"pk": 595, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "content": "You seem to be going at this a bit backwards. The first step in science is to make a hypothesis, then choose the appropriate tools to answer it.  That may include genome sequencing, it may not. It seems like you've got a hammer, and you're looking for a nail.\n\nIf you want to study cicadas, start reading up them. Look at the literature and see what other people are studying and what big unanswered cicada questions remain. If you lack access to subscription journals, try your local library, or other [online resources](http://friendfeed.com/references-wanted).  I suspect some of the questions relate to the different cycle lengths - have there been certain genes implicated? Do we know whether it's governed by differential gene expression, genomic factors, or even epigenomics? Has anyone sequenced them already? I'm sure some population geneticists would be interested in divergence patterns between the groups - might help you understand whether they're still the same species, or whether they're slowly splitting apart from each other because of the time differential in emergence.\n\nThe same applies for fungi. Find out what some of the big unanswered questions are, then try to figure out what approach you might take to answer some of them. Then narrow it down further to manageable size projects that a new biologist could handle.\n", "date": "2010-03-24 16:28:03", "action": 0, "post": 453}}, {"pk": 596, "model": "server.postrevision", "fields": {"author": 121, "tag_string": "", "title": "A: How to find all GWAS studies that a given gene has been implicated in?", "content": "While I've looked for this sort of information I've never actually found a reasonable database of this sort of information.  OMIM is close to what you're looking for but its data is woefully sparse.  [SNPpedia][1] is a wikipedia-like website trying to annotate the SNPs implicated in diseases but it is also terribly sparse.\n\nGood luck.\n\n\n  [1]: http://www.snpedia.com", "date": "2010-03-24 16:53:56", "action": 0, "post": 454}}, {"pk": 597, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "college project education", "title": "Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "content": "This is more of a general question as I am new to this site.  I teach at a community college and am trying to determine some projects that 1st year and 2nd year biology students could do.  Ideally, the project would be able to be continuous as 1. the turnover rate for the students would be pretty quick and 2. this couldn't be research done at universities.  \n\nOne thought I had involved the periodical cicadas.  These cicadas have life cycles where they are underground for either 13 or 17 years.  As a result, there are different populations of cicadas that are genetically isolated from each other.  One population will come out in 2011, another one in 2013 etc. etc.  When the populations emerge varies from state to state.  \n\nWould there be any value to sequencing these different populations?  What type of analysis would I do for each one?  There are a lot of details to be figured out and I would have to write a grant to get some equipment. I would also partner with a local university to see if I could use some of their equipment. Before I start trying to figure out the smaller details though, I just wanted some feedback to see if this would be worthwhile and what are some other details I may not have thought of.\n\nThe only other idea I had was sequencing some fungi as this area has not gotten a lot of attention.  Any ideas or comments are welcome.  Thank you!  ", "date": "2010-03-24 16:59:47", "action": 0, "post": 451}}, {"pk": 598, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "content": "It is a brainstorming question, so I will just give my 0.02$.\nThere are a number of fairly simple lab techniques producing useful but often not publishable results. \n\nIf you want to stick with Magicicada, quick look in Animal Genome Size Database http://www.genomesize.com/ reveals that there are no entries for Cicadidae.\nSo measuring of DNA content, counting chromosomes will be both new and useful for downstream DNA sequencing projects. \n\n\nYes, having genomic sequences for species with such life-cycles will be great for chronobiology. But it is a bit over the top as a student project. \n\nAt this point [NCBI][1] list just 19 nucleotide sequences for all Magicicada. So yes, you can contribute sequencing almost anything from any of these species, but if this is supposed to be more than an exercise in DNA extraction, subcloning and feeding sequencing machines then you will have to pick something interesting. \n\nLike sequencing as many as possible genes responsible for molecular clock. But then you are again on square one: complicated project requiring substantial funding.    \n  \n\n  [1]: http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=38085", "date": "2010-03-24 17:07:42", "action": 0, "post": 455}}, {"pk": 599, "model": "server.postrevision", "fields": {"author": 72, "tag_string": "peer articles journals", "title": "Are there websites which allow users to post comments on peer-reviewed articles?", "content": "I am looking for something like Amazon User Reviews but for journal articles.", "date": "2010-03-24 17:25:03", "action": 0, "post": 456}}, {"pk": 600, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "call papers conferences research not related", "title": "Is there a site where call for papers and conferences are listed in one place?", "content": "Is there an easy way to find out about current calls for papers and conferences? I find it incredibly frustrating every time I find an interesting conference announcement and see that the call for papers deadline expired the day before, or is too soon to prepare a paper for submission. Is there a global collection of bioinformatics related conferences somewhere?", "date": "2010-03-24 17:26:13", "action": 0, "post": 435}}, {"pk": 601, "model": "server.postrevision", "fields": {"author": 178, "tag_string": "", "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "content": "I don't know of any, but I am not as well versed in these areas as others here are - sounds like a great idea if there aren't any websites though!", "date": "2010-03-24 17:29:36", "action": 0, "post": 457}}, {"pk": 602, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "content": "Well, http://www.connotea.org and http://www.citeulike.org both allow you to add a comment to any article/site .\nI also found http://acawiki.org/Home in my bookmarks: \n> AcaWiki is like a \"Wikipedia for\n> academic research\" designed to\n> increase the impact of scholars,\n> students, and bloggers by enabling\n> them to share summaries and discuss\n> academic papers online\n\nand the ooooooold Annotea http://www.w3.org/2001/Annotea (only works for GET urls...)\n", "date": "2010-03-24 17:38:37", "action": 0, "post": 458}}, {"pk": 603, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "content": "The [PLoS Journals](http://www.plos.org/) let you comment on the articles directly.", "date": "2010-03-24 17:40:43", "action": 0, "post": 459}}, {"pk": 604, "model": "server.postrevision", "fields": {"author": 163, "tag_string": "", "title": "A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "content": "A good place for information on cicadas is [Chris Simon's web site](http://hydrodictyon.eeb.uconn.edu/projects/cicada/simon_lab/lab_pages/current.php). She maintains [Cicada Central](http://hydrodictyon.eeb.uconn.edu/projects/cicada/cc.php) which has loads of resources. You might also take a look at a recent PLoS ONE paper from her lab [doi:10.1371/journal.pone.0000892](http://dx.doi.org/10.1371/journal.pone.0000892). Chris might have some suggestions on possible projects.", "date": "2010-03-24 17:40:47", "action": 0, "post": 460}}, {"pk": 605, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "", "title": "A: Is there any useful information to be gathered analyzing the genomes of different populations of cicadas?", "content": "This question is somewhat fortuitous. I have a paper on Physica A with a automata model for *Magicicada*. Of course, to build the model we discussed a lot the underlying genetic architecture and possible ecological scenarios. It's a fair complicated problem. Despite plentiful cirscunstancial evidence, there are no sound ones for the underlying genetics. No clue about the biological clock, too. And aging and lifecycle are tipically governed by nontrivial QTL.\n<p>\nNevertheless, would be fantastic if you could track down the evolution of this two populations, phylogenetically speaking. This can be done at protein level and/or DNA level with just gels, PCR and Sanger sequencing. It's low resolution, but works.\n<p> This will be a great opportunity to teach evolutionary theory, ecology and scientific methodology. I can sure help with specific details.", "date": "2010-03-24 17:40:58", "action": 0, "post": 461}}, {"pk": 606, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "content": "The [PLoS Journals](http://www.plos.org/) let you comment on the articles directly, which I suppose is like reviewing an amazon product on its page.", "date": "2010-03-24 17:46:49", "action": 0, "post": 459}}, {"pk": 607, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "content": "Well, http://www.connotea.org and http://www.citeulike.org both allow you to add a comment to any article/site .\nI also found http://acawiki.org/Home in my bookmarks: \n> AcaWiki is like a \"Wikipedia for\n> academic research\" designed to\n> increase the impact of scholars,\n> students, and bloggers by enabling\n> them to share summaries and discuss\n> academic papers online\n\nGoogle side wiki ? http://www.google.com/sidewiki/intl/en/index.html\n\nand the ooooooold Annotea http://www.w3.org/2001/Annotea (only works for GET urls...)\n", "date": "2010-03-24 17:59:47", "action": 0, "post": 458}}, {"pk": 608, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: Tools to find gene ontology term enrichment", "content": "I think most of the enrichment analysis tools deals with same class of statistics methods (p-value, FDR, Boneferroni etc). Defining background is a very important in such enrichment methods. To get real meaning of enrichment with respect to your experiments, you should be able to upload the background. For example, if you are looking at a set of a genes from a particular tissue, a background of that tissue give more meaningful results than a background of whole genome.", "date": "2010-03-24 18:18:41", "action": 0, "post": 462}}, {"pk": 609, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "I would like to recommend the following books to any one who is interested in Bioinformatics (Not in order): \n\n1. [Genes, Proteins and Computers][1] : A concise introduction to the subject, mainly from a biological view point, yet provide a solid understanding of fundamental concepts in biology, computing, algorithm and statistics related to bioinformatics. Must read. \n2. [Bioinformatics by David Mount][2] : A very detailed account of bioinformatics concepts. I think its high time to revise this book. I am looking forward for the next edition. You should have a copy of this if you are Masters' or PhD in Bioinformatics. \n3. [Bioinformatics : Unix/Linux, Data Processing and Programming][3] : This is a cute little book that gives you an edge over Unix, linux, basic data processing and little bit of Perl programming. I appreciate this book for its handy examples. Highly recommend to those who are from biology and interest to get their hands on programming. \n4. [Bioinformatics : Machine learning approaches][4] Machine learning is now an integral part of bioinformatics and bioinformatics is an emerging area for the application of machine learning techniques. For computer science students : here is the real dose of bioinformatics algorithms. One of the first authentic books on bioinformatics algorithms. \n5. [An Introduction to Bioinformatics Algorithms][5] This one is my favorite, especially the pseudocode section and classification of algorithms and its concise description. Book features extensive content on the algorithms used in bioinforamtics categorized into different groups with interesting cartoons. A unique concept introduced in the book is profile of the authors. If you are really in to bioinformatics algorithms, this should be on your desk. \n\nPS. I have couple of more like [Computational Genome Analysis][6], [Programming Collective Intelligence][7] etc. But they are more of specialized in to different sub-domains of bioinformatics. \n\n  [1]: http://www.amazon.com/Bioinformatics-Genes-Proteins-Computers-Advanced/dp/1859960545\n  [2]: http://www.amazon.com/Bioinformatics-Sequence-Analysis-David-Mount/dp/0879696087\n  [3]: http://www.springer.com/life+sciences/bioinformatics/book/978-3-540-21142-6\n  [4]: http://books.google.com/books?id=pxSM7R1sdeQC&dq=Pierre+baldi+%2B+bioinformatics&printsec=frontcover&source=bn&hl=en&ei=IoGRS6uCIJT-NYLA8Z0N&sa=X&oi=book_result&ct=result&resnum=4&ved=0CBUQ6AEwAw#v=onepage&q=&f=false\n  [5]: http://mitpress.mit.edu/catalog/item/default.asp?tid=10337&ttype=2\n  [6]: http://www.amazon.com/Computational-Genome-Analysis-Introduction-Statistics/dp/0387987851\n  [7]: http://oreilly.com/catalog/9780596529321", "date": "2010-03-24 18:32:00", "action": 0, "post": 195}}, {"pk": 610, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "I've never found a good bioinformatics book.\n\nAll the books I've glanced  :\n\n  -  were too much theoretical\n  -  were too much trivial\n  -  don't have enough examples (code...)\n  -  only used perl\n  -  ...\n\nat the end, I learned much more at reading the blogs and the IT sites.\n", "date": "2010-03-24 18:48:27", "action": 0, "post": 463}}, {"pk": 611, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "content": "[Bosco Ho][1]'s **ANNOTATR** :\n\nhttp://annotatr.appspot.com/\n\n\n  [1]: http://boscoh.com/", "date": "2010-03-24 18:53:23", "action": 0, "post": 464}}, {"pk": 612, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "tips data practical", "title": "Tips to build a data storage for bioinformatics", "content": "Storing large amounts of data will become a problem for the bioinformatics, sooner or later. I've faced this problem recently and a lot of questions that I've never thought before just surfaced. The most obvious are:\nHow to decide the filesystem? How to partition a large (TB range) HD? When is a cheap solution (e. g. a bunch of low-end HDs) inappropriate?\n<p>\nThese are pressing issues here at brazilian medical community. Everyone wants to buy a NGS machine, mass spec or microarray but no one perceives the forthcomming data flood. \n<p>\nIn practical terms, how do you store your data? A good reason for a given decision would be great too.\n\n\n", "date": "2010-03-24 19:07:25", "action": 0, "post": 465}}, {"pk": 613, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "", "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "content": "Alternatively, you can blog about the article. Websites like [ResearchBlogging][1], [Chemical blogspace][2] and [NatureBlogs][3], and the PLoS journals will index those blogs and link the comments to the papers. Using userscripts you can have those comments show up on the journal website when you use your [GreaseMonkey][4]-enabled browser (e.g. [Firefox][5] or [Chrome][6]) to look at the article website (see doi:[10.1186/1471-2105-8-487][7]).\n\nAn example screenshot of a journal ToC:\n![alt text][8]\n\n  [1]: http://researchblogging.org/\n  [2]: http://cb.openmolecules.net/papers.php\n  [3]: http://blogs.nature.com/\n  [4]: http://en.wikipedia.org/wiki/Greasemonkey\n  [5]: http://firefox.com\n  [6]: http://www.google.com/chrome\n  [7]: http://www.biomedcentral.com/1471-2105/8/487\n  [8]: http://blueobelisk.sourceforge.net/wiki/images/6/60/CBandPG.png", "date": "2010-03-24 19:53:31", "action": 0, "post": 466}}, {"pk": 614, "model": "server.postrevision", "fields": {"author": 116, "tag_string": "", "title": "A: Tips to build a data storage for bioinformatics", "content": "I'm not an expert sysadmin, but here's something to consider: If you're connecting a file server to a cluster of compute nodes, don't forget to provide scratch space on each compute machine. This will allow users to do I/O intensive operations locally, rather than saturating the network and your disks with requests.", "date": "2010-03-24 19:58:24", "action": 0, "post": 467}}, {"pk": 615, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "", "title": "A: Is there a site where call for papers and conferences are listed in one place?", "content": "<p>You can find a listing at http://www.bioinformatics.fr/events.php.</p>\n<p>I try to update it during my spare time.</p>\n<p>There is an associated RSS Feed.</p>\n\n", "date": "2010-03-24 20:04:44", "action": 0, "post": 468}}, {"pk": 616, "model": "server.postrevision", "fields": {"author": 91, "tag_string": "markov", "title": "Markov chain for generating random protein sequences", "content": "I have 1000+ protein sequences. I want to generate random sequences using a Markov model based on residue transitions found my sequences. I'm told Matlab will make a Markov chain based on multiple sequences, but I would like to use a free alternative to Matlab (python, ruby, R, etc). Can anyone provide me with a library or module?", "date": "2010-03-24 20:05:25", "action": 0, "post": 469}}, {"pk": 617, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "markov chain", "title": "Markov chain for generating random protein sequences", "content": "I have 1000+ protein sequences. I want to generate random sequences using a Markov model based on residue transitions found my sequences. I'm told Matlab will make a Markov chain based on multiple sequences, but I would like to use a free alternative to Matlab (python, ruby, R, etc). Can anyone provide me with a library or module?", "date": "2010-03-24 20:07:11", "action": 0, "post": 469}}, {"pk": 618, "model": "server.postrevision", "fields": {"author": 85, "tag_string": "", "title": "A: Tips to build a data storage for bioinformatics", "content": "You might check out this blog post about using Amazon Web Services for analysis of NGS data: http://defsci.blogspot.com/2010/01/ruby-aws-easy-map-reduce.html\n\nNot directly about data storage per se, but certainly your NGS analysis strategy affects your data storage needs...", "date": "2010-03-24 20:25:11", "action": 0, "post": 470}}, {"pk": 619, "model": "server.postrevision", "fields": {"author": 179, "tag_string": "", "title": "A: What phylogeny viewing software do you use?", "content": "I really have one main usage for TreeViewX, and that is to quickly visualize a tree from the clipboard when I'm coding. I used TreeView for that previously, but I think I can't run that any more on my new OSX version (10.7 Pussycat or whatever). I vaguely miss the ability to show unrooted trees, which TreeView used to have but the X version doesn't seem to. All in all I find either very handy for this one use case. Other programs (e.g. mesquite) just aren't lightweight and quick enough.", "date": "2010-03-24 20:46:40", "action": 0, "post": 471}}, {"pk": 620, "model": "server.postrevision", "fields": {"author": 73, "tag_string": "", "title": "A: How do you explain what you do to the guy on the street or your mum?", "content": "My person-on-the-street explanation would include where I work, the term Bioinformatics, and something like \"I use computers to analyze biological data so we can better understand how life works\". I tend to emphasize that I like my job, I find it interesting, and that the complexity of life continues to amaze me.\n\nAs I'm explaining, I feel, nervous, proud, and afraid they won't understand. \n\nI am also slightly afraid they might think I am evil and enjoy killing cuddly animals and/or babies.", "date": "2010-03-24 20:47:16", "action": 0, "post": 472}}, {"pk": 621, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: How to find all GWAS studies that a given gene has been implicated in?", "content": "AFAIK, [dbGAP][1] is one of the official resource for GWAS studies. A mere gene search may not fetch the exact details about the studies. Dataset from large scale GWAS studies are not available under public access due to sensitive genotype and phenotype data from patients. You have to write to individual investigators to get access to the data. Usually this data will be available only after the Embargo Release date. This is usually after 1year of the submission of the data. I think once you have access to the dataset, you will able to get the p-values of the SNPs genotyped in the whole study with the de-identified case/control and their phenotypes. These SNPs may need further mapping to get the details about the genes. \n\n[NHGRI website][2] provides A Catalog of Published Genome-Wide Association Studies: They provide a detailed table of GWAS and their details. As of 03/24/10, this table includes 517 publications and 2443 SNPs. You may map this SNPs to get the respective genes. \n\nAlso this [manuscript][3] provides results from various GWAS studies. \n\nI am looking forward for other comments to know if there is any public resource that provides GWAS data. \n\n\n  [1]: http://www.ncbi.nlm.nih.gov/gap\n  [2]: http://www.genome.gov/26525384\n  [3]: http://www.biomedcentral.com/1471-2350/10/6", "date": "2010-03-24 20:51:05", "action": 0, "post": 428}}, {"pk": 622, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Tips to build a data storage for bioinformatics", "content": "You are very much right, and secure and reliable storage *is* already a problem. Im not a sysadmin person but got some insight from my work. Here is a little overview how it might [have looked in 2007 for a medium size setup][1] (this is a bit dated but I am sure it became just much bigger ;) ). \n\nBTW: I don't believe there much difference in requirements between bioinformatics storage and any other large scientific/business data. So, to get recommendations about top brands in storage better ask this on a sys-admin board, I guess there are some. \n\nMaybe most important about storage: \nStorage is nothing without a proper backup solution. And the backup systems are often much more expensive than the disks because you need some overhead for incremental backups. \nAnd that need to be taken care of by some admin.\n\nA tape archive system could also be used to store rarely used data.\n\nIf possible use an extensible solution and at that time that was some hotswappable RAID  (5?? or so) array disks. Why hot-swappable? Because disks fail and then it's nice to be able to replace them. \n\nFor data transfer of terabytes, fast connections are needed and that was fibre-channel. Redundant file servers are also nice to have. As you are working in a hospital, there\nmight be even sensitive person related data, so you might even have to think about cryptographic file systems.\n\nOf course this is sort of a maximum scenario and one can work with less. On my small  linux machines I am using Ext3 fs on some TB without many problems, also UFS worked very robust on FreeBSD and Mac.  \n\nbut as you say, your institute bought a/some highly expensive machines, the follow up costs must be considered. So if there is an application for research grants for a new -omics-machine (can call it ferrari too) then you have to be willing to pay the fuel, sorry the infrastructure and sysadmins.\n\n\n\n\n  [1]: http://www.cebitec.uni-bielefeld.de/brf/infrastructure/infrastructure.html", "date": "2010-03-24 21:03:21", "action": 0, "post": 473}}, {"pk": 623, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "sql bioinformatics server public resources", "title": "What are the public SQL servers for bioinformatics ?", "content": "Do you know any **public** scientific SQL server ?\n\nfor example, I would cite:\n\n - UCSC\thttp://genome.ucsc.edu/FAQ/FAQdownloads#download29\n - ENSEMBL\thttp://uswest.ensembl.org/info/data/mysql.html\n - GO\thttp://www.geneontology.org/GO.database.shtml#mirrors\n\n(I'll give a +1 to each correct answer)\n", "date": "2010-03-24 21:19:55", "action": 0, "post": 474}}, {"pk": 624, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "(Sorry, this is not an add, even if it sound like...)\n\nMy favourite bioinformatics book is a biology book [Lewin's Genes X][1]. Of course it's not a bioinformatics book, but is very good for getting a good understanding of the biology. Bio-informatics is an interdisciplinary field and for me, it is the fascination of the related genetics that motivates me to analyse it. I see the computer science as a means ti analyse genetics. This book can provide the necessary insight into genetics required for good bioinformatics. I cannot read this from cover to cover, it's just too much information, but it provides different levels of detail. Even when reading only the headlines, one could learn something new.\n\nMaybe not so well suited for absolute beginners in genetics, and some biologists say it is superficial sometimes. Might be, but that I cannot judge, I just found the parts I read well understandable. There are of course lots of references (rather many to \"Cell\").\n\n\n  [1]: http://www.jbpub.com/catalog/9780763766320/", "date": "2010-03-24 21:25:18", "action": 0, "post": 475}}, {"pk": 625, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "(Sorry, this is not an add, even if it sound like...)\n\nMy favourite bioinformatics book is a biology book [Lewin's Genes X][1]. Of course it's not a bioinformatics book, but is very good for getting a good understanding of the biology. Bio-informatics is an interdisciplinary field and for me, it is the fascination of the related genetics that motivates me to analyse it. I see computer science as a means to better understand genetics. This book can provide the necessary insight into genetics required for good bioinformatics. I cannot read this from cover to cover, it's just too much information, but it provides different levels of detail. Even when reading only the headlines, one could learn something new.\n\nMaybe not so well suited for absolute beginners in genetics, and some biologists say it is superficial sometimes. Might be, but that I cannot judge, I just found the parts I read well understandable. There are of course lots of references (rather many to \"Cell\").\n\n\n  [1]: http://www.jbpub.com/catalog/9780763766320/", "date": "2010-03-24 22:07:16", "action": 0, "post": 475}}, {"pk": 626, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "", "title": "A: What are the public SQL servers for bioinformatics ?", "content": "Flybase has direct access to its postgres chado database.\n\nhttp://flybase.org/forums/viewtopic.php?f=14&t=114\n \nhostname: flybase.org\nport: 5432\nusername: flybase\npassword: no password\ndatabase name: flybase\n\ne.g.\npsql -h flybase.org -U flybase flybase", "date": "2010-03-24 22:18:05", "action": 0, "post": 476}}, {"pk": 627, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Markov chain for generating random protein sequences", "content": "It seems Python programmers like writing Markov generators.  I often see this topic pop up on Python blogs in the context of generating pseudo random text. A quick search shows a few hits:\n\n - [Markov chains][1]\n - [Pseudo random text generator][2]\n - [Markov chains in python][3]\n - [Markov chain algorithm][4]\n\nI guess you would only need to change to tokenizer to split on letters rather than words.\n\n  [1]: http://www.evanfosmark.com/2009/11/python-markov-chains-and-how-to-use-them/\n  [2]: http://uswaretech.com/blog/2009/06/pseudo-random-text-markov-chains-python/\n  [3]: http://justinbozonier.posterous.com/markov-chains-in-python\n  [4]: http://code.activestate.com/recipes/194364-the-markov-chain-algorithm/", "date": "2010-03-24 23:06:53", "action": 0, "post": 477}}, {"pk": 628, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: What are the public SQL servers for bioinformatics ?", "content": "[PublicHouse][1] - uses the [BioWarehouse][2] system; requires user registration.\n\n\n  [1]: http://biowarehouse.ai.sri.com/PublicHouseOverview.html\n  [2]: http://biowarehouse.ai.sri.com/index.html", "date": "2010-03-25 00:44:54", "action": 0, "post": 478}}, {"pk": 629, "model": "server.postrevision", "fields": {"author": 141, "tag_string": "assembly unambiguous fastq ngs sequencing", "title": "Unambiguous assembly of next-gen fastq reads into fastq contigs?", "content": "Hi,\n\nDoes anybody know of any tool that will produce an unambiguous assembly of next-gen fastq files and give the assembled output back as fastq with consensus/combined scores?\n\nBy unambiguous I mean something like this in abyss:\n\nABYSS -k$k -b0 -t0 -e0 -c0\n\nCheers,\n\nAlbert. ", "date": "2010-03-25 07:09:27", "action": 0, "post": 215}}, {"pk": 630, "model": "server.postrevision", "fields": {"author": 184, "tag_string": "statistic", "title": "amino acid content statistical test", "content": "I would like to compare the amino acid and the codon usage content between two organisms.\nWhat statistical test would be appropriate for this purpose? And what are the inputs needed?", "date": "2010-03-25 07:34:14", "action": 0, "post": 479}}, {"pk": 631, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: amino acid content statistical test", "content": "I recommend that you study the work of Jean Lobry, who has done a lot of work in this area.\n\nSearch PubMed for \"Lobry JR[AU]\" or see his [partial list of publications][1].\n\nHe has also written an R package called [seqinR][2] which contains many methods for statistical analysis of sequences, including composition. Read the documentation, in particular chapter 9 on multivariate analysis.\n\n\n  [1]: http://pbil.univ-lyon1.fr/members/lobry/\n  [2]: http://seqinr.r-forge.r-project.org/", "date": "2010-03-25 07:57:13", "action": 0, "post": 480}}, {"pk": 632, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "statistics sequence", "title": "amino acid content statistical test", "content": "I would like to compare the amino acid and the codon usage content between two organisms.\nWhat statistical test would be appropriate for this purpose? And what are the inputs needed?", "date": "2010-03-25 08:01:20", "action": 0, "post": 479}}, {"pk": 633, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "", "title": "A: What are the public SQL servers for bioinformatics ?", "content": "This is quite an important one for people doing mouse work, though it is important to note that JAX offer Mart and Batch-Query functionality through the web site as well which may well suit many peoples needs.\n\n - Direct SQL Access to MGI\n - http://www.informatics.jax.org/software.shtml#sql\n\nNote that this is a public 'free' service, but that you do need to contact user support to get your login and password. They can also provide some custom SQLs to you if you contact user support.", "date": "2010-03-25 09:37:15", "action": 0, "post": 481}}, {"pk": 634, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "", "title": "A: Are there websites which allow users to post comments on peer-reviewed articles?", "content": "All of the BioMed Central journals accept comments on journal articles, so that is currently 207 journals.\n\nThey have a policy on comments which you can access here :-\n\nhttp://www.biomedcentral.com/info/about/commentpolicy", "date": "2010-03-25 09:41:26", "action": 0, "post": 482}}, {"pk": 635, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "statistic test r standard", "title": "test whether the variance in a group is lower than in another", "content": "I have two groups of data (not distributed under a normal distribution): I would like to test the hypothesis that the first group has a lower (or narrower) standard deviation than the other.\n\nAn alternative explanation to this is that I would like to tell whether the first group is less 'variable', 'heterogeneous', than the first. \n\nA [kruskal-wallis][1] won't do it because it compares the medians of two or more groups, and I am not interested in that.\n\nA [Levene][2] or a [Brown-Forsynth][3] test compare the variance between the two groups and tell whether they have the same variance. This is better, but I would also like to tell if the variance in the first group is lower than in the other(s) group(s).\n\nA simple [Chi-Square][4] test would tell me whether the standard deviation of a group is equal to a certain value, and the one-tailed version can tell me whether it is higher/lower.\n\nAn additional difficulty is that I would have to do this test as a two-way, because I have two grouping variables, but I would like to ask you if you can point me to any direction or give me some hint, I have not many ideas on where to search :-)\n\n\n  [1]: http://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_test\n  [2]: http://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm\n  [3]: http://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test\n  [4]: http://www.itl.nist.gov/div898/handbook/eda/section3/eda358.htm", "date": "2010-03-25 11:31:01", "action": 0, "post": 483}}, {"pk": 636, "model": "server.postrevision", "fields": {"author": 119, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "I really like [Biological Sequence Analysis, Durbin et al.][1] and, although not really bioinformatics-specific, I found [Perl Medic, Peter J. Scott][2] made a big difference to my newbie Perl code. For biology text books, I mainly relied on [Lewin][3] and [Alberts][4] for background during my undergrad.\n\n\n  [1]: http://www.amazon.co.uk/Biological-Sequence-Analysis-Probabilistic-Proteins/dp/0521629713\n  [2]: http://www.amazon.co.uk/Perl-Medic-Maintaining-Inherited-Code/dp/0201795264\n  [3]: http://www.amazon.co.uk/Genes-IX-Benjamin-Lewin/dp/0763752223\n  [4]: http://www.amazon.co.uk/Molecular-Biology-Cell-Bruce-Alberts/dp/0815341067/ref=sr_1_1?ie=UTF8&s=books&qid=1269517727&sr=1-1", "date": "2010-03-25 11:50:50", "action": 0, "post": 484}}, {"pk": 637, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: test whether the variance in a group is lower than in another", "content": "Look for the F-test or [Bartlett's test][1]. As your data is non-normal you need something more robust against deviation from normality. [Leven's test is for example mentioned as an alternative][2]\n\n\n  [1]: http://en.wikipedia.org/wiki/Bartlett%27s_test\n  [2]: http://en.wikipedia.org/wiki/Levene_test", "date": "2010-03-25 11:54:05", "action": 0, "post": 485}}, {"pk": 638, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "statistics testing r standard", "title": "test whether the variance in a group is lower than in another", "content": "I have two groups of data (not distributed under a normal distribution): I would like to test the hypothesis that the first group has a lower (or narrower) standard deviation than the other.\n\nAn alternative explanation to this is that I would like to tell whether the first group is less 'variable', 'heterogeneous', than the first. \n\nA [kruskal-wallis][1] won't do it because it compares the medians of two or more groups, and I am not interested in that.\n\nA [Levene][2] or a [Brown-Forsynth][3] test compare the variance between the two groups and tell whether they have the same variance. This is better, but I would also like to tell if the variance in the first group is lower than in the other(s) group(s).\n\nA simple [Chi-Square][4] test would tell me whether the standard deviation of a group is equal to a certain value, and the one-tailed version can tell me whether it is higher/lower.\n\nAn additional difficulty is that I would have to do this test as a two-way, because I have two grouping variables, but I would like to ask you if you can point me to any direction or give me some hint, I have not many ideas on where to search :-)\n\n\n  [1]: http://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_test\n  [2]: http://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm\n  [3]: http://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test\n  [4]: http://www.itl.nist.gov/div898/handbook/eda/section3/eda358.htm", "date": "2010-03-25 11:54:29", "action": 0, "post": 483}}, {"pk": 639, "model": "server.postrevision", "fields": {"author": 72, "tag_string": "c", "title": "Which C++ libraries are best for dealing with fastq files?", "content": "I would like to rewrite some perl scripts into something faster. I haven't written C++ since the Clinton administration. Granted I am not married to C++ per se but I would need something that benchmarks well.\n\nWhich C++ libraries are people using to deal with NGS data?\n\n", "date": "2010-03-25 13:51:09", "action": 0, "post": 486}}, {"pk": 640, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "", "title": "A: test whether the variance in a group is lower than in another", "content": "You can try a Friedman test at first for each factor (assuming they're independent) and, given that really there is some difference, proceed and adequate multiple hypothesis testing using Bonferroni method, for example. Not a sequential hypothesis testing like we usually do with microarray data. You'll need to specifiy all concurrent hypothesis (variance =, <, >) and significance/power levels.\n\nI don't know much about your experimental/test design. You could furnish additional detais.", "date": "2010-03-25 13:59:26", "action": 0, "post": 487}}, {"pk": 641, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "c fastq parser", "title": "Which C++ libraries are best for dealing with fastq files?", "content": "I would like to rewrite some perl scripts into something faster. I haven't written C++ since the Clinton administration. Granted I am not married to C++ per se but I would need something that benchmarks well.\n\nWhich C++ libraries are people using to deal with NGS data?\n\n", "date": "2010-03-25 14:08:58", "action": 0, "post": 486}}, {"pk": 642, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "c fastq", "title": "Which C++ libraries are best for dealing with fastq files?", "content": "I would like to rewrite some perl scripts into something faster. I haven't written C++ since the Clinton administration. Granted I am not married to C++ per se but I would need something that benchmarks well.\n\nWhich C++ libraries are people using to deal with NGS data?\n\n", "date": "2010-03-25 14:09:23", "action": 0, "post": 486}}, {"pk": 643, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "", "title": "A: Which C++ libraries are best for dealing with fastq files?", "content": "I wouldn't dream of doing this I admit, I tend to handle fastq files with applications other people develop.\n\nHowever there is a FASTA/FASTQ c++ parser here:\n\n[http://lh3lh3.users.sourceforge.net/parsefastq.shtml][1] which might serve as a base for what you want to do.\n\nIt's from Heng Li who also works on SAMtools, BWA and MAQ\n\n\n  [1]: http://lh3lh3.users.sourceforge.net/parsefastq.shtml", "date": "2010-03-25 14:10:58", "action": 0, "post": 488}}, {"pk": 644, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "c fastq ngs", "title": "Which C++ libraries are best for dealing with fastq files?", "content": "I would like to rewrite some perl scripts into something faster. I haven't written C++ since the Clinton administration. Granted I am not married to C++ per se but I would need something that benchmarks well.\n\nWhich C++ libraries are people using to deal with NGS data?\n\n", "date": "2010-03-25 14:14:45", "action": 0, "post": 486}}, {"pk": 645, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "", "title": "A: Which C++ libraries are best for dealing with fastq files?", "content": "I saw a SeqAn poster at ISMB last year. No experience with the library (nor C++) myself but they support the fastq format and they made the impression that they are quite competent.\n\n[SeqAn file formats][1]\n\n\n  [1]: http://www.seqan.de/dddoc/html/TAG_File+_Format.html", "date": "2010-03-25 14:44:17", "action": 0, "post": 489}}, {"pk": 646, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "", "title": "A: What is your experience with bioinformatics webservices?", "content": "We're currently gearing up to implement some of our fragmented analyses into Taverna workflows. The motivation for us is to provide web applications for both ourselves and other community members (for both dry and wet lab people) to get the most out of our high throughput data sources. There is no denying that part of this motivation is not purely philanthropic, but also to raise the impact of our work which makes our funders happy.\n\nFrom a technical point of view we are having to implement our own web services from quite a wide range of sources; mainly Perl, C, C++ and R. Some of these are quite easy to do fairly directly with SOAP/WDSL (especially for Perl). Others like R can take advantage of some recent tools such as RShell http://www.ncbi.nlm.nih.gov/pubmed/19607662. The hardest is implementing new algorithms in C or C++ into usable web services, which we really are feeling our way around at the moment.", "date": "2010-03-25 15:20:23", "action": 0, "post": 490}}, {"pk": 647, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "", "title": "A: Which software development technique is used in your lab? ", "content": "We use an agile technique with SVN using the Eclipse development suite http://www.eclipse.org/, the SVN-Team plugin http://www.eclipse.org/subversive/ and either sourceforge or an internal SVN service.\n\nOur team work tends to be done face to face, though we do have a personal wiki and use google apps as well.", "date": "2010-03-25 15:42:08", "action": 0, "post": 491}}, {"pk": 648, "model": "server.postrevision", "fields": {"author": 185, "tag_string": "", "title": "A: Is there a site where call for papers and conferences are listed in one place?", "content": "I found this one few days ago : http://www.wikicfp.com/\nI found it ok, also you have to check 2 categories : bioinformatics and computational biology", "date": "2010-03-25 16:29:02", "action": 0, "post": 492}}, {"pk": 649, "model": "server.postrevision", "fields": {"author": 168, "tag_string": "", "title": "A: What are the public SQL servers for bioinformatics ?", "content": "This is quite an important one for people doing mouse work, though it is important to note that JAX offer Mart and Batch-Query functionality through the web site as well which may well suit many peoples needs.\n\n - Direct SQL Access to MGI\n - http://www.informatics.jax.org/software.shtml#sql\n\nNote that this is a public 'free' service, but that you do need to contact user support to get your login and password. They are also happy to provide some custom SQL scripts to get you started.", "date": "2010-03-25 16:50:09", "action": 0, "post": 481}}, {"pk": 650, "model": "server.postrevision", "fields": {"author": 163, "tag_string": "", "title": "A: Recommend your favorite bioinformatics books", "content": "I've learnt pretty much everything from doing, i.e. programming, and rely heavily on online resources. There have been occasional programming books that I've used to bootstrap learning about a language (especially if it was a major leap, say from procedural to object-oriented languages, or from standalone application programming to web scripting). Of the bioinformatics books mentioned so far, [Durbin et al., Biological Sequence Analysis](http://rads.stackoverflow.com/amzn/click/0521629713) was the book I got the most out of, especially the section on RNA secondary structure, which I was obsessed with for a time. Good description of the problem, algorithms clearly explained, and pseudocode. Great stuff.\n\nPerhaps off topic, but the books I find most fun and inspiring to read have been more general web-oriented books such as  [Ambient Findability: What We Find Changes Who We Become ](http://rads.stackoverflow.com/amzn/click/0596007655).", "date": "2010-03-25 18:31:18", "action": 0, "post": 493}}, {"pk": 651, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "subjective relief fun", "title": "Which application is truly missing in bioinformatics?", "content": "It's a simple & straight questions. Just think about an app that when you found it, you first thought would be - \"OMG!!! That's it\" - or smth like - \"I wish I could have found/written/idealized it before\". \n\nMy example is quite simple. I really wish that some sort of Monte Carlo Simulator of Generic Urn Models (yeah, population genetics) just appear in the net, with a nice, clean and well documented API (written in C) and bindings for my favorite scripting languages. Hence, a whole new level of information would available for NGS data. That's what I really miss, right now. What's your story?\n\n", "date": "2010-03-25 19:42:11", "action": 0, "post": 494}}, {"pk": 652, "model": "server.postrevision", "fields": {"author": 118, "tag_string": "", "title": "A: Which application is truly missing in bioinformatics?", "content": "    /irony on\nSomething like the following is missing for bioinformatics:\nhttp://pdos.csail.mit.edu/scigen/\n\n    /irony off\n\nSeriously, I think whatever it is, a *clean and well documented API* - as you say - is something it should provide.", "date": "2010-03-25 19:55:48", "action": 0, "post": 495}}, {"pk": 653, "model": "server.postrevision", "fields": {"author": 72, "tag_string": "", "title": "A: Which application is truly missing in bioinformatics?", "content": "I wish R had an entire web application framework like Rails and that there was an easier way to go between genome browsers and analysis and back.\n\nThere are also not enough tools to properly organize individual genetic variation in humans much less poorly characterized species. I guess we'll have to see what 1000 genomes comes up with.", "date": "2010-03-25 20:03:16", "action": 0, "post": 496}}, {"pk": 654, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "subjective relief fun", "title": "Which application is truly missing in bioinformatics?", "content": "It's a simple & straight questions. Just think about an app that when you found it, you first thought would be - \"OMG!!! That's it\" - or smth like - \"I wish I could have found/written/idealized it before\". \n\nMy example is quite simple. I really wish that some sort of Monte Carlo Simulator of Generic Urn Models (yeah, population genetics) just appear in the net, with a nice, clean and well documented API (written in C) and bindings for my favorite scripting languages. Hence, a whole new level of information would be available for NGS data (at least for me). That's what I really miss, right now. What's your story?\n\n", "date": "2010-03-25 20:12:38", "action": 0, "post": 494}}, {"pk": 655, "model": "server.postrevision", "fields": {"author": 118, "tag_string": "", "title": "A: What license do you use when you release code and data?", "content": "I whole-heartedly agree with Pierre's answer w.r.t. what I'd like a licence to say. Be that as it may, I have sometimes used the [Artistic License 2.0][1].\n\n\n  [1]: http://www.opensource.org/licenses/artistic-license-2.0.php", "date": "2010-03-25 20:27:23", "action": 0, "post": 497}}, {"pk": 656, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: Which application is truly missing in bioinformatics?", "content": "I want a [bio2rdf][1] for the whole scientific *corpus*.\n\n\n  [1]: http://bio2rdf.org/", "date": "2010-03-25 20:39:53", "action": 0, "post": 498}}, {"pk": 657, "model": "server.postrevision", "fields": {"author": 72, "tag_string": "", "title": "A: Which application is truly missing in bioinformatics?", "content": "I wish R had an entire web application framework like Rails and that there was an easier way to go between genome browsers and analysis and back.\n\nThere are also not enough tools to properly organize individual genetic variation in humans much less poorly characterized species. I guess we'll have to see what 1000 genomes comes up with.\n\nI would also like a proper \"finishing tool\" to visualize and reconcile Velvet assemblies.", "date": "2010-03-25 21:37:22", "action": 0, "post": 496}}, {"pk": 658, "model": "server.postrevision", "fields": {"author": 65, "tag_string": "", "title": "A: Which application is truly missing in bioinformatics?", "content": "I think it would be incorrect to imagine that there is a single, \"killer app\" for bioinformatics.  I don't see bioinformatics as a field, discipline or topic.  For me it is about:  (1) inputs - many, diverse types of biological data, (2) processes - the code that we write to handle the data and (3) outputs - what the code produces and the subsequent biological interpretation.\n\nThat said, I'm sure there are tools we would all like to see when we handle whatever data type comes our way.  I'd like to see:\n\n 1. A RESTful API for every public, online database\n 2. Better web applications for data integration - so that when I search for, e.g. a gene, everything that's known about that gene and its products is presented to me in a way that enables effective data exploration\n\nThere are those who say that the \"linked data web\" is the answer to (2), which remains to be seen...", "date": "2010-03-26 00:25:36", "action": 0, "post": 499}}, {"pk": 659, "model": "server.postrevision", "fields": {"author": 88, "tag_string": "", "title": "A: Which application is truly missing in bioinformatics?", "content": "I'd like Bioconductor-like repository would exist for MATLAB. Probably not gonna happen. :(", "date": "2010-03-26 00:45:47", "action": 0, "post": 500}}, {"pk": 660, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "", "title": "A: test whether the variance in a group is lower than in another", "content": "You can try a Friedman test at first for each factor (assuming they're independent) and, given that really there is some difference, proceed an adequate multiple hypothesis testing using Bonferroni method, for example. Not a sequential hypothesis testing like we usually do with microarray data. You'll need to specifiy all concurrent hypothesis (variance =, <, >) and significance/power levels.\n\nI don't know much about your experimental/test design. You could furnish additional detais.", "date": "2010-03-26 14:20:34", "action": 0, "post": 487}}, {"pk": 661, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "webservice bioinformatics soap rest subjective", "title": "What is your experience with bioinformatics webservices?", "content": "[Web-services][1] using SOAP or REST style are becoming more and more popular in also bioinformatics. The [Embrace Registry][2] and [BioCatalogue][3] are registries which provide a good overview of publicly available bioinformatics services. They aim at making services easier to describe and find. It is also often heard that web-services provide a platform- and language-independent interface to databases and computation. Furthermore, web-services can be [composed into complex-workflows][4], [used for data-integration,][5] automated user-interface and API-generation, that's at least the theory. How does the reality look for you?\n\nDo you use  SOAP/REST/.NET services in bioinformatics,\nand what are your experiences with the different services and service providers?\n\nMain aspects I am interested in are motivated by my own recent (and very mixed) experiences:\n\n - Did you encounter interoperability or language-dependence problems?\n - How did the providers react?\n - What would make you replace local scripts and tools by web-services?\n\n------\nEdit: I will have difficulties to choose the right answer, because everything said so far is valid.  \n\nHere are some intermediate results. I am testing different SOAP services using Axis2/Java at the moment, using the wsdl2code to generate the Java trying adb and xmlbeans databindings. Maybe this list will grow:\n\n 1. KEGG: wsdl2code: only with xmlbeans , usable: no, couldn't set arrayOfString because use of soapenc:array\n 2. BRENDA: wsdl2code: Error message: Wsdl not WS-I compliant, usable: no\n 3. BioMart soap: wsdl2code: yes, usable: no, after few mods of wsdl-file and tweaking axis2 params could send a valid message, response message is not valid \n\n\n\n  [1]: http://en.wikipedia.org/wiki/Web_service\n  [2]: http://www.embraceregistry.net/\n  [3]: http://www.biocatalogue.org/\n  [4]: http://www.ncbi.nlm.nih.gov/pubmed/16845108\n  [5]: http://www.ncbi.nlm.nih.gov/pubmed/18056132", "date": "2010-03-26 14:59:09", "action": 0, "post": 420}}, {"pk": 662, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "subjective relief fun", "title": "Which application is truly missing in bioinformatics?", "content": "It's a simple & straight questions. Just think about an app that when you found it, you first thought would be - \"OMG!!! That's it\" - or smth like - \"I wish I could have found/written/idealized it before\". Don't need to be a bioinformatical swiss knife or a McGuyver paper clip. Just smth that would make your life much happier/easier.\n\nMy example is quite simple. I really wish that some sort of Monte Carlo Simulator of Generic Urn Models (population genetics rlz!) just appear in the net, with a nice, clean and well documented API (written in C) and bindings for my favorite scripting languages. That's what I really miss, right now. What's your story?\n\n-- Edit --\n\nI'm considering to start a bounty for this question. Maybe the first answer to get 10 up votes. Where are people's whishes? Don't be afraid, bionformaticians like me are lousy critics.", "date": "2010-03-31 18:47:39", "action": 0, "post": 494}}, {"pk": 663, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "fpga hpc reconfigurable", "title": "Hardware resources for HPC in Bioinformatics", "content": "Greetings everybody,\n\nWe're planning to build a very powerful computing machine to serve bioinformatics application here at [HCFMUSP][7] (check my profile). I know that the common choice is to build a cluster or go cloud. But our adventurous spirit urges for some experimentation. We are somewhat envious of proprietary solutions using FPGA cards like these ones:\n\n[CLCbio Cube][1]\n\n[TimeLogic DeCypher][2]\n\n[Pico Computing E-FPGA][3]\n\n\nFor the people who never heard of FPGA I do suggest to check out Wikipedia on these topics:\n\n[Field Programmable Gate Array][4]\n[Reconfigurable Computing][5]\n\nThere are several possible implementations of important algorithms in bioinformatics in those plataforms. This is  just one example:\n\n[160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)][6]\n\n\nDoes anybody have some experience with these cards? Do they scale well? Are they worth the trouble?\n\n\nCheers,\nDaniel\n\n-- Edit --\n\nFinally, my server is online!!! For now it's just some Xeons with lots of RAM. But, in a near future some Tesla/Fermi will be added. Happy !!!\n\n\n  [1]: http://www.clcbio.com/index.php?id=616\n  [2]: http://www.timelogic.com/decypher_intro.html\n  [3]: http://www.picocomputing.com/e_series.html\n  [4]: http://en.wikipedia.org/wiki/Fpga\n  [5]: http://en.wikipedia.org/wiki/Reconfigurable_computing\n  [6]: http://www.biomedcentral.com/1471-2105/8/185\n  [7]: http://www.hcnet.usp.br/", "date": "2010-04-01 14:02:04", "action": 0, "post": 328}}, {"pk": 664, "model": "server.postrevision", "fields": {"author": 215, "tag_string": "gene enrichment tool go", "title": "Tools to find gene ontology term enrichment", "content": "I need to make a recommendation to people working in a wet-lab looking for an easy to use tool that does GO term enrichment determination. For those unfamiliar with the concept it means that given a list of gene names they want to find out which gene ontology terms are present in numbers that are above random chance.\n\nThere is a huge [list here][1] yet a random sampling of the tools mentioned there has lead me to many non-working sites. Other tools seem out of date or just not reliable.\n\nWhat tool do you use to solve this problem?\n\nThanks.\n\n  [1]: http://www.geneontology.org/GO.tools.microarray.shtml", "date": "2010-04-14 13:44:10", "action": 0, "post": 245}}, {"pk": 665, "model": "server.postrevision", "fields": {"author": 215, "tag_string": "subjective gene go", "title": "How much do you trust GeneOntology?", "content": "[GeneOntology][1] is a nice project to provide a standard terminology for genes and gene functions, to help avoid the use of synonyms and wrong spelling when describing a gene.\n\nI have been using the GeneOntology for a while, but honestly I think that it contains many errors and that many terms have not enough terms associated. Moreover, the terminology they use is not always clear and there are some duplications.\n\nIt is frequent to read in article or in slideshows charts were the GO classification is used to infer the properties of a set of genes... But I wonder if the authors check the GO annotations that they use.\n\nWhat is your experience about [GO][2]?\n\n\n  [1]: http://www.geneontology.org/\n  [2]: http://www.geneontology.org/", "date": "2010-04-14 13:44:57", "action": 0, "post": 41}}, {"pk": 666, "model": "server.postrevision", "fields": {"author": 215, "tag_string": "protein sequence multiplealignment scoring", "title": "Score protein variants based on frequency of AA in multiple sequence alignment", "content": "For reference, please read this excerpt from  \n**Human non-synonymous SNPs: server and survey**  \nVasily Ramensky, Peer Bork, and Shamil Sunyaev\n\n\n> *Profile analysis of homologous\n> sequences*. The amino acid replacement\n> may be incompatible with the spectrum\n> of substitutions observed at that\n> position in a family of homologous\n> proteins. PolyPhen identifies\n> homologues of the input sequences via\n> a BLAST (23) search of the NRDB\n> database. The set of aligned sequences\n> with sequence identity to the input\n> sequence in the range 30\u00b194%\n> (inclusive) is used by the new version\n> of the PSIC (position-specific\n> independent counts) software (24) to\n> calculate the so-called profile matrix\n> (http://strand.imb.ac.ru/PSIC/).\n> Elements of the matrix (pro- file\n> scores) are logarithmic ratios of the\n> likelihood of a given amino acid\n> occurring at a particular site to the\n> likelihood of this amino acid\n> occurring at any site (background\n> frequency). PolyPhen computes the\n> absolute value of the difference\n> between profile scores of both allelic\n> variants in the polymorphic position.\n> PolyPhen also shows the number of\n> aligned sequences at the query\n> position; this may be used to assess\n> the reliability of profile score\n> calculations.\n\nI'd like to calculate something similar (score variants based on frequency that AA in aligned sequences) to what's mentioned here **programmatically**, but I can't find any implementation of the above described system.\n\nDoes anyone know of a working implementation of this or something similar, that's available either in code or as a web service?\n\nOr should it is easy enough to implement something like this ourselves?", "date": "2010-04-14 14:47:03", "action": 0, "post": 183}}, {"pk": 667, "model": "server.postrevision", "fields": {"author": 215, "tag_string": "sequence alignment scoring", "title": "Implementation of Blosum62 in the source code of global pairwise alignment of proteins", "content": "Hi,\n\nI am trying to implement protein pairwise sequence alignment using \"Global Alignment\" algorithm by 'Needleman -Wunsch'. I am using VB.NET. \n\nI am not clear about how to include 'Blosum62 Matrix' in my source code to do the scoring or to fill the two-dimensional matrix?\n\nI have googled and found that most people suggested to use flat file which contains the standard 'Blosum62 Matrix'. Does it mean that I need to read from this flat file and fill my coded \"Blosum62 Martrix' ?\n\nAlso, the other approach could be is to use some mathematical formula and include it in your programming logic to construct 'Blosum62 Matrix'. But not very sure about this option.\n\nAny ideas or insights are appreciated.\n\nAlso, is there any pesudo algorithm to do the protein pairwise alignment using Global available? I tired to find the basic steps of the alogrithm online but no luck so I am planning to do the same steps as I did for the global pairwise alignment of Nucleotides\n\nThanks.\n", "date": "2010-04-14 14:47:27", "action": 0, "post": 161}}, {"pk": 668, "model": "server.postrevision", "fields": {"author": 215, "tag_string": "protein sequence multiple scoring", "title": "Score protein variants based on frequency of AA in multiple sequence alignment", "content": "For reference, please read this excerpt from  \n**Human non-synonymous SNPs: server and survey**  \nVasily Ramensky, Peer Bork, and Shamil Sunyaev\n\n\n> *Profile analysis of homologous\n> sequences*. The amino acid replacement\n> may be incompatible with the spectrum\n> of substitutions observed at that\n> position in a family of homologous\n> proteins. PolyPhen identifies\n> homologues of the input sequences via\n> a BLAST (23) search of the NRDB\n> database. The set of aligned sequences\n> with sequence identity to the input\n> sequence in the range 30\u00b194%\n> (inclusive) is used by the new version\n> of the PSIC (position-specific\n> independent counts) software (24) to\n> calculate the so-called profile matrix\n> (http://strand.imb.ac.ru/PSIC/).\n> Elements of the matrix (pro- file\n> scores) are logarithmic ratios of the\n> likelihood of a given amino acid\n> occurring at a particular site to the\n> likelihood of this amino acid\n> occurring at any site (background\n> frequency). PolyPhen computes the\n> absolute value of the difference\n> between profile scores of both allelic\n> variants in the polymorphic position.\n> PolyPhen also shows the number of\n> aligned sequences at the query\n> position; this may be used to assess\n> the reliability of profile score\n> calculations.\n\nI'd like to calculate something similar (score variants based on frequency that AA in aligned sequences) to what's mentioned here **programmatically**, but I can't find any implementation of the above described system.\n\nDoes anyone know of a working implementation of this or something similar, that's available either in code or as a web service?\n\nOr should it is easy enough to implement something like this ourselves?", "date": "2010-04-14 14:49:03", "action": 0, "post": 183}}, {"pk": 669, "model": "server.postrevision", "fields": {"author": 215, "tag_string": "multiple alignment dna", "title": "Repeat subunit based multiple alignment of DNA", "content": "I want to align over 50 sequences of a polymorphic stretch of promoter DNA. The sequences consist of repeats of selections from 174 incompletely homologous subunits (14-31 subunits per sequence), the subunits are 18-29 bases in length, with a four-part internal structure.  I wish the alignment to be guided by the subunits more than by unstructured primary DNA sequence. Is there any software out there that can do this?\n\nThank you.", "date": "2010-04-14 14:49:20", "action": 0, "post": 162}}, {"pk": 670, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective programming languages", "title": "Which are the best programming languages to study for a bioinformatician?", "content": "This is also a very classic question: Which is your favorite programming language in bioinformatics? Which languages would you recommend to a student wishing to enter the world of bioinformatics?\n\nThis topic has already been discussed on the Internet, but I think it would be nice to discuss it here. Here there are some links to previous polls and discussions:\n\n - [Bioinformatics.org poll][1]\n - [Bioinformatics Career survey 2008 by Michael Barton][2]\n\n\n  [1]: http://www.bioinformatics.org/poll/index.php?dispid=17\n  [2]: http://openwetware.org/wiki/Biogang:Projects/Bioinformatics_Career_Survey_2008", "date": "2010-04-15 10:08:30", "action": 0, "post": 34}}, {"pk": 671, "model": "server.postrevision", "fields": {"author": 233, "tag_string": "licensing general software subjective", "title": "What license do you use when you release code and data?", "content": "Do you aim to make your resources as widely available and reusable as possible? \n\nConversely, do you try to protect the investment of time and resources that went into producing the IP?\n\nThe choice of license can be a tricky thing, and getting it wrong can cause considerable problems for you, and for others attempting to build on your work.\n\nThings to consider:\n\n[ISCB Discussion report on software sharing][1]\n\n[Ontology licensing][2]\n\n[Attribution vs Citation][3]\n\n\n\n\n  [1]: http://iscb-discussion.blogspot.com/2008/03/iscb-member-feedback-sought-on-revised.html\n  [2]: http://themindwobbles.wordpress.com/2009/11/12/science-commons-provide-a-list-of-considerations-for-researchers-looking-to-license-their-ontology/\n  [3]: http://peanutbutter.wordpress.com/2009/07/10/attribution-vs-citation-do-you-know-the-difference/", "date": "2010-04-26 13:44:12", "action": 0, "post": 349}}, {"pk": 672, "model": "server.postrevision", "fields": {"author": 233, "tag_string": "phylogeny software visualization feedback subjective", "title": "What phylogeny viewing software do you use?", "content": "There are numerous phylogeny viewing programs available, which ones do people use most often? Are there features (e.g., visualisations, data formats, size of tree that can be displayed, annotation) that people feel existing software lack?\n\nI'll declare an interest. I'm the author of http://taxonomy.zoology.gla.ac.uk/rod/treeview.html, which is beginning to show its age. There are some other great tools around, so I'm trying to gauge whether TreeView should be allowed to die gracefully, of whether I should invest time in developing it further (see http://darwin.zoology.gla.ac.uk/~rpage/treeviewx/ ).", "date": "2010-04-27 09:53:39", "action": 0, "post": 402}}, {"pk": 673, "model": "server.postrevision", "fields": {"author": 126, "tag_string": "phylogeny software visualization feedback", "title": "What phylogeny viewing software do you use?", "content": "There are numerous phylogeny viewing programs available, which ones do people use most often? Are there features (e.g., visualisations, data formats, size of tree that can be displayed, annotation) that people feel existing software lack?\n\nI'll declare an interest. I'm the author of http://taxonomy.zoology.gla.ac.uk/rod/treeview.html, which is beginning to show its age. There are some other great tools around, so I'm trying to gauge whether TreeView should be allowed to die gracefully, of whether I should invest time in developing it further (see http://darwin.zoology.gla.ac.uk/~rpage/treeviewx/ ).", "date": "2010-04-27 17:19:50", "action": 0, "post": 402}}, {"pk": 674, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: Where to advertise or find bioinformatics jobs", "content": "I used to check Biojobs at FriendFeed,  [Bioinformatics.org][1]  and [Bioinformatics.fr][2] \n\nRecently found this [GenomeWeb careers section][3], interesting opportunities mostly from industry.  \n\n\n  [1]: http://www.bioinformatics.org/jobs/?show=archives\n  [2]: http://bioinformatics.fr/jobs.php\n  [3]: http://www.genomeweb.com/jobs", "date": "2010-05-19 20:11:11", "action": 0, "post": 335}}, {"pk": 675, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "nucleotides python frequency density", "title": "How to generate multi-nucleotide occupancy counts for each coordinate of my reads?", "content": "I need to generate nucleotide occupancy counts for each position of a given sequence then summed over each of the input sequences. An example desired output (for di-nucleotide AT):\n\n![dinucleotide occupancy][1]\n\n\n  [1]: http://github.com/ialbert/biostar-codesample/raw/master/python/images/dinuc.png", "date": "2010-05-27 17:13:42", "action": 0, "post": 10}}, {"pk": 676, "model": "server.postrevision", "fields": {"author": 19, "tag_string": "meme sge motif motif compilation", "title": "Tips on compiling and using MEME 4.3 with a Sun Grid Engine computation cluster", "content": "Has anyone compiled and used MEME 4.x for use in a parallel computation environment, based upon operation with a Sun Grid Engine (SGE) cluster?\n\nI can compile the suite and its tests pass. However, when I attempt to use the `-p n` option, to specify `n` computation nodes, I get several error messages:\n\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    1: Command not found.\n\nWe do not have `/gridware/codine/util/arch`, but we do have `/gridengine/sgi/util/arch`.\n\nI tried looking around MEME's source code, particularly at `meme.c` and `mp.h`, but there are no references to these paths.\n\nI'm wondering if I am missing makefile directives. Here is my `./configure` statement:\n\n    ./configure --prefix=/home/areynolds/proj/meme/meme_4.3.0_build --with-url=\"http://meme.nbcr.net/meme\" --enable-openmp --enable-debug\n\nIs MPI a requirement; are there directives I am missing for MPI?\n\nThank you for any advice.\n\n**EDIT**\n\nI was able to successfully build a version of MEME 4.3 that supports OpenMPI.\n\nFirst, I worked with our sys admin to install [OpenMPI 1.4][1] on each of the SGE nodes ([compilation options][2]) and set up an [SGE parallel environment][3] called `mpi_test`:\n\n    $ qconf -sp mpi_test\n    pe_name           mpi_test\n    slots             120 \n    user_lists        NONE\n    xuser_lists       NONE\n    start_proc_args   /bin/true\n    stop_proc_args    /bin/true     \n    allocation_rule   $fill_up\n    control_slaves    TRUE\n    job_is_first_task FALSE \n    urgency_slots     min\n\nSecondly, I used the following build options for MEME:\n\n    $ ./configure --prefix=/home/areynolds/proj/meme/meme_4.3.0_build \\ \n    --with-url=\"http://meme.nbcr.net/meme\" \\\n    --enable-openmp \\\n    --enable-debug \\\n    --with-mpicc=/opt/openmpi-1.4/bin/mpicc \\\n    --enable-opt\n\nThirdly, the `mpirun` and `meme_p` binaries depend upon shared libraries in the OpenMPI installation. It is necessary to add `/opt/openmpi-1.4/lib` to your local `LD_LIBRARY_PATH` environment variable before running `qsub`.\n\nFinally, I set up a script (called `runall.cluster`) along the following lines. Runtime options can be adjusted to taste:\n\n    #!/bin/bash\n\n    #\n    # runall.cluster\n    #\n\n    #$ -N memeCluster64\n    #$ -S /bin/bash\n    #$ -pe mpi_test 64\n    #$ -v -np=64\n    #$ -cwd\n    #$ -o \"memeCluster64.out\"\n    #$ -e \"memeCluster64.err\"\n    #$ -notify\n    #$ -V\n\n    time /opt/openmpi-1.4/bin/mpirun -np 64 \\\n       /home/areynolds/proj/meme/meme/bin/meme_p \\\n       /home/areynolds/proj/meme/data/K562.DS9767.fps.not.in.promoters.fa.top10k.fa \\\n       -oc /home/areynolds/proj/meme/output/K562.DS9767.fps.not.in.promoters.10k.cluster.64 \\\n       -maxsize 230000 \\\n       -dna \\\n       -minw 8 -maxw 12 -allw \\\n       -p 64\n\nThis script is executed directly with `qsub` and runs the parallelized MEME binary `meme_p` with the specified options. In this case, it will run on 64 nodes of our computation cluster:\n\n    qsub ./runall.cluster\n\nHopefully this information will help out others.\n\n\n  [1]: http://www.open-mpi.org/\n  [2]: http://www.open-mpi.org/faq/?category=running#run-n1ge-or-sge\n  [3]: http://wikis.sun.com/display/GridEngine/Managing+Parallel+Environments#ManagingParallelEnvironments-AboutParallelEnvironments", "date": "2010-05-27 23:26:21", "action": 0, "post": 28}}, {"pk": 677, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: How to convert BLAST results to GFF", "content": "Start with tabulated blast output myfile.blast.out. Then check two-liners from:\n\nhttp://bergman-lab.blogspot.com/2009/12/ncbi-blast-tabular-output-format-fields.html\n\nFew lines tooutput proper gff are missing, but you may either go for minimalistic gff or try to encode everything in column 9. Also you may try validating your gff3 here:\n\nhttp://modencode.oicr.on.ca/cgi-bin/validate_gff3_online\n\n**NOTE:** *The blog linked above does not seem to exist anymore, here is the content of it from the wayback machine:*\n\n**NCBI Blast Tabular output format fields**\n\nCertainly, with the new NCBI Blast+ tools, you won't need this anymore, but as long as we are sticking with the old blastall programm with its horrible documentation, I keep forgetting the format of the BLAST tabular reports. Tabular format is created when you specify \"`-m 8`\". This is the most useful format for parsing blast yourself without having to learn strange libraries like BioPerl, BioJava, BioPython or BioErlang (doesn't this exist yet, Mike?)\n\nSo here is the meaning of the fields:\n\n    queryId, subjectId, percIdentity, alnLength, mismatchCount, \n    gapOpenCount, queryStart, queryEnd, subjectStart, subjectEnd, eVal, bitScore\n\nParsing is then simple\n\nPython:\n\n    for line in open(\"myfile.blast\"):\n        (queryId, subjectId, percIdentity, alnLength, mismatchCount, \n        gapOpenCount, queryStart, queryEnd, subjectStart, \n        subjectEnd, eVal, bitScore) = line.split(\"\\t\")\n\nPerl:\n\n    while (<>) {\n       ($queryId, $subjectId, $percIdentity, $alnLength, $mismatchCount, \n       $gapOpenCount, $queryStart, $queryEnd, $subjectStart, \n       $subjectEnd, $eVal, $bitScore) = split(/\\t/)\n    }\n", "date": "2010-05-28 14:15:48", "action": 0, "post": 281}}, {"pk": 678, "model": "server.postrevision", "fields": {"author": 86, "tag_string": "", "title": "A: How to find all GWAS studies that a given gene has been implicated in?", "content": "AFAIK, [dbGAP][1] is one of the official resource for GWAS studies. A mere gene search may not fetch the exact details about the studies. Dataset from large scale GWAS studies are not available under public access due to sensitive genotype and phenotype data from patients. You have to write to individual investigators to get access to the data. Usually this data will be available only after the Embargo Release date. This is usually after 1year of the submission of the data. I think once you have access to the dataset, you will able to get the p-values of the SNPs genotyped in the whole study with the de-identified case/control and their phenotypes. These SNPs may need further mapping to get the details about the genes. \n\n[NHGRI website][2] provides A Catalog of Published Genome-Wide Association Studies: They provide a detailed table of GWAS and their details. As of 03/24/10, this table includes 517 publications and 2443 SNPs. You may map this SNPs to get the respective genes. \n\nAlso this [manuscript][3] provides results from various GWAS studies. \n\nI am looking forward for other comments to know if there is any public resource that provides GWAS data. \n\nEDIT : I have recently used [SCANDB][4], [GWASIntegrator][5] and [VARIETAS][6] for integrating GWAS studies around a gene. \n\n\n  [1]: http://www.ncbi.nlm.nih.gov/gap\n  [2]: http://www.genome.gov/26525384\n  [3]: http://www.biomedcentral.com/1471-2350/10/6\n  [4]: http://www.scandb.org/newinterface/about.html\n  [5]: http://hugenavigator.net/HuGENavigator/gWAHitStartPage.do\n  [6]: http://database.oxfordjournals.org/cgi/content/full/2010/0/baq016", "date": "2010-08-13 21:32:59", "action": 0, "post": 428}}, {"pk": 679, "model": "server.postrevision", "fields": {"author": 70, "tag_string": "", "title": "A: Looking for a 'Hello world\" plugin for Taverna.", "content": "Pierre, I feel your pain; Maven is not quite my friend either... Taverna is a really modular, and comes with very many dependencies... these are recursively defined and resolved using Maven... I'd love to build a plugin without it too, but never dared setting up such a system myself :)\n\nHowever, the Taverna developers have written up a [tutorial for creating new plugins][1] all from within an Eclipse (with Maven plugin) environment, which I used on Friday to set up a functional plugin from scratch in a few hours. I first thought it was typical for calling SOAP services, but in fact is pretty general. You may find yourself removing a lot of template code, as the template you install (a Maven archetype) is a full 'activity', and not a simple one port in, one port out one.\n\n  [1]: http://www.mygrid.org.uk/dev/wiki/display/developer/Tutorial+-+Service+invocation+plugin", "date": "2010-10-16 11:49:12", "action": 0, "post": 147}}, {"pk": 680, "model": "server.postrevision", "fields": {"author": 418, "tag_string": "metabolomics chemoinformatics java opensource", "title": "What open source Java library can I use to query online, free databases in which pathways a metabolite is participating?", "content": "What opensource Java solutions are available to query online pathway databases like [KEGG][1] (or [BioMeta][2]), [MACiE][3] and [Brenda][4] for the pathways a certain metabolite is available, for example, based on the [InChI][5]? Preferably, the library would have a good data model for the pathway information, possibly [SMBL][6] or [RDF][7]-based. What would the code look like to make such a query?\n\n\n  [1]: http://www.genome.jp/kegg/\n  [2]: http://biometa.cmbi.ru.nl/\n  [3]: http://www.ebi.ac.uk/thornton-srv/databases/MACiE/\n  [4]: http://www.brenda-enzymes.org/\n  [5]: http://en.wikipedia.org/wiki/International_Chemical_Identifier\n  [6]: http://sbml.org/\n  [7]: http://en.wikipedia.org/wiki/Resource_description_framework", "date": "2010-10-27 19:32:35", "action": 0, "post": 251}}, {"pk": 681, "model": "server.postrevision", "fields": {"author": 418, "tag_string": "books open science python", "title": "Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "content": "**Bioinformatics Programming Using Python**\n\nPractical Programming for Biological Data\n\nBy [Mitchell L Model][1]\n\n![alt text][2]\n\n\nPublisher:[O'Reilly Media][3]\n\nReleased: December 2009 \n\nPages: 528\n\n*As [asked][4] by moderator [Istvan Albert][5] I made a separate question for this book review, so that the best review can come to the top.*\n\n\n  [1]: http://www.oreillynet.com/pub/au/3752\n  [2]: http://covers.oreilly.com/images/9780596154516/cat.gif\n  [3]: http://oreilly.com/catalog/9780596154516\n  [4]: http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books\n  [5]: http://biostar.stackexchange.com/users/2/istvan-albert", "date": "2010-10-27 19:42:00", "action": 0, "post": 185}}, {"pk": 682, "model": "server.postrevision", "fields": {"author": 418, "tag_string": "books python", "title": "Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "content": "**Bioinformatics Programming Using Python**\n\nPractical Programming for Biological Data\n\nBy [Mitchell L Model][1]\n\n![alt text][2]\n\n\nPublisher:[O'Reilly Media][3]\n\nReleased: December 2009 \n\nPages: 528\n\n*As [asked][4] by moderator [Istvan Albert][5] I made a separate question for this book review, so that the best review can come to the top.*\n\n\n  [1]: http://www.oreillynet.com/pub/au/3752\n  [2]: http://covers.oreilly.com/images/9780596154516/cat.gif\n  [3]: http://oreilly.com/catalog/9780596154516\n  [4]: http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books\n  [5]: http://biostar.stackexchange.com/users/2/istvan-albert", "date": "2010-10-27 19:42:32", "action": 0, "post": 185}}, {"pk": 683, "model": "server.postrevision", "fields": {"author": 418, "tag_string": "books python bioinformatics", "title": "Provide a book review for \"Bioinformatics Programming Using Python\" by Mitchell L. Model", "content": "**Bioinformatics Programming Using Python**\n\nPractical Programming for Biological Data\n\nBy [Mitchell L Model][1]\n\n![alt text][2]\n\n\nPublisher:[O'Reilly Media][3]\n\nReleased: December 2009 \n\nPages: 528\n\n*As [asked][4] by moderator [Istvan Albert][5] I made a separate question for this book review, so that the best review can come to the top.*\n\n\n  [1]: http://www.oreillynet.com/pub/au/3752\n  [2]: http://covers.oreilly.com/images/9780596154516/cat.gif\n  [3]: http://oreilly.com/catalog/9780596154516\n  [4]: http://biostar.stackexchange.com/questions/181/recommend-your-favorite-bioinformatics-books\n  [5]: http://biostar.stackexchange.com/users/2/istvan-albert", "date": "2010-10-27 19:43:51", "action": 0, "post": 185}}, {"pk": 684, "model": "server.postrevision", "fields": {"author": 35, "tag_string": "", "title": "A: What methods do you use for short read mapping?", "content": "I've only used [bowtie][1], but it seems to be extremely fast and makes use of multiple cores with no extra work on my part. Also, builds an index for the reference sequence which can be re-used after the first build. \n\nThis is mapping to Arabidopsis Thaliana, up to 5 or so Gigs of raw reads, so fastq of 4x that size. Using a pretty standard 8 core machine, it's relatively painless.\n\n\nUPDATE:\n\nWe've also found [gsnap][2] to be excellent. It can do fasta/fastq, spliced alignment (RNA-Seq), BS-Seq, and general mapping very quickly. It is a bit slower than bowtie but handles indels much better. Though it can read fastq files, it does not use the quality information so it is best to trim reads before sending through gsnap.\n\n\n  [1]: http://bowtie-bio.sourceforge.net/index.shtml\n  [2]: http://share.gene.com/gmap/", "date": "2010-11-01 18:22:28", "action": 0, "post": 224}}, {"pk": 685, "model": "server.postrevision", "fields": {"author": 313, "tag_string": "metabolomics chemoinformatics java open", "title": "What open source Java library can I use to query online, free databases in which pathways a metabolite is participating?", "content": "What opensource Java solutions are available to query online pathway databases like [KEGG][1] (or [BioMeta][2]), [MACiE][3] and [Brenda][4] for the pathways a certain metabolite is available, for example, based on the [InChI][5]? Preferably, the library would have a good data model for the pathway information, possibly [SMBL][6] or [RDF][7]-based. What would the code look like to make such a query?\n\n\n  [1]: http://www.genome.jp/kegg/\n  [2]: http://biometa.cmbi.ru.nl/\n  [3]: http://www.ebi.ac.uk/thornton-srv/databases/MACiE/\n  [4]: http://www.brenda-enzymes.org/\n  [5]: http://en.wikipedia.org/wiki/International_Chemical_Identifier\n  [6]: http://sbml.org/\n  [7]: http://en.wikipedia.org/wiki/Resource_description_framework", "date": "2010-11-13 10:05:01", "action": 0, "post": 251}}, {"pk": 686, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective programming languages", "title": "Which are the best programming languages to study for a bioinformatician?", "content": "This is a very classic question: Which is your favorite programming language in bioinformatics? Which languages would you recommend to a student wishing to enter the world of bioinformatics?\n\nThis topic has already been discussed on the Internet, but I think it would be nice to discuss it here. Here there are some links to previous polls and discussions:\n\n - [Bioinformatics.org poll][1]\n - [Bioinformatics Career survey 2008 by Michael Barton][2]\n\n\n  [1]: http://www.bioinformatics.org/poll/index.php?dispid=17\n  [2]: http://openwetware.org/wiki/Biogang:Projects/Bioinformatics_Career_Survey_2008", "date": "2010-12-01 09:06:04", "action": 0, "post": 34}}, {"pk": 687, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective programming languages", "title": "Which are the best programming languages for a bioinformatician?", "content": "This is a very classic question: Which is your favorite programming language in bioinformatics? Which languages would you recommend to a student wishing to enter the world of bioinformatics?\n\nThis topic has already been discussed on the Internet, but I think it would be nice to discuss it here. Here there are some links to previous polls and discussions:\n\n - [Bioinformatics.org poll][1]\n - [Bioinformatics Career survey 2008 by Michael Barton][2]\n\n\n  [1]: http://www.bioinformatics.org/poll/index.php?dispid=17\n  [2]: http://openwetware.org/wiki/Biogang:Projects/Bioinformatics_Career_Survey_2008", "date": "2010-12-01 13:26:22", "action": 0, "post": 34}}, {"pk": 688, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective gene go", "title": "How much do you trust GeneOntology annotations?", "content": "[GeneOntology][1] is a nice project to provide a standard terminology for genes and gene functions, to help avoid the use of synonyms and wrong spelling when describing a gene.\n\nI have been using the GeneOntology for a while, but honestly I think that it contains many errors and that many terms have not enough terms associated. Moreover, the terminology they use is not always clear and there are some duplications.\n\nIt is frequent to read in article or in slideshows charts were the GO classification is used to infer the properties of a set of genes... But I wonder if the authors check the GO annotations they use.\n\nWhat is your experience about [GO][2]?\n\n\n  [1]: http://www.geneontology.org/\n  [2]: http://www.geneontology.org/", "date": "2010-12-13 12:09:41", "action": 0, "post": 41}}, {"pk": 689, "model": "server.postrevision", "fields": {"author": 313, "tag_string": "literature bioinformatics python text", "title": "How difficult/reliable is it to programmatically (python) look up and download papers?", "content": "I know that it is possible to write a script that attempts to use the ezproxy that most universities use to download papers directly using some search query. I have seen a perl implementation of this but was looking for something a bit cleaner and hopefully in python.\n\nI don't mind having the script only be able to work within a university network, but it would have to be able to check if the paper is accessible via the current IP or such. Not sure how feasible this is, thus my question...", "date": "2011-01-05 08:11:40", "action": 0, "post": 403}}, {"pk": 690, "model": "server.postrevision", "fields": {"author": 147, "tag_string": "tips data practical data", "title": "Tips to build a data storage for bioinformatics", "content": "Storing large amounts of data will become a problem for the bioinformatics, sooner or later. I've faced this problem recently and a lot of questions that I've never thought before just surfaced. The most obvious are:\nHow to decide the filesystem? How to partition a large (TB range) HD? When is a cheap solution (e. g. a bunch of low-end HDs) inappropriate?\n<p>\nThese are pressing issues here at brazilian medical community. Everyone wants to buy a NGS machine, mass spec or microarray but no one perceives the forthcomming data flood. \n<p>\nIn practical terms, how do you store your data? A good reason for a given decision would be great too.\n\n\nEdit:\n\nI've asked this question not so long ago and thing got HOT here. They just finished to build a whole facility to deal with cancer. A lot of people aquired NGS machines and TB scale seems be a thing of the past. Now we are discussing what to keep and how to manage the process of data triage/filtering. So, I do really need new tips from the community. Is someone facing a similar problem (too many data)?", "date": "2011-01-13 00:51:47", "action": 0, "post": 465}}, {"pk": 691, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "markov sequence protein random generation", "title": "Markov chain for generating random protein sequences", "content": "I have 1000+ protein sequences. I want to generate random sequences using a Markov model based on residue transitions found my sequences. I'm told Matlab will make a Markov chain based on multiple sequences, but I would like to use a free alternative to Matlab (python, ruby, R, etc). Can anyone provide me with a library or module?", "date": "2011-01-17 10:02:20", "action": 0, "post": 469}}, {"pk": 692, "model": "server.postrevision", "fields": {"author": 58, "tag_string": "meta subjective", "title": "How far does bioinformatics go?", "content": "Being a metabolomics, and drug discovery dude, I consider myself a bioinformatician (well, I also consider myself a chemist, cheminformatician, statistician, and chemometrician, but that's not relevant to my question).\n\nHowever, some peers see bioinformatics restricted to stuff to do with DNA sequences, that is genomics. So, from a historical and literature perspective, *what is bioinformatics*? Please do back up your answer and argument with citations to primary literature.", "date": "2011-01-18 11:36:01", "action": 0, "post": 149}}, {"pk": 693, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "dna sequence competition", "title": "List all the tools or write a script to validate that a sequence only contains letters from a given alphabet", "content": "How do I verify that a sequence only contains letters from a given alphabet: DNA, RNA, protein?", "date": "2011-01-21 11:53:43", "action": 0, "post": 102}}, {"pk": 694, "model": "server.postrevision", "fields": {"author": 22, "tag_string": "subjective blog off resources", "title": "Your favorite bioinformatics blogs", "content": "I think that for a professional is very important to follow blogs focused on his own speciality, it is a good way to learn without too much effort and to stay updated. Which bioinformatics-related blogs do you usually read?\n\nnote: there is a [similar question][1] posted on stackoverflow.\n\n\n  [1]: http://stackoverflow.com/questions/2051319/bioinformatics-resources", "date": "2011-03-02 15:13:01", "action": 0, "post": 112}}, {"pk": 695, "model": "server.postrevision", "fields": {"author": 54, "tag_string": "job career general not related", "title": "What do different bioinformatics positions mean?", "content": "I went to several sites to look for a new position (thanks to recent [question][1]). With not much experience in bioinformatics market I'm confused with a lot of different positions. Some positions I understand but not everything. Some looks like just called differently for companies, academy or government. I tried to put here all I could find. Can somebody approximately sort them let's say by salary or level of responsibility? Which positions requires Ph.D. degree? Any systematic description would be very useful.\n\n - Bioinformatics Internship\n - Bioinformatics Postdoc \n - Bioinformatics Analyst (I, II, III) \n - Senior Bioinformatics Analyst \n - Bioinformatics Analyst Programmer (I, II, III)\n - Bioinformatics Developer Senior\n - Bioinformatics Developer\n - Bioinformatician (I, II, III)\n - Bioinformatics Expert \n - Bioinformatics Systems Administrator \n - Bioinformatics Research Fellow \n - Bioinformatics Research Assistant \n - Bioinformatics Research Associate \n - Bioinformatics Scientist (Researcher) \n - Bioinformatics Senior (Staff) Scientist\n - Bioinformatics Project Manager\n - Director (Head) of Bioinformatics\n\n  [1]: http://biostar.stackexchange.com/questions/296/where-to-advertise-or-find-bioinformatics-jobs", "date": "2011-03-23 17:13:23", "action": 0, "post": 398}}, {"pk": 696, "model": "server.postrevision", "fields": {"author": 61, "tag_string": "", "title": "A: Your favorite bioinformatics blogs (March 2010)", "content": "Maybe not The Greatest but these few are covering next gen sequencing:\n\nhttp://www.massgenomics.org/\n\nhttp://www.fejes.ca/labels/DNA.html\n\nhttp://omicsomics.blogspot.com/\n\n", "date": "2011-05-23 11:34:22", "action": 0, "post": 119}}, {"pk": 697, "model": "server.postrevision", "fields": {"author": 263, "tag_string": "meme sge motif compilation parallel", "title": "Tips on compiling and using MEME 4.3 with a Sun Grid Engine computation cluster", "content": "Has anyone compiled and used MEME 4.x for use in a parallel computation environment, based upon operation with a Sun Grid Engine (SGE) cluster?\n\nI can compile the suite and its tests pass. However, when I attempt to use the `-p n` option, to specify `n` computation nodes, I get several error messages:\n\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    /gridware/codine/util/arch: Command not found.\n    1: Command not found.\n\nWe do not have `/gridware/codine/util/arch`, but we do have `/gridengine/sgi/util/arch`.\n\nI tried looking around MEME's source code, particularly at `meme.c` and `mp.h`, but there are no references to these paths.\n\nI'm wondering if I am missing makefile directives. Here is my `./configure` statement:\n\n    ./configure --prefix=/home/areynolds/proj/meme/meme_4.3.0_build --with-url=\"http://meme.nbcr.net/meme\" --enable-openmp --enable-debug\n\nIs MPI a requirement; are there directives I am missing for MPI?\n\nThank you for any advice.\n\n**EDIT**\n\nI was able to successfully build a version of MEME 4.3 that supports OpenMPI.\n\nFirst, I worked with our sys admin to install [OpenMPI 1.4][1] on each of the SGE nodes ([compilation options][2]) and set up an [SGE parallel environment][3] called `mpi_test`:\n\n    $ qconf -sp mpi_test\n    pe_name           mpi_test\n    slots             120 \n    user_lists        NONE\n    xuser_lists       NONE\n    start_proc_args   /bin/true\n    stop_proc_args    /bin/true     \n    allocation_rule   $fill_up\n    control_slaves    TRUE\n    job_is_first_task FALSE \n    urgency_slots     min\n\nSecondly, I used the following build options for MEME:\n\n    $ ./configure --prefix=/home/areynolds/proj/meme/meme_4.3.0_build \\ \n    --with-url=\"http://meme.nbcr.net/meme\" \\\n    --enable-openmp \\\n    --enable-debug \\\n    --with-mpicc=/opt/openmpi-1.4/bin/mpicc \\\n    --enable-opt\n\nThirdly, the `mpirun` and `meme_p` binaries depend upon shared libraries in the OpenMPI installation. It is necessary to add `/opt/openmpi-1.4/lib` to your local `LD_LIBRARY_PATH` environment variable before running `qsub`.\n\nFinally, I set up a script (called `runall.cluster`) along the following lines. Runtime options can be adjusted to taste:\n\n    #!/bin/bash\n\n    #\n    # runall.cluster\n    #\n\n    #$ -N memeCluster64\n    #$ -S /bin/bash\n    #$ -pe mpi_test 64\n    #$ -v -np=64\n    #$ -cwd\n    #$ -o \"memeCluster64.out\"\n    #$ -e \"memeCluster64.err\"\n    #$ -notify\n    #$ -V\n\n    time /opt/openmpi-1.4/bin/mpirun -np 64 \\\n       /home/areynolds/proj/meme/meme/bin/meme_p \\\n       /home/areynolds/proj/meme/data/K562.DS9767.fps.not.in.promoters.fa.top10k.fa \\\n       -oc /home/areynolds/proj/meme/output/K562.DS9767.fps.not.in.promoters.10k.cluster.64 \\\n       -maxsize 230000 \\\n       -dna \\\n       -minw 8 -maxw 12 -allw \\\n       -p 64\n\nThis script is executed directly with `qsub` and runs the parallelized MEME binary `meme_p` with the specified options. In this case, it will run on 64 nodes of our computation cluster:\n\n    qsub ./runall.cluster\n\nHopefully this information will help out others.\n\n\n  [1]: http://www.open-mpi.org/\n  [2]: http://www.open-mpi.org/faq/?category=running#run-n1ge-or-sge\n  [3]: http://wikis.sun.com/display/GridEngine/Managing+Parallel+Environments#ManagingParallelEnvironments-AboutParallelEnvironments", "date": "2011-05-26 16:23:58", "action": 0, "post": 28}}, {"pk": 698, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "subjective blog off resources", "title": "Your favorite bioinformatics blogs (March 2010)", "content": "I think that for a professional is very important to follow blogs focused on his own speciality, it is a good way to learn without too much effort and to stay updated. Which bioinformatics-related blogs do you usually read?\n\nnote: there is a [similar question][1] posted on stackoverflow.\n\n\n  [1]: http://stackoverflow.com/questions/2051319/bioinformatics-resources", "date": "2011-10-28 01:13:23", "action": 0, "post": 112}}, {"pk": 699, "model": "server.postrevision", "fields": {"author": 4, "tag_string": "test", "title": "test by zhenhai", "content": "Hi, I just created my user id a few minutes ago. \n\nPost this question to see how it works.", "date": "2011-11-24 14:48:56", "action": 3, "post": 6}}, {"pk": 700, "model": "server.postrevision", "fields": {"author": 14, "tag_string": "boy george", "title": "do you have to be a guy to dress up as boy george", "content": "any ideas im a girl", "date": "2011-11-24 14:48:57", "action": 3, "post": 20}}, {"pk": 701, "model": "server.postrevision", "fields": {"author": 14, "tag_string": "boy george", "title": "do you have to be a guy to dress up as boy george", "content": "any ideas im a girl", "date": "2011-11-24 14:48:57", "action": 3, "post": 21}}, {"pk": 702, "model": "server.postrevision", "fields": {"author": 9, "tag_string": "python pygr use sequence", "title": "Computing the reverse and complement of a sequence with Pygr", "content": "Computing the reverse complement with the [Pygr][1] bioinformatics framework:\n\n    #\n    # Reverse complement example with pygr\n    #\n    \n    from pygr.sequence import Sequence\n    \n    # needs a separate function to reverse strings\n    def rev(it):\n        \"Reverses an interable and returns it as a string\"\n        return ''.join(reversed(it))\n    \n    # original sequence as as string\n    seq = 'ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG'\n    \n    # create a Sequence class  instance named bobo\n    dna = Sequence(seq,'bobo')\n    \n    # sequence class' type and content\n    print type(dna)\n    print dna\n    \n    # the -operator reverse complements the DNA, returns a new sequence\n    print -dna\n    \n    # to reverse the DNA, reverse the input data\n    rdna = Sequence( rev(seq),'bobo')\n    print rdna\n    \n    # to complement the DNA reverse complement, then reverse again\n    cseq = rev(str(-dna))\n    cdna = Sequence(cseq,'bobo')\n\n    print cdna\n\nProduces the output:\n\n    <class 'pygr.sequence.Sequence'>\n    ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\n    CTATCGGGCACCCTTTCAGCGGCCCATTACAATGGCCAT\n    GATAGCCCGTGGGAAAGTCGCCGGGTAATGTTACCGGTA\n    TACCGGTAACATTACCCGGCGACTTTCCCACGGGCTATC\n\n  [1]: http://code.google.com/p/pygr/wiki/PygrDocumentation\n\n", "date": "2011-11-24 14:48:57", "action": 1, "post": 92}}, {"pk": 703, "model": "server.postrevision", "fields": {"author": 1, "tag_string": "", "title": "A: Computing the reverse and complement of a sequence with Pygr", "content": "This post was not formulated in a question/answer format  therefore will be closed.", "date": "2011-11-24 14:48:57", "action": 3, "post": 230}}, {"pk": 704, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How to convert BLAST results to GFF", "content": "I found this via google: http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl\n\nelse I would save my blast result as **XML** and transform it to GFF with with a (should be) simple **XSLT** stylesheet. As an example, you can have a look at my 'old' stylesheet blast2svg: http://code.google.com/p/lindenb/source/browse/trunk/src/xsl/blast2svg.xsl\nPierre\n\n", "date": "2011-11-24 14:48:57", "action": 3, "post": 279}}, {"pk": 705, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How to convert BLAST results to GFF", "content": "I found this via google: http://jperl.googlecode.com/svn-history/r16/trunk/Blast2Gff.pl\n\nelse I would save my blast result as **XML** and transform it to GFF with with a (should be) simple **XSLT** stylesheet. As an example, you can have a look at my 'old' stylesheet blast2svg: http://code.google.com/p/lindenb/source/browse/trunk/src/xsl/blast2svg.xsl\nPierre\n\n", "date": "2011-11-24 14:48:57", "action": 4, "post": 279}}, {"pk": 706, "model": "server.postrevision", "fields": {"author": 145, "tag_string": "", "title": "A: Compare two protein sequences using local BLAST", "content": "And Will, your example seems overly complicated. Why not just give the multiple query input FASTA file directly to BLAST?\n\nAlso, satsurae - do you have to use BLAST? If the data set is not too big, you could use EMBOSS needleall to do a full Needleman-Wunsch alignment - although this may not offer the statistics you may want.\nhttp://emboss.sourceforge.net/apps/release/6.2/emboss/apps/needleall.html\n\n", "date": "2011-11-24 14:48:57", "action": 3, "post": 314}}, {"pk": 707, "model": "server.postrevision", "fields": {"author": 29, "tag_string": "", "title": "A: How difficult/reliable is it to programmatically (python) look up and download papers?", "content": "Sorry Ricardo, not python but the following codes contain some snippets that might be useful to find  the PDF from a doi/pmid...\n\n - http://code.google.com/p/pdfetch/\n - http://bio-geeks.com/?p=749\n\nAnd my version using java...\n\n - http://plindenbaum.blogspot.com/2009/11/my-pdfs-anywhere.html\n", "date": "2011-11-24 14:48:57", "action": 3, "post": 404}}, {"pk": 708, "model": "server.postrevision", "fields": {"author": 146, "tag_string": "microarray image", "title": "Convert microarray quantization in image", "content": "How can I convert the microarray quantization mathematically elaborated in the corresponding image? I need to see the image of the mathematic changes in the microarray quantization.  ", "date": "2011-11-24 14:48:57", "action": 3, "post": 327}}, {"pk": 709, "model": "server.postrevision", "fields": {"author": 157, "tag_string": "", "title": "A: Which are the best programming languages for a bioinformatician?", "content": "Hi, \n\nI like this thread: begins as a troll, ends with nice advices\n\n  ---jmf", "date": "2011-11-24 14:48:57", "action": 3, "post": 385}}, {"pk": 1, "model": "server.vote", "fields": {"post": 7, "type": 0, "author": 1}}, {"pk": 2, "model": "server.vote", "fields": {"post": 7, "type": 0, "author": 1}}, {"pk": 3, "model": "server.vote", "fields": {"post": 4, "type": 0, "author": 1}}, {"pk": 4, "model": "server.vote", "fields": {"post": 8, "type": 0, "author": 1}}, {"pk": 5, "model": "server.vote", "fields": {"post": 11, "type": 0, "author": 9}}, {"pk": 6, "model": "server.vote", "fields": {"post": 11, "type": 0, "author": 9}}, {"pk": 7, "model": "server.vote", "fields": {"post": 11, "type": 2, "author": 9}}, {"pk": 8, "model": "server.vote", "fields": {"post": 12, "type": 0, "author": 9}}, {"pk": 9, "model": "server.vote", "fields": {"post": 10, "type": 0, "author": 1}}, {"pk": 10, "model": "server.vote", "fields": {"post": 13, "type": 0, "author": 1}}, {"pk": 11, "model": "server.vote", "fields": {"post": 15, "type": 0, "author": 1}}, {"pk": 12, "model": "server.vote", "fields": {"post": 13, "type": 0, "author": 1}}, {"pk": 13, "model": "server.vote", "fields": {"post": 16, "type": 0, "author": 1}}, {"pk": 14, "model": "server.vote", "fields": {"post": 1, "type": 0, "author": 9}}, {"pk": 15, "model": "server.vote", "fields": {"post": 18, "type": 0, "author": 1}}, {"pk": 16, "model": "server.vote", "fields": {"post": 18, "type": 2, "author": 1}}, {"pk": 17, "model": "server.vote", "fields": {"post": 10, "type": 0, "author": 4}}, {"pk": 18, "model": "server.vote", "fields": {"post": 24, "type": 0, "author": 1}}, {"pk": 19, "model": "server.vote", "fields": {"post": 25, "type": 0, "author": 1}}, {"pk": 20, "model": "server.vote", "fields": {"post": 25, "type": 0, "author": 13}}, {"pk": 21, "model": "server.vote", "fields": {"post": 26, "type": 0, "author": 13}}, {"pk": 22, "model": "server.vote", "fields": {"post": 27, "type": 0, "author": 1}}, {"pk": 23, "model": "server.vote", "fields": {"post": 28, "type": 0, "author": 1}}, {"pk": 24, "model": "server.vote", "fields": {"post": 29, "type": 2, "author": 19}}, {"pk": 25, "model": "server.vote", "fields": {"post": 30, "type": 0, "author": 1}}, {"pk": 26, "model": "server.vote", "fields": {"post": 34, "type": 0, "author": 1}}, {"pk": 27, "model": "server.vote", "fields": {"post": 33, "type": 0, "author": 1}}, {"pk": 28, "model": "server.vote", "fields": {"post": 31, "type": 0, "author": 1}}, {"pk": 29, "model": "server.vote", "fields": {"post": 39, "type": 0, "author": 1}}, {"pk": 30, "model": "server.vote", "fields": {"post": 8, "type": 0, "author": 22}}, {"pk": 31, "model": "server.vote", "fields": {"post": 7, "type": 0, "author": 22}}, {"pk": 32, "model": "server.vote", "fields": {"post": 35, "type": 0, "author": 22}}, {"pk": 33, "model": "server.vote", "fields": {"post": 36, "type": 0, "author": 22}}, {"pk": 34, "model": "server.vote", "fields": {"post": 38, "type": 0, "author": 22}}, {"pk": 35, "model": "server.vote", "fields": {"post": 1, "type": 0, "author": 22}}, {"pk": 36, "model": "server.vote", "fields": {"post": 17, "type": 0, "author": 22}}, {"pk": 37, "model": "server.vote", "fields": {"post": 3, "type": 0, "author": 22}}, {"pk": 38, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 1}}, {"pk": 39, "model": "server.vote", "fields": {"post": 40, "type": 0, "author": 1}}, {"pk": 40, "model": "server.vote", "fields": {"post": 44, "type": 0, "author": 22}}, {"pk": 41, "model": "server.vote", "fields": {"post": 45, "type": 0, "author": 22}}, {"pk": 42, "model": "server.vote", "fields": {"post": 47, "type": 0, "author": 22}}, {"pk": 43, "model": "server.vote", "fields": {"post": 47, "type": 2, "author": 22}}, {"pk": 44, "model": "server.vote", "fields": {"post": 46, "type": 0, "author": 1}}, {"pk": 45, "model": "server.vote", "fields": {"post": 41, "type": 0, "author": 1}}, {"pk": 46, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 1}}, {"pk": 47, "model": "server.vote", "fields": {"post": 45, "type": 2, "author": 22}}, {"pk": 48, "model": "server.vote", "fields": {"post": 32, "type": 0, "author": 3}}, {"pk": 49, "model": "server.vote", "fields": {"post": 32, "type": 2, "author": 3}}, {"pk": 50, "model": "server.vote", "fields": {"post": 8, "type": 0, "author": 3}}, {"pk": 51, "model": "server.vote", "fields": {"post": 48, "type": 0, "author": 1}}, {"pk": 52, "model": "server.vote", "fields": {"post": 50, "type": 0, "author": 1}}, {"pk": 53, "model": "server.vote", "fields": {"post": 52, "type": 2, "author": 13}}, {"pk": 54, "model": "server.vote", "fields": {"post": 51, "type": 0, "author": 1}}, {"pk": 55, "model": "server.vote", "fields": {"post": 50, "type": 0, "author": 22}}, {"pk": 56, "model": "server.vote", "fields": {"post": 49, "type": 0, "author": 22}}, {"pk": 57, "model": "server.vote", "fields": {"post": 50, "type": 2, "author": 22}}, {"pk": 58, "model": "server.vote", "fields": {"post": 52, "type": 0, "author": 22}}, {"pk": 59, "model": "server.vote", "fields": {"post": 54, "type": 0, "author": 22}}, {"pk": 60, "model": "server.vote", "fields": {"post": 55, "type": 0, "author": 22}}, {"pk": 61, "model": "server.vote", "fields": {"post": 53, "type": 0, "author": 22}}, {"pk": 62, "model": "server.vote", "fields": {"post": 56, "type": 0, "author": 1}}, {"pk": 63, "model": "server.vote", "fields": {"post": 57, "type": 0, "author": 22}}, {"pk": 64, "model": "server.vote", "fields": {"post": 61, "type": 0, "author": 22}}, {"pk": 65, "model": "server.vote", "fields": {"post": 59, "type": 0, "author": 1}}, {"pk": 66, "model": "server.vote", "fields": {"post": 56, "type": 0, "author": 1}}, {"pk": 67, "model": "server.vote", "fields": {"post": 64, "type": 0, "author": 1}}, {"pk": 68, "model": "server.vote", "fields": {"post": 38, "type": 1, "author": 1}}, {"pk": 69, "model": "server.vote", "fields": {"post": 63, "type": 0, "author": 1}}, {"pk": 70, "model": "server.vote", "fields": {"post": 65, "type": 0, "author": 1}}, {"pk": 71, "model": "server.vote", "fields": {"post": 66, "type": 0, "author": 1}}, {"pk": 72, "model": "server.vote", "fields": {"post": 46, "type": 0, "author": 32}}, {"pk": 73, "model": "server.vote", "fields": {"post": 60, "type": 0, "author": 32}}, {"pk": 74, "model": "server.vote", "fields": {"post": 4, "type": 0, "author": 32}}, {"pk": 75, "model": "server.vote", "fields": {"post": 62, "type": 0, "author": 30}}, {"pk": 76, "model": "server.vote", "fields": {"post": 34, "type": 0, "author": 32}}, {"pk": 77, "model": "server.vote", "fields": {"post": 56, "type": 0, "author": 32}}, {"pk": 78, "model": "server.vote", "fields": {"post": 62, "type": 0, "author": 22}}, {"pk": 79, "model": "server.vote", "fields": {"post": 64, "type": 0, "author": 22}}, {"pk": 80, "model": "server.vote", "fields": {"post": 59, "type": 2, "author": 22}}, {"pk": 81, "model": "server.vote", "fields": {"post": 59, "type": 0, "author": 22}}, {"pk": 82, "model": "server.vote", "fields": {"post": 67, "type": 0, "author": 22}}, {"pk": 83, "model": "server.vote", "fields": {"post": 63, "type": 0, "author": 22}}, {"pk": 84, "model": "server.vote", "fields": {"post": 63, "type": 2, "author": 22}}, {"pk": 85, "model": "server.vote", "fields": {"post": 27, "type": 0, "author": 22}}, {"pk": 86, "model": "server.vote", "fields": {"post": 65, "type": 0, "author": 22}}, {"pk": 87, "model": "server.vote", "fields": {"post": 68, "type": 0, "author": 22}}, {"pk": 88, "model": "server.vote", "fields": {"post": 58, "type": 0, "author": 37}}, {"pk": 89, "model": "server.vote", "fields": {"post": 68, "type": 2, "author": 22}}, {"pk": 90, "model": "server.vote", "fields": {"post": 68, "type": 0, "author": 29}}, {"pk": 91, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 22}}, {"pk": 92, "model": "server.vote", "fields": {"post": 70, "type": 0, "author": 22}}, {"pk": 93, "model": "server.vote", "fields": {"post": 67, "type": 0, "author": 1}}, {"pk": 94, "model": "server.vote", "fields": {"post": 70, "type": 0, "author": 1}}, {"pk": 95, "model": "server.vote", "fields": {"post": 71, "type": 0, "author": 1}}, {"pk": 96, "model": "server.vote", "fields": {"post": 71, "type": 0, "author": 22}}, {"pk": 97, "model": "server.vote", "fields": {"post": 73, "type": 0, "author": 22}}, {"pk": 98, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 1}}, {"pk": 99, "model": "server.vote", "fields": {"post": 73, "type": 0, "author": 29}}, {"pk": 100, "model": "server.vote", "fields": {"post": 72, "type": 0, "author": 1}}, {"pk": 101, "model": "server.vote", "fields": {"post": 46, "type": 0, "author": 29}}, {"pk": 102, "model": "server.vote", "fields": {"post": 63, "type": 0, "author": 29}}, {"pk": 103, "model": "server.vote", "fields": {"post": 74, "type": 0, "author": 22}}, {"pk": 104, "model": "server.vote", "fields": {"post": 74, "type": 0, "author": 29}}, {"pk": 105, "model": "server.vote", "fields": {"post": 74, "type": 2, "author": 29}}, {"pk": 106, "model": "server.vote", "fields": {"post": 74, "type": 0, "author": 1}}, {"pk": 107, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 30}}, {"pk": 108, "model": "server.vote", "fields": {"post": 74, "type": 0, "author": 30}}, {"pk": 109, "model": "server.vote", "fields": {"post": 75, "type": 0, "author": 1}}, {"pk": 110, "model": "server.vote", "fields": {"post": 73, "type": 0, "author": 30}}, {"pk": 111, "model": "server.vote", "fields": {"post": 77, "type": 0, "author": 1}}, {"pk": 112, "model": "server.vote", "fields": {"post": 76, "type": 0, "author": 1}}, {"pk": 113, "model": "server.vote", "fields": {"post": 78, "type": 0, "author": 29}}, {"pk": 114, "model": "server.vote", "fields": {"post": 79, "type": 0, "author": 1}}, {"pk": 115, "model": "server.vote", "fields": {"post": 80, "type": 0, "author": 22}}, {"pk": 116, "model": "server.vote", "fields": {"post": 82, "type": 0, "author": 22}}, {"pk": 117, "model": "server.vote", "fields": {"post": 81, "type": 0, "author": 1}}, {"pk": 118, "model": "server.vote", "fields": {"post": 80, "type": 0, "author": 29}}, {"pk": 119, "model": "server.vote", "fields": {"post": 81, "type": 0, "author": 29}}, {"pk": 120, "model": "server.vote", "fields": {"post": 83, "type": 0, "author": 1}}, {"pk": 121, "model": "server.vote", "fields": {"post": 83, "type": 0, "author": 22}}, {"pk": 122, "model": "server.vote", "fields": {"post": 79, "type": 0, "author": 30}}, {"pk": 123, "model": "server.vote", "fields": {"post": 82, "type": 0, "author": 1}}, {"pk": 124, "model": "server.vote", "fields": {"post": 84, "type": 0, "author": 1}}, {"pk": 125, "model": "server.vote", "fields": {"post": 84, "type": 0, "author": 29}}, {"pk": 126, "model": "server.vote", "fields": {"post": 86, "type": 0, "author": 22}}, {"pk": 127, "model": "server.vote", "fields": {"post": 85, "type": 0, "author": 22}}, {"pk": 128, "model": "server.vote", "fields": {"post": 87, "type": 0, "author": 1}}, {"pk": 129, "model": "server.vote", "fields": {"post": 90, "type": 0, "author": 22}}, {"pk": 130, "model": "server.vote", "fields": {"post": 91, "type": 0, "author": 1}}, {"pk": 131, "model": "server.vote", "fields": {"post": 93, "type": 0, "author": 9}}, {"pk": 132, "model": "server.vote", "fields": {"post": 88, "type": 0, "author": 1}}, {"pk": 133, "model": "server.vote", "fields": {"post": 5, "type": 0, "author": 9}}, {"pk": 134, "model": "server.vote", "fields": {"post": 92, "type": 0, "author": 1}}, {"pk": 135, "model": "server.vote", "fields": {"post": 91, "type": 0, "author": 22}}, {"pk": 136, "model": "server.vote", "fields": {"post": 95, "type": 0, "author": 1}}, {"pk": 137, "model": "server.vote", "fields": {"post": 95, "type": 0, "author": 22}}, {"pk": 138, "model": "server.vote", "fields": {"post": 95, "type": 2, "author": 22}}, {"pk": 139, "model": "server.vote", "fields": {"post": 97, "type": 0, "author": 1}}, {"pk": 140, "model": "server.vote", "fields": {"post": 96, "type": 0, "author": 1}}, {"pk": 141, "model": "server.vote", "fields": {"post": 99, "type": 0, "author": 1}}, {"pk": 142, "model": "server.vote", "fields": {"post": 100, "type": 0, "author": 9}}, {"pk": 143, "model": "server.vote", "fields": {"post": 101, "type": 0, "author": 9}}, {"pk": 144, "model": "server.vote", "fields": {"post": 98, "type": 0, "author": 22}}, {"pk": 145, "model": "server.vote", "fields": {"post": 104, "type": 0, "author": 29}}, {"pk": 146, "model": "server.vote", "fields": {"post": 103, "type": 0, "author": 37}}, {"pk": 147, "model": "server.vote", "fields": {"post": 105, "type": 0, "author": 22}}, {"pk": 148, "model": "server.vote", "fields": {"post": 103, "type": 0, "author": 22}}, {"pk": 149, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 54}}, {"pk": 150, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 54}}, {"pk": 151, "model": "server.vote", "fields": {"post": 107, "type": 0, "author": 22}}, {"pk": 152, "model": "server.vote", "fields": {"post": 108, "type": 0, "author": 22}}, {"pk": 153, "model": "server.vote", "fields": {"post": 109, "type": 0, "author": 61}}, {"pk": 154, "model": "server.vote", "fields": {"post": 106, "type": 0, "author": 1}}, {"pk": 155, "model": "server.vote", "fields": {"post": 104, "type": 0, "author": 1}}, {"pk": 156, "model": "server.vote", "fields": {"post": 102, "type": 0, "author": 1}}, {"pk": 157, "model": "server.vote", "fields": {"post": 110, "type": 0, "author": 1}}, {"pk": 158, "model": "server.vote", "fields": {"post": 100, "type": 0, "author": 22}}, {"pk": 159, "model": "server.vote", "fields": {"post": 101, "type": 0, "author": 22}}, {"pk": 160, "model": "server.vote", "fields": {"post": 111, "type": 0, "author": 22}}, {"pk": 161, "model": "server.vote", "fields": {"post": 111, "type": 0, "author": 1}}, {"pk": 162, "model": "server.vote", "fields": {"post": 111, "type": 0, "author": 22}}, {"pk": 163, "model": "server.vote", "fields": {"post": 113, "type": 0, "author": 22}}, {"pk": 164, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 44}}, {"pk": 165, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 44}}, {"pk": 166, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 1}}, {"pk": 167, "model": "server.vote", "fields": {"post": 116, "type": 0, "author": 1}}, {"pk": 168, "model": "server.vote", "fields": {"post": 115, "type": 0, "author": 1}}, {"pk": 169, "model": "server.vote", "fields": {"post": 114, "type": 0, "author": 1}}, {"pk": 170, "model": "server.vote", "fields": {"post": 115, "type": 0, "author": 9}}, {"pk": 171, "model": "server.vote", "fields": {"post": 117, "type": 0, "author": 52}}, {"pk": 172, "model": "server.vote", "fields": {"post": 113, "type": 0, "author": 9}}, {"pk": 173, "model": "server.vote", "fields": {"post": 118, "type": 0, "author": 29}}, {"pk": 174, "model": "server.vote", "fields": {"post": 115, "type": 0, "author": 61}}, {"pk": 175, "model": "server.vote", "fields": {"post": 114, "type": 0, "author": 61}}, {"pk": 176, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 54}}, {"pk": 177, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 1}}, {"pk": 178, "model": "server.vote", "fields": {"post": 114, "type": 0, "author": 61}}, {"pk": 179, "model": "server.vote", "fields": {"post": 99, "type": 0, "author": 54}}, {"pk": 180, "model": "server.vote", "fields": {"post": 113, "type": 0, "author": 43}}, {"pk": 181, "model": "server.vote", "fields": {"post": 78, "type": 0, "author": 43}}, {"pk": 182, "model": "server.vote", "fields": {"post": 78, "type": 2, "author": 43}}, {"pk": 183, "model": "server.vote", "fields": {"post": 117, "type": 0, "author": 61}}, {"pk": 184, "model": "server.vote", "fields": {"post": 116, "type": 0, "author": 61}}, {"pk": 185, "model": "server.vote", "fields": {"post": 118, "type": 0, "author": 61}}, {"pk": 186, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 61}}, {"pk": 187, "model": "server.vote", "fields": {"post": 56, "type": 0, "author": 52}}, {"pk": 188, "model": "server.vote", "fields": {"post": 57, "type": 0, "author": 52}}, {"pk": 189, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 54}}, {"pk": 190, "model": "server.vote", "fields": {"post": 119, "type": 0, "author": 1}}, {"pk": 191, "model": "server.vote", "fields": {"post": 121, "type": 0, "author": 1}}, {"pk": 192, "model": "server.vote", "fields": {"post": 116, "type": 0, "author": 22}}, {"pk": 193, "model": "server.vote", "fields": {"post": 117, "type": 0, "author": 22}}, {"pk": 194, "model": "server.vote", "fields": {"post": 118, "type": 0, "author": 22}}, {"pk": 195, "model": "server.vote", "fields": {"post": 119, "type": 0, "author": 22}}, {"pk": 196, "model": "server.vote", "fields": {"post": 121, "type": 0, "author": 22}}, {"pk": 197, "model": "server.vote", "fields": {"post": 120, "type": 0, "author": 22}}, {"pk": 198, "model": "server.vote", "fields": {"post": 121, "type": 0, "author": 52}}, {"pk": 199, "model": "server.vote", "fields": {"post": 122, "type": 0, "author": 1}}, {"pk": 200, "model": "server.vote", "fields": {"post": 38, "type": 0, "author": 29}}, {"pk": 201, "model": "server.vote", "fields": {"post": 122, "type": 0, "author": 22}}, {"pk": 202, "model": "server.vote", "fields": {"post": 4, "type": 0, "author": 22}}, {"pk": 203, "model": "server.vote", "fields": {"post": 123, "type": 0, "author": 22}}, {"pk": 204, "model": "server.vote", "fields": {"post": 114, "type": 0, "author": 22}}, {"pk": 205, "model": "server.vote", "fields": {"post": 111, "type": 1, "author": 22}}, {"pk": 206, "model": "server.vote", "fields": {"post": 115, "type": 0, "author": 22}}, {"pk": 207, "model": "server.vote", "fields": {"post": 125, "type": 0, "author": 9}}, {"pk": 208, "model": "server.vote", "fields": {"post": 125, "type": 0, "author": 1}}, {"pk": 209, "model": "server.vote", "fields": {"post": 98, "type": 0, "author": 1}}, {"pk": 210, "model": "server.vote", "fields": {"post": 76, "type": 0, "author": 58}}, {"pk": 211, "model": "server.vote", "fields": {"post": 121, "type": 0, "author": 39}}, {"pk": 212, "model": "server.vote", "fields": {"post": 114, "type": 2, "author": 61}}, {"pk": 213, "model": "server.vote", "fields": {"post": 126, "type": 0, "author": 22}}, {"pk": 214, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 1}}, {"pk": 215, "model": "server.vote", "fields": {"post": 111, "type": 0, "author": 1}}, {"pk": 216, "model": "server.vote", "fields": {"post": 127, "type": 0, "author": 1}}, {"pk": 217, "model": "server.vote", "fields": {"post": 127, "type": 0, "author": 61}}, {"pk": 218, "model": "server.vote", "fields": {"post": 127, "type": 0, "author": 22}}, {"pk": 219, "model": "server.vote", "fields": {"post": 87, "type": 0, "author": 22}}, {"pk": 220, "model": "server.vote", "fields": {"post": 110, "type": 0, "author": 22}}, {"pk": 221, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 64}}, {"pk": 222, "model": "server.vote", "fields": {"post": 121, "type": 0, "author": 64}}, {"pk": 223, "model": "server.vote", "fields": {"post": 128, "type": 0, "author": 64}}, {"pk": 224, "model": "server.vote", "fields": {"post": 127, "type": 0, "author": 29}}, {"pk": 225, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 65}}, {"pk": 226, "model": "server.vote", "fields": {"post": 129, "type": 0, "author": 37}}, {"pk": 227, "model": "server.vote", "fields": {"post": 128, "type": 0, "author": 22}}, {"pk": 228, "model": "server.vote", "fields": {"post": 129, "type": 0, "author": 22}}, {"pk": 229, "model": "server.vote", "fields": {"post": 117, "type": 0, "author": 66}}, {"pk": 230, "model": "server.vote", "fields": {"post": 94, "type": 0, "author": 67}}, {"pk": 231, "model": "server.vote", "fields": {"post": 96, "type": 0, "author": 22}}, {"pk": 232, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 67}}, {"pk": 233, "model": "server.vote", "fields": {"post": 116, "type": 0, "author": 67}}, {"pk": 234, "model": "server.vote", "fields": {"post": 118, "type": 0, "author": 67}}, {"pk": 235, "model": "server.vote", "fields": {"post": 37, "type": 0, "author": 68}}, {"pk": 236, "model": "server.vote", "fields": {"post": 129, "type": 0, "author": 54}}, {"pk": 237, "model": "server.vote", "fields": {"post": 66, "type": 0, "author": 67}}, {"pk": 238, "model": "server.vote", "fields": {"post": 30, "type": 0, "author": 67}}, {"pk": 239, "model": "server.vote", "fields": {"post": 33, "type": 0, "author": 67}}, {"pk": 240, "model": "server.vote", "fields": {"post": 130, "type": 0, "author": 22}}, {"pk": 241, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 67}}, {"pk": 242, "model": "server.vote", "fields": {"post": 34, "type": 0, "author": 67}}, {"pk": 243, "model": "server.vote", "fields": {"post": 81, "type": 0, "author": 67}}, {"pk": 244, "model": "server.vote", "fields": {"post": 129, "type": 0, "author": 6}}, {"pk": 245, "model": "server.vote", "fields": {"post": 129, "type": 2, "author": 6}}, {"pk": 246, "model": "server.vote", "fields": {"post": 131, "type": 0, "author": 1}}, {"pk": 247, "model": "server.vote", "fields": {"post": 132, "type": 0, "author": 22}}, {"pk": 248, "model": "server.vote", "fields": {"post": 131, "type": 0, "author": 22}}, {"pk": 249, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 22}}, {"pk": 250, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 6}}, {"pk": 251, "model": "server.vote", "fields": {"post": 132, "type": 0, "author": 29}}, {"pk": 252, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 9}}, {"pk": 253, "model": "server.vote", "fields": {"post": 136, "type": 0, "author": 9}}, {"pk": 254, "model": "server.vote", "fields": {"post": 134, "type": 0, "author": 9}}, {"pk": 255, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 55}}, {"pk": 256, "model": "server.vote", "fields": {"post": 140, "type": 0, "author": 22}}, {"pk": 257, "model": "server.vote", "fields": {"post": 136, "type": 0, "author": 22}}, {"pk": 258, "model": "server.vote", "fields": {"post": 136, "type": 2, "author": 22}}, {"pk": 259, "model": "server.vote", "fields": {"post": 134, "type": 0, "author": 22}}, {"pk": 260, "model": "server.vote", "fields": {"post": 138, "type": 0, "author": 22}}, {"pk": 261, "model": "server.vote", "fields": {"post": 141, "type": 0, "author": 1}}, {"pk": 262, "model": "server.vote", "fields": {"post": 137, "type": 0, "author": 1}}, {"pk": 263, "model": "server.vote", "fields": {"post": 144, "type": 0, "author": 71}}, {"pk": 264, "model": "server.vote", "fields": {"post": 132, "type": 0, "author": 37}}, {"pk": 265, "model": "server.vote", "fields": {"post": 142, "type": 0, "author": 1}}, {"pk": 266, "model": "server.vote", "fields": {"post": 146, "type": 0, "author": 1}}, {"pk": 267, "model": "server.vote", "fields": {"post": 76, "type": 0, "author": 70}}, {"pk": 268, "model": "server.vote", "fields": {"post": 147, "type": 0, "author": 1}}, {"pk": 269, "model": "server.vote", "fields": {"post": 143, "type": 0, "author": 22}}, {"pk": 270, "model": "server.vote", "fields": {"post": 147, "type": 0, "author": 29}}, {"pk": 271, "model": "server.vote", "fields": {"post": 148, "type": 0, "author": 22}}, {"pk": 272, "model": "server.vote", "fields": {"post": 149, "type": 0, "author": 29}}, {"pk": 273, "model": "server.vote", "fields": {"post": 139, "type": 0, "author": 1}}, {"pk": 274, "model": "server.vote", "fields": {"post": 148, "type": 0, "author": 29}}, {"pk": 275, "model": "server.vote", "fields": {"post": 122, "type": 0, "author": 72}}, {"pk": 276, "model": "server.vote", "fields": {"post": 138, "type": 0, "author": 1}}, {"pk": 277, "model": "server.vote", "fields": {"post": 151, "type": 0, "author": 1}}, {"pk": 278, "model": "server.vote", "fields": {"post": 151, "type": 0, "author": 1}}, {"pk": 279, "model": "server.vote", "fields": {"post": 146, "type": 0, "author": 22}}, {"pk": 280, "model": "server.vote", "fields": {"post": 145, "type": 0, "author": 66}}, {"pk": 281, "model": "server.vote", "fields": {"post": 59, "type": 0, "author": 73}}, {"pk": 282, "model": "server.vote", "fields": {"post": 106, "type": 0, "author": 73}}, {"pk": 283, "model": "server.vote", "fields": {"post": 154, "type": 0, "author": 1}}, {"pk": 284, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 58}}, {"pk": 285, "model": "server.vote", "fields": {"post": 145, "type": 0, "author": 58}}, {"pk": 286, "model": "server.vote", "fields": {"post": 154, "type": 0, "author": 22}}, {"pk": 287, "model": "server.vote", "fields": {"post": 153, "type": 0, "author": 22}}, {"pk": 288, "model": "server.vote", "fields": {"post": 152, "type": 0, "author": 22}}, {"pk": 289, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 76}}, {"pk": 290, "model": "server.vote", "fields": {"post": 94, "type": 0, "author": 72}}, {"pk": 291, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 77}}, {"pk": 292, "model": "server.vote", "fields": {"post": 41, "type": 0, "author": 75}}, {"pk": 293, "model": "server.vote", "fields": {"post": 132, "type": 0, "author": 54}}, {"pk": 294, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 54}}, {"pk": 295, "model": "server.vote", "fields": {"post": 137, "type": 0, "author": 54}}, {"pk": 296, "model": "server.vote", "fields": {"post": 139, "type": 1, "author": 54}}, {"pk": 297, "model": "server.vote", "fields": {"post": 146, "type": 1, "author": 54}}, {"pk": 298, "model": "server.vote", "fields": {"post": 156, "type": 0, "author": 1}}, {"pk": 299, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 81}}, {"pk": 300, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 78}}, {"pk": 301, "model": "server.vote", "fields": {"post": 156, "type": 2, "author": 29}}, {"pk": 302, "model": "server.vote", "fields": {"post": 156, "type": 2, "author": 29}}, {"pk": 303, "model": "server.vote", "fields": {"post": 156, "type": 2, "author": 29}}, {"pk": 304, "model": "server.vote", "fields": {"post": 86, "type": 0, "author": 29}}, {"pk": 305, "model": "server.vote", "fields": {"post": 162, "type": 0, "author": 29}}, {"pk": 306, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 25}}, {"pk": 307, "model": "server.vote", "fields": {"post": 161, "type": 0, "author": 1}}, {"pk": 308, "model": "server.vote", "fields": {"post": 160, "type": 0, "author": 1}}, {"pk": 309, "model": "server.vote", "fields": {"post": 164, "type": 0, "author": 6}}, {"pk": 310, "model": "server.vote", "fields": {"post": 150, "type": 0, "author": 6}}, {"pk": 311, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 77}}, {"pk": 312, "model": "server.vote", "fields": {"post": 160, "type": 0, "author": 22}}, {"pk": 313, "model": "server.vote", "fields": {"post": 158, "type": 0, "author": 22}}, {"pk": 314, "model": "server.vote", "fields": {"post": 157, "type": 0, "author": 22}}, {"pk": 315, "model": "server.vote", "fields": {"post": 161, "type": 0, "author": 22}}, {"pk": 316, "model": "server.vote", "fields": {"post": 163, "type": 0, "author": 22}}, {"pk": 317, "model": "server.vote", "fields": {"post": 139, "type": 0, "author": 1}}, {"pk": 318, "model": "server.vote", "fields": {"post": 162, "type": 0, "author": 22}}, {"pk": 319, "model": "server.vote", "fields": {"post": 139, "type": 0, "author": 1}}, {"pk": 320, "model": "server.vote", "fields": {"post": 139, "type": 1, "author": 1}}, {"pk": 321, "model": "server.vote", "fields": {"post": 139, "type": 0, "author": 22}}, {"pk": 322, "model": "server.vote", "fields": {"post": 138, "type": 0, "author": 67}}, {"pk": 323, "model": "server.vote", "fields": {"post": 80, "type": 0, "author": 67}}, {"pk": 324, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 13}}, {"pk": 325, "model": "server.vote", "fields": {"post": 167, "type": 0, "author": 1}}, {"pk": 326, "model": "server.vote", "fields": {"post": 159, "type": 0, "author": 1}}, {"pk": 327, "model": "server.vote", "fields": {"post": 149, "type": 1, "author": 1}}, {"pk": 328, "model": "server.vote", "fields": {"post": 166, "type": 0, "author": 70}}, {"pk": 329, "model": "server.vote", "fields": {"post": 168, "type": 0, "author": 70}}, {"pk": 330, "model": "server.vote", "fields": {"post": 170, "type": 0, "author": 70}}, {"pk": 331, "model": "server.vote", "fields": {"post": 121, "type": 0, "author": 74}}, {"pk": 332, "model": "server.vote", "fields": {"post": 157, "type": 0, "author": 74}}, {"pk": 333, "model": "server.vote", "fields": {"post": 170, "type": 0, "author": 22}}, {"pk": 334, "model": "server.vote", "fields": {"post": 169, "type": 0, "author": 22}}, {"pk": 335, "model": "server.vote", "fields": {"post": 149, "type": 0, "author": 22}}, {"pk": 336, "model": "server.vote", "fields": {"post": 168, "type": 0, "author": 67}}, {"pk": 337, "model": "server.vote", "fields": {"post": 174, "type": 0, "author": 1}}, {"pk": 338, "model": "server.vote", "fields": {"post": 170, "type": 0, "author": 1}}, {"pk": 339, "model": "server.vote", "fields": {"post": 19, "type": 0, "author": 58}}, {"pk": 340, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 64}}, {"pk": 341, "model": "server.vote", "fields": {"post": 177, "type": 0, "author": 22}}, {"pk": 342, "model": "server.vote", "fields": {"post": 177, "type": 2, "author": 22}}, {"pk": 343, "model": "server.vote", "fields": {"post": 151, "type": 0, "author": 9}}, {"pk": 344, "model": "server.vote", "fields": {"post": 178, "type": 0, "author": 1}}, {"pk": 345, "model": "server.vote", "fields": {"post": 175, "type": 0, "author": 58}}, {"pk": 346, "model": "server.vote", "fields": {"post": 67, "type": 0, "author": 58}}, {"pk": 347, "model": "server.vote", "fields": {"post": 179, "type": 0, "author": 22}}, {"pk": 348, "model": "server.vote", "fields": {"post": 180, "type": 0, "author": 22}}, {"pk": 349, "model": "server.vote", "fields": {"post": 144, "type": 0, "author": 58}}, {"pk": 350, "model": "server.vote", "fields": {"post": 175, "type": 0, "author": 1}}, {"pk": 351, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 9}}, {"pk": 352, "model": "server.vote", "fields": {"post": 175, "type": 0, "author": 9}}, {"pk": 353, "model": "server.vote", "fields": {"post": 177, "type": 0, "author": 1}}, {"pk": 354, "model": "server.vote", "fields": {"post": 182, "type": 0, "author": 1}}, {"pk": 355, "model": "server.vote", "fields": {"post": 182, "type": 0, "author": 22}}, {"pk": 356, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 58}}, {"pk": 357, "model": "server.vote", "fields": {"post": 182, "type": 0, "author": 37}}, {"pk": 358, "model": "server.vote", "fields": {"post": 149, "type": 0, "author": 67}}, {"pk": 359, "model": "server.vote", "fields": {"post": 183, "type": 0, "author": 22}}, {"pk": 360, "model": "server.vote", "fields": {"post": 174, "type": 0, "author": 55}}, {"pk": 361, "model": "server.vote", "fields": {"post": 184, "type": 0, "author": 1}}, {"pk": 362, "model": "server.vote", "fields": {"post": 163, "type": 0, "author": 78}}, {"pk": 363, "model": "server.vote", "fields": {"post": 185, "type": 0, "author": 1}}, {"pk": 364, "model": "server.vote", "fields": {"post": 188, "type": 0, "author": 61}}, {"pk": 365, "model": "server.vote", "fields": {"post": 187, "type": 0, "author": 22}}, {"pk": 366, "model": "server.vote", "fields": {"post": 186, "type": 0, "author": 22}}, {"pk": 367, "model": "server.vote", "fields": {"post": 182, "type": 0, "author": 74}}, {"pk": 368, "model": "server.vote", "fields": {"post": 185, "type": 0, "author": 29}}, {"pk": 369, "model": "server.vote", "fields": {"post": 190, "type": 0, "author": 1}}, {"pk": 370, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 72}}, {"pk": 371, "model": "server.vote", "fields": {"post": 79, "type": 0, "author": 72}}, {"pk": 372, "model": "server.vote", "fields": {"post": 192, "type": 0, "author": 1}}, {"pk": 373, "model": "server.vote", "fields": {"post": 175, "type": 0, "author": 71}}, {"pk": 374, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 54}}, {"pk": 375, "model": "server.vote", "fields": {"post": 169, "type": 0, "author": 54}}, {"pk": 376, "model": "server.vote", "fields": {"post": 164, "type": 0, "author": 54}}, {"pk": 377, "model": "server.vote", "fields": {"post": 173, "type": 0, "author": 1}}, {"pk": 378, "model": "server.vote", "fields": {"post": 196, "type": 0, "author": 1}}, {"pk": 379, "model": "server.vote", "fields": {"post": 195, "type": 0, "author": 1}}, {"pk": 380, "model": "server.vote", "fields": {"post": 194, "type": 0, "author": 1}}, {"pk": 381, "model": "server.vote", "fields": {"post": 172, "type": 0, "author": 86}}, {"pk": 382, "model": "server.vote", "fields": {"post": 174, "type": 0, "author": 86}}, {"pk": 383, "model": "server.vote", "fields": {"post": 189, "type": 0, "author": 86}}, {"pk": 384, "model": "server.vote", "fields": {"post": 83, "type": 0, "author": 78}}, {"pk": 385, "model": "server.vote", "fields": {"post": 200, "type": 0, "author": 1}}, {"pk": 386, "model": "server.vote", "fields": {"post": 199, "type": 0, "author": 1}}, {"pk": 387, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 13}}, {"pk": 388, "model": "server.vote", "fields": {"post": 172, "type": 0, "author": 71}}, {"pk": 389, "model": "server.vote", "fields": {"post": 81, "type": 0, "author": 71}}, {"pk": 390, "model": "server.vote", "fields": {"post": 134, "type": 0, "author": 71}}, {"pk": 391, "model": "server.vote", "fields": {"post": 105, "type": 0, "author": 71}}, {"pk": 392, "model": "server.vote", "fields": {"post": 202, "type": 0, "author": 70}}, {"pk": 393, "model": "server.vote", "fields": {"post": 189, "type": 0, "author": 67}}, {"pk": 394, "model": "server.vote", "fields": {"post": 197, "type": 0, "author": 1}}, {"pk": 395, "model": "server.vote", "fields": {"post": 203, "type": 0, "author": 1}}, {"pk": 396, "model": "server.vote", "fields": {"post": 205, "type": 0, "author": 67}}, {"pk": 397, "model": "server.vote", "fields": {"post": 182, "type": 0, "author": 67}}, {"pk": 398, "model": "server.vote", "fields": {"post": 192, "type": 0, "author": 67}}, {"pk": 399, "model": "server.vote", "fields": {"post": 195, "type": 0, "author": 67}}, {"pk": 400, "model": "server.vote", "fields": {"post": 164, "type": 0, "author": 90}}, {"pk": 401, "model": "server.vote", "fields": {"post": 169, "type": 0, "author": 90}}, {"pk": 402, "model": "server.vote", "fields": {"post": 150, "type": 0, "author": 90}}, {"pk": 403, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 90}}, {"pk": 404, "model": "server.vote", "fields": {"post": 201, "type": 0, "author": 35}}, {"pk": 405, "model": "server.vote", "fields": {"post": 197, "type": 0, "author": 61}}, {"pk": 406, "model": "server.vote", "fields": {"post": 208, "type": 0, "author": 1}}, {"pk": 407, "model": "server.vote", "fields": {"post": 207, "type": 0, "author": 1}}, {"pk": 408, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 54}}, {"pk": 409, "model": "server.vote", "fields": {"post": 212, "type": 0, "author": 1}}, {"pk": 410, "model": "server.vote", "fields": {"post": 211, "type": 0, "author": 1}}, {"pk": 411, "model": "server.vote", "fields": {"post": 210, "type": 0, "author": 1}}, {"pk": 412, "model": "server.vote", "fields": {"post": 155, "type": 0, "author": 1}}, {"pk": 413, "model": "server.vote", "fields": {"post": 213, "type": 0, "author": 29}}, {"pk": 414, "model": "server.vote", "fields": {"post": 213, "type": 0, "author": 29}}, {"pk": 415, "model": "server.vote", "fields": {"post": 214, "type": 0, "author": 9}}, {"pk": 416, "model": "server.vote", "fields": {"post": 193, "type": 0, "author": 9}}, {"pk": 417, "model": "server.vote", "fields": {"post": 216, "type": 0, "author": 9}}, {"pk": 418, "model": "server.vote", "fields": {"post": 116, "type": 0, "author": 71}}, {"pk": 419, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 71}}, {"pk": 420, "model": "server.vote", "fields": {"post": 217, "type": 0, "author": 1}}, {"pk": 421, "model": "server.vote", "fields": {"post": 204, "type": 0, "author": 3}}, {"pk": 422, "model": "server.vote", "fields": {"post": 218, "type": 0, "author": 22}}, {"pk": 423, "model": "server.vote", "fields": {"post": 209, "type": 0, "author": 22}}, {"pk": 424, "model": "server.vote", "fields": {"post": 79, "type": 0, "author": 89}}, {"pk": 425, "model": "server.vote", "fields": {"post": 31, "type": 0, "author": 71}}, {"pk": 426, "model": "server.vote", "fields": {"post": 208, "type": 0, "author": 71}}, {"pk": 427, "model": "server.vote", "fields": {"post": 219, "type": 0, "author": 1}}, {"pk": 428, "model": "server.vote", "fields": {"post": 219, "type": 0, "author": 90}}, {"pk": 429, "model": "server.vote", "fields": {"post": 220, "type": 0, "author": 1}}, {"pk": 430, "model": "server.vote", "fields": {"post": 220, "type": 0, "author": 9}}, {"pk": 431, "model": "server.vote", "fields": {"post": 218, "type": 0, "author": 35}}, {"pk": 432, "model": "server.vote", "fields": {"post": 220, "type": 0, "author": 22}}, {"pk": 433, "model": "server.vote", "fields": {"post": 183, "type": 0, "author": 67}}, {"pk": 434, "model": "server.vote", "fields": {"post": 165, "type": 0, "author": 72}}, {"pk": 435, "model": "server.vote", "fields": {"post": 216, "type": 0, "author": 29}}, {"pk": 436, "model": "server.vote", "fields": {"post": 140, "type": 0, "author": 71}}, {"pk": 437, "model": "server.vote", "fields": {"post": 221, "type": 0, "author": 54}}, {"pk": 438, "model": "server.vote", "fields": {"post": 222, "type": 0, "author": 1}}, {"pk": 439, "model": "server.vote", "fields": {"post": 223, "type": 0, "author": 1}}, {"pk": 440, "model": "server.vote", "fields": {"post": 225, "type": 0, "author": 1}}, {"pk": 441, "model": "server.vote", "fields": {"post": 224, "type": 0, "author": 1}}, {"pk": 442, "model": "server.vote", "fields": {"post": 222, "type": 0, "author": 54}}, {"pk": 443, "model": "server.vote", "fields": {"post": 204, "type": 0, "author": 25}}, {"pk": 444, "model": "server.vote", "fields": {"post": 130, "type": 0, "author": 54}}, {"pk": 445, "model": "server.vote", "fields": {"post": 226, "type": 0, "author": 89}}, {"pk": 446, "model": "server.vote", "fields": {"post": 116, "type": 0, "author": 50}}, {"pk": 447, "model": "server.vote", "fields": {"post": 219, "type": 0, "author": 13}}, {"pk": 448, "model": "server.vote", "fields": {"post": 109, "type": 0, "author": 13}}, {"pk": 449, "model": "server.vote", "fields": {"post": 37, "type": 0, "author": 107}}, {"pk": 450, "model": "server.vote", "fields": {"post": 202, "type": 0, "author": 107}}, {"pk": 451, "model": "server.vote", "fields": {"post": 225, "type": 0, "author": 22}}, {"pk": 452, "model": "server.vote", "fields": {"post": 223, "type": 0, "author": 22}}, {"pk": 453, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 109}}, {"pk": 454, "model": "server.vote", "fields": {"post": 203, "type": 0, "author": 109}}, {"pk": 455, "model": "server.vote", "fields": {"post": 228, "type": 0, "author": 1}}, {"pk": 456, "model": "server.vote", "fields": {"post": 151, "type": 0, "author": 22}}, {"pk": 457, "model": "server.vote", "fields": {"post": 231, "type": 0, "author": 35}}, {"pk": 458, "model": "server.vote", "fields": {"post": 171, "type": 0, "author": 58}}, {"pk": 459, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 25}}, {"pk": 460, "model": "server.vote", "fields": {"post": 232, "type": 0, "author": 1}}, {"pk": 461, "model": "server.vote", "fields": {"post": 232, "type": 0, "author": 25}}, {"pk": 462, "model": "server.vote", "fields": {"post": 119, "type": 0, "author": 112}}, {"pk": 463, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 112}}, {"pk": 464, "model": "server.vote", "fields": {"post": 137, "type": 0, "author": 112}}, {"pk": 465, "model": "server.vote", "fields": {"post": 143, "type": 0, "author": 112}}, {"pk": 466, "model": "server.vote", "fields": {"post": 221, "type": 0, "author": 112}}, {"pk": 467, "model": "server.vote", "fields": {"post": 223, "type": 0, "author": 112}}, {"pk": 468, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 112}}, {"pk": 469, "model": "server.vote", "fields": {"post": 127, "type": 0, "author": 112}}, {"pk": 470, "model": "server.vote", "fields": {"post": 73, "type": 0, "author": 112}}, {"pk": 471, "model": "server.vote", "fields": {"post": 71, "type": 0, "author": 112}}, {"pk": 472, "model": "server.vote", "fields": {"post": 31, "type": 0, "author": 112}}, {"pk": 473, "model": "server.vote", "fields": {"post": 162, "type": 0, "author": 61}}, {"pk": 474, "model": "server.vote", "fields": {"post": 130, "type": 0, "author": 112}}, {"pk": 475, "model": "server.vote", "fields": {"post": 197, "type": 0, "author": 112}}, {"pk": 476, "model": "server.vote", "fields": {"post": 208, "type": 0, "author": 112}}, {"pk": 477, "model": "server.vote", "fields": {"post": 221, "type": 0, "author": 1}}, {"pk": 478, "model": "server.vote", "fields": {"post": 232, "type": 0, "author": 58}}, {"pk": 479, "model": "server.vote", "fields": {"post": 232, "type": 0, "author": 88}}, {"pk": 480, "model": "server.vote", "fields": {"post": 233, "type": 0, "author": 67}}, {"pk": 481, "model": "server.vote", "fields": {"post": 236, "type": 0, "author": 67}}, {"pk": 482, "model": "server.vote", "fields": {"post": 235, "type": 0, "author": 61}}, {"pk": 483, "model": "server.vote", "fields": {"post": 235, "type": 0, "author": 71}}, {"pk": 484, "model": "server.vote", "fields": {"post": 237, "type": 0, "author": 71}}, {"pk": 485, "model": "server.vote", "fields": {"post": 235, "type": 0, "author": 1}}, {"pk": 486, "model": "server.vote", "fields": {"post": 234, "type": 0, "author": 50}}, {"pk": 487, "model": "server.vote", "fields": {"post": 232, "type": 0, "author": 116}}, {"pk": 488, "model": "server.vote", "fields": {"post": 234, "type": 0, "author": 116}}, {"pk": 489, "model": "server.vote", "fields": {"post": 236, "type": 0, "author": 116}}, {"pk": 490, "model": "server.vote", "fields": {"post": 237, "type": 0, "author": 116}}, {"pk": 491, "model": "server.vote", "fields": {"post": 84, "type": 0, "author": 116}}, {"pk": 492, "model": "server.vote", "fields": {"post": 239, "type": 0, "author": 29}}, {"pk": 493, "model": "server.vote", "fields": {"post": 239, "type": 0, "author": 22}}, {"pk": 494, "model": "server.vote", "fields": {"post": 31, "type": 0, "author": 118}}, {"pk": 495, "model": "server.vote", "fields": {"post": 208, "type": 0, "author": 118}}, {"pk": 496, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 29}}, {"pk": 497, "model": "server.vote", "fields": {"post": 240, "type": 0, "author": 1}}, {"pk": 498, "model": "server.vote", "fields": {"post": 242, "type": 0, "author": 90}}, {"pk": 499, "model": "server.vote", "fields": {"post": 226, "type": 0, "author": 90}}, {"pk": 500, "model": "server.vote", "fields": {"post": 204, "type": 0, "author": 90}}, {"pk": 501, "model": "server.vote", "fields": {"post": 238, "type": 0, "author": 1}}, {"pk": 502, "model": "server.vote", "fields": {"post": 53, "type": 0, "author": 112}}, {"pk": 503, "model": "server.vote", "fields": {"post": 207, "type": 0, "author": 112}}, {"pk": 504, "model": "server.vote", "fields": {"post": 55, "type": 0, "author": 112}}, {"pk": 505, "model": "server.vote", "fields": {"post": 244, "type": 0, "author": 22}}, {"pk": 506, "model": "server.vote", "fields": {"post": 241, "type": 0, "author": 22}}, {"pk": 507, "model": "server.vote", "fields": {"post": 221, "type": 0, "author": 55}}, {"pk": 508, "model": "server.vote", "fields": {"post": 240, "type": 0, "author": 55}}, {"pk": 509, "model": "server.vote", "fields": {"post": 224, "type": 0, "author": 55}}, {"pk": 510, "model": "server.vote", "fields": {"post": 246, "type": 0, "author": 116}}, {"pk": 511, "model": "server.vote", "fields": {"post": 242, "type": 0, "author": 25}}, {"pk": 512, "model": "server.vote", "fields": {"post": 234, "type": 0, "author": 25}}, {"pk": 513, "model": "server.vote", "fields": {"post": 248, "type": 0, "author": 54}}, {"pk": 514, "model": "server.vote", "fields": {"post": 239, "type": 0, "author": 89}}, {"pk": 515, "model": "server.vote", "fields": {"post": 245, "type": 0, "author": 1}}, {"pk": 516, "model": "server.vote", "fields": {"post": 229, "type": 0, "author": 109}}, {"pk": 517, "model": "server.vote", "fields": {"post": 249, "type": 0, "author": 109}}, {"pk": 518, "model": "server.vote", "fields": {"post": 248, "type": 0, "author": 90}}, {"pk": 519, "model": "server.vote", "fields": {"post": 250, "type": 0, "author": 22}}, {"pk": 520, "model": "server.vote", "fields": {"post": 243, "type": 0, "author": 25}}, {"pk": 521, "model": "server.vote", "fields": {"post": 246, "type": 0, "author": 55}}, {"pk": 522, "model": "server.vote", "fields": {"post": 152, "type": 0, "author": 90}}, {"pk": 523, "model": "server.vote", "fields": {"post": 244, "type": 0, "author": 90}}, {"pk": 524, "model": "server.vote", "fields": {"post": 252, "type": 0, "author": 90}}, {"pk": 525, "model": "server.vote", "fields": {"post": 252, "type": 0, "author": 61}}, {"pk": 526, "model": "server.vote", "fields": {"post": 252, "type": 0, "author": 70}}, {"pk": 527, "model": "server.vote", "fields": {"post": 253, "type": 0, "author": 1}}, {"pk": 528, "model": "server.vote", "fields": {"post": 247, "type": 0, "author": 1}}, {"pk": 529, "model": "server.vote", "fields": {"post": 246, "type": 0, "author": 22}}, {"pk": 530, "model": "server.vote", "fields": {"post": 253, "type": 0, "author": 22}}, {"pk": 531, "model": "server.vote", "fields": {"post": 251, "type": 0, "author": 1}}, {"pk": 532, "model": "server.vote", "fields": {"post": 252, "type": 0, "author": 29}}, {"pk": 533, "model": "server.vote", "fields": {"post": 232, "type": 0, "author": 23}}, {"pk": 534, "model": "server.vote", "fields": {"post": 251, "type": 0, "author": 54}}, {"pk": 535, "model": "server.vote", "fields": {"post": 128, "type": 0, "author": 23}}, {"pk": 536, "model": "server.vote", "fields": {"post": 253, "type": 0, "author": 13}}, {"pk": 537, "model": "server.vote", "fields": {"post": 245, "type": 0, "author": 13}}, {"pk": 538, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 13}}, {"pk": 539, "model": "server.vote", "fields": {"post": 246, "type": 0, "author": 121}}, {"pk": 540, "model": "server.vote", "fields": {"post": 259, "type": 0, "author": 90}}, {"pk": 541, "model": "server.vote", "fields": {"post": 258, "type": 0, "author": 1}}, {"pk": 542, "model": "server.vote", "fields": {"post": 255, "type": 0, "author": 1}}, {"pk": 543, "model": "server.vote", "fields": {"post": 256, "type": 0, "author": 1}}, {"pk": 544, "model": "server.vote", "fields": {"post": 215, "type": 0, "author": 1}}, {"pk": 545, "model": "server.vote", "fields": {"post": 263, "type": 0, "author": 118}}, {"pk": 546, "model": "server.vote", "fields": {"post": 264, "type": 0, "author": 25}}, {"pk": 547, "model": "server.vote", "fields": {"post": 125, "type": 0, "author": 90}}, {"pk": 548, "model": "server.vote", "fields": {"post": 263, "type": 0, "author": 22}}, {"pk": 549, "model": "server.vote", "fields": {"post": 256, "type": 0, "author": 22}}, {"pk": 550, "model": "server.vote", "fields": {"post": 266, "type": 0, "author": 22}}, {"pk": 551, "model": "server.vote", "fields": {"post": 258, "type": 0, "author": 37}}, {"pk": 552, "model": "server.vote", "fields": {"post": 258, "type": 0, "author": 29}}, {"pk": 553, "model": "server.vote", "fields": {"post": 266, "type": 0, "author": 29}}, {"pk": 554, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 22}}, {"pk": 555, "model": "server.vote", "fields": {"post": 266, "type": 0, "author": 67}}, {"pk": 556, "model": "server.vote", "fields": {"post": 265, "type": 0, "author": 1}}, {"pk": 557, "model": "server.vote", "fields": {"post": 261, "type": 0, "author": 72}}, {"pk": 558, "model": "server.vote", "fields": {"post": 267, "type": 0, "author": 22}}, {"pk": 559, "model": "server.vote", "fields": {"post": 246, "type": 0, "author": 37}}, {"pk": 560, "model": "server.vote", "fields": {"post": 265, "type": 0, "author": 112}}, {"pk": 561, "model": "server.vote", "fields": {"post": 266, "type": 0, "author": 35}}, {"pk": 562, "model": "server.vote", "fields": {"post": 266, "type": 0, "author": 90}}, {"pk": 563, "model": "server.vote", "fields": {"post": 59, "type": 0, "author": 112}}, {"pk": 564, "model": "server.vote", "fields": {"post": 267, "type": 0, "author": 1}}, {"pk": 565, "model": "server.vote", "fields": {"post": 250, "type": 0, "author": 1}}, {"pk": 566, "model": "server.vote", "fields": {"post": 250, "type": 1, "author": 1}}, {"pk": 567, "model": "server.vote", "fields": {"post": 250, "type": 0, "author": 1}}, {"pk": 568, "model": "server.vote", "fields": {"post": 261, "type": 0, "author": 116}}, {"pk": 569, "model": "server.vote", "fields": {"post": 79, "type": 0, "author": 112}}, {"pk": 570, "model": "server.vote", "fields": {"post": 95, "type": 0, "author": 112}}, {"pk": 571, "model": "server.vote", "fields": {"post": 266, "type": 0, "author": 121}}, {"pk": 572, "model": "server.vote", "fields": {"post": 266, "type": 2, "author": 121}}, {"pk": 573, "model": "server.vote", "fields": {"post": 267, "type": 0, "author": 58}}, {"pk": 574, "model": "server.vote", "fields": {"post": 246, "type": 0, "author": 58}}, {"pk": 575, "model": "server.vote", "fields": {"post": 266, "type": 0, "author": 58}}, {"pk": 576, "model": "server.vote", "fields": {"post": 268, "type": 0, "author": 22}}, {"pk": 577, "model": "server.vote", "fields": {"post": 268, "type": 0, "author": 89}}, {"pk": 578, "model": "server.vote", "fields": {"post": 268, "type": 0, "author": 37}}, {"pk": 579, "model": "server.vote", "fields": {"post": 268, "type": 0, "author": 29}}, {"pk": 580, "model": "server.vote", "fields": {"post": 270, "type": 0, "author": 58}}, {"pk": 581, "model": "server.vote", "fields": {"post": 269, "type": 0, "author": 58}}, {"pk": 582, "model": "server.vote", "fields": {"post": 269, "type": 0, "author": 22}}, {"pk": 583, "model": "server.vote", "fields": {"post": 270, "type": 0, "author": 22}}, {"pk": 584, "model": "server.vote", "fields": {"post": 124, "type": 2, "author": 22}}, {"pk": 585, "model": "server.vote", "fields": {"post": 124, "type": 2, "author": 22}}, {"pk": 586, "model": "server.vote", "fields": {"post": 121, "type": 2, "author": 22}}, {"pk": 587, "model": "server.vote", "fields": {"post": 131, "type": 2, "author": 22}}, {"pk": 588, "model": "server.vote", "fields": {"post": 272, "type": 0, "author": 58}}, {"pk": 589, "model": "server.vote", "fields": {"post": 273, "type": 0, "author": 37}}, {"pk": 590, "model": "server.vote", "fields": {"post": 273, "type": 0, "author": 61}}, {"pk": 591, "model": "server.vote", "fields": {"post": 276, "type": 0, "author": 54}}, {"pk": 592, "model": "server.vote", "fields": {"post": 275, "type": 0, "author": 22}}, {"pk": 593, "model": "server.vote", "fields": {"post": 268, "type": 0, "author": 113}}, {"pk": 594, "model": "server.vote", "fields": {"post": 277, "type": 0, "author": 22}}, {"pk": 595, "model": "server.vote", "fields": {"post": 274, "type": 0, "author": 22}}, {"pk": 596, "model": "server.vote", "fields": {"post": 272, "type": 0, "author": 22}}, {"pk": 597, "model": "server.vote", "fields": {"post": 278, "type": 0, "author": 22}}, {"pk": 598, "model": "server.vote", "fields": {"post": 271, "type": 0, "author": 1}}, {"pk": 599, "model": "server.vote", "fields": {"post": 275, "type": 0, "author": 1}}, {"pk": 600, "model": "server.vote", "fields": {"post": 276, "type": 0, "author": 1}}, {"pk": 601, "model": "server.vote", "fields": {"post": 278, "type": 0, "author": 1}}, {"pk": 602, "model": "server.vote", "fields": {"post": 274, "type": 0, "author": 1}}, {"pk": 603, "model": "server.vote", "fields": {"post": 272, "type": 0, "author": 1}}, {"pk": 604, "model": "server.vote", "fields": {"post": 270, "type": 0, "author": 1}}, {"pk": 605, "model": "server.vote", "fields": {"post": 269, "type": 0, "author": 1}}, {"pk": 606, "model": "server.vote", "fields": {"post": 268, "type": 0, "author": 1}}, {"pk": 607, "model": "server.vote", "fields": {"post": 281, "type": 2, "author": 52}}, {"pk": 608, "model": "server.vote", "fields": {"post": 281, "type": 0, "author": 52}}, {"pk": 609, "model": "server.vote", "fields": {"post": 278, "type": 0, "author": 71}}, {"pk": 610, "model": "server.vote", "fields": {"post": 268, "type": 0, "author": 71}}, {"pk": 611, "model": "server.vote", "fields": {"post": 263, "type": 2, "author": 120}}, {"pk": 612, "model": "server.vote", "fields": {"post": 258, "type": 0, "author": 58}}, {"pk": 613, "model": "server.vote", "fields": {"post": 282, "type": 0, "author": 58}}, {"pk": 614, "model": "server.vote", "fields": {"post": 259, "type": 0, "author": 58}}, {"pk": 615, "model": "server.vote", "fields": {"post": 154, "type": 0, "author": 58}}, {"pk": 616, "model": "server.vote", "fields": {"post": 278, "type": 0, "author": 65}}, {"pk": 617, "model": "server.vote", "fields": {"post": 281, "type": 0, "author": 65}}, {"pk": 618, "model": "server.vote", "fields": {"post": 283, "type": 0, "author": 67}}, {"pk": 619, "model": "server.vote", "fields": {"post": 131, "type": 0, "author": 30}}, {"pk": 620, "model": "server.vote", "fields": {"post": 95, "type": 0, "author": 30}}, {"pk": 621, "model": "server.vote", "fields": {"post": 81, "type": 0, "author": 30}}, {"pk": 622, "model": "server.vote", "fields": {"post": 80, "type": 0, "author": 30}}, {"pk": 623, "model": "server.vote", "fields": {"post": 84, "type": 0, "author": 30}}, {"pk": 624, "model": "server.vote", "fields": {"post": 82, "type": 0, "author": 30}}, {"pk": 625, "model": "server.vote", "fields": {"post": 153, "type": 0, "author": 30}}, {"pk": 626, "model": "server.vote", "fields": {"post": 228, "type": 0, "author": 30}}, {"pk": 627, "model": "server.vote", "fields": {"post": 258, "type": 0, "author": 30}}, {"pk": 628, "model": "server.vote", "fields": {"post": 277, "type": 0, "author": 30}}, {"pk": 629, "model": "server.vote", "fields": {"post": 283, "type": 0, "author": 29}}, {"pk": 630, "model": "server.vote", "fields": {"post": 284, "type": 0, "author": 118}}, {"pk": 631, "model": "server.vote", "fields": {"post": 283, "type": 1, "author": 25}}, {"pk": 632, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 30}}, {"pk": 633, "model": "server.vote", "fields": {"post": 284, "type": 0, "author": 30}}, {"pk": 634, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 58}}, {"pk": 635, "model": "server.vote", "fields": {"post": 279, "type": 0, "author": 54}}, {"pk": 636, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 89}}, {"pk": 637, "model": "server.vote", "fields": {"post": 286, "type": 0, "author": 29}}, {"pk": 638, "model": "server.vote", "fields": {"post": 210, "type": 0, "author": 58}}, {"pk": 639, "model": "server.vote", "fields": {"post": 268, "type": 0, "author": 128}}, {"pk": 640, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 22}}, {"pk": 641, "model": "server.vote", "fields": {"post": 284, "type": 0, "author": 22}}, {"pk": 642, "model": "server.vote", "fields": {"post": 239, "type": 0, "author": 65}}, {"pk": 643, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 67}}, {"pk": 644, "model": "server.vote", "fields": {"post": 287, "type": 0, "author": 29}}, {"pk": 645, "model": "server.vote", "fields": {"post": 288, "type": 0, "author": 54}}, {"pk": 646, "model": "server.vote", "fields": {"post": 288, "type": 0, "author": 1}}, {"pk": 647, "model": "server.vote", "fields": {"post": 288, "type": 2, "author": 130}}, {"pk": 648, "model": "server.vote", "fields": {"post": 288, "type": 0, "author": 57}}, {"pk": 649, "model": "server.vote", "fields": {"post": 286, "type": 0, "author": 58}}, {"pk": 650, "model": "server.vote", "fields": {"post": 202, "type": 0, "author": 129}}, {"pk": 651, "model": "server.vote", "fields": {"post": 288, "type": 0, "author": 25}}, {"pk": 652, "model": "server.vote", "fields": {"post": 217, "type": 0, "author": 133}}, {"pk": 653, "model": "server.vote", "fields": {"post": 175, "type": 0, "author": 30}}, {"pk": 654, "model": "server.vote", "fields": {"post": 287, "type": 0, "author": 135}}, {"pk": 655, "model": "server.vote", "fields": {"post": 288, "type": 0, "author": 135}}, {"pk": 656, "model": "server.vote", "fields": {"post": 276, "type": 0, "author": 124}}, {"pk": 657, "model": "server.vote", "fields": {"post": 275, "type": 0, "author": 124}}, {"pk": 658, "model": "server.vote", "fields": {"post": 273, "type": 0, "author": 124}}, {"pk": 659, "model": "server.vote", "fields": {"post": 289, "type": 0, "author": 58}}, {"pk": 660, "model": "server.vote", "fields": {"post": 284, "type": 0, "author": 37}}, {"pk": 661, "model": "server.vote", "fields": {"post": 290, "type": 0, "author": 1}}, {"pk": 662, "model": "server.vote", "fields": {"post": 291, "type": 0, "author": 1}}, {"pk": 663, "model": "server.vote", "fields": {"post": 292, "type": 0, "author": 1}}, {"pk": 664, "model": "server.vote", "fields": {"post": 292, "type": 0, "author": 135}}, {"pk": 665, "model": "server.vote", "fields": {"post": 278, "type": 0, "author": 58}}, {"pk": 666, "model": "server.vote", "fields": {"post": 274, "type": 0, "author": 58}}, {"pk": 667, "model": "server.vote", "fields": {"post": 293, "type": 0, "author": 30}}, {"pk": 668, "model": "server.vote", "fields": {"post": 293, "type": 0, "author": 29}}, {"pk": 669, "model": "server.vote", "fields": {"post": 289, "type": 0, "author": 1}}, {"pk": 670, "model": "server.vote", "fields": {"post": 268, "type": 0, "author": 88}}, {"pk": 671, "model": "server.vote", "fields": {"post": 294, "type": 0, "author": 29}}, {"pk": 672, "model": "server.vote", "fields": {"post": 294, "type": 0, "author": 30}}, {"pk": 673, "model": "server.vote", "fields": {"post": 275, "type": 2, "author": 124}}, {"pk": 674, "model": "server.vote", "fields": {"post": 291, "type": 0, "author": 54}}, {"pk": 675, "model": "server.vote", "fields": {"post": 292, "type": 0, "author": 54}}, {"pk": 676, "model": "server.vote", "fields": {"post": 111, "type": 0, "author": 140}}, {"pk": 677, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 88}}, {"pk": 678, "model": "server.vote", "fields": {"post": 115, "type": 0, "author": 140}}, {"pk": 679, "model": "server.vote", "fields": {"post": 295, "type": 0, "author": 34}}, {"pk": 680, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 34}}, {"pk": 681, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 29}}, {"pk": 682, "model": "server.vote", "fields": {"post": 297, "type": 0, "author": 67}}, {"pk": 683, "model": "server.vote", "fields": {"post": 298, "type": 0, "author": 67}}, {"pk": 684, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 67}}, {"pk": 685, "model": "server.vote", "fields": {"post": 299, "type": 0, "author": 29}}, {"pk": 686, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 52}}, {"pk": 687, "model": "server.vote", "fields": {"post": 206, "type": 0, "author": 67}}, {"pk": 688, "model": "server.vote", "fields": {"post": 295, "type": 0, "author": 30}}, {"pk": 689, "model": "server.vote", "fields": {"post": 300, "type": 0, "author": 29}}, {"pk": 690, "model": "server.vote", "fields": {"post": 298, "type": 0, "author": 1}}, {"pk": 691, "model": "server.vote", "fields": {"post": 297, "type": 0, "author": 1}}, {"pk": 692, "model": "server.vote", "fields": {"post": 299, "type": 0, "author": 1}}, {"pk": 693, "model": "server.vote", "fields": {"post": 300, "type": 0, "author": 1}}, {"pk": 694, "model": "server.vote", "fields": {"post": 301, "type": 0, "author": 1}}, {"pk": 695, "model": "server.vote", "fields": {"post": 294, "type": 0, "author": 67}}, {"pk": 696, "model": "server.vote", "fields": {"post": 301, "type": 0, "author": 29}}, {"pk": 697, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 116}}, {"pk": 698, "model": "server.vote", "fields": {"post": 294, "type": 0, "author": 35}}, {"pk": 699, "model": "server.vote", "fields": {"post": 298, "type": 0, "author": 65}}, {"pk": 700, "model": "server.vote", "fields": {"post": 305, "type": 0, "author": 65}}, {"pk": 701, "model": "server.vote", "fields": {"post": 292, "type": 2, "author": 135}}, {"pk": 702, "model": "server.vote", "fields": {"post": 305, "type": 0, "author": 29}}, {"pk": 703, "model": "server.vote", "fields": {"post": 306, "type": 0, "author": 29}}, {"pk": 704, "model": "server.vote", "fields": {"post": 305, "type": 0, "author": 37}}, {"pk": 705, "model": "server.vote", "fields": {"post": 308, "type": 0, "author": 54}}, {"pk": 706, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 58}}, {"pk": 707, "model": "server.vote", "fields": {"post": 309, "type": 0, "author": 58}}, {"pk": 708, "model": "server.vote", "fields": {"post": 194, "type": 0, "author": 22}}, {"pk": 709, "model": "server.vote", "fields": {"post": 304, "type": 0, "author": 61}}, {"pk": 710, "model": "server.vote", "fields": {"post": 311, "type": 1, "author": 70}}, {"pk": 711, "model": "server.vote", "fields": {"post": 307, "type": 0, "author": 90}}, {"pk": 712, "model": "server.vote", "fields": {"post": 304, "type": 0, "author": 90}}, {"pk": 713, "model": "server.vote", "fields": {"post": 305, "type": 0, "author": 90}}, {"pk": 714, "model": "server.vote", "fields": {"post": 313, "type": 0, "author": 144}}, {"pk": 715, "model": "server.vote", "fields": {"post": 311, "type": 0, "author": 22}}, {"pk": 716, "model": "server.vote", "fields": {"post": 175, "type": 0, "author": 22}}, {"pk": 717, "model": "server.vote", "fields": {"post": 308, "type": 0, "author": 67}}, {"pk": 718, "model": "server.vote", "fields": {"post": 311, "type": 0, "author": 29}}, {"pk": 719, "model": "server.vote", "fields": {"post": 316, "type": 0, "author": 29}}, {"pk": 720, "model": "server.vote", "fields": {"post": 312, "type": 0, "author": 29}}, {"pk": 721, "model": "server.vote", "fields": {"post": 308, "type": 0, "author": 29}}, {"pk": 722, "model": "server.vote", "fields": {"post": 318, "type": 0, "author": 22}}, {"pk": 723, "model": "server.vote", "fields": {"post": 317, "type": 0, "author": 22}}, {"pk": 724, "model": "server.vote", "fields": {"post": 311, "type": 0, "author": 22}}, {"pk": 725, "model": "server.vote", "fields": {"post": 316, "type": 0, "author": 144}}, {"pk": 726, "model": "server.vote", "fields": {"post": 316, "type": 2, "author": 144}}, {"pk": 727, "model": "server.vote", "fields": {"post": 175, "type": 0, "author": 144}}, {"pk": 728, "model": "server.vote", "fields": {"post": 175, "type": 0, "author": 144}}, {"pk": 729, "model": "server.vote", "fields": {"post": 316, "type": 0, "author": 67}}, {"pk": 730, "model": "server.vote", "fields": {"post": 298, "type": 0, "author": 22}}, {"pk": 731, "model": "server.vote", "fields": {"post": 299, "type": 0, "author": 22}}, {"pk": 732, "model": "server.vote", "fields": {"post": 300, "type": 0, "author": 22}}, {"pk": 733, "model": "server.vote", "fields": {"post": 306, "type": 0, "author": 22}}, {"pk": 734, "model": "server.vote", "fields": {"post": 309, "type": 0, "author": 22}}, {"pk": 735, "model": "server.vote", "fields": {"post": 304, "type": 0, "author": 142}}, {"pk": 736, "model": "server.vote", "fields": {"post": 305, "type": 0, "author": 142}}, {"pk": 737, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 37}}, {"pk": 738, "model": "server.vote", "fields": {"post": 308, "type": 0, "author": 22}}, {"pk": 739, "model": "server.vote", "fields": {"post": 321, "type": 0, "author": 22}}, {"pk": 740, "model": "server.vote", "fields": {"post": 307, "type": 0, "author": 22}}, {"pk": 741, "model": "server.vote", "fields": {"post": 304, "type": 0, "author": 22}}, {"pk": 742, "model": "server.vote", "fields": {"post": 305, "type": 0, "author": 22}}, {"pk": 743, "model": "server.vote", "fields": {"post": 302, "type": 0, "author": 22}}, {"pk": 744, "model": "server.vote", "fields": {"post": 316, "type": 0, "author": 135}}, {"pk": 745, "model": "server.vote", "fields": {"post": 317, "type": 0, "author": 141}}, {"pk": 746, "model": "server.vote", "fields": {"post": 322, "type": 0, "author": 29}}, {"pk": 747, "model": "server.vote", "fields": {"post": 305, "type": 0, "author": 67}}, {"pk": 748, "model": "server.vote", "fields": {"post": 302, "type": 0, "author": 67}}, {"pk": 749, "model": "server.vote", "fields": {"post": 305, "type": 0, "author": 1}}, {"pk": 750, "model": "server.vote", "fields": {"post": 304, "type": 0, "author": 1}}, {"pk": 751, "model": "server.vote", "fields": {"post": 315, "type": 0, "author": 1}}, {"pk": 752, "model": "server.vote", "fields": {"post": 311, "type": 0, "author": 1}}, {"pk": 753, "model": "server.vote", "fields": {"post": 283, "type": 0, "author": 71}}, {"pk": 754, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 71}}, {"pk": 755, "model": "server.vote", "fields": {"post": 319, "type": 0, "author": 71}}, {"pk": 756, "model": "server.vote", "fields": {"post": 322, "type": 0, "author": 71}}, {"pk": 757, "model": "server.vote", "fields": {"post": 317, "type": 0, "author": 118}}, {"pk": 758, "model": "server.vote", "fields": {"post": 316, "type": 0, "author": 58}}, {"pk": 759, "model": "server.vote", "fields": {"post": 310, "type": 0, "author": 1}}, {"pk": 760, "model": "server.vote", "fields": {"post": 324, "type": 0, "author": 1}}, {"pk": 761, "model": "server.vote", "fields": {"post": 324, "type": 0, "author": 58}}, {"pk": 762, "model": "server.vote", "fields": {"post": 324, "type": 0, "author": 22}}, {"pk": 763, "model": "server.vote", "fields": {"post": 322, "type": 0, "author": 30}}, {"pk": 764, "model": "server.vote", "fields": {"post": 319, "type": 0, "author": 30}}, {"pk": 765, "model": "server.vote", "fields": {"post": 308, "type": 0, "author": 88}}, {"pk": 766, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 35}}, {"pk": 767, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 35}}, {"pk": 768, "model": "server.vote", "fields": {"post": 317, "type": 0, "author": 67}}, {"pk": 769, "model": "server.vote", "fields": {"post": 325, "type": 0, "author": 22}}, {"pk": 770, "model": "server.vote", "fields": {"post": 323, "type": 0, "author": 22}}, {"pk": 771, "model": "server.vote", "fields": {"post": 325, "type": 0, "author": 141}}, {"pk": 772, "model": "server.vote", "fields": {"post": 320, "type": 0, "author": 141}}, {"pk": 773, "model": "server.vote", "fields": {"post": 326, "type": 0, "author": 29}}, {"pk": 774, "model": "server.vote", "fields": {"post": 322, "type": 0, "author": 65}}, {"pk": 775, "model": "server.vote", "fields": {"post": 194, "type": 0, "author": 86}}, {"pk": 776, "model": "server.vote", "fields": {"post": 327, "type": 1, "author": 58}}, {"pk": 777, "model": "server.vote", "fields": {"post": 326, "type": 0, "author": 22}}, {"pk": 778, "model": "server.vote", "fields": {"post": 308, "type": 0, "author": 89}}, {"pk": 779, "model": "server.vote", "fields": {"post": 327, "type": 1, "author": 54}}, {"pk": 780, "model": "server.vote", "fields": {"post": 322, "type": 0, "author": 147}}, {"pk": 781, "model": "server.vote", "fields": {"post": 328, "type": 0, "author": 1}}, {"pk": 782, "model": "server.vote", "fields": {"post": 329, "type": 0, "author": 30}}, {"pk": 783, "model": "server.vote", "fields": {"post": 330, "type": 0, "author": 1}}, {"pk": 784, "model": "server.vote", "fields": {"post": 320, "type": 0, "author": 1}}, {"pk": 785, "model": "server.vote", "fields": {"post": 320, "type": 1, "author": 1}}, {"pk": 786, "model": "server.vote", "fields": {"post": 320, "type": 0, "author": 1}}, {"pk": 787, "model": "server.vote", "fields": {"post": 320, "type": 1, "author": 1}}, {"pk": 788, "model": "server.vote", "fields": {"post": 319, "type": 0, "author": 116}}, {"pk": 789, "model": "server.vote", "fields": {"post": 85, "type": 0, "author": 65}}, {"pk": 790, "model": "server.vote", "fields": {"post": 331, "type": 0, "author": 29}}, {"pk": 791, "model": "server.vote", "fields": {"post": 329, "type": 0, "author": 29}}, {"pk": 792, "model": "server.vote", "fields": {"post": 180, "type": 0, "author": 29}}, {"pk": 793, "model": "server.vote", "fields": {"post": 332, "type": 0, "author": 54}}, {"pk": 794, "model": "server.vote", "fields": {"post": 332, "type": 0, "author": 22}}, {"pk": 795, "model": "server.vote", "fields": {"post": 332, "type": 2, "author": 22}}, {"pk": 796, "model": "server.vote", "fields": {"post": 331, "type": 0, "author": 22}}, {"pk": 797, "model": "server.vote", "fields": {"post": 332, "type": 0, "author": 37}}, {"pk": 798, "model": "server.vote", "fields": {"post": 327, "type": 1, "author": 58}}, {"pk": 799, "model": "server.vote", "fields": {"post": 327, "type": 1, "author": 37}}, {"pk": 800, "model": "server.vote", "fields": {"post": 327, "type": 1, "author": 141}}, {"pk": 801, "model": "server.vote", "fields": {"post": 332, "type": 0, "author": 141}}, {"pk": 802, "model": "server.vote", "fields": {"post": 289, "type": 0, "author": 22}}, {"pk": 803, "model": "server.vote", "fields": {"post": 272, "type": 2, "author": 58}}, {"pk": 804, "model": "server.vote", "fields": {"post": 328, "type": 0, "author": 22}}, {"pk": 805, "model": "server.vote", "fields": {"post": 333, "type": 0, "author": 22}}, {"pk": 806, "model": "server.vote", "fields": {"post": 192, "type": 0, "author": 22}}, {"pk": 807, "model": "server.vote", "fields": {"post": 195, "type": 0, "author": 22}}, {"pk": 808, "model": "server.vote", "fields": {"post": 184, "type": 0, "author": 22}}, {"pk": 809, "model": "server.vote", "fields": {"post": 320, "type": 0, "author": 22}}, {"pk": 810, "model": "server.vote", "fields": {"post": 330, "type": 0, "author": 22}}, {"pk": 811, "model": "server.vote", "fields": {"post": 92, "type": 1, "author": 141}}, {"pk": 812, "model": "server.vote", "fields": {"post": 202, "type": 0, "author": 22}}, {"pk": 813, "model": "server.vote", "fields": {"post": 324, "type": 2, "author": 22}}, {"pk": 814, "model": "server.vote", "fields": {"post": 312, "type": 0, "author": 137}}, {"pk": 815, "model": "server.vote", "fields": {"post": 328, "type": 0, "author": 88}}, {"pk": 816, "model": "server.vote", "fields": {"post": 327, "type": 1, "author": 1}}, {"pk": 817, "model": "server.vote", "fields": {"post": 328, "type": 0, "author": 1}}, {"pk": 818, "model": "server.vote", "fields": {"post": 332, "type": 0, "author": 1}}, {"pk": 819, "model": "server.vote", "fields": {"post": 332, "type": 0, "author": 61}}, {"pk": 820, "model": "server.vote", "fields": {"post": 334, "type": 0, "author": 58}}, {"pk": 821, "model": "server.vote", "fields": {"post": 308, "type": 0, "author": 147}}, {"pk": 822, "model": "server.vote", "fields": {"post": 336, "type": 0, "author": 86}}, {"pk": 823, "model": "server.vote", "fields": {"post": 337, "type": 0, "author": 86}}, {"pk": 824, "model": "server.vote", "fields": {"post": 336, "type": 0, "author": 29}}, {"pk": 825, "model": "server.vote", "fields": {"post": 336, "type": 0, "author": 37}}, {"pk": 826, "model": "server.vote", "fields": {"post": 336, "type": 0, "author": 1}}, {"pk": 827, "model": "server.vote", "fields": {"post": 334, "type": 0, "author": 1}}, {"pk": 828, "model": "server.vote", "fields": {"post": 337, "type": 0, "author": 1}}, {"pk": 829, "model": "server.vote", "fields": {"post": 84, "type": 0, "author": 140}}, {"pk": 830, "model": "server.vote", "fields": {"post": 105, "type": 0, "author": 140}}, {"pk": 831, "model": "server.vote", "fields": {"post": 105, "type": 0, "author": 140}}, {"pk": 832, "model": "server.vote", "fields": {"post": 334, "type": 0, "author": 22}}, {"pk": 833, "model": "server.vote", "fields": {"post": 336, "type": 0, "author": 22}}, {"pk": 834, "model": "server.vote", "fields": {"post": 337, "type": 0, "author": 22}}, {"pk": 835, "model": "server.vote", "fields": {"post": 328, "type": 0, "author": 61}}, {"pk": 836, "model": "server.vote", "fields": {"post": 338, "type": 0, "author": 147}}, {"pk": 837, "model": "server.vote", "fields": {"post": 327, "type": 1, "author": 88}}, {"pk": 838, "model": "server.vote", "fields": {"post": 317, "type": 0, "author": 72}}, {"pk": 839, "model": "server.vote", "fields": {"post": 331, "type": 0, "author": 72}}, {"pk": 840, "model": "server.vote", "fields": {"post": 340, "type": 0, "author": 29}}, {"pk": 841, "model": "server.vote", "fields": {"post": 341, "type": 0, "author": 29}}, {"pk": 842, "model": "server.vote", "fields": {"post": 341, "type": 0, "author": 22}}, {"pk": 843, "model": "server.vote", "fields": {"post": 328, "type": 0, "author": 86}}, {"pk": 844, "model": "server.vote", "fields": {"post": 332, "type": 0, "author": 86}}, {"pk": 845, "model": "server.vote", "fields": {"post": 307, "type": 0, "author": 86}}, {"pk": 846, "model": "server.vote", "fields": {"post": 292, "type": 0, "author": 86}}, {"pk": 847, "model": "server.vote", "fields": {"post": 279, "type": 0, "author": 86}}, {"pk": 848, "model": "server.vote", "fields": {"post": 266, "type": 0, "author": 86}}, {"pk": 849, "model": "server.vote", "fields": {"post": 342, "type": 0, "author": 22}}, {"pk": 850, "model": "server.vote", "fields": {"post": 327, "type": 1, "author": 116}}, {"pk": 851, "model": "server.vote", "fields": {"post": 248, "type": 0, "author": 116}}, {"pk": 852, "model": "server.vote", "fields": {"post": 328, "type": 0, "author": 71}}, {"pk": 853, "model": "server.vote", "fields": {"post": 318, "type": 0, "author": 71}}, {"pk": 854, "model": "server.vote", "fields": {"post": 336, "type": 0, "author": 67}}, {"pk": 855, "model": "server.vote", "fields": {"post": 347, "type": 0, "author": 67}}, {"pk": 856, "model": "server.vote", "fields": {"post": 343, "type": 0, "author": 144}}, {"pk": 857, "model": "server.vote", "fields": {"post": 338, "type": 0, "author": 67}}, {"pk": 858, "model": "server.vote", "fields": {"post": 333, "type": 0, "author": 67}}, {"pk": 859, "model": "server.vote", "fields": {"post": 328, "type": 0, "author": 67}}, {"pk": 860, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 58}}, {"pk": 861, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 29}}, {"pk": 862, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 141}}, {"pk": 863, "model": "server.vote", "fields": {"post": 350, "type": 1, "author": 141}}, {"pk": 864, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 141}}, {"pk": 865, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 37}}, {"pk": 866, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 65}}, {"pk": 867, "model": "server.vote", "fields": {"post": 346, "type": 0, "author": 22}}, {"pk": 868, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 22}}, {"pk": 869, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 22}}, {"pk": 870, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 118}}, {"pk": 871, "model": "server.vote", "fields": {"post": 348, "type": 0, "author": 67}}, {"pk": 872, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 67}}, {"pk": 873, "model": "server.vote", "fields": {"post": 351, "type": 0, "author": 67}}, {"pk": 874, "model": "server.vote", "fields": {"post": 345, "type": 0, "author": 1}}, {"pk": 875, "model": "server.vote", "fields": {"post": 344, "type": 0, "author": 1}}, {"pk": 876, "model": "server.vote", "fields": {"post": 335, "type": 0, "author": 1}}, {"pk": 877, "model": "server.vote", "fields": {"post": 352, "type": 0, "author": 58}}, {"pk": 878, "model": "server.vote", "fields": {"post": 353, "type": 0, "author": 58}}, {"pk": 879, "model": "server.vote", "fields": {"post": 353, "type": 0, "author": 37}}, {"pk": 880, "model": "server.vote", "fields": {"post": 351, "type": 0, "author": 58}}, {"pk": 881, "model": "server.vote", "fields": {"post": 348, "type": 0, "author": 1}}, {"pk": 882, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 58}}, {"pk": 883, "model": "server.vote", "fields": {"post": 261, "type": 2, "author": 72}}, {"pk": 884, "model": "server.vote", "fields": {"post": 351, "type": 0, "author": 88}}, {"pk": 885, "model": "server.vote", "fields": {"post": 353, "type": 0, "author": 35}}, {"pk": 886, "model": "server.vote", "fields": {"post": 354, "type": 0, "author": 1}}, {"pk": 887, "model": "server.vote", "fields": {"post": 355, "type": 0, "author": 88}}, {"pk": 888, "model": "server.vote", "fields": {"post": 348, "type": 0, "author": 88}}, {"pk": 889, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 88}}, {"pk": 890, "model": "server.vote", "fields": {"post": 352, "type": 0, "author": 88}}, {"pk": 891, "model": "server.vote", "fields": {"post": 353, "type": 0, "author": 88}}, {"pk": 892, "model": "server.vote", "fields": {"post": 354, "type": 0, "author": 88}}, {"pk": 893, "model": "server.vote", "fields": {"post": 355, "type": 0, "author": 58}}, {"pk": 894, "model": "server.vote", "fields": {"post": 355, "type": 0, "author": 29}}, {"pk": 895, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 116}}, {"pk": 896, "model": "server.vote", "fields": {"post": 354, "type": 0, "author": 29}}, {"pk": 897, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 35}}, {"pk": 898, "model": "server.vote", "fields": {"post": 353, "type": 0, "author": 34}}, {"pk": 899, "model": "server.vote", "fields": {"post": 358, "type": 0, "author": 65}}, {"pk": 900, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 71}}, {"pk": 901, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 29}}, {"pk": 902, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 67}}, {"pk": 903, "model": "server.vote", "fields": {"post": 357, "type": 0, "author": 67}}, {"pk": 904, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 116}}, {"pk": 905, "model": "server.vote", "fields": {"post": 357, "type": 0, "author": 1}}, {"pk": 906, "model": "server.vote", "fields": {"post": 358, "type": 0, "author": 1}}, {"pk": 907, "model": "server.vote", "fields": {"post": 359, "type": 0, "author": 1}}, {"pk": 908, "model": "server.vote", "fields": {"post": 360, "type": 2, "author": 120}}, {"pk": 909, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 109}}, {"pk": 910, "model": "server.vote", "fields": {"post": 358, "type": 0, "author": 109}}, {"pk": 911, "model": "server.vote", "fields": {"post": 359, "type": 0, "author": 109}}, {"pk": 912, "model": "server.vote", "fields": {"post": 317, "type": 0, "author": 109}}, {"pk": 913, "model": "server.vote", "fields": {"post": 331, "type": 0, "author": 109}}, {"pk": 914, "model": "server.vote", "fields": {"post": 318, "type": 0, "author": 109}}, {"pk": 915, "model": "server.vote", "fields": {"post": 318, "type": 0, "author": 109}}, {"pk": 916, "model": "server.vote", "fields": {"post": 312, "type": 0, "author": 109}}, {"pk": 917, "model": "server.vote", "fields": {"post": 359, "type": 0, "author": 90}}, {"pk": 918, "model": "server.vote", "fields": {"post": 356, "type": 0, "author": 90}}, {"pk": 919, "model": "server.vote", "fields": {"post": 355, "type": 0, "author": 90}}, {"pk": 920, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 22}}, {"pk": 921, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 54}}, {"pk": 922, "model": "server.vote", "fields": {"post": 361, "type": 0, "author": 29}}, {"pk": 923, "model": "server.vote", "fields": {"post": 353, "type": 0, "author": 22}}, {"pk": 924, "model": "server.vote", "fields": {"post": 354, "type": 0, "author": 22}}, {"pk": 925, "model": "server.vote", "fields": {"post": 352, "type": 0, "author": 22}}, {"pk": 926, "model": "server.vote", "fields": {"post": 176, "type": 0, "author": 1}}, {"pk": 927, "model": "server.vote", "fields": {"post": 303, "type": 0, "author": 1}}, {"pk": 928, "model": "server.vote", "fields": {"post": 361, "type": 0, "author": 116}}, {"pk": 929, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 29}}, {"pk": 930, "model": "server.vote", "fields": {"post": 364, "type": 0, "author": 22}}, {"pk": 931, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 22}}, {"pk": 932, "model": "server.vote", "fields": {"post": 365, "type": 0, "author": 29}}, {"pk": 933, "model": "server.vote", "fields": {"post": 365, "type": 2, "author": 29}}, {"pk": 934, "model": "server.vote", "fields": {"post": 365, "type": 0, "author": 1}}, {"pk": 935, "model": "server.vote", "fields": {"post": 362, "type": 0, "author": 1}}, {"pk": 936, "model": "server.vote", "fields": {"post": 364, "type": 0, "author": 66}}, {"pk": 937, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 66}}, {"pk": 938, "model": "server.vote", "fields": {"post": 367, "type": 0, "author": 29}}, {"pk": 939, "model": "server.vote", "fields": {"post": 366, "type": 0, "author": 22}}, {"pk": 940, "model": "server.vote", "fields": {"post": 367, "type": 0, "author": 22}}, {"pk": 941, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 29}}, {"pk": 942, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 1}}, {"pk": 943, "model": "server.vote", "fields": {"post": 369, "type": 0, "author": 61}}, {"pk": 944, "model": "server.vote", "fields": {"post": 231, "type": 0, "author": 112}}, {"pk": 945, "model": "server.vote", "fields": {"post": 222, "type": 0, "author": 112}}, {"pk": 946, "model": "server.vote", "fields": {"post": 345, "type": 0, "author": 86}}, {"pk": 947, "model": "server.vote", "fields": {"post": 344, "type": 0, "author": 86}}, {"pk": 948, "model": "server.vote", "fields": {"post": 362, "type": 0, "author": 86}}, {"pk": 949, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 71}}, {"pk": 950, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 71}}, {"pk": 951, "model": "server.vote", "fields": {"post": 350, "type": 2, "author": 37}}, {"pk": 952, "model": "server.vote", "fields": {"post": 357, "type": 0, "author": 72}}, {"pk": 953, "model": "server.vote", "fields": {"post": 362, "type": 0, "author": 54}}, {"pk": 954, "model": "server.vote", "fields": {"post": 362, "type": 0, "author": 54}}, {"pk": 955, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 30}}, {"pk": 956, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 65}}, {"pk": 957, "model": "server.vote", "fields": {"post": 372, "type": 0, "author": 29}}, {"pk": 958, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 86}}, {"pk": 959, "model": "server.vote", "fields": {"post": 366, "type": 0, "author": 86}}, {"pk": 960, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 86}}, {"pk": 961, "model": "server.vote", "fields": {"post": 372, "type": 0, "author": 86}}, {"pk": 962, "model": "server.vote", "fields": {"post": 364, "type": 0, "author": 86}}, {"pk": 963, "model": "server.vote", "fields": {"post": 98, "type": 0, "author": 65}}, {"pk": 964, "model": "server.vote", "fields": {"post": 39, "type": 0, "author": 65}}, {"pk": 965, "model": "server.vote", "fields": {"post": 349, "type": 1, "author": 70}}, {"pk": 966, "model": "server.vote", "fields": {"post": 370, "type": 0, "author": 140}}, {"pk": 967, "model": "server.vote", "fields": {"post": 305, "type": 0, "author": 153}}, {"pk": 968, "model": "server.vote", "fields": {"post": 272, "type": 0, "author": 153}}, {"pk": 969, "model": "server.vote", "fields": {"post": 269, "type": 0, "author": 153}}, {"pk": 970, "model": "server.vote", "fields": {"post": 270, "type": 0, "author": 153}}, {"pk": 971, "model": "server.vote", "fields": {"post": 289, "type": 0, "author": 153}}, {"pk": 972, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 153}}, {"pk": 973, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 79}}, {"pk": 974, "model": "server.vote", "fields": {"post": 354, "type": 0, "author": 79}}, {"pk": 975, "model": "server.vote", "fields": {"post": 298, "type": 0, "author": 79}}, {"pk": 976, "model": "server.vote", "fields": {"post": 297, "type": 0, "author": 79}}, {"pk": 977, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 79}}, {"pk": 978, "model": "server.vote", "fields": {"post": 37, "type": 0, "author": 153}}, {"pk": 979, "model": "server.vote", "fields": {"post": 177, "type": 0, "author": 153}}, {"pk": 980, "model": "server.vote", "fields": {"post": 177, "type": 0, "author": 153}}, {"pk": 981, "model": "server.vote", "fields": {"post": 232, "type": 0, "author": 153}}, {"pk": 982, "model": "server.vote", "fields": {"post": 278, "type": 0, "author": 79}}, {"pk": 983, "model": "server.vote", "fields": {"post": 268, "type": 0, "author": 79}}, {"pk": 984, "model": "server.vote", "fields": {"post": 122, "type": 0, "author": 153}}, {"pk": 985, "model": "server.vote", "fields": {"post": 157, "type": 0, "author": 153}}, {"pk": 986, "model": "server.vote", "fields": {"post": 38, "type": 0, "author": 153}}, {"pk": 987, "model": "server.vote", "fields": {"post": 136, "type": 0, "author": 153}}, {"pk": 988, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 25}}, {"pk": 989, "model": "server.vote", "fields": {"post": 368, "type": 1, "author": 25}}, {"pk": 990, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 25}}, {"pk": 991, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 25}}, {"pk": 992, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 153}}, {"pk": 993, "model": "server.vote", "fields": {"post": 298, "type": 0, "author": 153}}, {"pk": 994, "model": "server.vote", "fields": {"post": 306, "type": 0, "author": 153}}, {"pk": 995, "model": "server.vote", "fields": {"post": 300, "type": 0, "author": 153}}, {"pk": 996, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 153}}, {"pk": 997, "model": "server.vote", "fields": {"post": 358, "type": 0, "author": 153}}, {"pk": 998, "model": "server.vote", "fields": {"post": 359, "type": 0, "author": 153}}, {"pk": 999, "model": "server.vote", "fields": {"post": 359, "type": 0, "author": 153}}, {"pk": 1000, "model": "server.vote", "fields": {"post": 50, "type": 0, "author": 65}}, {"pk": 1001, "model": "server.vote", "fields": {"post": 83, "type": 0, "author": 65}}, {"pk": 1002, "model": "server.vote", "fields": {"post": 377, "type": 0, "author": 88}}, {"pk": 1003, "model": "server.vote", "fields": {"post": 375, "type": 0, "author": 88}}, {"pk": 1004, "model": "server.vote", "fields": {"post": 376, "type": 0, "author": 88}}, {"pk": 1005, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 88}}, {"pk": 1006, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 88}}, {"pk": 1007, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 88}}, {"pk": 1008, "model": "server.vote", "fields": {"post": 375, "type": 0, "author": 1}}, {"pk": 1009, "model": "server.vote", "fields": {"post": 374, "type": 0, "author": 1}}, {"pk": 1010, "model": "server.vote", "fields": {"post": 378, "type": 0, "author": 29}}, {"pk": 1011, "model": "server.vote", "fields": {"post": 380, "type": 0, "author": 29}}, {"pk": 1012, "model": "server.vote", "fields": {"post": 380, "type": 0, "author": 89}}, {"pk": 1013, "model": "server.vote", "fields": {"post": 345, "type": 0, "author": 29}}, {"pk": 1014, "model": "server.vote", "fields": {"post": 198, "type": 0, "author": 22}}, {"pk": 1015, "model": "server.vote", "fields": {"post": 374, "type": 0, "author": 22}}, {"pk": 1016, "model": "server.vote", "fields": {"post": 211, "type": 0, "author": 22}}, {"pk": 1017, "model": "server.vote", "fields": {"post": 376, "type": 0, "author": 58}}, {"pk": 1018, "model": "server.vote", "fields": {"post": 375, "type": 0, "author": 58}}, {"pk": 1019, "model": "server.vote", "fields": {"post": 377, "type": 0, "author": 153}}, {"pk": 1020, "model": "server.vote", "fields": {"post": 376, "type": 0, "author": 153}}, {"pk": 1021, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 94}}, {"pk": 1022, "model": "server.vote", "fields": {"post": 328, "type": 0, "author": 94}}, {"pk": 1023, "model": "server.vote", "fields": {"post": 384, "type": 0, "author": 29}}, {"pk": 1024, "model": "server.vote", "fields": {"post": 383, "type": 0, "author": 1}}, {"pk": 1025, "model": "server.vote", "fields": {"post": 122, "type": 0, "author": 157}}, {"pk": 1026, "model": "server.vote", "fields": {"post": 38, "type": 0, "author": 157}}, {"pk": 1027, "model": "server.vote", "fields": {"post": 64, "type": 0, "author": 157}}, {"pk": 1028, "model": "server.vote", "fields": {"post": 36, "type": 0, "author": 157}}, {"pk": 1029, "model": "server.vote", "fields": {"post": 383, "type": 0, "author": 70}}, {"pk": 1030, "model": "server.vote", "fields": {"post": 299, "type": 0, "author": 70}}, {"pk": 1031, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 70}}, {"pk": 1032, "model": "server.vote", "fields": {"post": 386, "type": 0, "author": 22}}, {"pk": 1033, "model": "server.vote", "fields": {"post": 379, "type": 0, "author": 22}}, {"pk": 1034, "model": "server.vote", "fields": {"post": 380, "type": 0, "author": 22}}, {"pk": 1035, "model": "server.vote", "fields": {"post": 381, "type": 0, "author": 22}}, {"pk": 1036, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 22}}, {"pk": 1037, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 22}}, {"pk": 1038, "model": "server.vote", "fields": {"post": 372, "type": 0, "author": 22}}, {"pk": 1039, "model": "server.vote", "fields": {"post": 370, "type": 0, "author": 22}}, {"pk": 1040, "model": "server.vote", "fields": {"post": 387, "type": 0, "author": 67}}, {"pk": 1041, "model": "server.vote", "fields": {"post": 378, "type": 0, "author": 67}}, {"pk": 1042, "model": "server.vote", "fields": {"post": 48, "type": 0, "author": 67}}, {"pk": 1043, "model": "server.vote", "fields": {"post": 310, "type": 0, "author": 67}}, {"pk": 1044, "model": "server.vote", "fields": {"post": 385, "type": 1, "author": 67}}, {"pk": 1045, "model": "server.vote", "fields": {"post": 387, "type": 0, "author": 29}}, {"pk": 1046, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 39}}, {"pk": 1047, "model": "server.vote", "fields": {"post": 385, "type": 1, "author": 65}}, {"pk": 1048, "model": "server.vote", "fields": {"post": 38, "type": 0, "author": 65}}, {"pk": 1049, "model": "server.vote", "fields": {"post": 122, "type": 0, "author": 65}}, {"pk": 1050, "model": "server.vote", "fields": {"post": 122, "type": 0, "author": 141}}, {"pk": 1051, "model": "server.vote", "fields": {"post": 392, "type": 0, "author": 1}}, {"pk": 1052, "model": "server.vote", "fields": {"post": 393, "type": 0, "author": 65}}, {"pk": 1053, "model": "server.vote", "fields": {"post": 391, "type": 0, "author": 22}}, {"pk": 1054, "model": "server.vote", "fields": {"post": 389, "type": 0, "author": 65}}, {"pk": 1055, "model": "server.vote", "fields": {"post": 388, "type": 0, "author": 22}}, {"pk": 1056, "model": "server.vote", "fields": {"post": 392, "type": 0, "author": 116}}, {"pk": 1057, "model": "server.vote", "fields": {"post": 393, "type": 0, "author": 88}}, {"pk": 1058, "model": "server.vote", "fields": {"post": 392, "type": 0, "author": 88}}, {"pk": 1059, "model": "server.vote", "fields": {"post": 395, "type": 0, "author": 22}}, {"pk": 1060, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 147}}, {"pk": 1061, "model": "server.vote", "fields": {"post": 395, "type": 0, "author": 88}}, {"pk": 1062, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 35}}, {"pk": 1063, "model": "server.vote", "fields": {"post": 214, "type": 0, "author": 88}}, {"pk": 1064, "model": "server.vote", "fields": {"post": 388, "type": 0, "author": 88}}, {"pk": 1065, "model": "server.vote", "fields": {"post": 393, "type": 0, "author": 35}}, {"pk": 1066, "model": "server.vote", "fields": {"post": 395, "type": 0, "author": 159}}, {"pk": 1067, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 22}}, {"pk": 1068, "model": "server.vote", "fields": {"post": 397, "type": 0, "author": 22}}, {"pk": 1069, "model": "server.vote", "fields": {"post": 398, "type": 0, "author": 22}}, {"pk": 1070, "model": "server.vote", "fields": {"post": 163, "type": 0, "author": 22}}, {"pk": 1071, "model": "server.vote", "fields": {"post": 392, "type": 0, "author": 86}}, {"pk": 1072, "model": "server.vote", "fields": {"post": 394, "type": 0, "author": 1}}, {"pk": 1073, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 159}}, {"pk": 1074, "model": "server.vote", "fields": {"post": 2, "type": 0, "author": 159}}, {"pk": 1075, "model": "server.vote", "fields": {"post": 163, "type": 0, "author": 29}}, {"pk": 1076, "model": "server.vote", "fields": {"post": 391, "type": 0, "author": 29}}, {"pk": 1077, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 29}}, {"pk": 1078, "model": "server.vote", "fields": {"post": 398, "type": 0, "author": 116}}, {"pk": 1079, "model": "server.vote", "fields": {"post": 395, "type": 0, "author": 34}}, {"pk": 1080, "model": "server.vote", "fields": {"post": 183, "type": 0, "author": 29}}, {"pk": 1081, "model": "server.vote", "fields": {"post": 398, "type": 0, "author": 30}}, {"pk": 1082, "model": "server.vote", "fields": {"post": 400, "type": 0, "author": 30}}, {"pk": 1083, "model": "server.vote", "fields": {"post": 402, "type": 0, "author": 29}}, {"pk": 1084, "model": "server.vote", "fields": {"post": 400, "type": 0, "author": 1}}, {"pk": 1085, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 85}}, {"pk": 1086, "model": "server.vote", "fields": {"post": 402, "type": 0, "author": 1}}, {"pk": 1087, "model": "server.vote", "fields": {"post": 403, "type": 0, "author": 1}}, {"pk": 1088, "model": "server.vote", "fields": {"post": 406, "type": 0, "author": 1}}, {"pk": 1089, "model": "server.vote", "fields": {"post": 402, "type": 0, "author": 57}}, {"pk": 1090, "model": "server.vote", "fields": {"post": 402, "type": 0, "author": 22}}, {"pk": 1091, "model": "server.vote", "fields": {"post": 403, "type": 0, "author": 22}}, {"pk": 1092, "model": "server.vote", "fields": {"post": 408, "type": 0, "author": 88}}, {"pk": 1093, "model": "server.vote", "fields": {"post": 327, "type": 1, "author": 52}}, {"pk": 1094, "model": "server.vote", "fields": {"post": 361, "type": 0, "author": 52}}, {"pk": 1095, "model": "server.vote", "fields": {"post": 410, "type": 0, "author": 29}}, {"pk": 1096, "model": "server.vote", "fields": {"post": 409, "type": 0, "author": 29}}, {"pk": 1097, "model": "server.vote", "fields": {"post": 407, "type": 0, "author": 29}}, {"pk": 1098, "model": "server.vote", "fields": {"post": 394, "type": 0, "author": 70}}, {"pk": 1099, "model": "server.vote", "fields": {"post": 406, "type": 2, "author": 127}}, {"pk": 1100, "model": "server.vote", "fields": {"post": 406, "type": 0, "author": 127}}, {"pk": 1101, "model": "server.vote", "fields": {"post": 402, "type": 0, "author": 147}}, {"pk": 1102, "model": "server.vote", "fields": {"post": 402, "type": 0, "author": 85}}, {"pk": 1103, "model": "server.vote", "fields": {"post": 411, "type": 0, "author": 29}}, {"pk": 1104, "model": "server.vote", "fields": {"post": 412, "type": 0, "author": 29}}, {"pk": 1105, "model": "server.vote", "fields": {"post": 414, "type": 2, "author": 88}}, {"pk": 1106, "model": "server.vote", "fields": {"post": 414, "type": 0, "author": 88}}, {"pk": 1107, "model": "server.vote", "fields": {"post": 388, "type": 0, "author": 58}}, {"pk": 1108, "model": "server.vote", "fields": {"post": 395, "type": 0, "author": 58}}, {"pk": 1109, "model": "server.vote", "fields": {"post": 402, "type": 0, "author": 52}}, {"pk": 1110, "model": "server.vote", "fields": {"post": 378, "type": 0, "author": 54}}, {"pk": 1111, "model": "server.vote", "fields": {"post": 388, "type": 1, "author": 54}}, {"pk": 1112, "model": "server.vote", "fields": {"post": 418, "type": 0, "author": 54}}, {"pk": 1113, "model": "server.vote", "fields": {"post": 38, "type": 1, "author": 61}}, {"pk": 1114, "model": "server.vote", "fields": {"post": 418, "type": 0, "author": 88}}, {"pk": 1115, "model": "server.vote", "fields": {"post": 413, "type": 0, "author": 88}}, {"pk": 1116, "model": "server.vote", "fields": {"post": 407, "type": 0, "author": 1}}, {"pk": 1117, "model": "server.vote", "fields": {"post": 409, "type": 0, "author": 1}}, {"pk": 1118, "model": "server.vote", "fields": {"post": 411, "type": 0, "author": 1}}, {"pk": 1119, "model": "server.vote", "fields": {"post": 412, "type": 0, "author": 1}}, {"pk": 1120, "model": "server.vote", "fields": {"post": 410, "type": 0, "author": 1}}, {"pk": 1121, "model": "server.vote", "fields": {"post": 413, "type": 0, "author": 22}}, {"pk": 1122, "model": "server.vote", "fields": {"post": 405, "type": 0, "author": 1}}, {"pk": 1123, "model": "server.vote", "fields": {"post": 415, "type": 0, "author": 22}}, {"pk": 1124, "model": "server.vote", "fields": {"post": 416, "type": 0, "author": 22}}, {"pk": 1125, "model": "server.vote", "fields": {"post": 417, "type": 0, "author": 22}}, {"pk": 1126, "model": "server.vote", "fields": {"post": 417, "type": 0, "author": 1}}, {"pk": 1127, "model": "server.vote", "fields": {"post": 408, "type": 0, "author": 1}}, {"pk": 1128, "model": "server.vote", "fields": {"post": 409, "type": 0, "author": 22}}, {"pk": 1129, "model": "server.vote", "fields": {"post": 411, "type": 0, "author": 22}}, {"pk": 1130, "model": "server.vote", "fields": {"post": 412, "type": 0, "author": 22}}, {"pk": 1131, "model": "server.vote", "fields": {"post": 410, "type": 0, "author": 22}}, {"pk": 1132, "model": "server.vote", "fields": {"post": 400, "type": 0, "author": 72}}, {"pk": 1133, "model": "server.vote", "fields": {"post": 414, "type": 0, "author": 65}}, {"pk": 1134, "model": "server.vote", "fields": {"post": 391, "type": 0, "author": 61}}, {"pk": 1135, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 127}}, {"pk": 1136, "model": "server.vote", "fields": {"post": 418, "type": 2, "author": 86}}, {"pk": 1137, "model": "server.vote", "fields": {"post": 418, "type": 0, "author": 86}}, {"pk": 1138, "model": "server.vote", "fields": {"post": 385, "type": 1, "author": 86}}, {"pk": 1139, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 66}}, {"pk": 1140, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 66}}, {"pk": 1141, "model": "server.vote", "fields": {"post": 414, "type": 0, "author": 29}}, {"pk": 1142, "model": "server.vote", "fields": {"post": 395, "type": 2, "author": 159}}, {"pk": 1143, "model": "server.vote", "fields": {"post": 409, "type": 2, "author": 163}}, {"pk": 1144, "model": "server.vote", "fields": {"post": 409, "type": 2, "author": 163}}, {"pk": 1145, "model": "server.vote", "fields": {"post": 418, "type": 0, "author": 90}}, {"pk": 1146, "model": "server.vote", "fields": {"post": 419, "type": 0, "author": 90}}, {"pk": 1147, "model": "server.vote", "fields": {"post": 385, "type": 1, "author": 54}}, {"pk": 1148, "model": "server.vote", "fields": {"post": 408, "type": 0, "author": 90}}, {"pk": 1149, "model": "server.vote", "fields": {"post": 136, "type": 0, "author": 54}}, {"pk": 1150, "model": "server.vote", "fields": {"post": 387, "type": 1, "author": 54}}, {"pk": 1151, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 159}}, {"pk": 1152, "model": "server.vote", "fields": {"post": 420, "type": 0, "author": 147}}, {"pk": 1153, "model": "server.vote", "fields": {"post": 422, "type": 0, "author": 54}}, {"pk": 1154, "model": "server.vote", "fields": {"post": 420, "type": 0, "author": 1}}, {"pk": 1155, "model": "server.vote", "fields": {"post": 422, "type": 0, "author": 1}}, {"pk": 1156, "model": "server.vote", "fields": {"post": 421, "type": 0, "author": 1}}, {"pk": 1157, "model": "server.vote", "fields": {"post": 420, "type": 0, "author": 72}}, {"pk": 1158, "model": "server.vote", "fields": {"post": 424, "type": 0, "author": 54}}, {"pk": 1159, "model": "server.vote", "fields": {"post": 423, "type": 0, "author": 54}}, {"pk": 1160, "model": "server.vote", "fields": {"post": 425, "type": 0, "author": 1}}, {"pk": 1161, "model": "server.vote", "fields": {"post": 424, "type": 0, "author": 1}}, {"pk": 1162, "model": "server.vote", "fields": {"post": 422, "type": 0, "author": 86}}, {"pk": 1163, "model": "server.vote", "fields": {"post": 426, "type": 0, "author": 1}}, {"pk": 1164, "model": "server.vote", "fields": {"post": 126, "type": 0, "author": 1}}, {"pk": 1165, "model": "server.vote", "fields": {"post": 425, "type": 0, "author": 58}}, {"pk": 1166, "model": "server.vote", "fields": {"post": 408, "type": 2, "author": 88}}, {"pk": 1167, "model": "server.vote", "fields": {"post": 425, "type": 0, "author": 112}}, {"pk": 1168, "model": "server.vote", "fields": {"post": 426, "type": 0, "author": 112}}, {"pk": 1169, "model": "server.vote", "fields": {"post": 424, "type": 0, "author": 29}}, {"pk": 1170, "model": "server.vote", "fields": {"post": 336, "type": 2, "author": 86}}, {"pk": 1171, "model": "server.vote", "fields": {"post": 427, "type": 0, "author": 1}}, {"pk": 1172, "model": "server.vote", "fields": {"post": 421, "type": 0, "author": 147}}, {"pk": 1173, "model": "server.vote", "fields": {"post": 421, "type": 2, "author": 147}}, {"pk": 1174, "model": "server.vote", "fields": {"post": 427, "type": 0, "author": 29}}, {"pk": 1175, "model": "server.vote", "fields": {"post": 427, "type": 0, "author": 86}}, {"pk": 1176, "model": "server.vote", "fields": {"post": 427, "type": 0, "author": 86}}, {"pk": 1177, "model": "server.vote", "fields": {"post": 427, "type": 0, "author": 86}}, {"pk": 1178, "model": "server.vote", "fields": {"post": 426, "type": 0, "author": 25}}, {"pk": 1179, "model": "server.vote", "fields": {"post": 428, "type": 0, "author": 85}}, {"pk": 1180, "model": "server.vote", "fields": {"post": 429, "type": 0, "author": 1}}, {"pk": 1181, "model": "server.vote", "fields": {"post": 430, "type": 0, "author": 1}}, {"pk": 1182, "model": "server.vote", "fields": {"post": 429, "type": 0, "author": 58}}, {"pk": 1183, "model": "server.vote", "fields": {"post": 431, "type": 0, "author": 1}}, {"pk": 1184, "model": "server.vote", "fields": {"post": 431, "type": 0, "author": 86}}, {"pk": 1185, "model": "server.vote", "fields": {"post": 430, "type": 0, "author": 86}}, {"pk": 1186, "model": "server.vote", "fields": {"post": 430, "type": 0, "author": 86}}, {"pk": 1187, "model": "server.vote", "fields": {"post": 364, "type": 0, "author": 168}}, {"pk": 1188, "model": "server.vote", "fields": {"post": 81, "type": 0, "author": 168}}, {"pk": 1189, "model": "server.vote", "fields": {"post": 430, "type": 0, "author": 61}}, {"pk": 1190, "model": "server.vote", "fields": {"post": 431, "type": 0, "author": 61}}, {"pk": 1191, "model": "server.vote", "fields": {"post": 433, "type": 0, "author": 29}}, {"pk": 1192, "model": "server.vote", "fields": {"post": 389, "type": 0, "author": 86}}, {"pk": 1193, "model": "server.vote", "fields": {"post": 389, "type": 1, "author": 86}}, {"pk": 1194, "model": "server.vote", "fields": {"post": 389, "type": 0, "author": 86}}, {"pk": 1195, "model": "server.vote", "fields": {"post": 432, "type": 0, "author": 70}}, {"pk": 1196, "model": "server.vote", "fields": {"post": 434, "type": 0, "author": 29}}, {"pk": 1197, "model": "server.vote", "fields": {"post": 376, "type": 0, "author": 168}}, {"pk": 1198, "model": "server.vote", "fields": {"post": 377, "type": 0, "author": 168}}, {"pk": 1199, "model": "server.vote", "fields": {"post": 234, "type": 0, "author": 168}}, {"pk": 1200, "model": "server.vote", "fields": {"post": 437, "type": 0, "author": 54}}, {"pk": 1201, "model": "server.vote", "fields": {"post": 80, "type": 0, "author": 172}}, {"pk": 1202, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 168}}, {"pk": 1203, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 168}}, {"pk": 1204, "model": "server.vote", "fields": {"post": 334, "type": 0, "author": 168}}, {"pk": 1205, "model": "server.vote", "fields": {"post": 79, "type": 0, "author": 168}}, {"pk": 1206, "model": "server.vote", "fields": {"post": 438, "type": 0, "author": 37}}, {"pk": 1207, "model": "server.vote", "fields": {"post": 439, "type": 0, "author": 67}}, {"pk": 1208, "model": "server.vote", "fields": {"post": 438, "type": 0, "author": 135}}, {"pk": 1209, "model": "server.vote", "fields": {"post": 439, "type": 0, "author": 135}}, {"pk": 1210, "model": "server.vote", "fields": {"post": 435, "type": 0, "author": 1}}, {"pk": 1211, "model": "server.vote", "fields": {"post": 442, "type": 0, "author": 1}}, {"pk": 1212, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 1}}, {"pk": 1213, "model": "server.vote", "fields": {"post": 420, "type": 0, "author": 71}}, {"pk": 1214, "model": "server.vote", "fields": {"post": 443, "type": 0, "author": 168}}, {"pk": 1215, "model": "server.vote", "fields": {"post": 444, "type": 0, "author": 1}}, {"pk": 1216, "model": "server.vote", "fields": {"post": 437, "type": 0, "author": 1}}, {"pk": 1217, "model": "server.vote", "fields": {"post": 445, "type": 0, "author": 168}}, {"pk": 1218, "model": "server.vote", "fields": {"post": 444, "type": 0, "author": 168}}, {"pk": 1219, "model": "server.vote", "fields": {"post": 274, "type": 0, "author": 73}}, {"pk": 1220, "model": "server.vote", "fields": {"post": 446, "type": 0, "author": 1}}, {"pk": 1221, "model": "server.vote", "fields": {"post": 443, "type": 0, "author": 54}}, {"pk": 1222, "model": "server.vote", "fields": {"post": 445, "type": 0, "author": 54}}, {"pk": 1223, "model": "server.vote", "fields": {"post": 448, "type": 0, "author": 168}}, {"pk": 1224, "model": "server.vote", "fields": {"post": 245, "type": 0, "author": 168}}, {"pk": 1225, "model": "server.vote", "fields": {"post": 246, "type": 0, "author": 168}}, {"pk": 1226, "model": "server.vote", "fields": {"post": 442, "type": 0, "author": 22}}, {"pk": 1227, "model": "server.vote", "fields": {"post": 448, "type": 0, "author": 22}}, {"pk": 1228, "model": "server.vote", "fields": {"post": 445, "type": 0, "author": 22}}, {"pk": 1229, "model": "server.vote", "fields": {"post": 444, "type": 0, "author": 22}}, {"pk": 1230, "model": "server.vote", "fields": {"post": 434, "type": 0, "author": 54}}, {"pk": 1231, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 58}}, {"pk": 1232, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 88}}, {"pk": 1233, "model": "server.vote", "fields": {"post": 437, "type": 0, "author": 88}}, {"pk": 1234, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 116}}, {"pk": 1235, "model": "server.vote", "fields": {"post": 437, "type": 2, "author": 88}}, {"pk": 1236, "model": "server.vote", "fields": {"post": 435, "type": 0, "author": 116}}, {"pk": 1237, "model": "server.vote", "fields": {"post": 452, "type": 0, "author": 168}}, {"pk": 1238, "model": "server.vote", "fields": {"post": 451, "type": 0, "author": 22}}, {"pk": 1239, "model": "server.vote", "fields": {"post": 453, "type": 1, "author": 121}}, {"pk": 1240, "model": "server.vote", "fields": {"post": 444, "type": 0, "author": 121}}, {"pk": 1241, "model": "server.vote", "fields": {"post": 442, "type": 0, "author": 168}}, {"pk": 1242, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 29}}, {"pk": 1243, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 29}}, {"pk": 1244, "model": "server.vote", "fields": {"post": 435, "type": 0, "author": 29}}, {"pk": 1245, "model": "server.vote", "fields": {"post": 437, "type": 0, "author": 29}}, {"pk": 1246, "model": "server.vote", "fields": {"post": 451, "type": 0, "author": 147}}, {"pk": 1247, "model": "server.vote", "fields": {"post": 453, "type": 0, "author": 1}}, {"pk": 1248, "model": "server.vote", "fields": {"post": 458, "type": 0, "author": 115}}, {"pk": 1249, "model": "server.vote", "fields": {"post": 455, "type": 0, "author": 1}}, {"pk": 1250, "model": "server.vote", "fields": {"post": 460, "type": 0, "author": 1}}, {"pk": 1251, "model": "server.vote", "fields": {"post": 461, "type": 0, "author": 1}}, {"pk": 1252, "model": "server.vote", "fields": {"post": 456, "type": 0, "author": 1}}, {"pk": 1253, "model": "server.vote", "fields": {"post": 459, "type": 0, "author": 1}}, {"pk": 1254, "model": "server.vote", "fields": {"post": 461, "type": 0, "author": 116}}, {"pk": 1255, "model": "server.vote", "fields": {"post": 460, "type": 0, "author": 116}}, {"pk": 1256, "model": "server.vote", "fields": {"post": 451, "type": 0, "author": 29}}, {"pk": 1257, "model": "server.vote", "fields": {"post": 320, "type": 0, "author": 29}}, {"pk": 1258, "model": "server.vote", "fields": {"post": 330, "type": 0, "author": 137}}, {"pk": 1259, "model": "server.vote", "fields": {"post": 464, "type": 0, "author": 72}}, {"pk": 1260, "model": "server.vote", "fields": {"post": 459, "type": 0, "author": 72}}, {"pk": 1261, "model": "server.vote", "fields": {"post": 458, "type": 0, "author": 72}}, {"pk": 1262, "model": "server.vote", "fields": {"post": 463, "type": 0, "author": 72}}, {"pk": 1263, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 29}}, {"pk": 1264, "model": "server.vote", "fields": {"post": 460, "type": 0, "author": 178}}, {"pk": 1265, "model": "server.vote", "fields": {"post": 461, "type": 0, "author": 178}}, {"pk": 1266, "model": "server.vote", "fields": {"post": 455, "type": 0, "author": 178}}, {"pk": 1267, "model": "server.vote", "fields": {"post": 457, "type": 1, "author": 116}}, {"pk": 1268, "model": "server.vote", "fields": {"post": 456, "type": 0, "author": 70}}, {"pk": 1269, "model": "server.vote", "fields": {"post": 466, "type": 0, "author": 29}}, {"pk": 1270, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 116}}, {"pk": 1271, "model": "server.vote", "fields": {"post": 469, "type": 0, "author": 121}}, {"pk": 1272, "model": "server.vote", "fields": {"post": 450, "type": 0, "author": 70}}, {"pk": 1273, "model": "server.vote", "fields": {"post": 435, "type": 0, "author": 70}}, {"pk": 1274, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 88}}, {"pk": 1275, "model": "server.vote", "fields": {"post": 383, "type": 0, "author": 73}}, {"pk": 1276, "model": "server.vote", "fields": {"post": 364, "type": 0, "author": 73}}, {"pk": 1277, "model": "server.vote", "fields": {"post": 245, "type": 0, "author": 73}}, {"pk": 1278, "model": "server.vote", "fields": {"post": 390, "type": 0, "author": 73}}, {"pk": 1279, "model": "server.vote", "fields": {"post": 397, "type": 0, "author": 73}}, {"pk": 1280, "model": "server.vote", "fields": {"post": 389, "type": 1, "author": 73}}, {"pk": 1281, "model": "server.vote", "fields": {"post": 418, "type": 0, "author": 168}}, {"pk": 1282, "model": "server.vote", "fields": {"post": 388, "type": 0, "author": 73}}, {"pk": 1283, "model": "server.vote", "fields": {"post": 419, "type": 0, "author": 168}}, {"pk": 1284, "model": "server.vote", "fields": {"post": 395, "type": 0, "author": 168}}, {"pk": 1285, "model": "server.vote", "fields": {"post": 471, "type": 0, "author": 163}}, {"pk": 1286, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 168}}, {"pk": 1287, "model": "server.vote", "fields": {"post": 182, "type": 0, "author": 168}}, {"pk": 1288, "model": "server.vote", "fields": {"post": 474, "type": 0, "author": 70}}, {"pk": 1289, "model": "server.vote", "fields": {"post": 451, "type": 0, "author": 54}}, {"pk": 1290, "model": "server.vote", "fields": {"post": 474, "type": 0, "author": 168}}, {"pk": 1291, "model": "server.vote", "fields": {"post": 466, "type": 0, "author": 115}}, {"pk": 1292, "model": "server.vote", "fields": {"post": 476, "type": 0, "author": 29}}, {"pk": 1293, "model": "server.vote", "fields": {"post": 472, "type": 0, "author": 178}}, {"pk": 1294, "model": "server.vote", "fields": {"post": 388, "type": 0, "author": 178}}, {"pk": 1295, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 178}}, {"pk": 1296, "model": "server.vote", "fields": {"post": 435, "type": 0, "author": 178}}, {"pk": 1297, "model": "server.vote", "fields": {"post": 438, "type": 0, "author": 178}}, {"pk": 1298, "model": "server.vote", "fields": {"post": 450, "type": 0, "author": 178}}, {"pk": 1299, "model": "server.vote", "fields": {"post": 469, "type": 0, "author": 22}}, {"pk": 1300, "model": "server.vote", "fields": {"post": 473, "type": 0, "author": 1}}, {"pk": 1301, "model": "server.vote", "fields": {"post": 470, "type": 0, "author": 1}}, {"pk": 1302, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 1}}, {"pk": 1303, "model": "server.vote", "fields": {"post": 471, "type": 0, "author": 1}}, {"pk": 1304, "model": "server.vote", "fields": {"post": 436, "type": 0, "author": 1}}, {"pk": 1305, "model": "server.vote", "fields": {"post": 399, "type": 0, "author": 1}}, {"pk": 1306, "model": "server.vote", "fields": {"post": 472, "type": 0, "author": 1}}, {"pk": 1307, "model": "server.vote", "fields": {"post": 474, "type": 0, "author": 86}}, {"pk": 1308, "model": "server.vote", "fields": {"post": 474, "type": 0, "author": 65}}, {"pk": 1309, "model": "server.vote", "fields": {"post": 440, "type": 0, "author": 127}}, {"pk": 1310, "model": "server.vote", "fields": {"post": 477, "type": 0, "author": 91}}, {"pk": 1311, "model": "server.vote", "fields": {"post": 477, "type": 2, "author": 91}}, {"pk": 1312, "model": "server.vote", "fields": {"post": 478, "type": 0, "author": 29}}, {"pk": 1313, "model": "server.vote", "fields": {"post": 450, "type": 0, "author": 135}}, {"pk": 1314, "model": "server.vote", "fields": {"post": 468, "type": 0, "author": 135}}, {"pk": 1315, "model": "server.vote", "fields": {"post": 477, "type": 0, "author": 168}}, {"pk": 1316, "model": "server.vote", "fields": {"post": 480, "type": 0, "author": 168}}, {"pk": 1317, "model": "server.vote", "fields": {"post": 456, "type": 0, "author": 168}}, {"pk": 1318, "model": "server.vote", "fields": {"post": 466, "type": 0, "author": 168}}, {"pk": 1319, "model": "server.vote", "fields": {"post": 444, "type": 2, "author": 168}}, {"pk": 1320, "model": "server.vote", "fields": {"post": 480, "type": 0, "author": 22}}, {"pk": 1321, "model": "server.vote", "fields": {"post": 425, "type": 0, "author": 22}}, {"pk": 1322, "model": "server.vote", "fields": {"post": 473, "type": 0, "author": 147}}, {"pk": 1323, "model": "server.vote", "fields": {"post": 482, "type": 0, "author": 65}}, {"pk": 1324, "model": "server.vote", "fields": {"post": 458, "type": 0, "author": 65}}, {"pk": 1325, "model": "server.vote", "fields": {"post": 459, "type": 0, "author": 65}}, {"pk": 1326, "model": "server.vote", "fields": {"post": 463, "type": 0, "author": 65}}, {"pk": 1327, "model": "server.vote", "fields": {"post": 485, "type": 0, "author": 22}}, {"pk": 1328, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 22}}, {"pk": 1329, "model": "server.vote", "fields": {"post": 479, "type": 0, "author": 1}}, {"pk": 1330, "model": "server.vote", "fields": {"post": 484, "type": 0, "author": 1}}, {"pk": 1331, "model": "server.vote", "fields": {"post": 483, "type": 0, "author": 58}}, {"pk": 1332, "model": "server.vote", "fields": {"post": 458, "type": 0, "author": 1}}, {"pk": 1333, "model": "server.vote", "fields": {"post": 456, "type": 0, "author": 163}}, {"pk": 1334, "model": "server.vote", "fields": {"post": 484, "type": 0, "author": 54}}, {"pk": 1335, "model": "server.vote", "fields": {"post": 482, "type": 0, "author": 72}}, {"pk": 1336, "model": "server.vote", "fields": {"post": 319, "type": 0, "author": 73}}, {"pk": 1337, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 73}}, {"pk": 1338, "model": "server.vote", "fields": {"post": 486, "type": 0, "author": 58}}, {"pk": 1339, "model": "server.vote", "fields": {"post": 488, "type": 0, "author": 72}}, {"pk": 1340, "model": "server.vote", "fields": {"post": 477, "type": 0, "author": 121}}, {"pk": 1341, "model": "server.vote", "fields": {"post": 488, "type": 0, "author": 147}}, {"pk": 1342, "model": "server.vote", "fields": {"post": 488, "type": 0, "author": 112}}, {"pk": 1343, "model": "server.vote", "fields": {"post": 16, "type": 0, "author": 112}}, {"pk": 1344, "model": "server.vote", "fields": {"post": 489, "type": 0, "author": 72}}, {"pk": 1345, "model": "server.vote", "fields": {"post": 479, "type": 0, "author": 88}}, {"pk": 1346, "model": "server.vote", "fields": {"post": 480, "type": 0, "author": 88}}, {"pk": 1347, "model": "server.vote", "fields": {"post": 490, "type": 0, "author": 58}}, {"pk": 1348, "model": "server.vote", "fields": {"post": 420, "type": 0, "author": 168}}, {"pk": 1349, "model": "server.vote", "fields": {"post": 491, "type": 0, "author": 22}}, {"pk": 1350, "model": "server.vote", "fields": {"post": 485, "type": 0, "author": 180}}, {"pk": 1351, "model": "server.vote", "fields": {"post": 481, "type": 0, "author": 29}}, {"pk": 1352, "model": "server.vote", "fields": {"post": 429, "type": 0, "author": 180}}, {"pk": 1353, "model": "server.vote", "fields": {"post": 480, "type": 0, "author": 29}}, {"pk": 1354, "model": "server.vote", "fields": {"post": 487, "type": 0, "author": 22}}, {"pk": 1355, "model": "server.vote", "fields": {"post": 484, "type": 0, "author": 163}}, {"pk": 1356, "model": "server.vote", "fields": {"post": 431, "type": 0, "author": 147}}, {"pk": 1357, "model": "server.vote", "fields": {"post": 490, "type": 0, "author": 54}}, {"pk": 1358, "model": "server.vote", "fields": {"post": 494, "type": 0, "author": 180}}, {"pk": 1359, "model": "server.vote", "fields": {"post": 496, "type": 0, "author": 86}}, {"pk": 1360, "model": "server.vote", "fields": {"post": 498, "type": 0, "author": 86}}, {"pk": 1361, "model": "server.vote", "fields": {"post": 492, "type": 0, "author": 61}}, {"pk": 1362, "model": "server.vote", "fields": {"post": 499, "type": 0, "author": 30}}, {"pk": 1363, "model": "server.vote", "fields": {"post": 499, "type": 0, "author": 116}}, {"pk": 1364, "model": "server.vote", "fields": {"post": 492, "type": 0, "author": 135}}, {"pk": 1365, "model": "server.vote", "fields": {"post": 474, "type": 0, "author": 141}}, {"pk": 1366, "model": "server.vote", "fields": {"post": 494, "type": 0, "author": 66}}, {"pk": 1367, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 54}}, {"pk": 1368, "model": "server.vote", "fields": {"post": 310, "type": 0, "author": 187}}, {"pk": 1369, "model": "server.vote", "fields": {"post": 342, "type": 0, "author": 187}}, {"pk": 1370, "model": "server.vote", "fields": {"post": 331, "type": 0, "author": 54}}, {"pk": 1371, "model": "server.vote", "fields": {"post": 495, "type": 0, "author": 22}}, {"pk": 1372, "model": "server.vote", "fields": {"post": 482, "type": 0, "author": 54}}, {"pk": 1373, "model": "server.vote", "fields": {"post": 486, "type": 0, "author": 112}}, {"pk": 1374, "model": "server.vote", "fields": {"post": 197, "type": 0, "author": 72}}, {"pk": 1375, "model": "server.vote", "fields": {"post": 333, "type": 0, "author": 71}}, {"pk": 1376, "model": "server.vote", "fields": {"post": 130, "type": 0, "author": 72}}, {"pk": 1377, "model": "server.vote", "fields": {"post": 428, "type": 0, "author": 112}}, {"pk": 1378, "model": "server.vote", "fields": {"post": 454, "type": 0, "author": 112}}, {"pk": 1379, "model": "server.vote", "fields": {"post": 494, "type": 0, "author": 22}}, {"pk": 1380, "model": "server.vote", "fields": {"post": 499, "type": 0, "author": 86}}, {"pk": 1381, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 71}}, {"pk": 1382, "model": "server.vote", "fields": {"post": 231, "type": 0, "author": 22}}, {"pk": 1383, "model": "server.vote", "fields": {"post": 191, "type": 0, "author": 67}}, {"pk": 1384, "model": "server.vote", "fields": {"post": 190, "type": 2, "author": 67}}, {"pk": 1385, "model": "server.vote", "fields": {"post": 492, "type": 2, "author": 135}}, {"pk": 1386, "model": "server.vote", "fields": {"post": 430, "type": 0, "author": 30}}, {"pk": 1387, "model": "server.vote", "fields": {"post": 463, "type": 0, "author": 30}}, {"pk": 1388, "model": "server.vote", "fields": {"post": 475, "type": 0, "author": 30}}, {"pk": 1389, "model": "server.vote", "fields": {"post": 493, "type": 0, "author": 30}}, {"pk": 1390, "model": "server.vote", "fields": {"post": 492, "type": 0, "author": 85}}, {"pk": 1391, "model": "server.vote", "fields": {"post": 486, "type": 0, "author": 22}}, {"pk": 1392, "model": "server.vote", "fields": {"post": 488, "type": 0, "author": 22}}, {"pk": 1393, "model": "server.vote", "fields": {"post": 489, "type": 0, "author": 22}}, {"pk": 1394, "model": "server.vote", "fields": {"post": 262, "type": 0, "author": 35}}, {"pk": 1395, "model": "server.vote", "fields": {"post": 435, "type": 0, "author": 22}}, {"pk": 1396, "model": "server.vote", "fields": {"post": 468, "type": 0, "author": 22}}, {"pk": 1397, "model": "server.vote", "fields": {"post": 439, "type": 0, "author": 22}}, {"pk": 1398, "model": "server.vote", "fields": {"post": 450, "type": 0, "author": 22}}, {"pk": 1399, "model": "server.vote", "fields": {"post": 438, "type": 0, "author": 22}}, {"pk": 1400, "model": "server.vote", "fields": {"post": 492, "type": 0, "author": 22}}, {"pk": 1401, "model": "server.vote", "fields": {"post": 227, "type": 0, "author": 22}}, {"pk": 1402, "model": "server.vote", "fields": {"post": 395, "type": 0, "author": 13}}, {"pk": 1403, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 54}}, {"pk": 1404, "model": "server.vote", "fields": {"post": 492, "type": 0, "author": 23}}, {"pk": 1405, "model": "server.vote", "fields": {"post": 474, "type": 0, "author": 73}}, {"pk": 1406, "model": "server.vote", "fields": {"post": 499, "type": 0, "author": 22}}, {"pk": 1407, "model": "server.vote", "fields": {"post": 498, "type": 0, "author": 22}}, {"pk": 1408, "model": "server.vote", "fields": {"post": 496, "type": 0, "author": 22}}, {"pk": 1409, "model": "server.vote", "fields": {"post": 443, "type": 0, "author": 125}}, {"pk": 1410, "model": "server.vote", "fields": {"post": 452, "type": 0, "author": 125}}, {"pk": 1411, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 125}}, {"pk": 1412, "model": "server.vote", "fields": {"post": 483, "type": 0, "author": 125}}, {"pk": 1413, "model": "server.vote", "fields": {"post": 132, "type": 0, "author": 204}}, {"pk": 1414, "model": "server.vote", "fields": {"post": 161, "type": 0, "author": 204}}, {"pk": 1415, "model": "server.vote", "fields": {"post": 401, "type": 0, "author": 1}}, {"pk": 1416, "model": "server.vote", "fields": {"post": 499, "type": 0, "author": 204}}, {"pk": 1417, "model": "server.vote", "fields": {"post": 163, "type": 0, "author": 67}}, {"pk": 1418, "model": "server.vote", "fields": {"post": 395, "type": 0, "author": 67}}, {"pk": 1419, "model": "server.vote", "fields": {"post": 397, "type": 0, "author": 67}}, {"pk": 1420, "model": "server.vote", "fields": {"post": 137, "type": 0, "author": 29}}, {"pk": 1421, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 1}}, {"pk": 1422, "model": "server.vote", "fields": {"post": 254, "type": 0, "author": 1}}, {"pk": 1423, "model": "server.vote", "fields": {"post": 128, "type": 0, "author": 30}}, {"pk": 1424, "model": "server.vote", "fields": {"post": 235, "type": 0, "author": 54}}, {"pk": 1425, "model": "server.vote", "fields": {"post": 12, "type": 0, "author": 202}}, {"pk": 1426, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 13}}, {"pk": 1427, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 13}}, {"pk": 1428, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 13}}, {"pk": 1429, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 55}}, {"pk": 1430, "model": "server.vote", "fields": {"post": 479, "type": 0, "author": 215}}, {"pk": 1431, "model": "server.vote", "fields": {"post": 379, "type": 0, "author": 86}}, {"pk": 1432, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 151}}, {"pk": 1433, "model": "server.vote", "fields": {"post": 12, "type": 0, "author": 73}}, {"pk": 1434, "model": "server.vote", "fields": {"post": 462, "type": 0, "author": 90}}, {"pk": 1435, "model": "server.vote", "fields": {"post": 5, "type": 0, "author": 215}}, {"pk": 1436, "model": "server.vote", "fields": {"post": 168, "type": 0, "author": 215}}, {"pk": 1437, "model": "server.vote", "fields": {"post": 449, "type": 0, "author": 22}}, {"pk": 1438, "model": "server.vote", "fields": {"post": 447, "type": 0, "author": 22}}, {"pk": 1439, "model": "server.vote", "fields": {"post": 462, "type": 0, "author": 22}}, {"pk": 1440, "model": "server.vote", "fields": {"post": 245, "type": 0, "author": 22}}, {"pk": 1441, "model": "server.vote", "fields": {"post": 189, "type": 0, "author": 22}}, {"pk": 1442, "model": "server.vote", "fields": {"post": 172, "type": 0, "author": 22}}, {"pk": 1443, "model": "server.vote", "fields": {"post": 174, "type": 0, "author": 22}}, {"pk": 1444, "model": "server.vote", "fields": {"post": 168, "type": 0, "author": 22}}, {"pk": 1445, "model": "server.vote", "fields": {"post": 383, "type": 0, "author": 22}}, {"pk": 1446, "model": "server.vote", "fields": {"post": 344, "type": 0, "author": 22}}, {"pk": 1447, "model": "server.vote", "fields": {"post": 335, "type": 0, "author": 22}}, {"pk": 1448, "model": "server.vote", "fields": {"post": 405, "type": 0, "author": 22}}, {"pk": 1449, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 22}}, {"pk": 1450, "model": "server.vote", "fields": {"post": 93, "type": 0, "author": 222}}, {"pk": 1451, "model": "server.vote", "fields": {"post": 12, "type": 0, "author": 222}}, {"pk": 1452, "model": "server.vote", "fields": {"post": 210, "type": 0, "author": 22}}, {"pk": 1453, "model": "server.vote", "fields": {"post": 97, "type": 0, "author": 22}}, {"pk": 1454, "model": "server.vote", "fields": {"post": 155, "type": 0, "author": 22}}, {"pk": 1455, "model": "server.vote", "fields": {"post": 174, "type": 0, "author": 231}}, {"pk": 1456, "model": "server.vote", "fields": {"post": 41, "type": 0, "author": 224}}, {"pk": 1457, "model": "server.vote", "fields": {"post": 41, "type": 0, "author": 29}}, {"pk": 1458, "model": "server.vote", "fields": {"post": 45, "type": 0, "author": 29}}, {"pk": 1459, "model": "server.vote", "fields": {"post": 41, "type": 0, "author": 215}}, {"pk": 1460, "model": "server.vote", "fields": {"post": 45, "type": 0, "author": 222}}, {"pk": 1461, "model": "server.vote", "fields": {"post": 183, "type": 0, "author": 204}}, {"pk": 1462, "model": "server.vote", "fields": {"post": 161, "type": 0, "author": 204}}, {"pk": 1463, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 204}}, {"pk": 1464, "model": "server.vote", "fields": {"post": 479, "type": 0, "author": 22}}, {"pk": 1465, "model": "server.vote", "fields": {"post": 38, "type": 1, "author": 215}}, {"pk": 1466, "model": "server.vote", "fields": {"post": 444, "type": 0, "author": 29}}, {"pk": 1467, "model": "server.vote", "fields": {"post": 183, "type": 0, "author": 215}}, {"pk": 1468, "model": "server.vote", "fields": {"post": 469, "type": 0, "author": 215}}, {"pk": 1469, "model": "server.vote", "fields": {"post": 271, "type": 0, "author": 215}}, {"pk": 1470, "model": "server.vote", "fields": {"post": 77, "type": 0, "author": 215}}, {"pk": 1471, "model": "server.vote", "fields": {"post": 228, "type": 0, "author": 215}}, {"pk": 1472, "model": "server.vote", "fields": {"post": 104, "type": 0, "author": 215}}, {"pk": 1473, "model": "server.vote", "fields": {"post": 302, "type": 0, "author": 215}}, {"pk": 1474, "model": "server.vote", "fields": {"post": 161, "type": 0, "author": 215}}, {"pk": 1475, "model": "server.vote", "fields": {"post": 222, "type": 0, "author": 215}}, {"pk": 1476, "model": "server.vote", "fields": {"post": 219, "type": 0, "author": 215}}, {"pk": 1477, "model": "server.vote", "fields": {"post": 28, "type": 0, "author": 215}}, {"pk": 1478, "model": "server.vote", "fields": {"post": 311, "type": 0, "author": 215}}, {"pk": 1479, "model": "server.vote", "fields": {"post": 453, "type": 0, "author": 215}}, {"pk": 1480, "model": "server.vote", "fields": {"post": 425, "type": 0, "author": 215}}, {"pk": 1481, "model": "server.vote", "fields": {"post": 282, "type": 0, "author": 215}}, {"pk": 1482, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 13}}, {"pk": 1483, "model": "server.vote", "fields": {"post": 24, "type": 0, "author": 215}}, {"pk": 1484, "model": "server.vote", "fields": {"post": 322, "type": 0, "author": 231}}, {"pk": 1485, "model": "server.vote", "fields": {"post": 136, "type": 1, "author": 126}}, {"pk": 1486, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 126}}, {"pk": 1487, "model": "server.vote", "fields": {"post": 385, "type": 1, "author": 126}}, {"pk": 1488, "model": "server.vote", "fields": {"post": 38, "type": 0, "author": 204}}, {"pk": 1489, "model": "server.vote", "fields": {"post": 136, "type": 0, "author": 204}}, {"pk": 1490, "model": "server.vote", "fields": {"post": 415, "type": 0, "author": 69}}, {"pk": 1491, "model": "server.vote", "fields": {"post": 277, "type": 0, "author": 140}}, {"pk": 1492, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 217}}, {"pk": 1493, "model": "server.vote", "fields": {"post": 4, "type": 0, "author": 29}}, {"pk": 1494, "model": "server.vote", "fields": {"post": 51, "type": 0, "author": 215}}, {"pk": 1495, "model": "server.vote", "fields": {"post": 122, "type": 0, "author": 54}}, {"pk": 1496, "model": "server.vote", "fields": {"post": 4, "type": 0, "author": 13}}, {"pk": 1497, "model": "server.vote", "fields": {"post": 125, "type": 0, "author": 13}}, {"pk": 1498, "model": "server.vote", "fields": {"post": 8, "type": 0, "author": 215}}, {"pk": 1499, "model": "server.vote", "fields": {"post": 40, "type": 0, "author": 215}}, {"pk": 1500, "model": "server.vote", "fields": {"post": 60, "type": 0, "author": 215}}, {"pk": 1501, "model": "server.vote", "fields": {"post": 4, "type": 0, "author": 215}}, {"pk": 1502, "model": "server.vote", "fields": {"post": 60, "type": 0, "author": 22}}, {"pk": 1503, "model": "server.vote", "fields": {"post": 277, "type": 0, "author": 233}}, {"pk": 1504, "model": "server.vote", "fields": {"post": 100, "type": 0, "author": 247}}, {"pk": 1505, "model": "server.vote", "fields": {"post": 7, "type": 1, "author": 215}}, {"pk": 1506, "model": "server.vote", "fields": {"post": 45, "type": 0, "author": 218}}, {"pk": 1507, "model": "server.vote", "fields": {"post": 182, "type": 0, "author": 217}}, {"pk": 1508, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 215}}, {"pk": 1509, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 215}}, {"pk": 1510, "model": "server.vote", "fields": {"post": 301, "type": 0, "author": 22}}, {"pk": 1511, "model": "server.vote", "fields": {"post": 167, "type": 0, "author": 22}}, {"pk": 1512, "model": "server.vote", "fields": {"post": 303, "type": 0, "author": 22}}, {"pk": 1513, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 264}}, {"pk": 1514, "model": "server.vote", "fields": {"post": 283, "type": 0, "author": 215}}, {"pk": 1515, "model": "server.vote", "fields": {"post": 293, "type": 0, "author": 215}}, {"pk": 1516, "model": "server.vote", "fields": {"post": 232, "type": 0, "author": 215}}, {"pk": 1517, "model": "server.vote", "fields": {"post": 146, "type": 0, "author": 215}}, {"pk": 1518, "model": "server.vote", "fields": {"post": 134, "type": 0, "author": 215}}, {"pk": 1519, "model": "server.vote", "fields": {"post": 136, "type": 0, "author": 215}}, {"pk": 1520, "model": "server.vote", "fields": {"post": 428, "type": 2, "author": 85}}, {"pk": 1521, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 237}}, {"pk": 1522, "model": "server.vote", "fields": {"post": 492, "type": 0, "author": 270}}, {"pk": 1523, "model": "server.vote", "fields": {"post": 450, "type": 0, "author": 270}}, {"pk": 1524, "model": "server.vote", "fields": {"post": 116, "type": 0, "author": 270}}, {"pk": 1525, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 270}}, {"pk": 1526, "model": "server.vote", "fields": {"post": 113, "type": 0, "author": 270}}, {"pk": 1527, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 270}}, {"pk": 1528, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 270}}, {"pk": 1529, "model": "server.vote", "fields": {"post": 354, "type": 0, "author": 270}}, {"pk": 1530, "model": "server.vote", "fields": {"post": 117, "type": 0, "author": 35}}, {"pk": 1531, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 247}}, {"pk": 1532, "model": "server.vote", "fields": {"post": 138, "type": 0, "author": 270}}, {"pk": 1533, "model": "server.vote", "fields": {"post": 403, "type": 0, "author": 270}}, {"pk": 1534, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 272}}, {"pk": 1535, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 272}}, {"pk": 1536, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 4}}, {"pk": 1537, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 22}}, {"pk": 1538, "model": "server.vote", "fields": {"post": 144, "type": 0, "author": 22}}, {"pk": 1539, "model": "server.vote", "fields": {"post": 203, "type": 0, "author": 22}}, {"pk": 1540, "model": "server.vote", "fields": {"post": 259, "type": 0, "author": 22}}, {"pk": 1541, "model": "server.vote", "fields": {"post": 373, "type": 0, "author": 22}}, {"pk": 1542, "model": "server.vote", "fields": {"post": 432, "type": 0, "author": 22}}, {"pk": 1543, "model": "server.vote", "fields": {"post": 497, "type": 0, "author": 22}}, {"pk": 1544, "model": "server.vote", "fields": {"post": 131, "type": 0, "author": 276}}, {"pk": 1545, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 276}}, {"pk": 1546, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 276}}, {"pk": 1547, "model": "server.vote", "fields": {"post": 59, "type": 0, "author": 279}}, {"pk": 1548, "model": "server.vote", "fields": {"post": 471, "type": 0, "author": 22}}, {"pk": 1549, "model": "server.vote", "fields": {"post": 410, "type": 0, "author": 233}}, {"pk": 1550, "model": "server.vote", "fields": {"post": 409, "type": 1, "author": 233}}, {"pk": 1551, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 69}}, {"pk": 1552, "model": "server.vote", "fields": {"post": 387, "type": 0, "author": 125}}, {"pk": 1553, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 86}}, {"pk": 1554, "model": "server.vote", "fields": {"post": 353, "type": 0, "author": 86}}, {"pk": 1555, "model": "server.vote", "fields": {"post": 484, "type": 0, "author": 245}}, {"pk": 1556, "model": "server.vote", "fields": {"post": 330, "type": 0, "author": 245}}, {"pk": 1557, "model": "server.vote", "fields": {"post": 138, "type": 0, "author": 215}}, {"pk": 1558, "model": "server.vote", "fields": {"post": 75, "type": 0, "author": 215}}, {"pk": 1559, "model": "server.vote", "fields": {"post": 489, "type": 0, "author": 252}}, {"pk": 1560, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 38}}, {"pk": 1561, "model": "server.vote", "fields": {"post": 433, "type": 0, "author": 86}}, {"pk": 1562, "model": "server.vote", "fields": {"post": 347, "type": 0, "author": 86}}, {"pk": 1563, "model": "server.vote", "fields": {"post": 142, "type": 0, "author": 86}}, {"pk": 1564, "model": "server.vote", "fields": {"post": 373, "type": 0, "author": 274}}, {"pk": 1565, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 270}}, {"pk": 1566, "model": "server.vote", "fields": {"post": 383, "type": 0, "author": 270}}, {"pk": 1567, "model": "server.vote", "fields": {"post": 499, "type": 0, "author": 279}}, {"pk": 1568, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 54}}, {"pk": 1569, "model": "server.vote", "fields": {"post": 320, "type": 0, "author": 54}}, {"pk": 1570, "model": "server.vote", "fields": {"post": 261, "type": 0, "author": 22}}, {"pk": 1571, "model": "server.vote", "fields": {"post": 262, "type": 0, "author": 22}}, {"pk": 1572, "model": "server.vote", "fields": {"post": 424, "type": 0, "author": 85}}, {"pk": 1573, "model": "server.vote", "fields": {"post": 422, "type": 2, "author": 54}}, {"pk": 1574, "model": "server.vote", "fields": {"post": 441, "type": 1, "author": 54}}, {"pk": 1575, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 54}}, {"pk": 1576, "model": "server.vote", "fields": {"post": 424, "type": 0, "author": 86}}, {"pk": 1577, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 215}}, {"pk": 1578, "model": "server.vote", "fields": {"post": 283, "type": 0, "author": 22}}, {"pk": 1579, "model": "server.vote", "fields": {"post": 456, "type": 0, "author": 22}}, {"pk": 1580, "model": "server.vote", "fields": {"post": 466, "type": 0, "author": 247}}, {"pk": 1581, "model": "server.vote", "fields": {"post": 458, "type": 0, "author": 106}}, {"pk": 1582, "model": "server.vote", "fields": {"post": 458, "type": 0, "author": 270}}, {"pk": 1583, "model": "server.vote", "fields": {"post": 459, "type": 0, "author": 270}}, {"pk": 1584, "model": "server.vote", "fields": {"post": 420, "type": 0, "author": 13}}, {"pk": 1585, "model": "server.vote", "fields": {"post": 444, "type": 0, "author": 222}}, {"pk": 1586, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 237}}, {"pk": 1587, "model": "server.vote", "fields": {"post": 463, "type": 0, "author": 39}}, {"pk": 1588, "model": "server.vote", "fields": {"post": 417, "type": 0, "author": 86}}, {"pk": 1589, "model": "server.vote", "fields": {"post": 418, "type": 0, "author": 324}}, {"pk": 1590, "model": "server.vote", "fields": {"post": 492, "type": 0, "author": 324}}, {"pk": 1591, "model": "server.vote", "fields": {"post": 424, "type": 0, "author": 279}}, {"pk": 1592, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 86}}, {"pk": 1593, "model": "server.vote", "fields": {"post": 474, "type": 0, "author": 324}}, {"pk": 1594, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 324}}, {"pk": 1595, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 215}}, {"pk": 1596, "model": "server.vote", "fields": {"post": 473, "type": 0, "author": 215}}, {"pk": 1597, "model": "server.vote", "fields": {"post": 470, "type": 0, "author": 215}}, {"pk": 1598, "model": "server.vote", "fields": {"post": 122, "type": 2, "author": 22}}, {"pk": 1599, "model": "server.vote", "fields": {"post": 400, "type": 0, "author": 73}}, {"pk": 1600, "model": "server.vote", "fields": {"post": 298, "type": 0, "author": 237}}, {"pk": 1601, "model": "server.vote", "fields": {"post": 405, "type": 0, "author": 237}}, {"pk": 1602, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 13}}, {"pk": 1603, "model": "server.vote", "fields": {"post": 298, "type": 0, "author": 186}}, {"pk": 1604, "model": "server.vote", "fields": {"post": 383, "type": 0, "author": 186}}, {"pk": 1605, "model": "server.vote", "fields": {"post": 309, "type": 0, "author": 186}}, {"pk": 1606, "model": "server.vote", "fields": {"post": 177, "type": 0, "author": 324}}, {"pk": 1607, "model": "server.vote", "fields": {"post": 248, "type": 0, "author": 324}}, {"pk": 1608, "model": "server.vote", "fields": {"post": 226, "type": 0, "author": 324}}, {"pk": 1609, "model": "server.vote", "fields": {"post": 95, "type": 0, "author": 324}}, {"pk": 1610, "model": "server.vote", "fields": {"post": 437, "type": 0, "author": 324}}, {"pk": 1611, "model": "server.vote", "fields": {"post": 59, "type": 0, "author": 74}}, {"pk": 1612, "model": "server.vote", "fields": {"post": 154, "type": 0, "author": 74}}, {"pk": 1613, "model": "server.vote", "fields": {"post": 149, "type": 0, "author": 125}}, {"pk": 1614, "model": "server.vote", "fields": {"post": 175, "type": 0, "author": 125}}, {"pk": 1615, "model": "server.vote", "fields": {"post": 308, "type": 0, "author": 86}}, {"pk": 1616, "model": "server.vote", "fields": {"post": 467, "type": 0, "author": 71}}, {"pk": 1617, "model": "server.vote", "fields": {"post": 470, "type": 0, "author": 71}}, {"pk": 1618, "model": "server.vote", "fields": {"post": 82, "type": 0, "author": 341}}, {"pk": 1619, "model": "server.vote", "fields": {"post": 325, "type": 0, "author": 54}}, {"pk": 1620, "model": "server.vote", "fields": {"post": 323, "type": 0, "author": 54}}, {"pk": 1621, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 338}}, {"pk": 1622, "model": "server.vote", "fields": {"post": 428, "type": 0, "author": 54}}, {"pk": 1623, "model": "server.vote", "fields": {"post": 428, "type": 0, "author": 54}}, {"pk": 1624, "model": "server.vote", "fields": {"post": 32, "type": 0, "author": 112}}, {"pk": 1625, "model": "server.vote", "fields": {"post": 229, "type": 0, "author": 86}}, {"pk": 1626, "model": "server.vote", "fields": {"post": 249, "type": 0, "author": 86}}, {"pk": 1627, "model": "server.vote", "fields": {"post": 400, "type": 0, "author": 22}}, {"pk": 1628, "model": "server.vote", "fields": {"post": 408, "type": 0, "author": 22}}, {"pk": 1629, "model": "server.vote", "fields": {"post": 332, "type": 0, "author": 233}}, {"pk": 1630, "model": "server.vote", "fields": {"post": 274, "type": 0, "author": 339}}, {"pk": 1631, "model": "server.vote", "fields": {"post": 180, "type": 0, "author": 86}}, {"pk": 1632, "model": "server.vote", "fields": {"post": 11, "type": 0, "author": 22}}, {"pk": 1633, "model": "server.vote", "fields": {"post": 10, "type": 0, "author": 22}}, {"pk": 1634, "model": "server.vote", "fields": {"post": 2, "type": 0, "author": 22}}, {"pk": 1635, "model": "server.vote", "fields": {"post": 2, "type": 0, "author": 215}}, {"pk": 1636, "model": "server.vote", "fields": {"post": 28, "type": 0, "author": 86}}, {"pk": 1637, "model": "server.vote", "fields": {"post": 408, "type": 0, "author": 112}}, {"pk": 1638, "model": "server.vote", "fields": {"post": 29, "type": 0, "author": 58}}, {"pk": 1639, "model": "server.vote", "fields": {"post": 286, "type": 0, "author": 1}}, {"pk": 1640, "model": "server.vote", "fields": {"post": 281, "type": 0, "author": 1}}, {"pk": 1641, "model": "server.vote", "fields": {"post": 277, "type": 0, "author": 1}}, {"pk": 1642, "model": "server.vote", "fields": {"post": 279, "type": 0, "author": 1}}, {"pk": 1643, "model": "server.vote", "fields": {"post": 280, "type": 0, "author": 1}}, {"pk": 1644, "model": "server.vote", "fields": {"post": 185, "type": 1, "author": 126}}, {"pk": 1645, "model": "server.vote", "fields": {"post": 277, "type": 0, "author": 72}}, {"pk": 1646, "model": "server.vote", "fields": {"post": 330, "type": 0, "author": 202}}, {"pk": 1647, "model": "server.vote", "fields": {"post": 79, "type": 0, "author": 351}}, {"pk": 1648, "model": "server.vote", "fields": {"post": 395, "type": 0, "author": 341}}, {"pk": 1649, "model": "server.vote", "fields": {"post": 288, "type": 0, "author": 233}}, {"pk": 1650, "model": "server.vote", "fields": {"post": 18, "type": 0, "author": 58}}, {"pk": 1651, "model": "server.vote", "fields": {"post": 24, "type": 0, "author": 58}}, {"pk": 1652, "model": "server.vote", "fields": {"post": 187, "type": 0, "author": 324}}, {"pk": 1653, "model": "server.vote", "fields": {"post": 154, "type": 0, "author": 324}}, {"pk": 1654, "model": "server.vote", "fields": {"post": 486, "type": 0, "author": 338}}, {"pk": 1655, "model": "server.vote", "fields": {"post": 144, "type": 0, "author": 86}}, {"pk": 1656, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 233}}, {"pk": 1657, "model": "server.vote", "fields": {"post": 95, "type": 0, "author": 233}}, {"pk": 1658, "model": "server.vote", "fields": {"post": 106, "type": 0, "author": 217}}, {"pk": 1659, "model": "server.vote", "fields": {"post": 99, "type": 0, "author": 217}}, {"pk": 1660, "model": "server.vote", "fields": {"post": 133, "type": 0, "author": 116}}, {"pk": 1661, "model": "server.vote", "fields": {"post": 132, "type": 0, "author": 69}}, {"pk": 1662, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 69}}, {"pk": 1663, "model": "server.vote", "fields": {"post": 135, "type": 0, "author": 234}}, {"pk": 1664, "model": "server.vote", "fields": {"post": 19, "type": 0, "author": 215}}, {"pk": 1665, "model": "server.vote", "fields": {"post": 171, "type": 0, "author": 215}}, {"pk": 1666, "model": "server.vote", "fields": {"post": 132, "type": 0, "author": 71}}, {"pk": 1667, "model": "server.vote", "fields": {"post": 165, "type": 0, "author": 58}}, {"pk": 1668, "model": "server.vote", "fields": {"post": 138, "type": 0, "author": 58}}, {"pk": 1669, "model": "server.vote", "fields": {"post": 68, "type": 0, "author": 58}}, {"pk": 1670, "model": "server.vote", "fields": {"post": 322, "type": 0, "author": 58}}, {"pk": 1671, "model": "server.vote", "fields": {"post": 391, "type": 0, "author": 58}}, {"pk": 1672, "model": "server.vote", "fields": {"post": 394, "type": 0, "author": 58}}, {"pk": 1673, "model": "server.vote", "fields": {"post": 53, "type": 0, "author": 58}}, {"pk": 1674, "model": "server.vote", "fields": {"post": 55, "type": 0, "author": 58}}, {"pk": 1675, "model": "server.vote", "fields": {"post": 207, "type": 0, "author": 58}}, {"pk": 1676, "model": "server.vote", "fields": {"post": 173, "type": 0, "author": 58}}, {"pk": 1677, "model": "server.vote", "fields": {"post": 217, "type": 0, "author": 58}}, {"pk": 1678, "model": "server.vote", "fields": {"post": 212, "type": 0, "author": 58}}, {"pk": 1679, "model": "server.vote", "fields": {"post": 10, "type": 0, "author": 58}}, {"pk": 1680, "model": "server.vote", "fields": {"post": 11, "type": 0, "author": 58}}, {"pk": 1681, "model": "server.vote", "fields": {"post": 1, "type": 0, "author": 58}}, {"pk": 1682, "model": "server.vote", "fields": {"post": 66, "type": 0, "author": 58}}, {"pk": 1683, "model": "server.vote", "fields": {"post": 75, "type": 0, "author": 58}}, {"pk": 1684, "model": "server.vote", "fields": {"post": 17, "type": 0, "author": 58}}, {"pk": 1685, "model": "server.vote", "fields": {"post": 42, "type": 0, "author": 58}}, {"pk": 1686, "model": "server.vote", "fields": {"post": 13, "type": 0, "author": 58}}, {"pk": 1687, "model": "server.vote", "fields": {"post": 16, "type": 0, "author": 58}}, {"pk": 1688, "model": "server.vote", "fields": {"post": 15, "type": 0, "author": 58}}, {"pk": 1689, "model": "server.vote", "fields": {"post": 14, "type": 0, "author": 58}}, {"pk": 1690, "model": "server.vote", "fields": {"post": 25, "type": 0, "author": 58}}, {"pk": 1691, "model": "server.vote", "fields": {"post": 26, "type": 0, "author": 58}}, {"pk": 1692, "model": "server.vote", "fields": {"post": 186, "type": 0, "author": 58}}, {"pk": 1693, "model": "server.vote", "fields": {"post": 188, "type": 0, "author": 58}}, {"pk": 1694, "model": "server.vote", "fields": {"post": 102, "type": 0, "author": 58}}, {"pk": 1695, "model": "server.vote", "fields": {"post": 103, "type": 0, "author": 58}}, {"pk": 1696, "model": "server.vote", "fields": {"post": 5, "type": 0, "author": 58}}, {"pk": 1697, "model": "server.vote", "fields": {"post": 12, "type": 0, "author": 58}}, {"pk": 1698, "model": "server.vote", "fields": {"post": 93, "type": 0, "author": 58}}, {"pk": 1699, "model": "server.vote", "fields": {"post": 159, "type": 0, "author": 58}}, {"pk": 1700, "model": "server.vote", "fields": {"post": 88, "type": 0, "author": 58}}, {"pk": 1701, "model": "server.vote", "fields": {"post": 91, "type": 0, "author": 58}}, {"pk": 1702, "model": "server.vote", "fields": {"post": 89, "type": 0, "author": 58}}, {"pk": 1703, "model": "server.vote", "fields": {"post": 185, "type": 0, "author": 58}}, {"pk": 1704, "model": "server.vote", "fields": {"post": 190, "type": 0, "author": 58}}, {"pk": 1705, "model": "server.vote", "fields": {"post": 201, "type": 0, "author": 58}}, {"pk": 1706, "model": "server.vote", "fields": {"post": 219, "type": 0, "author": 58}}, {"pk": 1707, "model": "server.vote", "fields": {"post": 226, "type": 0, "author": 58}}, {"pk": 1708, "model": "server.vote", "fields": {"post": 242, "type": 0, "author": 58}}, {"pk": 1709, "model": "server.vote", "fields": {"post": 243, "type": 0, "author": 58}}, {"pk": 1710, "model": "server.vote", "fields": {"post": 204, "type": 0, "author": 58}}, {"pk": 1711, "model": "server.vote", "fields": {"post": 187, "type": 0, "author": 237}}, {"pk": 1712, "model": "server.vote", "fields": {"post": 271, "type": 0, "author": 58}}, {"pk": 1713, "model": "server.vote", "fields": {"post": 276, "type": 0, "author": 58}}, {"pk": 1714, "model": "server.vote", "fields": {"post": 273, "type": 0, "author": 58}}, {"pk": 1715, "model": "server.vote", "fields": {"post": 195, "type": 0, "author": 57}}, {"pk": 1716, "model": "server.vote", "fields": {"post": 132, "type": 0, "author": 88}}, {"pk": 1717, "model": "server.vote", "fields": {"post": 198, "type": 0, "author": 453}}, {"pk": 1718, "model": "server.vote", "fields": {"post": 122, "type": 0, "author": 324}}, {"pk": 1719, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 54}}, {"pk": 1720, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 54}}, {"pk": 1721, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 54}}, {"pk": 1722, "model": "server.vote", "fields": {"post": 436, "type": 0, "author": 116}}, {"pk": 1723, "model": "server.vote", "fields": {"post": 305, "type": 2, "author": 142}}, {"pk": 1724, "model": "server.vote", "fields": {"post": 142, "type": 0, "author": 191}}, {"pk": 1725, "model": "server.vote", "fields": {"post": 394, "type": 0, "author": 218}}, {"pk": 1726, "model": "server.vote", "fields": {"post": 267, "type": 0, "author": 86}}, {"pk": 1727, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 119}}, {"pk": 1728, "model": "server.vote", "fields": {"post": 420, "type": 0, "author": 69}}, {"pk": 1729, "model": "server.vote", "fields": {"post": 420, "type": 0, "author": 414}}, {"pk": 1730, "model": "server.vote", "fields": {"post": 422, "type": 0, "author": 363}}, {"pk": 1731, "model": "server.vote", "fields": {"post": 456, "type": 0, "author": 341}}, {"pk": 1732, "model": "server.vote", "fields": {"post": 458, "type": 0, "author": 341}}, {"pk": 1733, "model": "server.vote", "fields": {"post": 420, "type": 0, "author": 324}}, {"pk": 1734, "model": "server.vote", "fields": {"post": 458, "type": 0, "author": 305}}, {"pk": 1735, "model": "server.vote", "fields": {"post": 398, "type": 0, "author": 129}}, {"pk": 1736, "model": "server.vote", "fields": {"post": 442, "type": 0, "author": 233}}, {"pk": 1737, "model": "server.vote", "fields": {"post": 319, "type": 0, "author": 233}}, {"pk": 1738, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 233}}, {"pk": 1739, "model": "server.vote", "fields": {"post": 478, "type": 0, "author": 233}}, {"pk": 1740, "model": "server.vote", "fields": {"post": 476, "type": 0, "author": 233}}, {"pk": 1741, "model": "server.vote", "fields": {"post": 481, "type": 0, "author": 233}}, {"pk": 1742, "model": "server.vote", "fields": {"post": 306, "type": 0, "author": 233}}, {"pk": 1743, "model": "server.vote", "fields": {"post": 421, "type": 0, "author": 233}}, {"pk": 1744, "model": "server.vote", "fields": {"post": 392, "type": 0, "author": 233}}, {"pk": 1745, "model": "server.vote", "fields": {"post": 480, "type": 0, "author": 233}}, {"pk": 1746, "model": "server.vote", "fields": {"post": 479, "type": 0, "author": 233}}, {"pk": 1747, "model": "server.vote", "fields": {"post": 99, "type": 0, "author": 72}}, {"pk": 1748, "model": "server.vote", "fields": {"post": 377, "type": 0, "author": 233}}, {"pk": 1749, "model": "server.vote", "fields": {"post": 376, "type": 0, "author": 233}}, {"pk": 1750, "model": "server.vote", "fields": {"post": 307, "type": 0, "author": 233}}, {"pk": 1751, "model": "server.vote", "fields": {"post": 304, "type": 0, "author": 233}}, {"pk": 1752, "model": "server.vote", "fields": {"post": 252, "type": 2, "author": 70}}, {"pk": 1753, "model": "server.vote", "fields": {"post": 175, "type": 2, "author": 70}}, {"pk": 1754, "model": "server.vote", "fields": {"post": 416, "type": 0, "author": 86}}, {"pk": 1755, "model": "server.vote", "fields": {"post": 303, "type": 0, "author": 234}}, {"pk": 1756, "model": "server.vote", "fields": {"post": 234, "type": 0, "author": 233}}, {"pk": 1757, "model": "server.vote", "fields": {"post": 192, "type": 0, "author": 233}}, {"pk": 1758, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 233}}, {"pk": 1759, "model": "server.vote", "fields": {"post": 331, "type": 0, "author": 233}}, {"pk": 1760, "model": "server.vote", "fields": {"post": 466, "type": 0, "author": 233}}, {"pk": 1761, "model": "server.vote", "fields": {"post": 474, "type": 0, "author": 86}}, {"pk": 1762, "model": "server.vote", "fields": {"post": 2, "type": 0, "author": 126}}, {"pk": 1763, "model": "server.vote", "fields": {"post": 30, "type": 0, "author": 126}}, {"pk": 1764, "model": "server.vote", "fields": {"post": 4, "type": 0, "author": 126}}, {"pk": 1765, "model": "server.vote", "fields": {"post": 60, "type": 0, "author": 126}}, {"pk": 1766, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 126}}, {"pk": 1767, "model": "server.vote", "fields": {"post": 27, "type": 0, "author": 126}}, {"pk": 1768, "model": "server.vote", "fields": {"post": 155, "type": 0, "author": 126}}, {"pk": 1769, "model": "server.vote", "fields": {"post": 302, "type": 0, "author": 126}}, {"pk": 1770, "model": "server.vote", "fields": {"post": 321, "type": 0, "author": 126}}, {"pk": 1771, "model": "server.vote", "fields": {"post": 283, "type": 0, "author": 126}}, {"pk": 1772, "model": "server.vote", "fields": {"post": 294, "type": 0, "author": 126}}, {"pk": 1773, "model": "server.vote", "fields": {"post": 293, "type": 0, "author": 126}}, {"pk": 1774, "model": "server.vote", "fields": {"post": 271, "type": 0, "author": 126}}, {"pk": 1775, "model": "server.vote", "fields": {"post": 276, "type": 0, "author": 126}}, {"pk": 1776, "model": "server.vote", "fields": {"post": 256, "type": 0, "author": 126}}, {"pk": 1777, "model": "server.vote", "fields": {"post": 265, "type": 0, "author": 126}}, {"pk": 1778, "model": "server.vote", "fields": {"post": 264, "type": 0, "author": 126}}, {"pk": 1779, "model": "server.vote", "fields": {"post": 238, "type": 0, "author": 126}}, {"pk": 1780, "model": "server.vote", "fields": {"post": 248, "type": 0, "author": 126}}, {"pk": 1781, "model": "server.vote", "fields": {"post": 425, "type": 0, "author": 126}}, {"pk": 1782, "model": "server.vote", "fields": {"post": 426, "type": 0, "author": 126}}, {"pk": 1783, "model": "server.vote", "fields": {"post": 446, "type": 0, "author": 126}}, {"pk": 1784, "model": "server.vote", "fields": {"post": 403, "type": 0, "author": 126}}, {"pk": 1785, "model": "server.vote", "fields": {"post": 440, "type": 0, "author": 126}}, {"pk": 1786, "model": "server.vote", "fields": {"post": 402, "type": 0, "author": 126}}, {"pk": 1787, "model": "server.vote", "fields": {"post": 409, "type": 0, "author": 126}}, {"pk": 1788, "model": "server.vote", "fields": {"post": 411, "type": 0, "author": 126}}, {"pk": 1789, "model": "server.vote", "fields": {"post": 471, "type": 0, "author": 126}}, {"pk": 1790, "model": "server.vote", "fields": {"post": 414, "type": 0, "author": 313}}, {"pk": 1791, "model": "server.vote", "fields": {"post": 287, "type": 0, "author": 126}}, {"pk": 1792, "model": "server.vote", "fields": {"post": 340, "type": 0, "author": 126}}, {"pk": 1793, "model": "server.vote", "fields": {"post": 441, "type": 0, "author": 126}}, {"pk": 1794, "model": "server.vote", "fields": {"post": 448, "type": 0, "author": 126}}, {"pk": 1795, "model": "server.vote", "fields": {"post": 83, "type": 0, "author": 167}}, {"pk": 1796, "model": "server.vote", "fields": {"post": 409, "type": 0, "author": 487}}, {"pk": 1797, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 230}}, {"pk": 1798, "model": "server.vote", "fields": {"post": 319, "type": 0, "author": 58}}, {"pk": 1799, "model": "server.vote", "fields": {"post": 237, "type": 0, "author": 58}}, {"pk": 1800, "model": "server.vote", "fields": {"post": 442, "type": 0, "author": 58}}, {"pk": 1801, "model": "server.vote", "fields": {"post": 372, "type": 0, "author": 58}}, {"pk": 1802, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 233}}, {"pk": 1803, "model": "server.vote", "fields": {"post": 499, "type": 0, "author": 233}}, {"pk": 1804, "model": "server.vote", "fields": {"post": 496, "type": 0, "author": 233}}, {"pk": 1805, "model": "server.vote", "fields": {"post": 494, "type": 0, "author": 233}}, {"pk": 1806, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 233}}, {"pk": 1807, "model": "server.vote", "fields": {"post": 372, "type": 0, "author": 233}}, {"pk": 1808, "model": "server.vote", "fields": {"post": 237, "type": 0, "author": 233}}, {"pk": 1809, "model": "server.vote", "fields": {"post": 232, "type": 0, "author": 233}}, {"pk": 1810, "model": "server.vote", "fields": {"post": 190, "type": 0, "author": 35}}, {"pk": 1811, "model": "server.vote", "fields": {"post": 191, "type": 0, "author": 35}}, {"pk": 1812, "model": "server.vote", "fields": {"post": 116, "type": 0, "author": 141}}, {"pk": 1813, "model": "server.vote", "fields": {"post": 184, "type": 0, "author": 233}}, {"pk": 1814, "model": "server.vote", "fields": {"post": 131, "type": 0, "author": 116}}, {"pk": 1815, "model": "server.vote", "fields": {"post": 116, "type": 0, "author": 221}}, {"pk": 1816, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 221}}, {"pk": 1817, "model": "server.vote", "fields": {"post": 191, "type": 0, "author": 237}}, {"pk": 1818, "model": "server.vote", "fields": {"post": 113, "type": 0, "author": 1}}, {"pk": 1819, "model": "server.vote", "fields": {"post": 171, "type": 0, "author": 1}}, {"pk": 1820, "model": "server.vote", "fields": {"post": 19, "type": 0, "author": 1}}, {"pk": 1821, "model": "server.vote", "fields": {"post": 93, "type": 0, "author": 1}}, {"pk": 1822, "model": "server.vote", "fields": {"post": 5, "type": 0, "author": 485}}, {"pk": 1823, "model": "server.vote", "fields": {"post": 12, "type": 0, "author": 485}}, {"pk": 1824, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 320}}, {"pk": 1825, "model": "server.vote", "fields": {"post": 116, "type": 0, "author": 320}}, {"pk": 1826, "model": "server.vote", "fields": {"post": 274, "type": 0, "author": 237}}, {"pk": 1827, "model": "server.vote", "fields": {"post": 499, "type": 1, "author": 70}}, {"pk": 1828, "model": "server.vote", "fields": {"post": 118, "type": 0, "author": 1}}, {"pk": 1829, "model": "server.vote", "fields": {"post": 483, "type": 0, "author": 54}}, {"pk": 1830, "model": "server.vote", "fields": {"post": 316, "type": 0, "author": 54}}, {"pk": 1831, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 230}}, {"pk": 1832, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 230}}, {"pk": 1833, "model": "server.vote", "fields": {"post": 119, "type": 0, "author": 230}}, {"pk": 1834, "model": "server.vote", "fields": {"post": 316, "type": 0, "author": 204}}, {"pk": 1835, "model": "server.vote", "fields": {"post": 166, "type": 0, "author": 204}}, {"pk": 1836, "model": "server.vote", "fields": {"post": 175, "type": 1, "author": 204}}, {"pk": 1837, "model": "server.vote", "fields": {"post": 463, "type": 0, "author": 204}}, {"pk": 1838, "model": "server.vote", "fields": {"post": 34, "type": 0, "author": 445}}, {"pk": 1839, "model": "server.vote", "fields": {"post": 208, "type": 0, "author": 313}}, {"pk": 1840, "model": "server.vote", "fields": {"post": 208, "type": 0, "author": 54}}, {"pk": 1841, "model": "server.vote", "fields": {"post": 488, "type": 0, "author": 86}}, {"pk": 1842, "model": "server.vote", "fields": {"post": 489, "type": 0, "author": 55}}, {"pk": 1843, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 180}}, {"pk": 1844, "model": "server.vote", "fields": {"post": 187, "type": 0, "author": 1}}, {"pk": 1845, "model": "server.vote", "fields": {"post": 209, "type": 0, "author": 1}}, {"pk": 1846, "model": "server.vote", "fields": {"post": 227, "type": 0, "author": 1}}, {"pk": 1847, "model": "server.vote", "fields": {"post": 408, "type": 0, "author": 116}}, {"pk": 1848, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 215}}, {"pk": 1849, "model": "server.vote", "fields": {"post": 140, "type": 0, "author": 88}}, {"pk": 1850, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 74}}, {"pk": 1851, "model": "server.vote", "fields": {"post": 358, "type": 0, "author": 74}}, {"pk": 1852, "model": "server.vote", "fields": {"post": 361, "type": 0, "author": 74}}, {"pk": 1853, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 418}}, {"pk": 1854, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 418}}, {"pk": 1855, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 418}}, {"pk": 1856, "model": "server.vote", "fields": {"post": 372, "type": 0, "author": 418}}, {"pk": 1857, "model": "server.vote", "fields": {"post": 364, "type": 0, "author": 418}}, {"pk": 1858, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 418}}, {"pk": 1859, "model": "server.vote", "fields": {"post": 366, "type": 0, "author": 418}}, {"pk": 1860, "model": "server.vote", "fields": {"post": 367, "type": 0, "author": 418}}, {"pk": 1861, "model": "server.vote", "fields": {"post": 370, "type": 0, "author": 418}}, {"pk": 1862, "model": "server.vote", "fields": {"post": 484, "type": 0, "author": 313}}, {"pk": 1863, "model": "server.vote", "fields": {"post": 354, "type": 0, "author": 37}}, {"pk": 1864, "model": "server.vote", "fields": {"post": 351, "type": 0, "author": 37}}, {"pk": 1865, "model": "server.vote", "fields": {"post": 352, "type": 0, "author": 37}}, {"pk": 1866, "model": "server.vote", "fields": {"post": 373, "type": 0, "author": 37}}, {"pk": 1867, "model": "server.vote", "fields": {"post": 432, "type": 0, "author": 37}}, {"pk": 1868, "model": "server.vote", "fields": {"post": 497, "type": 0, "author": 37}}, {"pk": 1869, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 221}}, {"pk": 1870, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 38}}, {"pk": 1871, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 38}}, {"pk": 1872, "model": "server.vote", "fields": {"post": 354, "type": 0, "author": 38}}, {"pk": 1873, "model": "server.vote", "fields": {"post": 152, "type": 0, "author": 140}}, {"pk": 1874, "model": "server.vote", "fields": {"post": 349, "type": 0, "author": 54}}, {"pk": 1875, "model": "server.vote", "fields": {"post": 408, "type": 0, "author": 324}}, {"pk": 1876, "model": "server.vote", "fields": {"post": 48, "type": 0, "author": 457}}, {"pk": 1877, "model": "server.vote", "fields": {"post": 350, "type": 0, "author": 230}}, {"pk": 1878, "model": "server.vote", "fields": {"post": 378, "type": 0, "author": 324}}, {"pk": 1879, "model": "server.vote", "fields": {"post": 221, "type": 0, "author": 273}}, {"pk": 1880, "model": "server.vote", "fields": {"post": 240, "type": 0, "author": 54}}, {"pk": 1881, "model": "server.vote", "fields": {"post": 143, "type": 0, "author": 54}}, {"pk": 1882, "model": "server.vote", "fields": {"post": 151, "type": 0, "author": 54}}, {"pk": 1883, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 247}}, {"pk": 1884, "model": "server.vote", "fields": {"post": 185, "type": 0, "author": 69}}, {"pk": 1885, "model": "server.vote", "fields": {"post": 141, "type": 0, "author": 29}}, {"pk": 1886, "model": "server.vote", "fields": {"post": 357, "type": 0, "author": 334}}, {"pk": 1887, "model": "server.vote", "fields": {"post": 464, "type": 0, "author": 313}}, {"pk": 1888, "model": "server.vote", "fields": {"post": 108, "type": 0, "author": 445}}, {"pk": 1889, "model": "server.vote", "fields": {"post": 277, "type": 0, "author": 451}}, {"pk": 1890, "model": "server.vote", "fields": {"post": 91, "type": 2, "author": 22}}, {"pk": 1891, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 221}}, {"pk": 1892, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 221}}, {"pk": 1893, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 221}}, {"pk": 1894, "model": "server.vote", "fields": {"post": 73, "type": 0, "author": 35}}, {"pk": 1895, "model": "server.vote", "fields": {"post": 463, "type": 0, "author": 225}}, {"pk": 1896, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 473}}, {"pk": 1897, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 341}}, {"pk": 1898, "model": "server.vote", "fields": {"post": 360, "type": 0, "author": 230}}, {"pk": 1899, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 445}}, {"pk": 1900, "model": "server.vote", "fields": {"post": 285, "type": 0, "author": 125}}, {"pk": 1901, "model": "server.vote", "fields": {"post": 319, "type": 0, "author": 125}}, {"pk": 1902, "model": "server.vote", "fields": {"post": 322, "type": 0, "author": 125}}, {"pk": 1903, "model": "server.vote", "fields": {"post": 36, "type": 0, "author": 141}}, {"pk": 1904, "model": "server.vote", "fields": {"post": 388, "type": 0, "author": 313}}, {"pk": 1905, "model": "server.vote", "fields": {"post": 195, "type": 0, "author": 313}}, {"pk": 1906, "model": "server.vote", "fields": {"post": 298, "type": 0, "author": 204}}, {"pk": 1907, "model": "server.vote", "fields": {"post": 195, "type": 0, "author": 215}}, {"pk": 1908, "model": "server.vote", "fields": {"post": 484, "type": 0, "author": 122}}, {"pk": 1909, "model": "server.vote", "fields": {"post": 122, "type": 0, "author": 121}}, {"pk": 1910, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 121}}, {"pk": 1911, "model": "server.vote", "fields": {"post": 493, "type": 0, "author": 1}}, {"pk": 1912, "model": "server.vote", "fields": {"post": 43, "type": 0, "author": 274}}, {"pk": 1913, "model": "server.vote", "fields": {"post": 195, "type": 0, "author": 221}}, {"pk": 1914, "model": "server.vote", "fields": {"post": 43, "type": 1, "author": 140}}, {"pk": 1915, "model": "server.vote", "fields": {"post": 34, "type": 1, "author": 70}}, {"pk": 1916, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 52}}, {"pk": 1917, "model": "server.vote", "fields": {"post": 309, "type": 0, "author": 1}}, {"pk": 1918, "model": "server.vote", "fields": {"post": 306, "type": 0, "author": 1}}, {"pk": 1919, "model": "server.vote", "fields": {"post": 50, "type": 0, "author": 204}}, {"pk": 1920, "model": "server.vote", "fields": {"post": 83, "type": 0, "author": 274}}, {"pk": 1921, "model": "server.vote", "fields": {"post": 353, "type": 0, "author": 418}}, {"pk": 1922, "model": "server.vote", "fields": {"post": 45, "type": 0, "author": 221}}, {"pk": 1923, "model": "server.vote", "fields": {"post": 41, "type": 0, "author": 121}}, {"pk": 1924, "model": "server.vote", "fields": {"post": 197, "type": 0, "author": 313}}, {"pk": 1925, "model": "server.vote", "fields": {"post": 130, "type": 0, "author": 313}}, {"pk": 1926, "model": "server.vote", "fields": {"post": 111, "type": 0, "author": 473}}, {"pk": 1927, "model": "server.vote", "fields": {"post": 137, "type": 0, "author": 159}}, {"pk": 1928, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 413}}, {"pk": 1929, "model": "server.vote", "fields": {"post": 201, "type": 0, "author": 86}}, {"pk": 1930, "model": "server.vote", "fields": {"post": 219, "type": 0, "author": 86}}, {"pk": 1931, "model": "server.vote", "fields": {"post": 204, "type": 0, "author": 86}}, {"pk": 1932, "model": "server.vote", "fields": {"post": 226, "type": 0, "author": 86}}, {"pk": 1933, "model": "server.vote", "fields": {"post": 242, "type": 0, "author": 86}}, {"pk": 1934, "model": "server.vote", "fields": {"post": 243, "type": 0, "author": 86}}, {"pk": 1935, "model": "server.vote", "fields": {"post": 435, "type": 0, "author": 85}}, {"pk": 1936, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 204}}, {"pk": 1937, "model": "server.vote", "fields": {"post": 406, "type": 0, "author": 233}}, {"pk": 1938, "model": "server.vote", "fields": {"post": 69, "type": 0, "author": 364}}, {"pk": 1939, "model": "server.vote", "fields": {"post": 465, "type": 0, "author": 324}}, {"pk": 1940, "model": "server.vote", "fields": {"post": 165, "type": 0, "author": 320}}, {"pk": 1941, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 215}}, {"pk": 1942, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 215}}, {"pk": 1943, "model": "server.vote", "fields": {"post": 372, "type": 0, "author": 215}}, {"pk": 1944, "model": "server.vote", "fields": {"post": 366, "type": 0, "author": 215}}, {"pk": 1945, "model": "server.vote", "fields": {"post": 367, "type": 0, "author": 215}}, {"pk": 1946, "model": "server.vote", "fields": {"post": 201, "type": 0, "author": 252}}, {"pk": 1947, "model": "server.vote", "fields": {"post": 488, "type": 0, "author": 198}}, {"pk": 1948, "model": "server.vote", "fields": {"post": 102, "type": 0, "author": 204}}, {"pk": 1949, "model": "server.vote", "fields": {"post": 102, "type": 0, "author": 225}}, {"pk": 1950, "model": "server.vote", "fields": {"post": 495, "type": 0, "author": 54}}, {"pk": 1951, "model": "server.vote", "fields": {"post": 494, "type": 0, "author": 54}}, {"pk": 1952, "model": "server.vote", "fields": {"post": 99, "type": 0, "author": 274}}, {"pk": 1953, "model": "server.vote", "fields": {"post": 498, "type": 0, "author": 234}}, {"pk": 1954, "model": "server.vote", "fields": {"post": 408, "type": 0, "author": 72}}, {"pk": 1955, "model": "server.vote", "fields": {"post": 499, "type": 0, "author": 320}}, {"pk": 1956, "model": "server.vote", "fields": {"post": 494, "type": 1, "author": 70}}, {"pk": 1957, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 451}}, {"pk": 1958, "model": "server.vote", "fields": {"post": 237, "type": 0, "author": 73}}, {"pk": 1959, "model": "server.vote", "fields": {"post": 479, "type": 0, "author": 204}}, {"pk": 1960, "model": "server.vote", "fields": {"post": 336, "type": 0, "author": 40}}, {"pk": 1961, "model": "server.vote", "fields": {"post": 170, "type": 0, "author": 113}}, {"pk": 1962, "model": "server.vote", "fields": {"post": 142, "type": 0, "author": 22}}, {"pk": 1963, "model": "server.vote", "fields": {"post": 142, "type": 0, "author": 312}}, {"pk": 1964, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 445}}, {"pk": 1965, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 312}}, {"pk": 1966, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 312}}, {"pk": 1967, "model": "server.vote", "fields": {"post": 372, "type": 0, "author": 312}}, {"pk": 1968, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 312}}, {"pk": 1969, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 312}}, {"pk": 1970, "model": "server.vote", "fields": {"post": 364, "type": 0, "author": 312}}, {"pk": 1971, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 230}}, {"pk": 1972, "model": "server.vote", "fields": {"post": 79, "type": 0, "author": 312}}, {"pk": 1973, "model": "server.vote", "fields": {"post": 95, "type": 0, "author": 312}}, {"pk": 1974, "model": "server.vote", "fields": {"post": 220, "type": 0, "author": 312}}, {"pk": 1975, "model": "server.vote", "fields": {"post": 134, "type": 0, "author": 312}}, {"pk": 1976, "model": "server.vote", "fields": {"post": 81, "type": 0, "author": 312}}, {"pk": 1977, "model": "server.vote", "fields": {"post": 80, "type": 0, "author": 312}}, {"pk": 1978, "model": "server.vote", "fields": {"post": 81, "type": 0, "author": 312}}, {"pk": 1979, "model": "server.vote", "fields": {"post": 218, "type": 0, "author": 312}}, {"pk": 1980, "model": "server.vote", "fields": {"post": 153, "type": 0, "author": 312}}, {"pk": 1981, "model": "server.vote", "fields": {"post": 107, "type": 0, "author": 312}}, {"pk": 1982, "model": "server.vote", "fields": {"post": 84, "type": 0, "author": 312}}, {"pk": 1983, "model": "server.vote", "fields": {"post": 82, "type": 0, "author": 312}}, {"pk": 1984, "model": "server.vote", "fields": {"post": 174, "type": 2, "author": 86}}, {"pk": 1985, "model": "server.vote", "fields": {"post": 364, "type": 0, "author": 492}}, {"pk": 1986, "model": "server.vote", "fields": {"post": 366, "type": 0, "author": 492}}, {"pk": 1987, "model": "server.vote", "fields": {"post": 370, "type": 0, "author": 492}}, {"pk": 1988, "model": "server.vote", "fields": {"post": 142, "type": 0, "author": 74}}, {"pk": 1989, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 312}}, {"pk": 1990, "model": "server.vote", "fields": {"post": 345, "type": 0, "author": 312}}, {"pk": 1991, "model": "server.vote", "fields": {"post": 344, "type": 0, "author": 312}}, {"pk": 1992, "model": "server.vote", "fields": {"post": 335, "type": 0, "author": 312}}, {"pk": 1993, "model": "server.vote", "fields": {"post": 76, "type": 0, "author": 312}}, {"pk": 1994, "model": "server.vote", "fields": {"post": 394, "type": 0, "author": 312}}, {"pk": 1995, "model": "server.vote", "fields": {"post": 431, "type": 0, "author": 312}}, {"pk": 1996, "model": "server.vote", "fields": {"post": 430, "type": 0, "author": 312}}, {"pk": 1997, "model": "server.vote", "fields": {"post": 58, "type": 0, "author": 312}}, {"pk": 1998, "model": "server.vote", "fields": {"post": 61, "type": 0, "author": 312}}, {"pk": 1999, "model": "server.vote", "fields": {"post": 68, "type": 0, "author": 312}}, {"pk": 2000, "model": "server.vote", "fields": {"post": 160, "type": 0, "author": 312}}, {"pk": 2001, "model": "server.vote", "fields": {"post": 145, "type": 0, "author": 29}}, {"pk": 2002, "model": "server.vote", "fields": {"post": 165, "type": 0, "author": 312}}, {"pk": 2003, "model": "server.vote", "fields": {"post": 429, "type": 0, "author": 418}}, {"pk": 2004, "model": "server.vote", "fields": {"post": 184, "type": 0, "author": 312}}, {"pk": 2005, "model": "server.vote", "fields": {"post": 192, "type": 0, "author": 312}}, {"pk": 2006, "model": "server.vote", "fields": {"post": 333, "type": 0, "author": 147}}, {"pk": 2007, "model": "server.vote", "fields": {"post": 499, "type": 0, "author": 147}}, {"pk": 2008, "model": "server.vote", "fields": {"post": 495, "type": 0, "author": 147}}, {"pk": 2009, "model": "server.vote", "fields": {"post": 138, "type": 0, "author": 147}}, {"pk": 2010, "model": "server.vote", "fields": {"post": 145, "type": 0, "author": 312}}, {"pk": 2011, "model": "server.vote", "fields": {"post": 131, "type": 2, "author": 22}}, {"pk": 2012, "model": "server.vote", "fields": {"post": 255, "type": 0, "author": 145}}, {"pk": 2013, "model": "server.vote", "fields": {"post": 389, "type": 0, "author": 374}}, {"pk": 2014, "model": "server.vote", "fields": {"post": 466, "type": 0, "author": 72}}, {"pk": 2015, "model": "server.vote", "fields": {"post": 398, "type": 0, "author": 244}}, {"pk": 2016, "model": "server.vote", "fields": {"post": 408, "type": 0, "author": 123}}, {"pk": 2017, "model": "server.vote", "fields": {"post": 398, "type": 0, "author": 123}}, {"pk": 2018, "model": "server.vote", "fields": {"post": 499, "type": 0, "author": 29}}, {"pk": 2019, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 418}}, {"pk": 2020, "model": "server.vote", "fields": {"post": 498, "type": 0, "author": 147}}, {"pk": 2021, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 35}}, {"pk": 2022, "model": "server.vote", "fields": {"post": 366, "type": 0, "author": 35}}, {"pk": 2023, "model": "server.vote", "fields": {"post": 203, "type": 0, "author": 313}}, {"pk": 2024, "model": "server.vote", "fields": {"post": 98, "type": 0, "author": 237}}, {"pk": 2025, "model": "server.vote", "fields": {"post": 354, "type": 0, "author": 155}}, {"pk": 2026, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 155}}, {"pk": 2027, "model": "server.vote", "fields": {"post": 368, "type": 0, "author": 155}}, {"pk": 2028, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 155}}, {"pk": 2029, "model": "server.vote", "fields": {"post": 372, "type": 0, "author": 155}}, {"pk": 2030, "model": "server.vote", "fields": {"post": 364, "type": 0, "author": 155}}, {"pk": 2031, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 155}}, {"pk": 2032, "model": "server.vote", "fields": {"post": 366, "type": 0, "author": 155}}, {"pk": 2033, "model": "server.vote", "fields": {"post": 370, "type": 0, "author": 155}}, {"pk": 2034, "model": "server.vote", "fields": {"post": 367, "type": 0, "author": 155}}, {"pk": 2035, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 237}}, {"pk": 2036, "model": "server.vote", "fields": {"post": 171, "type": 0, "author": 3}}, {"pk": 2037, "model": "server.vote", "fields": {"post": 19, "type": 0, "author": 3}}, {"pk": 2038, "model": "server.vote", "fields": {"post": 371, "type": 0, "author": 1}}, {"pk": 2039, "model": "server.vote", "fields": {"post": 372, "type": 0, "author": 1}}, {"pk": 2040, "model": "server.vote", "fields": {"post": 364, "type": 0, "author": 1}}, {"pk": 2041, "model": "server.vote", "fields": {"post": 396, "type": 0, "author": 1}}, {"pk": 2042, "model": "server.vote", "fields": {"post": 367, "type": 0, "author": 1}}, {"pk": 2043, "model": "server.vote", "fields": {"post": 403, "type": 0, "author": 155}}, {"pk": 2044, "model": "server.vote", "fields": {"post": 406, "type": 0, "author": 155}}, {"pk": 2045, "model": "server.vote", "fields": {"post": 440, "type": 0, "author": 155}}, {"pk": 2046, "model": "server.vote", "fields": {"post": 365, "type": 0, "author": 155}}, {"pk": 2047, "model": "server.vote", "fields": {"post": 362, "type": 0, "author": 155}}, {"pk": 2048, "model": "server.vote", "fields": {"post": 144, "type": 0, "author": 35}}, {"pk": 2049, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 313}}, {"pk": 2050, "model": "server.vote", "fields": {"post": 345, "type": 0, "author": 221}}, {"pk": 2051, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 123}}, {"pk": 2052, "model": "server.vote", "fields": {"post": 195, "type": 0, "author": 123}}, {"pk": 2053, "model": "server.vote", "fields": {"post": 36, "type": 0, "author": 54}}, {"pk": 2054, "model": "server.vote", "fields": {"post": 221, "type": 0, "author": 68}}, {"pk": 2055, "model": "server.vote", "fields": {"post": 132, "type": 0, "author": 341}}, {"pk": 2056, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 313}}, {"pk": 2057, "model": "server.vote", "fields": {"post": 426, "type": 0, "author": 215}}, {"pk": 2058, "model": "server.vote", "fields": {"post": 426, "type": 2, "author": 165}}, {"pk": 2059, "model": "server.vote", "fields": {"post": 22, "type": 0, "author": 237}}, {"pk": 2060, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 445}}, {"pk": 2061, "model": "server.vote", "fields": {"post": 124, "type": 0, "author": 445}}, {"pk": 2062, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 98}}, {"pk": 2063, "model": "server.vote", "fields": {"post": 191, "type": 0, "author": 215}}, {"pk": 2064, "model": "server.vote", "fields": {"post": 28, "type": 0, "author": 263}}, {"pk": 2065, "model": "server.vote", "fields": {"post": 80, "type": 0, "author": 339}}, {"pk": 2066, "model": "server.vote", "fields": {"post": 79, "type": 0, "author": 339}}, {"pk": 2067, "model": "server.vote", "fields": {"post": 320, "type": 0, "author": 263}}, {"pk": 2068, "model": "server.vote", "fields": {"post": 237, "type": 0, "author": 237}}, {"pk": 2069, "model": "server.vote", "fields": {"post": 84, "type": 0, "author": 86}}, {"pk": 2070, "model": "server.vote", "fields": {"post": 290, "type": 0, "author": 72}}, {"pk": 2071, "model": "server.vote", "fields": {"post": 459, "type": 0, "author": 497}}, {"pk": 2072, "model": "server.vote", "fields": {"post": 482, "type": 0, "author": 497}}, {"pk": 2073, "model": "server.vote", "fields": {"post": 67, "type": 0, "author": 67}}, {"pk": 2074, "model": "server.vote", "fields": {"post": 193, "type": 0, "author": 67}}, {"pk": 2075, "model": "server.vote", "fields": {"post": 495, "type": 0, "author": 418}}, {"pk": 2076, "model": "server.vote", "fields": {"post": 466, "type": 0, "author": 313}}, {"pk": 2077, "model": "server.vote", "fields": {"post": 437, "type": 0, "author": 35}}, {"pk": 2078, "model": "server.vote", "fields": {"post": 277, "type": 0, "author": 118}}, {"pk": 2079, "model": "server.vote", "fields": {"post": 231, "type": 0, "author": 114}}, {"pk": 2080, "model": "server.vote", "fields": {"post": 111, "type": 0, "author": 397}}, {"pk": 2081, "model": "server.vote", "fields": {"post": 463, "type": 0, "author": 263}}, {"pk": 2082, "model": "server.vote", "fields": {"post": 484, "type": 0, "author": 98}}, {"pk": 2083, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 186}}, {"pk": 2084, "model": "server.vote", "fields": {"post": 181, "type": 0, "author": 186}}, {"pk": 2085, "model": "server.vote", "fields": {"post": 304, "type": 0, "author": 192}}, {"pk": 2086, "model": "server.vote", "fields": {"post": 305, "type": 0, "author": 192}}, {"pk": 2087, "model": "server.vote", "fields": {"post": 86, "type": 0, "author": 237}}, {"pk": 2088, "model": "server.vote", "fields": {"post": 320, "type": 0, "author": 237}}, {"pk": 2089, "model": "server.vote", "fields": {"post": 68, "type": 0, "author": 71}}, {"pk": 2090, "model": "server.vote", "fields": {"post": 62, "type": 0, "author": 419}}, {"pk": 2091, "model": "server.vote", "fields": {"post": 362, "type": 0, "author": 132}}, {"pk": 2092, "model": "server.vote", "fields": {"post": 362, "type": 0, "author": 132}}, {"pk": 2093, "model": "server.vote", "fields": {"post": 187, "type": 0, "author": 86}}, {"pk": 2094, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 186}}, {"pk": 2095, "model": "server.vote", "fields": {"post": 296, "type": 0, "author": 54}}, {"pk": 2096, "model": "server.vote", "fields": {"post": 383, "type": 0, "author": 54}}, {"pk": 2097, "model": "server.vote", "fields": {"post": 137, "type": 0, "author": 123}}, {"pk": 2098, "model": "server.vote", "fields": {"post": 89, "type": 0, "author": 141}}, {"pk": 2099, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 273}}, {"pk": 2100, "model": "server.vote", "fields": {"post": 363, "type": 0, "author": 57}}, {"pk": 2101, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 57}}, {"pk": 2102, "model": "server.vote", "fields": {"post": 274, "type": 0, "author": 263}}, {"pk": 2103, "model": "server.vote", "fields": {"post": 34, "type": 0, "author": 52}}, {"pk": 2104, "model": "server.vote", "fields": {"post": 437, "type": 0, "author": 22}}, {"pk": 2105, "model": "server.vote", "fields": {"post": 378, "type": 0, "author": 22}}, {"pk": 2106, "model": "server.vote", "fields": {"post": 414, "type": 0, "author": 22}}, {"pk": 2107, "model": "server.vote", "fields": {"post": 89, "type": 0, "author": 22}}, {"pk": 2108, "model": "server.vote", "fields": {"post": 88, "type": 0, "author": 86}}, {"pk": 2109, "model": "server.vote", "fields": {"post": 175, "type": 0, "author": 263}}, {"pk": 2110, "model": "server.vote", "fields": {"post": 195, "type": 0, "author": 263}}, {"pk": 2111, "model": "server.vote", "fields": {"post": 117, "type": 0, "author": 237}}, {"pk": 2112, "model": "server.vote", "fields": {"post": 90, "type": 1, "author": 145}}, {"pk": 2113, "model": "server.vote", "fields": {"post": 96, "type": 0, "author": 145}}, {"pk": 2114, "model": "server.vote", "fields": {"post": 99, "type": 0, "author": 252}}, {"pk": 2115, "model": "server.vote", "fields": {"post": 100, "type": 0, "author": 252}}, {"pk": 2116, "model": "server.vote", "fields": {"post": 221, "type": 0, "author": 497}}, {"pk": 2117, "model": "server.vote", "fields": {"post": 388, "type": 0, "author": 257}}, {"pk": 2118, "model": "server.vote", "fields": {"post": 472, "type": 0, "author": 313}}, {"pk": 2119, "model": "server.vote", "fields": {"post": 399, "type": 0, "author": 313}}, {"pk": 2120, "model": "server.vote", "fields": {"post": 397, "type": 0, "author": 313}}, {"pk": 2121, "model": "server.vote", "fields": {"post": 390, "type": 0, "author": 313}}, {"pk": 2122, "model": "server.vote", "fields": {"post": 389, "type": 0, "author": 313}}, {"pk": 2123, "model": "server.vote", "fields": {"post": 395, "type": 0, "author": 223}}, {"pk": 2124, "model": "server.vote", "fields": {"post": 112, "type": 0, "author": 123}}, {"pk": 2125, "model": "server.vote", "fields": {"post": 5, "type": 0, "author": 22}}, {"pk": 2126, "model": "server.vote", "fields": {"post": 79, "type": 0, "author": 223}}, {"pk": 2127, "model": "server.vote", "fields": {"post": 95, "type": 0, "author": 366}}, {"pk": 2128, "model": "server.vote", "fields": {"post": 511, "type": 0, "author": 22}}, {"pk": 2129, "model": "server.vote", "fields": {"post": 543, "type": 0, "author": 22}}, {"pk": 2130, "model": "server.vote", "fields": {"post": 560, "type": 0, "author": 29}}, {"pk": 2131, "model": "server.vote", "fields": {"post": 541, "type": 0, "author": 22}}, {"pk": 2132, "model": "server.vote", "fields": {"post": 537, "type": 0, "author": 64}}, {"pk": 2133, "model": "server.vote", "fields": {"post": 569, "type": 0, "author": 29}}, {"pk": 2134, "model": "server.vote", "fields": {"post": 586, "type": 0, "author": 67}}, {"pk": 2135, "model": "server.vote", "fields": {"post": 648, "type": 0, "author": 89}}, {"pk": 2136, "model": "server.vote", "fields": {"post": 651, "type": 0, "author": 37}}, {"pk": 2137, "model": "server.vote", "fields": {"post": 651, "type": 0, "author": 58}}, {"pk": 2138, "model": "server.vote", "fields": {"post": 660, "type": 0, "author": 22}}, {"pk": 2139, "model": "server.vote", "fields": {"post": 677, "type": 0, "author": 29}}, {"pk": 2140, "model": "server.vote", "fields": {"post": 684, "type": 0, "author": 29}}, {"pk": 2141, "model": "server.vote", "fields": {"post": 674, "type": 0, "author": 30}}, {"pk": 2142, "model": "server.vote", "fields": {"post": 696, "type": 0, "author": 30}}, {"pk": 2143, "model": "server.vote", "fields": {"post": 686, "type": 0, "author": 29}}, {"pk": 2144, "model": "server.vote", "fields": {"post": 703, "type": 0, "author": 29}}, {"pk": 2145, "model": "server.vote", "fields": {"post": 704, "type": 0, "author": 30}}, {"pk": 2146, "model": "server.vote", "fields": {"post": 702, "type": 0, "author": 25}}, {"pk": 2147, "model": "server.vote", "fields": {"post": 708, "type": 0, "author": 30}}, {"pk": 2148, "model": "server.vote", "fields": {"post": 716, "type": 0, "author": 29}}, {"pk": 2149, "model": "server.vote", "fields": {"post": 707, "type": 0, "author": 29}}, {"pk": 2150, "model": "server.vote", "fields": {"post": 724, "type": 0, "author": 25}}, {"pk": 2151, "model": "server.vote", "fields": {"post": 721, "type": 0, "author": 25}}, {"pk": 2152, "model": "server.vote", "fields": {"post": 724, "type": 0, "author": 70}}, {"pk": 2153, "model": "server.vote", "fields": {"post": 727, "type": 0, "author": 141}}, {"pk": 2154, "model": "server.vote", "fields": {"post": 720, "type": 0, "author": 29}}, {"pk": 2155, "model": "server.vote", "fields": {"post": 724, "type": 0, "author": 29}}, {"pk": 2156, "model": "server.vote", "fields": {"post": 741, "type": 0, "author": 88}}, {"pk": 2157, "model": "server.vote", "fields": {"post": 741, "type": 0, "author": 141}}, {"pk": 2158, "model": "server.vote", "fields": {"post": 749, "type": 0, "author": 54}}, {"pk": 2159, "model": "server.vote", "fields": {"post": 723, "type": 0, "author": 30}}, {"pk": 2160, "model": "server.vote", "fields": {"post": 749, "type": 0, "author": 1}}, {"pk": 2161, "model": "server.vote", "fields": {"post": 592, "type": 0, "author": 29}}, {"pk": 2162, "model": "server.vote", "fields": {"post": 753, "type": 0, "author": 22}}, {"pk": 2163, "model": "server.vote", "fields": {"post": 754, "type": 0, "author": 22}}, {"pk": 2164, "model": "server.vote", "fields": {"post": 769, "type": 0, "author": 1}}, {"pk": 2165, "model": "server.vote", "fields": {"post": 768, "type": 0, "author": 29}}, {"pk": 2166, "model": "server.vote", "fields": {"post": 736, "type": 0, "author": 144}}, {"pk": 2167, "model": "server.vote", "fields": {"post": 774, "type": 0, "author": 35}}, {"pk": 2168, "model": "server.vote", "fields": {"post": 775, "type": 0, "author": 35}}, {"pk": 2169, "model": "server.vote", "fields": {"post": 775, "type": 0, "author": 29}}, {"pk": 2170, "model": "server.vote", "fields": {"post": 774, "type": 0, "author": 29}}, {"pk": 2171, "model": "server.vote", "fields": {"post": 813, "type": 0, "author": 22}}, {"pk": 2172, "model": "server.vote", "fields": {"post": 816, "type": 0, "author": 22}}, {"pk": 2173, "model": "server.vote", "fields": {"post": 814, "type": 0, "author": 88}}, {"pk": 2174, "model": "server.vote", "fields": {"post": 769, "type": 0, "author": 52}}, {"pk": 2175, "model": "server.vote", "fields": {"post": 814, "type": 0, "author": 29}}, {"pk": 2176, "model": "server.vote", "fields": {"post": 813, "type": 0, "author": 70}}, {"pk": 2177, "model": "server.vote", "fields": {"post": 774, "type": 0, "author": 52}}, {"pk": 2178, "model": "server.vote", "fields": {"post": 826, "type": 0, "author": 29}}, {"pk": 2179, "model": "server.vote", "fields": {"post": 817, "type": 0, "author": 29}}, {"pk": 2180, "model": "server.vote", "fields": {"post": 841, "type": 0, "author": 29}}, {"pk": 2181, "model": "server.vote", "fields": {"post": 813, "type": 0, "author": 67}}, {"pk": 2182, "model": "server.vote", "fields": {"post": 856, "type": 0, "author": 54}}, {"pk": 2183, "model": "server.vote", "fields": {"post": 905, "type": 0, "author": 29}}, {"pk": 2184, "model": "server.vote", "fields": {"post": 873, "type": 0, "author": 86}}, {"pk": 2185, "model": "server.vote", "fields": {"post": 874, "type": 0, "author": 86}}, {"pk": 2186, "model": "server.vote", "fields": {"post": 902, "type": 0, "author": 37}}, {"pk": 2187, "model": "server.vote", "fields": {"post": 823, "type": 0, "author": 25}}, {"pk": 2188, "model": "server.vote", "fields": {"post": 913, "type": 0, "author": 178}}, {"pk": 2189, "model": "server.vote", "fields": {"post": 905, "type": 0, "author": 178}}, {"pk": 2190, "model": "server.vote", "fields": {"post": 914, "type": 0, "author": 25}}, {"pk": 2191, "model": "server.vote", "fields": {"post": 933, "type": 0, "author": 29}}, {"pk": 2192, "model": "server.vote", "fields": {"post": 936, "type": 0, "author": 22}}, {"pk": 2193, "model": "server.vote", "fields": {"post": 933, "type": 0, "author": 58}}, {"pk": 2194, "model": "server.vote", "fields": {"post": 950, "type": 0, "author": 58}}, {"pk": 2195, "model": "server.vote", "fields": {"post": 953, "type": 0, "author": 168}}, {"pk": 2196, "model": "server.vote", "fields": {"post": 867, "type": 0, "author": 29}}, {"pk": 2197, "model": "server.vote", "fields": {"post": 919, "type": 0, "author": 178}}, {"pk": 2198, "model": "server.vote", "fields": {"post": 953, "type": 0, "author": 54}}, {"pk": 2199, "model": "server.vote", "fields": {"post": 612, "type": 0, "author": 22}}, {"pk": 2200, "model": "server.vote", "fields": {"post": 774, "type": 0, "author": 54}}, {"pk": 2201, "model": "server.vote", "fields": {"post": 527, "type": 0, "author": 215}}, {"pk": 2202, "model": "server.vote", "fields": {"post": 957, "type": 0, "author": 67}}, {"pk": 2203, "model": "server.vote", "fields": {"post": 519, "type": 0, "author": 215}}, {"pk": 2204, "model": "server.vote", "fields": {"post": 502, "type": 0, "author": 13}}, {"pk": 2205, "model": "server.vote", "fields": {"post": 699, "type": 0, "author": 86}}, {"pk": 2206, "model": "server.vote", "fields": {"post": 571, "type": 0, "author": 270}}, {"pk": 2207, "model": "server.vote", "fields": {"post": 902, "type": 0, "author": 86}}, {"pk": 2208, "model": "server.vote", "fields": {"post": 856, "type": 0, "author": 85}}, {"pk": 2209, "model": "server.vote", "fields": {"post": 926, "type": 0, "author": 35}}, {"pk": 2210, "model": "server.vote", "fields": {"post": 603, "type": 0, "author": 112}}, {"pk": 2211, "model": "server.vote", "fields": {"post": 832, "type": 0, "author": 22}}, {"pk": 2212, "model": "server.vote", "fields": {"post": 877, "type": 0, "author": 22}}, {"pk": 2213, "model": "server.vote", "fields": {"post": 952, "type": 0, "author": 22}}, {"pk": 2214, "model": "server.vote", "fields": {"post": 877, "type": 0, "author": 299}}, {"pk": 2215, "model": "server.vote", "fields": {"post": 813, "type": 0, "author": 299}}, {"pk": 2216, "model": "server.vote", "fields": {"post": 953, "type": 0, "author": 414}}, {"pk": 2217, "model": "server.vote", "fields": {"post": 923, "type": 0, "author": 341}}, {"pk": 2218, "model": "server.vote", "fields": {"post": 775, "type": 0, "author": 418}}, {"pk": 2219, "model": "server.vote", "fields": {"post": 868, "type": 0, "author": 492}}, {"pk": 2220, "model": "server.vote", "fields": {"post": 628, "type": 0, "author": 86}}, {"pk": 2221, "model": "server.vote", "fields": {"post": 934, "type": 0, "author": 86}}, {"pk": 2222, "model": "server.vote", "fields": {"post": 752, "type": 0, "author": 71}}, {"pk": 1, "model": "server.badge", "fields": {"count": 246, "name": "Teacher", "secret": false, "unique": true, "type": 0, "description": "Answered first question with at least one up vote"}}, {"pk": 2, "model": "server.badge", "fields": {"count": 209, "name": "Student", "secret": false, "unique": true, "type": 0, "description": "Asked first question with at least one up vote"}}, {"pk": 3, "model": "server.badge", "fields": {"count": 138, "name": "Editor", "secret": false, "unique": true, "type": 0, "description": "First edit"}}, {"pk": 4, "model": "server.badge", "fields": {"count": 11, "name": "Cleanup", "secret": false, "unique": true, "type": 0, "description": "First rollback"}}, {"pk": 5, "model": "server.badge", "fields": {"count": 59, "name": "Organizer", "secret": false, "unique": true, "type": 0, "description": "First retag"}}, {"pk": 6, "model": "server.badge", "fields": {"count": 249, "name": "Supporter", "secret": false, "unique": true, "type": 0, "description": "First up vote"}}, {"pk": 7, "model": "server.badge", "fields": {"count": 85, "name": "Critic", "secret": false, "unique": true, "type": 0, "description": "First down vote"}}, {"pk": 8, "model": "server.badge", "fields": {"count": 17, "name": "Citizen Patrol", "secret": false, "unique": true, "type": 0, "description": "First flagged post"}}, {"pk": 9, "model": "server.badge", "fields": {"count": 90, "name": "Autobiographer", "secret": false, "unique": true, "type": 0, "description": "Completed all user profile fields"}}, {"pk": 10, "model": "server.badge", "fields": {"count": 131, "name": "Scholar", "secret": false, "unique": true, "type": 0, "description": "First accepted answer on your own question"}}, {"pk": 11, "model": "server.badge", "fields": {"count": 27, "name": "Taxonomist", "secret": false, "unique": true, "type": 1, "description": "Created a tag used by 50 questions"}}, {"pk": 12, "model": "server.badge", "fields": {"count": 2, "name": "Strunk & White", "secret": false, "unique": true, "type": 1, "description": "Edited 100 entries"}}, {"pk": 13, "model": "server.badge", "fields": {"count": 112, "name": "Yearling", "secret": false, "unique": false, "type": 1, "description": "Active member for a year, earning at least 200 reputation"}}, {"pk": 14, "model": "server.badge", "fields": {"count": 27, "name": "Self-Learner", "secret": false, "unique": true, "type": 0, "description": "Answered your own question with at least 3 up votes"}}, {"pk": 15, "model": "server.badge", "fields": {"count": 0, "name": "Generalist", "secret": true, "unique": false, "type": 1, "description": "Active in many different tags"}}, {"pk": 16, "model": "server.badge", "fields": {"count": 23, "name": "Necromancer", "secret": false, "unique": false, "type": 1, "description": "Answered a question more than 60 days later with at least 5 votes"}}, {"pk": 17, "model": "server.badge", "fields": {"count": 1, "name": "Guru", "secret": false, "unique": false, "type": 1, "description": "Accepted answer and voted up 40 times"}}, {"pk": 18, "model": "server.badge", "fields": {"count": 44, "name": "Enlightened", "secret": false, "unique": false, "type": 1, "description": "First answer was accepted with at least 10 up votes"}}, {"pk": 19, "model": "server.badge", "fields": {"count": 109, "name": "Nice Question", "secret": false, "unique": false, "type": 0, "description": "Question voted up 10 times"}}, {"pk": 20, "model": "server.badge", "fields": {"count": 8, "name": "Good Question", "secret": false, "unique": false, "type": 1, "description": "Question voted up 25 times"}}, {"pk": 21, "model": "server.badge", "fields": {"count": 0, "name": "Great Question", "secret": false, "unique": false, "type": 2, "description": "Question voted up 100 times"}}, {"pk": 22, "model": "server.badge", "fields": {"count": 221, "name": "Nice Answer", "secret": false, "unique": false, "type": 0, "description": "Answer voted up 10 times"}}, {"pk": 23, "model": "server.badge", "fields": {"count": 5, "name": "Good Answer", "secret": false, "unique": false, "type": 1, "description": "Answer voted up 25 times"}}, {"pk": 24, "model": "server.badge", "fields": {"count": 0, "name": "Great Answer", "secret": false, "unique": false, "type": 2, "description": "Answer voted up 100 times"}}, {"pk": 25, "model": "server.badge", "fields": {"count": 119, "name": "Popular Question", "secret": false, "unique": false, "type": 0, "description": "Asked a question with 1,000 views"}}, {"pk": 26, "model": "server.badge", "fields": {"count": 26, "name": "Notable Question", "secret": false, "unique": false, "type": 1, "description": "Asked a question with 2,500 views"}}, {"pk": 27, "model": "server.badge", "fields": {"count": 1, "name": "Famous Question", "secret": false, "unique": false, "type": 2, "description": "Asked a question with 10,000 views"}}, {"pk": 28, "model": "server.badge", "fields": {"count": 0, "name": "Hacker", "secret": true, "unique": true, "type": 1, "description": "Contributed to Stack Overflow in an unusual way"}}, {"pk": 29, "model": "server.badge", "fields": {"count": 88, "name": "Commentator", "secret": false, "unique": true, "type": 0, "description": "Left 10 comments"}}, {"pk": 30, "model": "server.badge", "fields": {"count": 22, "name": "Civic Duty", "secret": false, "unique": true, "type": 1, "description": "Voted 300 times"}}, {"pk": 31, "model": "server.badge", "fields": {"count": 4, "name": "Favorite Question", "secret": false, "unique": false, "type": 1, "description": "Question favorited by 25 users"}}, {"pk": 32, "model": "server.badge", "fields": {"count": 0, "name": "Stellar Question", "secret": false, "unique": false, "type": 2, "description": "Question favorited by 100 users"}}, {"pk": 33, "model": "server.badge", "fields": {"count": 4, "name": "Disciplined", "secret": false, "unique": true, "type": 0, "description": "Deleted own post with score of 3 or higher"}}, {"pk": 34, "model": "server.badge", "fields": {"count": 0, "name": "Peer Pressure", "secret": false, "unique": true, "type": 0, "description": "Deleted own post with score of -3 or lower"}}, {"pk": 35, "model": "server.badge", "fields": {"count": 0, "name": "Populist", "secret": false, "unique": false, "type": 2, "description": "Provided an answer that outscored an accepted answer with 10 votes by 2x"}}, {"pk": 36, "model": "server.badge", "fields": {"count": 1, "name": "Tumbleweed", "secret": true, "unique": true, "type": 0, "description": "Asked a question with no answers, no comments, and low views for a week"}}, {"pk": 37, "model": "server.badge", "fields": {"count": 44, "name": "Enthusiast", "secret": false, "unique": true, "type": 1, "description": "Visited the site each day for 30 days"}}, {"pk": 38, "model": "server.badge", "fields": {"count": 19, "name": "Fanatic", "secret": false, "unique": true, "type": 2, "description": "Visited the site each day for 100 days"}}, {"pk": 39, "model": "server.badge", "fields": {"count": 0, "name": "Pundit", "secret": false, "unique": true, "type": 1, "description": "Left 10 comments with score of 10 or more"}}, {"pk": 40, "model": "server.badge", "fields": {"count": 0, "name": "Reversal", "secret": false, "unique": false, "type": 2, "description": "Provided answer of +20 score to a question of -5 score"}}, {"pk": 41, "model": "server.badge", "fields": {"count": 3, "name": "Mortarboard", "secret": false, "unique": true, "type": 0, "description": "Hit the daily reputation cap for the first time"}}, {"pk": 42, "model": "server.badge", "fields": {"count": 0, "name": "Epic", "secret": false, "unique": true, "type": 1, "description": "Hit the daily reputation cap on 50 days"}}, {"pk": 43, "model": "server.badge", "fields": {"count": 0, "name": "Legendary", "secret": false, "unique": true, "type": 2, "description": "Hit the daily reputation cap on 150 days"}}, {"pk": 1, "model": "server.award", "fields": {"date": "2009-09-30 15:19:15", "badge": 3, "user": 1}}, {"pk": 2, "model": "server.award", "fields": {"date": "2009-09-30 19:05:41", "badge": 1, "user": 4}}, {"pk": 3, "model": "server.award", "fields": {"date": "2009-09-30 19:05:41", "badge": 2, "user": 2}}, {"pk": 4, "model": "server.award", "fields": {"date": "2009-09-30 19:05:41", "badge": 6, "user": 1}}, {"pk": 5, "model": "server.award", "fields": {"date": "2009-09-30 19:45:41", "badge": 1, "user": 5}}, {"pk": 6, "model": "server.award", "fields": {"date": "2009-10-05 16:05:41", "badge": 1, "user": 1}}, {"pk": 7, "model": "server.award", "fields": {"date": "2009-10-05 16:05:41", "badge": 6, "user": 9}}, {"pk": 8, "model": "server.award", "fields": {"date": "2009-10-05 16:05:41", "badge": 10, "user": 9}}, {"pk": 9, "model": "server.award", "fields": {"date": "2009-10-05 16:15:41", "badge": 3, "user": 9}}, {"pk": 10, "model": "server.award", "fields": {"date": "2009-10-06 12:50:43", "badge": 2, "user": 9}}, {"pk": 11, "model": "server.award", "fields": {"date": "2009-10-06 20:10:44", "badge": 2, "user": 11}}, {"pk": 12, "model": "server.award", "fields": {"date": "2009-10-06 22:15:44", "badge": 1, "user": 12}}, {"pk": 13, "model": "server.award", "fields": {"date": "2009-10-07 14:16:16", "badge": 36, "user": 1}}, {"pk": 14, "model": "server.award", "fields": {"date": "2009-10-07 16:46:17", "badge": 2, "user": 1}}, {"pk": 15, "model": "server.award", "fields": {"date": "2009-10-09 17:05:57", "badge": 1, "user": 13}}, {"pk": 16, "model": "server.award", "fields": {"date": "2009-10-09 17:05:57", "badge": 10, "user": 1}}, {"pk": 17, "model": "server.award", "fields": {"date": "2009-10-13 15:07:39", "badge": 5, "user": 1}}, {"pk": 18, "model": "server.award", "fields": {"date": "2009-10-13 16:52:21", "badge": 6, "user": 4}}, {"pk": 19, "model": "server.award", "fields": {"date": "2009-12-01 20:59:37", "badge": 1, "user": 17}}, {"pk": 20, "model": "server.award", "fields": {"date": "2009-12-01 20:59:37", "badge": 2, "user": 13}}, {"pk": 21, "model": "server.award", "fields": {"date": "2009-12-01 20:59:37", "badge": 6, "user": 13}}, {"pk": 22, "model": "server.award", "fields": {"date": "2009-12-09 21:20:50", "badge": 1, "user": 18}}, {"pk": 23, "model": "server.award", "fields": {"date": "2010-01-13 22:08:19", "badge": 2, "user": 19}}, {"pk": 24, "model": "server.award", "fields": {"date": "2010-01-15 08:50:57", "badge": 10, "user": 19}}, {"pk": 25, "model": "server.award", "fields": {"date": "2010-01-22 15:51:05", "badge": 1, "user": 19}}, {"pk": 26, "model": "server.award", "fields": {"date": "2010-01-26 20:35:54", "badge": 2, "user": 22}}, {"pk": 27, "model": "server.award", "fields": {"date": "2010-01-26 20:50:52", "badge": 2, "user": 3}}, {"pk": 28, "model": "server.award", "fields": {"date": "2010-01-27 14:21:01", "badge": 1, "user": 22}}, {"pk": 29, "model": "server.award", "fields": {"date": "2010-01-28 16:25:01", "badge": 1, "user": 9}}, {"pk": 30, "model": "server.award", "fields": {"date": "2010-01-28 16:25:02", "badge": 1, "user": 24}}, {"pk": 31, "model": "server.award", "fields": {"date": "2010-01-28 16:25:02", "badge": 6, "user": 22}}, {"pk": 32, "model": "server.award", "fields": {"date": "2010-01-29 10:24:51", "badge": 1, "user": 3}}, {"pk": 33, "model": "server.award", "fields": {"date": "2010-01-29 14:20:52", "badge": 10, "user": 22}}, {"pk": 34, "model": "server.award", "fields": {"date": "2010-01-29 16:20:56", "badge": 2, "user": 15}}, {"pk": 35, "model": "server.award", "fields": {"date": "2010-01-31 03:20:52", "badge": 6, "user": 3}}, {"pk": 36, "model": "server.award", "fields": {"date": "2010-01-31 03:20:52", "badge": 10, "user": 3}}, {"pk": 37, "model": "server.award", "fields": {"date": "2010-02-13 18:06:00", "badge": 1, "user": 25}}, {"pk": 38, "model": "server.award", "fields": {"date": "2010-02-16 19:35:59", "badge": 10, "user": 13}}, {"pk": 39, "model": "server.award", "fields": {"date": "2010-02-20 17:06:05", "badge": 1, "user": 26}}, {"pk": 40, "model": "server.award", "fields": {"date": "2010-02-20 17:06:05", "badge": 1, "user": 27}}, {"pk": 41, "model": "server.award", "fields": {"date": "2010-02-20 17:06:05", "badge": 2, "user": 26}}, {"pk": 42, "model": "server.award", "fields": {"date": "2010-02-25 18:05:51", "badge": 1, "user": 30}}, {"pk": 43, "model": "server.award", "fields": {"date": "2010-02-25 18:35:56", "badge": 1, "user": 29}}, {"pk": 44, "model": "server.award", "fields": {"date": "2010-02-25 18:35:56", "badge": 9, "user": 31}}, {"pk": 45, "model": "server.award", "fields": {"date": "2010-02-25 18:35:57", "badge": 29, "user": 1}}, {"pk": 46, "model": "server.award", "fields": {"date": "2010-02-25 22:38:48", "badge": 1, "user": 32}}, {"pk": 47, "model": "server.award", "fields": {"date": "2010-02-25 22:38:48", "badge": 1, "user": 34}}, {"pk": 48, "model": "server.award", "fields": {"date": "2010-02-25 22:38:48", "badge": 6, "user": 32}}, {"pk": 49, "model": "server.award", "fields": {"date": "2010-02-25 22:38:48", "badge": 7, "user": 1}}, {"pk": 50, "model": "server.award", "fields": {"date": "2010-02-25 23:50:54", "badge": 6, "user": 30}}, {"pk": 51, "model": "server.award", "fields": {"date": "2010-02-26 00:05:52", "badge": 9, "user": 30}}, {"pk": 52, "model": "server.award", "fields": {"date": "2010-02-26 09:36:25", "badge": 9, "user": 37}}, {"pk": 53, "model": "server.award", "fields": {"date": "2010-02-26 10:05:58", "badge": 1, "user": 37}}, {"pk": 54, "model": "server.award", "fields": {"date": "2010-02-26 10:05:58", "badge": 3, "user": 37}}, {"pk": 55, "model": "server.award", "fields": {"date": "2010-02-26 10:51:03", "badge": 6, "user": 37}}, {"pk": 56, "model": "server.award", "fields": {"date": "2010-02-26 11:36:19", "badge": 6, "user": 29}}, {"pk": 57, "model": "server.award", "fields": {"date": "2010-02-26 13:23:45", "badge": 1, "user": 39}}, {"pk": 58, "model": "server.award", "fields": {"date": "2010-02-26 13:23:45", "badge": 2, "user": 29}}, {"pk": 59, "model": "server.award", "fields": {"date": "2010-02-26 15:07:43", "badge": 1, "user": 41}}, {"pk": 60, "model": "server.award", "fields": {"date": "2010-02-26 15:07:43", "badge": 9, "user": 22}}, {"pk": 61, "model": "server.award", "fields": {"date": "2010-02-26 15:07:43", "badge": 10, "user": 29}}, {"pk": 62, "model": "server.award", "fields": {"date": "2010-02-26 16:36:08", "badge": 2, "user": 43}}, {"pk": 63, "model": "server.award", "fields": {"date": "2010-02-26 17:20:53", "badge": 1, "user": 46}}, {"pk": 64, "model": "server.award", "fields": {"date": "2010-02-26 18:05:54", "badge": 1, "user": 6}}, {"pk": 65, "model": "server.award", "fields": {"date": "2010-02-26 20:35:55", "badge": 9, "user": 52}}, {"pk": 66, "model": "server.award", "fields": {"date": "2010-02-26 22:39:00", "badge": 1, "user": 52}}, {"pk": 67, "model": "server.award", "fields": {"date": "2010-02-27 10:05:55", "badge": 1, "user": 23}}, {"pk": 68, "model": "server.award", "fields": {"date": "2010-02-27 10:05:55", "badge": 3, "user": 22}}, {"pk": 69, "model": "server.award", "fields": {"date": "2010-03-01 01:05:51", "badge": 1, "user": 54}}, {"pk": 70, "model": "server.award", "fields": {"date": "2010-03-01 15:07:52", "badge": 1, "user": 38}}, {"pk": 71, "model": "server.award", "fields": {"date": "2010-03-01 15:07:52", "badge": 1, "user": 44}}, {"pk": 72, "model": "server.award", "fields": {"date": "2010-03-01 18:36:14", "badge": 1, "user": 58}}, {"pk": 73, "model": "server.award", "fields": {"date": "2010-03-01 18:36:14", "badge": 9, "user": 58}}, {"pk": 74, "model": "server.award", "fields": {"date": "2010-03-01 18:36:14", "badge": 29, "user": 22}}, {"pk": 75, "model": "server.award", "fields": {"date": "2010-03-02 07:35:59", "badge": 1, "user": 60}}, {"pk": 76, "model": "server.award", "fields": {"date": "2010-03-02 10:20:49", "badge": 6, "user": 54}}, {"pk": 77, "model": "server.award", "fields": {"date": "2010-03-02 11:05:51", "badge": 1, "user": 61}}, {"pk": 78, "model": "server.award", "fields": {"date": "2010-03-02 11:20:49", "badge": 3, "user": 61}}, {"pk": 79, "model": "server.award", "fields": {"date": "2010-03-02 12:20:52", "badge": 2, "user": 61}}, {"pk": 80, "model": "server.award", "fields": {"date": "2010-03-02 12:35:50", "badge": 6, "user": 61}}, {"pk": 81, "model": "server.award", "fields": {"date": "2010-03-02 17:50:51", "badge": 5, "user": 22}}, {"pk": 82, "model": "server.award", "fields": {"date": "2010-03-02 18:20:49", "badge": 6, "user": 44}}, {"pk": 83, "model": "server.award", "fields": {"date": "2010-03-02 18:35:51", "badge": 6, "user": 52}}, {"pk": 84, "model": "server.award", "fields": {"date": "2010-03-02 19:50:57", "badge": 6, "user": 43}}, {"pk": 85, "model": "server.award", "fields": {"date": "2010-03-02 19:50:57", "badge": 10, "user": 43}}, {"pk": 86, "model": "server.award", "fields": {"date": "2010-03-03 11:36:57", "badge": 7, "user": 22}}, {"pk": 87, "model": "server.award", "fields": {"date": "2010-03-03 14:09:13", "badge": 5, "user": 58}}, {"pk": 88, "model": "server.award", "fields": {"date": "2010-03-03 15:21:05", "badge": 6, "user": 39}}, {"pk": 89, "model": "server.award", "fields": {"date": "2010-03-03 15:21:05", "badge": 6, "user": 58}}, {"pk": 90, "model": "server.award", "fields": {"date": "2010-03-03 17:20:53", "badge": 10, "user": 61}}, {"pk": 91, "model": "server.award", "fields": {"date": "2010-03-03 17:35:56", "badge": 1, "user": 63}}, {"pk": 92, "model": "server.award", "fields": {"date": "2010-03-03 22:38:59", "badge": 1, "user": 64}}, {"pk": 93, "model": "server.award", "fields": {"date": "2010-03-04 04:05:54", "badge": 2, "user": 6}}, {"pk": 94, "model": "server.award", "fields": {"date": "2010-03-04 04:05:54", "badge": 6, "user": 64}}, {"pk": 95, "model": "server.award", "fields": {"date": "2010-03-04 08:05:53", "badge": 6, "user": 65}}, {"pk": 96, "model": "server.award", "fields": {"date": "2010-03-04 09:20:52", "badge": 6, "user": 66}}, {"pk": 97, "model": "server.award", "fields": {"date": "2010-03-04 09:35:51", "badge": 9, "user": 67}}, {"pk": 98, "model": "server.award", "fields": {"date": "2010-03-04 09:50:50", "badge": 6, "user": 67}}, {"pk": 99, "model": "server.award", "fields": {"date": "2010-03-04 10:05:51", "badge": 6, "user": 68}}, {"pk": 100, "model": "server.award", "fields": {"date": "2010-03-04 14:38:59", "badge": 1, "user": 67}}, {"pk": 101, "model": "server.award", "fields": {"date": "2010-03-04 14:38:59", "badge": 6, "user": 6}}, {"pk": 102, "model": "server.award", "fields": {"date": "2010-03-04 14:38:59", "badge": 10, "user": 6}}, {"pk": 103, "model": "server.award", "fields": {"date": "2010-03-04 15:36:11", "badge": 1, "user": 70}}, {"pk": 104, "model": "server.award", "fields": {"date": "2010-03-04 15:36:11", "badge": 2, "user": 63}}, {"pk": 105, "model": "server.award", "fields": {"date": "2010-03-04 15:36:11", "badge": 6, "user": 55}}, {"pk": 106, "model": "server.award", "fields": {"date": "2010-03-04 15:36:11", "badge": 6, "user": 70}}, {"pk": 107, "model": "server.award", "fields": {"date": "2010-03-04 15:36:11", "badge": 6, "user": 71}}, {"pk": 108, "model": "server.award", "fields": {"date": "2010-03-04 15:36:11", "badge": 9, "user": 72}}, {"pk": 109, "model": "server.award", "fields": {"date": "2010-03-04 15:36:11", "badge": 14, "user": 22}}, {"pk": 110, "model": "server.award", "fields": {"date": "2010-03-04 15:51:03", "badge": 2, "user": 70}}, {"pk": 111, "model": "server.award", "fields": {"date": "2010-03-04 15:51:03", "badge": 6, "user": 72}}, {"pk": 112, "model": "server.award", "fields": {"date": "2010-03-04 16:05:53", "badge": 1, "user": 73}}, {"pk": 113, "model": "server.award", "fields": {"date": "2010-03-04 16:20:56", "badge": 6, "user": 73}}, {"pk": 114, "model": "server.award", "fields": {"date": "2010-03-04 16:20:56", "badge": 29, "user": 29}}, {"pk": 115, "model": "server.award", "fields": {"date": "2010-03-04 17:05:58", "badge": 6, "user": 76}}, {"pk": 116, "model": "server.award", "fields": {"date": "2010-03-04 18:21:08", "badge": 6, "user": 77}}, {"pk": 117, "model": "server.award", "fields": {"date": "2010-03-04 18:35:51", "badge": 6, "user": 75}}, {"pk": 118, "model": "server.award", "fields": {"date": "2010-03-04 19:20:53", "badge": 7, "user": 54}}, {"pk": 119, "model": "server.award", "fields": {"date": "2010-03-04 19:35:51", "badge": 1, "user": 78}}, {"pk": 120, "model": "server.award", "fields": {"date": "2010-03-04 20:05:54", "badge": 6, "user": 81}}, {"pk": 121, "model": "server.award", "fields": {"date": "2010-03-04 20:20:50", "badge": 6, "user": 78}}, {"pk": 122, "model": "server.award", "fields": {"date": "2010-03-04 21:07:22", "badge": 2, "user": 84}}, {"pk": 123, "model": "server.award", "fields": {"date": "2010-03-04 22:38:57", "badge": 1, "user": 81}}, {"pk": 124, "model": "server.award", "fields": {"date": "2010-03-04 22:38:57", "badge": 2, "user": 83}}, {"pk": 125, "model": "server.award", "fields": {"date": "2010-03-04 22:38:57", "badge": 6, "user": 25}}, {"pk": 126, "model": "server.award", "fields": {"date": "2010-03-04 23:36:16", "badge": 3, "user": 6}}, {"pk": 127, "model": "server.award", "fields": {"date": "2010-03-05 00:21:00", "badge": 1, "user": 85}}, {"pk": 128, "model": "server.award", "fields": {"date": "2010-03-05 02:50:51", "badge": 9, "user": 86}}, {"pk": 129, "model": "server.award", "fields": {"date": "2010-03-05 07:51:00", "badge": 1, "user": 86}}, {"pk": 130, "model": "server.award", "fields": {"date": "2010-03-05 07:51:01", "badge": 2, "user": 86}}, {"pk": 131, "model": "server.award", "fields": {"date": "2010-03-05 08:06:01", "badge": 6, "user": 74}}, {"pk": 132, "model": "server.award", "fields": {"date": "2010-03-05 09:51:13", "badge": 1, "user": 71}}, {"pk": 133, "model": "server.award", "fields": {"date": "2010-03-05 14:23:57", "badge": 3, "user": 58}}, {"pk": 134, "model": "server.award", "fields": {"date": "2010-03-05 15:21:06", "badge": 2, "user": 78}}, {"pk": 135, "model": "server.award", "fields": {"date": "2010-03-05 16:05:55", "badge": 2, "user": 67}}, {"pk": 136, "model": "server.award", "fields": {"date": "2010-03-05 16:35:51", "badge": 2, "user": 87}}, {"pk": 137, "model": "server.award", "fields": {"date": "2010-03-05 18:53:59", "badge": 3, "user": 67}}, {"pk": 138, "model": "server.award", "fields": {"date": "2010-03-05 19:36:04", "badge": 3, "user": 72}}, {"pk": 139, "model": "server.award", "fields": {"date": "2010-03-05 20:05:56", "badge": 1, "user": 72}}, {"pk": 140, "model": "server.award", "fields": {"date": "2010-03-05 22:36:03", "badge": 5, "user": 86}}, {"pk": 141, "model": "server.award", "fields": {"date": "2010-03-05 23:35:54", "badge": 6, "user": 86}}, {"pk": 142, "model": "server.award", "fields": {"date": "2010-03-06 02:06:03", "badge": 9, "user": 88}}, {"pk": 143, "model": "server.award", "fields": {"date": "2010-03-06 15:35:53", "badge": 3, "user": 90}}, {"pk": 144, "model": "server.award", "fields": {"date": "2010-03-06 15:35:53", "badge": 6, "user": 90}}, {"pk": 145, "model": "server.award", "fields": {"date": "2010-03-06 15:50:51", "badge": 2, "user": 89}}, {"pk": 146, "model": "server.award", "fields": {"date": "2010-03-06 15:50:51", "badge": 6, "user": 35}}, {"pk": 147, "model": "server.award", "fields": {"date": "2010-03-06 15:50:51", "badge": 9, "user": 91}}, {"pk": 148, "model": "server.award", "fields": {"date": "2010-03-06 16:35:58", "badge": 1, "user": 90}}, {"pk": 149, "model": "server.award", "fields": {"date": "2010-03-06 16:35:58", "badge": 3, "user": 54}}, {"pk": 150, "model": "server.award", "fields": {"date": "2010-03-06 18:06:00", "badge": 9, "user": 94}}, {"pk": 151, "model": "server.award", "fields": {"date": "2010-03-06 18:20:52", "badge": 1, "user": 91}}, {"pk": 152, "model": "server.award", "fields": {"date": "2010-03-06 18:20:52", "badge": 1, "user": 93}}, {"pk": 153, "model": "server.award", "fields": {"date": "2010-03-06 18:20:52", "badge": 1, "user": 96}}, {"pk": 154, "model": "server.award", "fields": {"date": "2010-03-06 18:50:55", "badge": 1, "user": 97}}, {"pk": 155, "model": "server.award", "fields": {"date": "2010-03-06 18:50:55", "badge": 5, "user": 9}}, {"pk": 156, "model": "server.award", "fields": {"date": "2010-03-06 19:20:54", "badge": 1, "user": 99}}, {"pk": 157, "model": "server.award", "fields": {"date": "2010-03-06 22:06:03", "badge": 6, "user": 89}}, {"pk": 158, "model": "server.award", "fields": {"date": "2010-03-07 00:20:50", "badge": 1, "user": 50}}, {"pk": 159, "model": "server.award", "fields": {"date": "2010-03-07 03:35:48", "badge": 1, "user": 35}}, {"pk": 160, "model": "server.award", "fields": {"date": "2010-03-07 10:21:08", "badge": 9, "user": 102}}, {"pk": 161, "model": "server.award", "fields": {"date": "2010-03-07 12:20:51", "badge": 3, "user": 78}}, {"pk": 162, "model": "server.award", "fields": {"date": "2010-03-07 18:20:59", "badge": 2, "user": 104}}, {"pk": 163, "model": "server.award", "fields": {"date": "2010-03-08 02:21:00", "badge": 6, "user": 50}}, {"pk": 164, "model": "server.award", "fields": {"date": "2010-03-08 07:20:57", "badge": 9, "user": 98}}, {"pk": 165, "model": "server.award", "fields": {"date": "2010-03-08 07:50:54", "badge": 6, "user": 107}}, {"pk": 166, "model": "server.award", "fields": {"date": "2010-03-08 07:50:54", "badge": 9, "user": 107}}, {"pk": 167, "model": "server.award", "fields": {"date": "2010-03-08 13:06:27", "badge": 6, "user": 109}}, {"pk": 168, "model": "server.award", "fields": {"date": "2010-03-08 14:06:06", "badge": 2, "user": 109}}, {"pk": 169, "model": "server.award", "fields": {"date": "2010-03-08 19:20:51", "badge": 9, "user": 112}}, {"pk": 170, "model": "server.award", "fields": {"date": "2010-03-08 19:35:56", "badge": 6, "user": 112}}, {"pk": 171, "model": "server.award", "fields": {"date": "2010-03-08 20:20:56", "badge": 9, "user": 113}}, {"pk": 172, "model": "server.award", "fields": {"date": "2010-03-08 22:36:10", "badge": 6, "user": 88}}, {"pk": 173, "model": "server.award", "fields": {"date": "2010-03-08 23:20:51", "badge": 1, "user": 88}}, {"pk": 174, "model": "server.award", "fields": {"date": "2010-03-08 23:20:51", "badge": 1, "user": 115}}, {"pk": 175, "model": "server.award", "fields": {"date": "2010-03-09 00:20:51", "badge": 1, "user": 65}}, {"pk": 176, "model": "server.award", "fields": {"date": "2010-03-09 05:06:28", "badge": 6, "user": 116}}, {"pk": 177, "model": "server.award", "fields": {"date": "2010-03-09 07:21:00", "badge": 1, "user": 116}}, {"pk": 178, "model": "server.award", "fields": {"date": "2010-03-09 12:20:52", "badge": 6, "user": 118}}, {"pk": 179, "model": "server.award", "fields": {"date": "2010-03-09 14:06:07", "badge": 1, "user": 118}}, {"pk": 180, "model": "server.award", "fields": {"date": "2010-03-09 20:05:52", "badge": 1, "user": 57}}, {"pk": 181, "model": "server.award", "fields": {"date": "2010-03-09 20:20:53", "badge": 5, "user": 25}}, {"pk": 182, "model": "server.award", "fields": {"date": "2010-03-10 09:21:55", "badge": 1, "user": 89}}, {"pk": 183, "model": "server.award", "fields": {"date": "2010-03-10 20:50:54", "badge": 6, "user": 23}}, {"pk": 184, "model": "server.award", "fields": {"date": "2010-03-11 01:06:48", "badge": 6, "user": 121}}, {"pk": 185, "model": "server.award", "fields": {"date": "2010-03-11 02:36:05", "badge": 1, "user": 121}}, {"pk": 186, "model": "server.award", "fields": {"date": "2010-03-11 02:36:05", "badge": 9, "user": 119}}, {"pk": 187, "model": "server.award", "fields": {"date": "2010-03-11 04:05:55", "badge": 2, "user": 72}}, {"pk": 188, "model": "server.award", "fields": {"date": "2010-03-11 04:05:55", "badge": 2, "user": 120}}, {"pk": 189, "model": "server.award", "fields": {"date": "2010-03-11 04:05:55", "badge": 2, "user": 121}}, {"pk": 190, "model": "server.award", "fields": {"date": "2010-03-11 04:20:50", "badge": 2, "user": 98}}, {"pk": 191, "model": "server.award", "fields": {"date": "2010-03-11 18:05:56", "badge": 5, "user": 35}}, {"pk": 192, "model": "server.award", "fields": {"date": "2010-03-12 04:35:50", "badge": 10, "user": 121}}, {"pk": 193, "model": "server.award", "fields": {"date": "2010-03-12 11:06:04", "badge": 2, "user": 58}}, {"pk": 194, "model": "server.award", "fields": {"date": "2010-03-12 11:50:54", "badge": 5, "user": 89}}, {"pk": 195, "model": "server.award", "fields": {"date": "2010-03-12 14:06:10", "badge": 9, "user": 124}}, {"pk": 196, "model": "server.award", "fields": {"date": "2010-03-12 14:20:57", "badge": 5, "user": 118}}, {"pk": 197, "model": "server.award", "fields": {"date": "2010-03-12 17:51:07", "badge": 2, "user": 52}}, {"pk": 198, "model": "server.award", "fields": {"date": "2010-03-12 17:51:07", "badge": 3, "user": 29}}, {"pk": 199, "model": "server.award", "fields": {"date": "2010-03-12 17:51:08", "badge": 6, "user": 113}}, {"pk": 200, "model": "server.award", "fields": {"date": "2010-03-12 18:20:51", "badge": 2, "user": 124}}, {"pk": 201, "model": "server.award", "fields": {"date": "2010-03-12 22:06:04", "badge": 10, "user": 52}}, {"pk": 202, "model": "server.award", "fields": {"date": "2010-03-12 22:06:04", "badge": 29, "user": 52}}, {"pk": 203, "model": "server.award", "fields": {"date": "2010-03-13 00:50:49", "badge": 10, "user": 120}}, {"pk": 204, "model": "server.award", "fields": {"date": "2010-03-13 15:50:51", "badge": 2, "user": 30}}, {"pk": 205, "model": "server.award", "fields": {"date": "2010-03-13 16:35:54", "badge": 9, "user": 127}}, {"pk": 206, "model": "server.award", "fields": {"date": "2010-03-13 18:20:54", "badge": 7, "user": 25}}, {"pk": 207, "model": "server.award", "fields": {"date": "2010-03-14 00:50:55", "badge": 29, "user": 30}}, {"pk": 208, "model": "server.award", "fields": {"date": "2010-03-14 01:51:04", "badge": 6, "user": 128}}, {"pk": 209, "model": "server.award", "fields": {"date": "2010-03-14 08:22:32", "badge": 29, "user": 25}}, {"pk": 210, "model": "server.award", "fields": {"date": "2010-03-14 16:51:02", "badge": 2, "user": 130}}, {"pk": 211, "model": "server.award", "fields": {"date": "2010-03-14 17:35:57", "badge": 10, "user": 130}}, {"pk": 212, "model": "server.award", "fields": {"date": "2010-03-14 18:20:50", "badge": 6, "user": 57}}, {"pk": 213, "model": "server.award", "fields": {"date": "2010-03-14 20:06:24", "badge": 6, "user": 129}}, {"pk": 214, "model": "server.award", "fields": {"date": "2010-03-14 22:21:00", "badge": 6, "user": 133}}, {"pk": 215, "model": "server.award", "fields": {"date": "2010-03-15 07:20:53", "badge": 6, "user": 135}}, {"pk": 216, "model": "server.award", "fields": {"date": "2010-03-15 07:20:53", "badge": 9, "user": 135}}, {"pk": 217, "model": "server.award", "fields": {"date": "2010-03-15 09:05:53", "badge": 6, "user": 124}}, {"pk": 218, "model": "server.award", "fields": {"date": "2010-03-15 10:50:51", "badge": 1, "user": 134}}, {"pk": 219, "model": "server.award", "fields": {"date": "2010-03-15 14:06:05", "badge": 1, "user": 135}}, {"pk": 220, "model": "server.award", "fields": {"date": "2010-03-15 14:06:05", "badge": 2, "user": 135}}, {"pk": 221, "model": "server.award", "fields": {"date": "2010-03-15 15:05:53", "badge": 1, "user": 137}}, {"pk": 222, "model": "server.award", "fields": {"date": "2010-03-15 17:50:53", "badge": 10, "user": 124}}, {"pk": 223, "model": "server.award", "fields": {"date": "2010-03-15 19:05:54", "badge": 6, "user": 140}}, {"pk": 224, "model": "server.award", "fields": {"date": "2010-03-15 19:50:49", "badge": 6, "user": 34}}, {"pk": 225, "model": "server.award", "fields": {"date": "2010-03-15 22:06:03", "badge": 9, "user": 141}}, {"pk": 226, "model": "server.award", "fields": {"date": "2010-03-15 22:20:57", "badge": 1, "user": 141}}, {"pk": 227, "model": "server.award", "fields": {"date": "2010-03-16 00:06:48", "badge": 3, "user": 142}}, {"pk": 228, "model": "server.award", "fields": {"date": "2010-03-16 07:05:49", "badge": 10, "user": 135}}, {"pk": 229, "model": "server.award", "fields": {"date": "2010-03-16 09:06:02", "badge": 2, "user": 141}}, {"pk": 230, "model": "server.award", "fields": {"date": "2010-03-16 09:06:02", "badge": 3, "user": 141}}, {"pk": 231, "model": "server.award", "fields": {"date": "2010-03-16 11:05:53", "badge": 7, "user": 70}}, {"pk": 232, "model": "server.award", "fields": {"date": "2010-03-16 11:20:50", "badge": 5, "user": 70}}, {"pk": 233, "model": "server.award", "fields": {"date": "2010-03-16 11:35:57", "badge": 6, "user": 144}}, {"pk": 234, "model": "server.award", "fields": {"date": "2010-03-16 13:05:59", "badge": 1, "user": 130}}, {"pk": 235, "model": "server.award", "fields": {"date": "2010-03-16 13:05:59", "badge": 2, "user": 144}}, {"pk": 236, "model": "server.award", "fields": {"date": "2010-03-16 13:05:59", "badge": 10, "user": 144}}, {"pk": 237, "model": "server.award", "fields": {"date": "2010-03-16 13:20:54", "badge": 6, "user": 142}}, {"pk": 238, "model": "server.award", "fields": {"date": "2010-03-16 13:35:52", "badge": 2, "user": 142}}, {"pk": 239, "model": "server.award", "fields": {"date": "2010-03-16 14:05:54", "badge": 6, "user": 141}}, {"pk": 240, "model": "server.award", "fields": {"date": "2010-03-16 14:35:51", "badge": 1, "user": 145}}, {"pk": 241, "model": "server.award", "fields": {"date": "2010-03-16 14:35:51", "badge": 5, "user": 37}}, {"pk": 242, "model": "server.award", "fields": {"date": "2010-03-16 15:35:50", "badge": 3, "user": 35}}, {"pk": 243, "model": "server.award", "fields": {"date": "2010-03-16 17:05:53", "badge": 3, "user": 88}}, {"pk": 244, "model": "server.award", "fields": {"date": "2010-03-16 22:06:06", "badge": 7, "user": 58}}, {"pk": 245, "model": "server.award", "fields": {"date": "2010-03-16 22:35:57", "badge": 9, "user": 147}}, {"pk": 246, "model": "server.award", "fields": {"date": "2010-03-16 23:05:50", "badge": 3, "user": 147}}, {"pk": 247, "model": "server.award", "fields": {"date": "2010-03-16 23:20:51", "badge": 6, "user": 147}}, {"pk": 248, "model": "server.award", "fields": {"date": "2010-03-16 23:51:01", "badge": 1, "user": 147}}, {"pk": 249, "model": "server.award", "fields": {"date": "2010-03-16 23:51:01", "badge": 2, "user": 147}}, {"pk": 250, "model": "server.award", "fields": {"date": "2010-03-17 08:21:56", "badge": 3, "user": 70}}, {"pk": 251, "model": "server.award", "fields": {"date": "2010-03-17 09:21:04", "badge": 1, "user": 148}}, {"pk": 252, "model": "server.award", "fields": {"date": "2010-03-17 09:50:58", "badge": 7, "user": 37}}, {"pk": 253, "model": "server.award", "fields": {"date": "2010-03-17 10:35:55", "badge": 7, "user": 141}}, {"pk": 254, "model": "server.award", "fields": {"date": "2010-03-17 11:50:50", "badge": 10, "user": 58}}, {"pk": 255, "model": "server.award", "fields": {"date": "2010-03-17 14:35:55", "badge": 6, "user": 137}}, {"pk": 256, "model": "server.award", "fields": {"date": "2010-03-17 17:50:53", "badge": 8, "user": 54}}, {"pk": 257, "model": "server.award", "fields": {"date": "2010-03-17 19:20:49", "badge": 7, "user": 88}}, {"pk": 258, "model": "server.award", "fields": {"date": "2010-03-17 23:05:54", "badge": 7, "user": 116}}, {"pk": 259, "model": "server.award", "fields": {"date": "2010-03-17 23:05:54", "badge": 9, "user": 116}}, {"pk": 260, "model": "server.award", "fields": {"date": "2010-03-18 10:20:51", "badge": 2, "user": 37}}, {"pk": 261, "model": "server.award", "fields": {"date": "2010-03-18 11:50:52", "badge": 37, "user": 22}}, {"pk": 262, "model": "server.award", "fields": {"date": "2010-03-18 14:06:37", "badge": 29, "user": 58}}, {"pk": 263, "model": "server.award", "fields": {"date": "2010-03-18 15:21:47", "badge": 10, "user": 72}}, {"pk": 264, "model": "server.award", "fields": {"date": "2010-03-18 21:21:37", "badge": 29, "user": 61}}, {"pk": 265, "model": "server.award", "fields": {"date": "2010-03-19 12:06:25", "badge": 3, "user": 137}}, {"pk": 266, "model": "server.award", "fields": {"date": "2010-03-19 15:21:00", "badge": 2, "user": 35}}, {"pk": 267, "model": "server.award", "fields": {"date": "2010-03-19 17:35:58", "badge": 3, "user": 116}}, {"pk": 268, "model": "server.award", "fields": {"date": "2010-03-19 18:05:52", "badge": 1, "user": 119}}, {"pk": 269, "model": "server.award", "fields": {"date": "2010-03-19 22:06:03", "badge": 10, "user": 37}}, {"pk": 270, "model": "server.award", "fields": {"date": "2010-03-20 11:05:48", "badge": 9, "user": 153}}, {"pk": 271, "model": "server.award", "fields": {"date": "2010-03-20 11:20:49", "badge": 6, "user": 153}}, {"pk": 272, "model": "server.award", "fields": {"date": "2010-03-20 11:35:49", "badge": 6, "user": 79}}, {"pk": 273, "model": "server.award", "fields": {"date": "2010-03-20 11:50:51", "badge": 19, "user": 58}}, {"pk": 274, "model": "server.award", "fields": {"date": "2010-03-20 14:50:56", "badge": 2, "user": 153}}, {"pk": 275, "model": "server.award", "fields": {"date": "2010-03-20 15:05:49", "badge": 1, "user": 153}}, {"pk": 276, "model": "server.award", "fields": {"date": "2010-03-20 15:35:52", "badge": 2, "user": 88}}, {"pk": 277, "model": "server.award", "fields": {"date": "2010-03-21 16:51:00", "badge": 6, "user": 94}}, {"pk": 278, "model": "server.award", "fields": {"date": "2010-03-22 00:06:43", "badge": 1, "user": 94}}, {"pk": 279, "model": "server.award", "fields": {"date": "2010-03-22 08:21:52", "badge": 6, "user": 157}}, {"pk": 280, "model": "server.award", "fields": {"date": "2010-03-22 09:50:57", "badge": 9, "user": 159}}, {"pk": 281, "model": "server.award", "fields": {"date": "2010-03-22 10:20:57", "badge": 19, "user": 1}}, {"pk": 282, "model": "server.award", "fields": {"date": "2010-03-22 10:50:52", "badge": 1, "user": 160}}, {"pk": 283, "model": "server.award", "fields": {"date": "2010-03-22 11:50:50", "badge": 7, "user": 67}}, {"pk": 284, "model": "server.award", "fields": {"date": "2010-03-22 13:05:53", "badge": 7, "user": 65}}, {"pk": 285, "model": "server.award", "fields": {"date": "2010-03-22 13:50:51", "badge": 2, "user": 159}}, {"pk": 286, "model": "server.award", "fields": {"date": "2010-03-22 15:35:51", "badge": 6, "user": 159}}, {"pk": 287, "model": "server.award", "fields": {"date": "2010-03-22 17:20:58", "badge": 19, "user": 35}}, {"pk": 288, "model": "server.award", "fields": {"date": "2010-03-22 17:35:54", "badge": 5, "user": 29}}, {"pk": 289, "model": "server.award", "fields": {"date": "2010-03-22 18:21:25", "badge": 2, "user": 127}}, {"pk": 290, "model": "server.award", "fields": {"date": "2010-03-22 18:21:25", "badge": 2, "user": 163}}, {"pk": 291, "model": "server.award", "fields": {"date": "2010-03-22 18:21:25", "badge": 6, "user": 85}}, {"pk": 292, "model": "server.award", "fields": {"date": "2010-03-22 19:05:48", "badge": 3, "user": 118}}, {"pk": 293, "model": "server.award", "fields": {"date": "2010-03-22 19:05:48", "badge": 7, "user": 52}}, {"pk": 294, "model": "server.award", "fields": {"date": "2010-03-22 19:35:50", "badge": 3, "user": 86}}, {"pk": 295, "model": "server.award", "fields": {"date": "2010-03-22 20:18:37", "badge": 6, "user": 127}}, {"pk": 296, "model": "server.award", "fields": {"date": "2010-03-22 20:18:37", "badge": 10, "user": 127}}, {"pk": 297, "model": "server.award", "fields": {"date": "2010-03-22 23:20:47", "badge": 7, "user": 61}}, {"pk": 298, "model": "server.award", "fields": {"date": "2010-03-23 00:35:48", "badge": 29, "user": 65}}, {"pk": 299, "model": "server.award", "fields": {"date": "2010-03-23 02:05:48", "badge": 7, "user": 86}}, {"pk": 300, "model": "server.award", "fields": {"date": "2010-03-23 02:05:49", "badge": 10, "user": 86}}, {"pk": 301, "model": "server.award", "fields": {"date": "2010-03-23 02:20:47", "badge": 29, "user": 86}}, {"pk": 302, "model": "server.award", "fields": {"date": "2010-03-23 09:05:47", "badge": 29, "user": 54}}, {"pk": 303, "model": "server.award", "fields": {"date": "2010-03-23 09:50:48", "badge": 10, "user": 159}}, {"pk": 304, "model": "server.award", "fields": {"date": "2010-03-23 11:20:48", "badge": 10, "user": 163}}, {"pk": 305, "model": "server.award", "fields": {"date": "2010-03-23 12:20:47", "badge": 2, "user": 54}}, {"pk": 306, "model": "server.award", "fields": {"date": "2010-03-23 13:50:47", "badge": 29, "user": 147}}, {"pk": 307, "model": "server.award", "fields": {"date": "2010-03-23 15:20:47", "badge": 2, "user": 165}}, {"pk": 308, "model": "server.award", "fields": {"date": "2010-03-23 17:50:48", "badge": 10, "user": 88}}, {"pk": 309, "model": "server.award", "fields": {"date": "2010-03-23 18:50:48", "badge": 2, "user": 85}}, {"pk": 310, "model": "server.award", "fields": {"date": "2010-03-23 18:50:48", "badge": 10, "user": 147}}, {"pk": 311, "model": "server.award", "fields": {"date": "2010-03-23 23:05:49", "badge": 6, "user": 168}}, {"pk": 312, "model": "server.award", "fields": {"date": "2010-03-23 23:35:47", "badge": 1, "user": 168}}, {"pk": 313, "model": "server.award", "fields": {"date": "2010-03-24 10:20:48", "badge": 1, "user": 170}}, {"pk": 314, "model": "server.award", "fields": {"date": "2010-03-24 10:50:48", "badge": 6, "user": 172}}, {"pk": 315, "model": "server.award", "fields": {"date": "2010-03-24 11:05:48", "badge": 9, "user": 168}}, {"pk": 316, "model": "server.award", "fields": {"date": "2010-03-24 11:35:48", "badge": 3, "user": 170}}, {"pk": 317, "model": "server.award", "fields": {"date": "2010-03-24 13:20:48", "badge": 2, "user": 168}}, {"pk": 318, "model": "server.award", "fields": {"date": "2010-03-24 14:20:52", "badge": 29, "user": 168}}, {"pk": 319, "model": "server.award", "fields": {"date": "2010-03-24 14:35:48", "badge": 1, "user": 175}}, {"pk": 320, "model": "server.award", "fields": {"date": "2010-03-24 15:05:49", "badge": 1, "user": 176}}, {"pk": 321, "model": "server.award", "fields": {"date": "2010-03-24 16:35:48", "badge": 2, "user": 178}}, {"pk": 322, "model": "server.award", "fields": {"date": "2010-03-24 16:50:47", "badge": 7, "user": 121}}, {"pk": 323, "model": "server.award", "fields": {"date": "2010-03-24 17:05:48", "badge": 5, "user": 168}}, {"pk": 324, "model": "server.award", "fields": {"date": "2010-03-24 18:05:48", "badge": 1, "user": 163}}, {"pk": 325, "model": "server.award", "fields": {"date": "2010-03-24 18:05:48", "badge": 6, "user": 115}}, {"pk": 326, "model": "server.award", "fields": {"date": "2010-03-24 19:50:47", "badge": 6, "user": 178}}, {"pk": 327, "model": "server.award", "fields": {"date": "2010-03-24 19:50:47", "badge": 9, "user": 166}}, {"pk": 328, "model": "server.award", "fields": {"date": "2010-03-24 20:05:51", "badge": 29, "user": 116}}, {"pk": 329, "model": "server.award", "fields": {"date": "2010-03-24 20:20:47", "badge": 2, "user": 91}}, {"pk": 330, "model": "server.award", "fields": {"date": "2010-03-24 20:20:47", "badge": 5, "user": 141}}, {"pk": 331, "model": "server.award", "fields": {"date": "2010-03-24 20:50:49", "badge": 7, "user": 73}}, {"pk": 332, "model": "server.award", "fields": {"date": "2010-03-24 21:35:48", "badge": 1, "user": 179}}, {"pk": 333, "model": "server.award", "fields": {"date": "2010-03-24 21:35:48", "badge": 6, "user": 163}}, {"pk": 334, "model": "server.award", "fields": {"date": "2010-03-24 23:35:48", "badge": 9, "user": 181}}, {"pk": 335, "model": "server.award", "fields": {"date": "2010-03-25 00:20:47", "badge": 1, "user": 171}}, {"pk": 336, "model": "server.award", "fields": {"date": "2010-03-25 02:50:49", "badge": 6, "user": 91}}, {"pk": 337, "model": "server.award", "fields": {"date": "2010-03-25 02:50:49", "badge": 10, "user": 91}}, {"pk": 338, "model": "server.award", "fields": {"date": "2010-03-25 08:05:49", "badge": 5, "user": 65}}, {"pk": 339, "model": "server.award", "fields": {"date": "2010-03-25 11:20:48", "badge": 10, "user": 168}}, {"pk": 340, "model": "server.award", "fields": {"date": "2010-03-25 12:35:48", "badge": 2, "user": 184}}, {"pk": 341, "model": "server.award", "fields": {"date": "2010-03-25 14:50:48", "badge": 29, "user": 72}}, {"pk": 342, "model": "server.award", "fields": {"date": "2010-03-25 16:50:49", "badge": 3, "user": 168}}, {"pk": 343, "model": "server.award", "fields": {"date": "2010-03-25 17:35:53", "badge": 6, "user": 180}}, {"pk": 344, "model": "server.award", "fields": {"date": "2010-03-26 00:05:47", "badge": 1, "user": 185}}, {"pk": 345, "model": "server.award", "fields": {"date": "2010-03-26 07:50:48", "badge": 37, "user": 29}}, {"pk": 346, "model": "server.award", "fields": {"date": "2010-03-26 10:50:47", "badge": 6, "user": 187}}, {"pk": 347, "model": "server.award", "fields": {"date": "2010-03-26 10:50:47", "badge": 9, "user": 187}}, {"pk": 348, "model": "server.award", "fields": {"date": "2010-03-26 11:20:47", "badge": 1, "user": 187}}, {"pk": 349, "model": "server.award", "fields": {"date": "2010-03-26 11:50:47", "badge": 7, "user": 168}}, {"pk": 350, "model": "server.award", "fields": {"date": "2010-03-26 11:50:47", "badge": 8, "user": 22}}, {"pk": 351, "model": "server.award", "fields": {"date": "2010-03-26 13:20:47", "badge": 1, "user": 114}}, {"pk": 352, "model": "server.award", "fields": {"date": "2010-03-26 13:20:47", "badge": 2, "user": 39}}, {"pk": 353, "model": "server.award", "fields": {"date": "2010-03-26 13:20:47", "badge": 2, "user": 186}}, {"pk": 354, "model": "server.award", "fields": {"date": "2010-03-26 16:05:48", "badge": 7, "user": 72}}, {"pk": 355, "model": "server.award", "fields": {"date": "2010-03-26 21:50:48", "badge": 3, "user": 121}}, {"pk": 356, "model": "server.award", "fields": {"date": "2010-03-27 13:05:47", "badge": 10, "user": 67}}, {"pk": 357, "model": "server.award", "fields": {"date": "2010-03-27 17:50:48", "badge": 2, "user": 140}}, {"pk": 358, "model": "server.award", "fields": {"date": "2010-03-28 09:05:48", "badge": 6, "user": 175}}, {"pk": 359, "model": "server.award", "fields": {"date": "2010-03-28 16:05:48", "badge": 37, "user": 54}}, {"pk": 360, "model": "server.award", "fields": {"date": "2010-03-28 16:35:48", "badge": 10, "user": 140}}, {"pk": 361, "model": "server.award", "fields": {"date": "2010-03-28 20:05:49", "badge": 1, "user": 140}}, {"pk": 362, "model": "server.award", "fields": {"date": "2010-03-28 22:35:47", "badge": 1, "user": 193}}, {"pk": 363, "model": "server.award", "fields": {"date": "2010-03-29 04:20:49", "badge": 6, "user": 167}}, {"pk": 364, "model": "server.award", "fields": {"date": "2010-03-29 14:20:47", "badge": 10, "user": 54}}, {"pk": 365, "model": "server.award", "fields": {"date": "2010-03-29 14:35:47", "badge": 29, "user": 88}}, {"pk": 366, "model": "server.award", "fields": {"date": "2010-03-29 14:50:49", "badge": 9, "user": 197}}, {"pk": 367, "model": "server.award", "fields": {"date": "2010-03-29 15:05:48", "badge": 9, "user": 54}}, {"pk": 368, "model": "server.award", "fields": {"date": "2010-03-29 19:20:53", "badge": 2, "user": 196}}, {"pk": 369, "model": "server.award", "fields": {"date": "2010-03-30 02:05:47", "badge": 37, "user": 1}}, {"pk": 370, "model": "server.award", "fields": {"date": "2010-03-30 17:05:49", "badge": 1, "user": 55}}, {"pk": 371, "model": "server.award", "fields": {"date": "2010-03-30 18:50:48", "badge": 3, "user": 120}}, {"pk": 372, "model": "server.award", "fields": {"date": "2010-03-31 05:35:48", "badge": 1, "user": 151}}, {"pk": 373, "model": "server.award", "fields": {"date": "2010-03-31 07:20:47", "badge": 6, "user": 151}}, {"pk": 374, "model": "server.award", "fields": {"date": "2010-03-31 09:50:49", "badge": 1, "user": 87}}, {"pk": 375, "model": "server.award", "fields": {"date": "2010-03-31 10:05:48", "badge": 1, "user": 189}}, {"pk": 376, "model": "server.award", "fields": {"date": "2010-03-31 11:50:48", "badge": 6, "user": 198}}, {"pk": 377, "model": "server.award", "fields": {"date": "2010-03-31 12:35:47", "badge": 22, "user": 29}}, {"pk": 378, "model": "server.award", "fields": {"date": "2010-03-31 12:50:49", "badge": 18, "user": 29}}, {"pk": 379, "model": "server.award", "fields": {"date": "2010-04-01 02:50:48", "badge": 7, "user": 35}}, {"pk": 380, "model": "server.award", "fields": {"date": "2010-04-02 07:35:49", "badge": 3, "user": 140}}, {"pk": 381, "model": "server.award", "fields": {"date": "2010-04-02 15:35:48", "badge": 1, "user": 203}}, {"pk": 382, "model": "server.award", "fields": {"date": "2010-04-02 18:20:49", "badge": 6, "user": 125}}, {"pk": 383, "model": "server.award", "fields": {"date": "2010-04-02 19:05:48", "badge": 1, "user": 125}}, {"pk": 384, "model": "server.award", "fields": {"date": "2010-04-02 20:20:47", "badge": 9, "user": 125}}, {"pk": 385, "model": "server.award", "fields": {"date": "2010-04-02 20:20:47", "badge": 29, "user": 70}}, {"pk": 386, "model": "server.award", "fields": {"date": "2010-04-02 22:05:49", "badge": 6, "user": 204}}, {"pk": 387, "model": "server.award", "fields": {"date": "2010-04-02 22:50:51", "badge": 1, "user": 202}}, {"pk": 388, "model": "server.award", "fields": {"date": "2010-04-02 22:50:51", "badge": 1, "user": 204}}, {"pk": 389, "model": "server.award", "fields": {"date": "2010-04-03 04:20:48", "badge": 9, "user": 205}}, {"pk": 390, "model": "server.award", "fields": {"date": "2010-04-03 08:50:47", "badge": 2, "user": 205}}, {"pk": 391, "model": "server.award", "fields": {"date": "2010-04-03 21:35:48", "badge": 3, "user": 204}}, {"pk": 392, "model": "server.award", "fields": {"date": "2010-04-03 22:35:48", "badge": 9, "user": 204}}, {"pk": 393, "model": "server.award", "fields": {"date": "2010-04-04 02:35:48", "badge": 6, "user": 205}}, {"pk": 394, "model": "server.award", "fields": {"date": "2010-04-05 18:05:47", "badge": 1, "user": 206}}, {"pk": 395, "model": "server.award", "fields": {"date": "2010-04-06 13:50:51", "badge": 1, "user": 210}}, {"pk": 396, "model": "server.award", "fields": {"date": "2010-04-07 06:50:48", "badge": 6, "user": 186}}, {"pk": 397, "model": "server.award", "fields": {"date": "2010-04-07 07:35:47", "badge": 1, "user": 197}}, {"pk": 398, "model": "server.award", "fields": {"date": "2010-04-07 07:35:47", "badge": 3, "user": 197}}, {"pk": 399, "model": "server.award", "fields": {"date": "2010-04-07 07:35:47", "badge": 7, "user": 71}}, {"pk": 400, "model": "server.award", "fields": {"date": "2010-04-07 07:35:47", "badge": 8, "user": 71}}, {"pk": 401, "model": "server.award", "fields": {"date": "2010-04-07 14:50:47", "badge": 2, "user": 119}}, {"pk": 402, "model": "server.award", "fields": {"date": "2010-04-07 15:50:48", "badge": 10, "user": 119}}, {"pk": 403, "model": "server.award", "fields": {"date": "2010-04-08 06:50:47", "badge": 1, "user": 213}}, {"pk": 404, "model": "server.award", "fields": {"date": "2010-04-08 13:05:46", "badge": 2, "user": 214}}, {"pk": 405, "model": "server.award", "fields": {"date": "2010-04-08 17:35:47", "badge": 1, "user": 215}}, {"pk": 406, "model": "server.award", "fields": {"date": "2010-04-08 17:35:47", "badge": 3, "user": 215}}, {"pk": 407, "model": "server.award", "fields": {"date": "2010-04-08 18:05:48", "badge": 2, "user": 116}}, {"pk": 408, "model": "server.award", "fields": {"date": "2010-04-08 18:50:51", "badge": 1, "user": 216}}, {"pk": 409, "model": "server.award", "fields": {"date": "2010-04-08 19:50:47", "badge": 2, "user": 118}}, {"pk": 410, "model": "server.award", "fields": {"date": "2010-04-08 21:20:47", "badge": 9, "user": 217}}, {"pk": 411, "model": "server.award", "fields": {"date": "2010-04-08 21:35:48", "badge": 3, "user": 114}}, {"pk": 412, "model": "server.award", "fields": {"date": "2010-04-08 21:50:47", "badge": 6, "user": 217}}, {"pk": 413, "model": "server.award", "fields": {"date": "2010-04-08 23:05:47", "badge": 1, "user": 217}}, {"pk": 414, "model": "server.award", "fields": {"date": "2010-04-09 00:05:48", "badge": 2, "user": 215}}, {"pk": 415, "model": "server.award", "fields": {"date": "2010-04-09 11:20:47", "badge": 6, "user": 218}}, {"pk": 416, "model": "server.award", "fields": {"date": "2010-04-09 12:35:48", "badge": 6, "user": 215}}, {"pk": 417, "model": "server.award", "fields": {"date": "2010-04-09 14:05:49", "badge": 10, "user": 118}}, {"pk": 418, "model": "server.award", "fields": {"date": "2010-04-09 14:20:48", "badge": 7, "user": 147}}, {"pk": 419, "model": "server.award", "fields": {"date": "2010-04-09 20:20:47", "badge": 6, "user": 202}}, {"pk": 420, "model": "server.award", "fields": {"date": "2010-04-09 21:20:47", "badge": 1, "user": 126}}, {"pk": 421, "model": "server.award", "fields": {"date": "2010-04-09 21:20:47", "badge": 6, "user": 126}}, {"pk": 422, "model": "server.award", "fields": {"date": "2010-04-09 23:35:48", "badge": 29, "user": 215}}, {"pk": 423, "model": "server.award", "fields": {"date": "2010-04-10 01:50:47", "badge": 30, "user": 1}}, {"pk": 424, "model": "server.award", "fields": {"date": "2010-04-10 14:20:47", "badge": 29, "user": 35}}, {"pk": 425, "model": "server.award", "fields": {"date": "2010-04-11 12:20:47", "badge": 1, "user": 219}}, {"pk": 426, "model": "server.award", "fields": {"date": "2010-04-11 22:50:47", "badge": 9, "user": 126}}, {"pk": 427, "model": "server.award", "fields": {"date": "2010-04-12 03:20:47", "badge": 6, "user": 213}}, {"pk": 428, "model": "server.award", "fields": {"date": "2010-04-12 08:20:48", "badge": 10, "user": 39}}, {"pk": 429, "model": "server.award", "fields": {"date": "2010-04-12 11:05:48", "badge": 8, "user": 126}}, {"pk": 430, "model": "server.award", "fields": {"date": "2010-04-12 15:05:48", "badge": 7, "user": 215}}, {"pk": 431, "model": "server.award", "fields": {"date": "2010-04-12 15:05:48", "badge": 8, "user": 73}}, {"pk": 432, "model": "server.award", "fields": {"date": "2010-04-12 15:05:48", "badge": 8, "user": 215}}, {"pk": 433, "model": "server.award", "fields": {"date": "2010-04-12 15:05:48", "badge": 10, "user": 215}}, {"pk": 434, "model": "server.award", "fields": {"date": "2010-04-12 15:05:48", "badge": 14, "user": 1}}, {"pk": 435, "model": "server.award", "fields": {"date": "2010-04-12 15:20:48", "badge": 7, "user": 29}}, {"pk": 436, "model": "server.award", "fields": {"date": "2010-04-12 16:05:49", "badge": 8, "user": 35}}, {"pk": 437, "model": "server.award", "fields": {"date": "2010-04-12 17:20:49", "badge": 6, "user": 221}}, {"pk": 438, "model": "server.award", "fields": {"date": "2010-04-13 13:35:48", "badge": 6, "user": 222}}, {"pk": 439, "model": "server.award", "fields": {"date": "2010-04-13 14:35:50", "badge": 2, "user": 224}}, {"pk": 440, "model": "server.award", "fields": {"date": "2010-04-13 14:35:50", "badge": 5, "user": 215}}, {"pk": 441, "model": "server.award", "fields": {"date": "2010-04-13 14:35:50", "badge": 9, "user": 192}}, {"pk": 442, "model": "server.award", "fields": {"date": "2010-04-13 14:50:47", "badge": 9, "user": 222}}, {"pk": 443, "model": "server.award", "fields": {"date": "2010-04-13 16:35:49", "badge": 2, "user": 225}}, {"pk": 444, "model": "server.award", "fields": {"date": "2010-04-14 00:20:49", "badge": 6, "user": 230}}, {"pk": 445, "model": "server.award", "fields": {"date": "2010-04-14 00:20:49", "badge": 22, "user": 215}}, {"pk": 446, "model": "server.award", "fields": {"date": "2010-04-14 00:50:51", "badge": 1, "user": 225}}, {"pk": 447, "model": "server.award", "fields": {"date": "2010-04-14 01:35:49", "badge": 6, "user": 231}}, {"pk": 448, "model": "server.award", "fields": {"date": "2010-04-14 05:50:49", "badge": 3, "user": 135}}, {"pk": 449, "model": "server.award", "fields": {"date": "2010-04-14 08:50:52", "badge": 7, "user": 87}}, {"pk": 450, "model": "server.award", "fields": {"date": "2010-04-14 09:50:50", "badge": 1, "user": 233}}, {"pk": 451, "model": "server.award", "fields": {"date": "2010-04-14 09:50:50", "badge": 6, "user": 233}}, {"pk": 452, "model": "server.award", "fields": {"date": "2010-04-14 11:05:50", "badge": 7, "user": 126}}, {"pk": 453, "model": "server.award", "fields": {"date": "2010-04-14 13:35:52", "badge": 6, "user": 224}}, {"pk": 454, "model": "server.award", "fields": {"date": "2010-04-14 15:20:50", "badge": 1, "user": 222}}, {"pk": 455, "model": "server.award", "fields": {"date": "2010-04-14 15:20:50", "badge": 2, "user": 198}}, {"pk": 456, "model": "server.award", "fields": {"date": "2010-04-14 15:35:49", "badge": 1, "user": 234}}, {"pk": 457, "model": "server.award", "fields": {"date": "2010-04-14 16:05:50", "badge": 3, "user": 222}}, {"pk": 458, "model": "server.award", "fields": {"date": "2010-04-15 00:20:49", "badge": 9, "user": 215}}, {"pk": 459, "model": "server.award", "fields": {"date": "2010-04-15 00:50:48", "badge": 4, "user": 215}}, {"pk": 460, "model": "server.award", "fields": {"date": "2010-04-15 02:05:48", "badge": 37, "user": 126}}, {"pk": 461, "model": "server.award", "fields": {"date": "2010-04-15 02:20:49", "badge": 1, "user": 224}}, {"pk": 462, "model": "server.award", "fields": {"date": "2010-04-15 07:50:50", "badge": 30, "user": 22}}, {"pk": 463, "model": "server.award", "fields": {"date": "2010-04-15 08:20:48", "badge": 6, "user": 225}}, {"pk": 464, "model": "server.award", "fields": {"date": "2010-04-15 12:50:50", "badge": 1, "user": 198}}, {"pk": 465, "model": "server.award", "fields": {"date": "2010-04-15 13:35:50", "badge": 2, "user": 217}}, {"pk": 466, "model": "server.award", "fields": {"date": "2010-04-15 13:35:50", "badge": 6, "user": 69}}, {"pk": 467, "model": "server.award", "fields": {"date": "2010-04-15 13:50:49", "badge": 10, "user": 224}}, {"pk": 468, "model": "server.award", "fields": {"date": "2010-04-15 14:05:49", "badge": 5, "user": 147}}, {"pk": 469, "model": "server.award", "fields": {"date": "2010-04-15 14:05:49", "badge": 9, "user": 234}}, {"pk": 470, "model": "server.award", "fields": {"date": "2010-04-15 18:05:49", "badge": 29, "user": 126}}, {"pk": 471, "model": "server.award", "fields": {"date": "2010-04-16 02:05:48", "badge": 3, "user": 89}}, {"pk": 472, "model": "server.award", "fields": {"date": "2010-04-16 09:35:48", "badge": 2, "user": 241}}, {"pk": 473, "model": "server.award", "fields": {"date": "2010-04-16 09:50:49", "badge": 10, "user": 241}}, {"pk": 474, "model": "server.award", "fields": {"date": "2010-04-16 12:35:51", "badge": 2, "user": 240}}, {"pk": 475, "model": "server.award", "fields": {"date": "2010-04-16 13:50:49", "badge": 5, "user": 54}}, {"pk": 476, "model": "server.award", "fields": {"date": "2010-04-16 14:20:49", "badge": 3, "user": 39}}, {"pk": 477, "model": "server.award", "fields": {"date": "2010-04-16 19:50:48", "badge": 2, "user": 243}}, {"pk": 478, "model": "server.award", "fields": {"date": "2010-04-17 02:20:47", "badge": 2, "user": 199}}, {"pk": 479, "model": "server.award", "fields": {"date": "2010-04-17 08:50:47", "badge": 10, "user": 217}}, {"pk": 480, "model": "server.award", "fields": {"date": "2010-04-17 17:50:49", "badge": 6, "user": 241}}, {"pk": 481, "model": "server.award", "fields": {"date": "2010-04-17 18:35:47", "badge": 1, "user": 244}}, {"pk": 482, "model": "server.award", "fields": {"date": "2010-04-17 18:35:47", "badge": 3, "user": 126}}, {"pk": 483, "model": "server.award", "fields": {"date": "2010-04-17 18:50:48", "badge": 6, "user": 237}}, {"pk": 484, "model": "server.award", "fields": {"date": "2010-04-17 19:05:48", "badge": 9, "user": 237}}, {"pk": 485, "model": "server.award", "fields": {"date": "2010-04-17 19:20:48", "badge": 9, "user": 245}}, {"pk": 486, "model": "server.award", "fields": {"date": "2010-04-17 21:05:47", "badge": 2, "user": 237}}, {"pk": 487, "model": "server.award", "fields": {"date": "2010-04-18 12:05:52", "badge": 2, "user": 151}}, {"pk": 488, "model": "server.award", "fields": {"date": "2010-04-19 08:20:48", "badge": 6, "user": 247}}, {"pk": 489, "model": "server.award", "fields": {"date": "2010-04-19 14:20:50", "badge": 2, "user": 248}}, {"pk": 490, "model": "server.award", "fields": {"date": "2010-04-19 16:50:48", "badge": 2, "user": 233}}, {"pk": 491, "model": "server.award", "fields": {"date": "2010-04-19 17:20:49", "badge": 9, "user": 249}}, {"pk": 492, "model": "server.award", "fields": {"date": "2010-04-19 17:35:49", "badge": 10, "user": 237}}, {"pk": 493, "model": "server.award", "fields": {"date": "2010-04-19 23:05:48", "badge": 1, "user": 251}}, {"pk": 494, "model": "server.award", "fields": {"date": "2010-04-20 03:50:50", "badge": 9, "user": 254}}, {"pk": 495, "model": "server.award", "fields": {"date": "2010-04-20 07:05:49", "badge": 10, "user": 233}}, {"pk": 496, "model": "server.award", "fields": {"date": "2010-04-20 13:05:49", "badge": 5, "user": 72}}, {"pk": 497, "model": "server.award", "fields": {"date": "2010-04-20 16:50:49", "badge": 6, "user": 244}}, {"pk": 498, "model": "server.award", "fields": {"date": "2010-04-20 20:35:51", "badge": 29, "user": 141}}, {"pk": 499, "model": "server.award", "fields": {"date": "2010-04-20 21:50:48", "badge": 3, "user": 85}}, {"pk": 500, "model": "server.award", "fields": {"date": "2010-04-20 23:05:48", "badge": 1, "user": 112}}, {"pk": 501, "model": "server.award", "fields": {"date": "2010-04-21 02:35:49", "badge": 22, "user": 119}}, {"pk": 502, "model": "server.award", "fields": {"date": "2010-04-21 10:20:46", "badge": 1, "user": 259}}, {"pk": 503, "model": "server.award", "fields": {"date": "2010-04-21 10:20:47", "badge": 29, "user": 67}}, {"pk": 504, "model": "server.award", "fields": {"date": "2010-04-21 10:35:49", "badge": 3, "user": 244}}, {"pk": 505, "model": "server.award", "fields": {"date": "2010-04-21 12:05:52", "badge": 3, "user": 55}}, {"pk": 506, "model": "server.award", "fields": {"date": "2010-04-21 16:20:48", "badge": 1, "user": 261}}, {"pk": 507, "model": "server.award", "fields": {"date": "2010-04-22 16:05:51", "badge": 6, "user": 82}}, {"pk": 508, "model": "server.award", "fields": {"date": "2010-04-22 16:50:51", "badge": 2, "user": 262}}, {"pk": 509, "model": "server.award", "fields": {"date": "2010-04-22 17:50:49", "badge": 6, "user": 264}}, {"pk": 510, "model": "server.award", "fields": {"date": "2010-04-23 02:20:47", "badge": 19, "user": 29}}, {"pk": 511, "model": "server.award", "fields": {"date": "2010-04-23 02:35:48", "badge": 1, "user": 265}}, {"pk": 512, "model": "server.award", "fields": {"date": "2010-04-23 09:35:47", "badge": 2, "user": 267}}, {"pk": 513, "model": "server.award", "fields": {"date": "2010-04-23 12:05:52", "badge": 19, "user": 86}}, {"pk": 514, "model": "server.award", "fields": {"date": "2010-04-23 15:50:48", "badge": 1, "user": 268}}, {"pk": 515, "model": "server.award", "fields": {"date": "2010-04-23 16:20:49", "badge": 2, "user": 126}}, {"pk": 516, "model": "server.award", "fields": {"date": "2010-04-23 21:35:49", "badge": 29, "user": 204}}, {"pk": 517, "model": "server.award", "fields": {"date": "2010-04-24 06:20:48", "badge": 10, "user": 85}}, {"pk": 518, "model": "server.award", "fields": {"date": "2010-04-24 08:50:46", "badge": 1, "user": 237}}, {"pk": 519, "model": "server.award", "fields": {"date": "2010-04-24 14:20:47", "badge": 6, "user": 270}}, {"pk": 520, "model": "server.award", "fields": {"date": "2010-04-24 14:50:46", "badge": 19, "user": 37}}, {"pk": 521, "model": "server.award", "fields": {"date": "2010-04-24 15:50:46", "badge": 2, "user": 270}}, {"pk": 522, "model": "server.award", "fields": {"date": "2010-04-24 19:20:47", "badge": 1, "user": 271}}, {"pk": 523, "model": "server.award", "fields": {"date": "2010-04-25 02:20:47", "badge": 10, "user": 89}}, {"pk": 524, "model": "server.award", "fields": {"date": "2010-04-25 09:20:50", "badge": 1, "user": 270}}, {"pk": 525, "model": "server.award", "fields": {"date": "2010-04-25 18:20:49", "badge": 6, "user": 272}}, {"pk": 526, "model": "server.award", "fields": {"date": "2010-04-25 18:20:49", "badge": 9, "user": 272}}, {"pk": 527, "model": "server.award", "fields": {"date": "2010-04-25 19:35:49", "badge": 9, "user": 273}}, {"pk": 528, "model": "server.award", "fields": {"date": "2010-04-26 00:20:47", "badge": 1, "user": 245}}, {"pk": 529, "model": "server.award", "fields": {"date": "2010-04-26 12:20:47", "badge": 1, "user": 274}}, {"pk": 530, "model": "server.award", "fields": {"date": "2010-04-26 13:50:47", "badge": 5, "user": 233}}, {"pk": 531, "model": "server.award", "fields": {"date": "2010-04-26 15:50:52", "badge": 10, "user": 126}}, {"pk": 532, "model": "server.award", "fields": {"date": "2010-04-26 17:35:48", "badge": 6, "user": 275}}, {"pk": 533, "model": "server.award", "fields": {"date": "2010-04-26 18:20:47", "badge": 6, "user": 276}}, {"pk": 534, "model": "server.award", "fields": {"date": "2010-04-26 18:35:47", "badge": 22, "user": 22}}, {"pk": 535, "model": "server.award", "fields": {"date": "2010-04-26 22:35:48", "badge": 2, "user": 278}}, {"pk": 536, "model": "server.award", "fields": {"date": "2010-04-27 01:35:48", "badge": 2, "user": 96}}, {"pk": 537, "model": "server.award", "fields": {"date": "2010-04-27 02:20:47", "badge": 1, "user": 275}}, {"pk": 538, "model": "server.award", "fields": {"date": "2010-04-27 02:20:47", "badge": 1, "user": 277}}, {"pk": 539, "model": "server.award", "fields": {"date": "2010-04-27 04:20:48", "badge": 3, "user": 265}}, {"pk": 540, "model": "server.award", "fields": {"date": "2010-04-27 05:50:47", "badge": 2, "user": 252}}, {"pk": 541, "model": "server.award", "fields": {"date": "2010-04-27 06:20:47", "badge": 6, "user": 279}}, {"pk": 542, "model": "server.award", "fields": {"date": "2010-04-27 10:05:47", "badge": 7, "user": 233}}, {"pk": 543, "model": "server.award", "fields": {"date": "2010-04-27 11:50:48", "badge": 1, "user": 69}}, {"pk": 544, "model": "server.award", "fields": {"date": "2010-04-27 13:20:47", "badge": 22, "user": 1}}, {"pk": 545, "model": "server.award", "fields": {"date": "2010-04-27 13:50:48", "badge": 9, "user": 69}}, {"pk": 546, "model": "server.award", "fields": {"date": "2010-04-27 14:20:48", "badge": 22, "user": 22}}, {"pk": 547, "model": "server.award", "fields": {"date": "2010-04-27 17:20:48", "badge": 3, "user": 224}}, {"pk": 548, "model": "server.award", "fields": {"date": "2010-04-27 17:20:48", "badge": 5, "user": 126}}, {"pk": 549, "model": "server.award", "fields": {"date": "2010-04-28 06:35:48", "badge": 29, "user": 270}}, {"pk": 550, "model": "server.award", "fields": {"date": "2010-04-28 13:20:50", "badge": 6, "user": 216}}, {"pk": 551, "model": "server.award", "fields": {"date": "2010-04-28 13:35:48", "badge": 2, "user": 250}}, {"pk": 552, "model": "server.award", "fields": {"date": "2010-04-28 14:20:48", "badge": 2, "user": 255}}, {"pk": 553, "model": "server.award", "fields": {"date": "2010-04-28 14:50:47", "badge": 3, "user": 270}}, {"pk": 554, "model": "server.award", "fields": {"date": "2010-04-28 14:50:47", "badge": 6, "user": 245}}, {"pk": 555, "model": "server.award", "fields": {"date": "2010-04-28 15:05:49", "badge": 1, "user": 282}}, {"pk": 556, "model": "server.award", "fields": {"date": "2010-04-28 16:50:48", "badge": 3, "user": 277}}, {"pk": 557, "model": "server.award", "fields": {"date": "2010-04-29 03:50:50", "badge": 2, "user": 284}}, {"pk": 558, "model": "server.award", "fields": {"date": "2010-04-29 04:50:47", "badge": 6, "user": 252}}, {"pk": 559, "model": "server.award", "fields": {"date": "2010-04-29 06:20:48", "badge": 6, "user": 38}}, {"pk": 560, "model": "server.award", "fields": {"date": "2010-04-29 07:05:48", "badge": 6, "user": 255}}, {"pk": 561, "model": "server.award", "fields": {"date": "2010-04-29 07:35:49", "badge": 3, "user": 255}}, {"pk": 562, "model": "server.award", "fields": {"date": "2010-04-29 08:50:46", "badge": 2, "user": 274}}, {"pk": 563, "model": "server.award", "fields": {"date": "2010-04-29 12:20:48", "badge": 2, "user": 53}}, {"pk": 564, "model": "server.award", "fields": {"date": "2010-04-29 12:35:48", "badge": 10, "user": 198}}, {"pk": 565, "model": "server.award", "fields": {"date": "2010-04-29 13:05:47", "badge": 1, "user": 286}}, {"pk": 566, "model": "server.award", "fields": {"date": "2010-04-29 13:05:47", "badge": 2, "user": 268}}, {"pk": 567, "model": "server.award", "fields": {"date": "2010-04-29 13:05:48", "badge": 6, "user": 286}}, {"pk": 568, "model": "server.award", "fields": {"date": "2010-04-29 14:20:47", "badge": 6, "user": 119}}, {"pk": 569, "model": "server.award", "fields": {"date": "2010-04-29 14:50:48", "badge": 6, "user": 53}}, {"pk": 570, "model": "server.award", "fields": {"date": "2010-04-29 15:35:47", "badge": 3, "user": 284}}, {"pk": 571, "model": "server.award", "fields": {"date": "2010-04-29 15:50:48", "badge": 6, "user": 274}}, {"pk": 572, "model": "server.award", "fields": {"date": "2010-04-30 07:35:48", "badge": 6, "user": 284}}, {"pk": 573, "model": "server.award", "fields": {"date": "2010-04-30 12:05:53", "badge": 5, "user": 286}}, {"pk": 574, "model": "server.award", "fields": {"date": "2010-05-01 10:05:47", "badge": 9, "user": 291}}, {"pk": 575, "model": "server.award", "fields": {"date": "2010-05-01 12:35:47", "badge": 5, "user": 291}}, {"pk": 576, "model": "server.award", "fields": {"date": "2010-05-01 18:05:47", "badge": 6, "user": 262}}, {"pk": 577, "model": "server.award", "fields": {"date": "2010-05-02 01:05:49", "badge": 37, "user": 35}}, {"pk": 578, "model": "server.award", "fields": {"date": "2010-05-02 06:05:48", "badge": 10, "user": 284}}, {"pk": 579, "model": "server.award", "fields": {"date": "2010-05-02 08:05:47", "badge": 7, "user": 204}}, {"pk": 580, "model": "server.award", "fields": {"date": "2010-05-02 08:05:47", "badge": 10, "user": 262}}, {"pk": 581, "model": "server.award", "fields": {"date": "2010-05-03 15:35:48", "badge": 7, "user": 85}}, {"pk": 582, "model": "server.award", "fields": {"date": "2010-05-03 17:50:49", "badge": 2, "user": 294}}, {"pk": 583, "model": "server.award", "fields": {"date": "2010-05-04 01:50:48", "badge": 6, "user": 295}}, {"pk": 584, "model": "server.award", "fields": {"date": "2010-05-04 14:35:46", "badge": 2, "user": 296}}, {"pk": 585, "model": "server.award", "fields": {"date": "2010-05-05 16:05:47", "badge": 6, "user": 16}}, {"pk": 586, "model": "server.award", "fields": {"date": "2010-05-05 16:20:47", "badge": 14, "user": 29}}, {"pk": 587, "model": "server.award", "fields": {"date": "2010-05-05 20:20:47", "badge": 2, "user": 299}}, {"pk": 588, "model": "server.award", "fields": {"date": "2010-05-06 00:35:48", "badge": 9, "user": 301}}, {"pk": 589, "model": "server.award", "fields": {"date": "2010-05-06 00:35:49", "badge": 37, "user": 3}}, {"pk": 590, "model": "server.award", "fields": {"date": "2010-05-06 01:20:49", "badge": 1, "user": 252}}, {"pk": 591, "model": "server.award", "fields": {"date": "2010-05-06 01:20:49", "badge": 2, "user": 301}}, {"pk": 592, "model": "server.award", "fields": {"date": "2010-05-06 07:50:49", "badge": 10, "user": 200}}, {"pk": 593, "model": "server.award", "fields": {"date": "2010-05-06 09:05:49", "badge": 6, "user": 145}}, {"pk": 594, "model": "server.award", "fields": {"date": "2010-05-06 10:05:47", "badge": 1, "user": 186}}, {"pk": 595, "model": "server.award", "fields": {"date": "2010-05-06 10:35:48", "badge": 2, "user": 303}}, {"pk": 596, "model": "server.award", "fields": {"date": "2010-05-06 10:50:47", "badge": 6, "user": 303}}, {"pk": 597, "model": "server.award", "fields": {"date": "2010-05-06 12:20:47", "badge": 6, "user": 301}}, {"pk": 598, "model": "server.award", "fields": {"date": "2010-05-06 12:20:47", "badge": 10, "user": 301}}, {"pk": 599, "model": "server.award", "fields": {"date": "2010-05-06 13:05:47", "badge": 6, "user": 299}}, {"pk": 600, "model": "server.award", "fields": {"date": "2010-05-06 13:05:47", "badge": 10, "user": 299}}, {"pk": 601, "model": "server.award", "fields": {"date": "2010-05-06 14:50:49", "badge": 10, "user": 186}}, {"pk": 602, "model": "server.award", "fields": {"date": "2010-05-06 15:50:48", "badge": 3, "user": 303}}, {"pk": 603, "model": "server.award", "fields": {"date": "2010-05-06 16:35:47", "badge": 1, "user": 303}}, {"pk": 604, "model": "server.award", "fields": {"date": "2010-05-06 18:05:47", "badge": 2, "user": 304}}, {"pk": 605, "model": "server.award", "fields": {"date": "2010-05-06 19:05:48", "badge": 1, "user": 304}}, {"pk": 606, "model": "server.award", "fields": {"date": "2010-05-06 23:05:48", "badge": 9, "user": 305}}, {"pk": 607, "model": "server.award", "fields": {"date": "2010-05-07 17:35:48", "badge": 29, "user": 85}}, {"pk": 608, "model": "server.award", "fields": {"date": "2010-05-08 18:35:47", "badge": 14, "user": 303}}, {"pk": 609, "model": "server.award", "fields": {"date": "2010-05-08 21:20:47", "badge": 3, "user": 301}}, {"pk": 610, "model": "server.award", "fields": {"date": "2010-05-09 01:05:46", "badge": 37, "user": 86}}, {"pk": 611, "model": "server.award", "fields": {"date": "2010-05-09 09:50:47", "badge": 1, "user": 308}}, {"pk": 612, "model": "server.award", "fields": {"date": "2010-05-09 10:05:46", "badge": 1, "user": 306}}, {"pk": 613, "model": "server.award", "fields": {"date": "2010-05-09 17:50:46", "badge": 6, "user": 229}}, {"pk": 614, "model": "server.award", "fields": {"date": "2010-05-10 08:50:47", "badge": 2, "user": 309}}, {"pk": 615, "model": "server.award", "fields": {"date": "2010-05-11 03:35:47", "badge": 6, "user": 304}}, {"pk": 616, "model": "server.award", "fields": {"date": "2010-05-11 10:35:47", "badge": 2, "user": 311}}, {"pk": 617, "model": "server.award", "fields": {"date": "2010-05-11 13:35:46", "badge": 3, "user": 247}}, {"pk": 618, "model": "server.award", "fields": {"date": "2010-05-11 14:05:47", "badge": 2, "user": 312}}, {"pk": 619, "model": "server.award", "fields": {"date": "2010-05-12 02:35:47", "badge": 37, "user": 224}}, {"pk": 620, "model": "server.award", "fields": {"date": "2010-05-12 08:50:48", "badge": 2, "user": 315}}, {"pk": 621, "model": "server.award", "fields": {"date": "2010-05-12 11:05:49", "badge": 29, "user": 118}}, {"pk": 622, "model": "server.award", "fields": {"date": "2010-05-12 12:20:48", "badge": 10, "user": 247}}, {"pk": 623, "model": "server.award", "fields": {"date": "2010-05-12 13:50:48", "badge": 6, "user": 273}}, {"pk": 624, "model": "server.award", "fields": {"date": "2010-05-12 15:35:48", "badge": 1, "user": 273}}, {"pk": 625, "model": "server.award", "fields": {"date": "2010-05-12 15:35:48", "badge": 1, "user": 313}}, {"pk": 626, "model": "server.award", "fields": {"date": "2010-05-12 16:20:48", "badge": 6, "user": 199}}, {"pk": 627, "model": "server.award", "fields": {"date": "2010-05-12 21:05:49", "badge": 3, "user": 312}}, {"pk": 628, "model": "server.award", "fields": {"date": "2010-05-12 23:05:47", "badge": 3, "user": 134}}, {"pk": 629, "model": "server.award", "fields": {"date": "2010-05-13 02:05:47", "badge": 3, "user": 273}}, {"pk": 630, "model": "server.award", "fields": {"date": "2010-05-13 03:05:47", "badge": 37, "user": 213}}, {"pk": 631, "model": "server.award", "fields": {"date": "2010-05-13 09:35:47", "badge": 6, "user": 234}}, {"pk": 632, "model": "server.award", "fields": {"date": "2010-05-13 10:20:48", "badge": 6, "user": 311}}, {"pk": 633, "model": "server.award", "fields": {"date": "2010-05-13 10:35:46", "badge": 7, "user": 286}}, {"pk": 634, "model": "server.award", "fields": {"date": "2010-05-13 11:20:47", "badge": 6, "user": 106}}, {"pk": 635, "model": "server.award", "fields": {"date": "2010-05-13 13:05:47", "badge": 1, "user": 312}}, {"pk": 636, "model": "server.award", "fields": {"date": "2010-05-13 13:05:47", "badge": 2, "user": 247}}, {"pk": 637, "model": "server.award", "fields": {"date": "2010-05-13 18:35:48", "badge": 9, "user": 318}}, {"pk": 638, "model": "server.award", "fields": {"date": "2010-05-14 07:05:47", "badge": 10, "user": 315}}, {"pk": 639, "model": "server.award", "fields": {"date": "2010-05-14 07:20:47", "badge": 2, "user": 321}}, {"pk": 640, "model": "server.award", "fields": {"date": "2010-05-14 08:20:47", "badge": 1, "user": 320}}, {"pk": 641, "model": "server.award", "fields": {"date": "2010-05-14 13:05:48", "badge": 3, "user": 214}}, {"pk": 642, "model": "server.award", "fields": {"date": "2010-05-14 18:50:46", "badge": 29, "user": 71}}, {"pk": 643, "model": "server.award", "fields": {"date": "2010-05-14 23:50:46", "badge": 22, "user": 22}}, {"pk": 644, "model": "server.award", "fields": {"date": "2010-05-15 20:35:47", "badge": 9, "user": 322}}, {"pk": 645, "model": "server.award", "fields": {"date": "2010-05-17 00:05:47", "badge": 37, "user": 215}}, {"pk": 646, "model": "server.award", "fields": {"date": "2010-05-17 02:20:47", "badge": 14, "user": 312}}, {"pk": 647, "model": "server.award", "fields": {"date": "2010-05-17 12:20:46", "badge": 6, "user": 324}}, {"pk": 648, "model": "server.award", "fields": {"date": "2010-05-17 16:05:47", "badge": 6, "user": 320}}, {"pk": 649, "model": "server.award", "fields": {"date": "2010-05-17 16:35:48", "badge": 1, "user": 324}}, {"pk": 650, "model": "server.award", "fields": {"date": "2010-05-17 17:35:47", "badge": 1, "user": 325}}, {"pk": 651, "model": "server.award", "fields": {"date": "2010-05-17 21:50:47", "badge": 2, "user": 273}}, {"pk": 652, "model": "server.award", "fields": {"date": "2010-05-18 01:35:47", "badge": 3, "user": 327}}, {"pk": 653, "model": "server.award", "fields": {"date": "2010-05-18 02:50:47", "badge": 2, "user": 327}}, {"pk": 654, "model": "server.award", "fields": {"date": "2010-05-18 06:35:48", "badge": 3, "user": 324}}, {"pk": 655, "model": "server.award", "fields": {"date": "2010-05-18 09:20:46", "badge": 3, "user": 233}}, {"pk": 656, "model": "server.award", "fields": {"date": "2010-05-18 11:20:46", "badge": 2, "user": 328}}, {"pk": 657, "model": "server.award", "fields": {"date": "2010-05-18 11:35:47", "badge": 6, "user": 328}}, {"pk": 658, "model": "server.award", "fields": {"date": "2010-05-18 12:35:48", "badge": 9, "user": 329}}, {"pk": 659, "model": "server.award", "fields": {"date": "2010-05-18 13:05:47", "badge": 2, "user": 329}}, {"pk": 660, "model": "server.award", "fields": {"date": "2010-05-19 12:05:51", "badge": 2, "user": 333}}, {"pk": 661, "model": "server.award", "fields": {"date": "2010-05-19 23:05:47", "badge": 6, "user": 305}}, {"pk": 662, "model": "server.award", "fields": {"date": "2010-05-19 23:50:46", "badge": 9, "user": 104}}, {"pk": 663, "model": "server.award", "fields": {"date": "2010-05-20 01:05:48", "badge": 5, "user": 237}}, {"pk": 664, "model": "server.award", "fields": {"date": "2010-05-20 02:20:46", "badge": 3, "user": 333}}, {"pk": 665, "model": "server.award", "fields": {"date": "2010-05-20 02:35:48", "badge": 1, "user": 333}}, {"pk": 666, "model": "server.award", "fields": {"date": "2010-05-20 15:05:48", "badge": 29, "user": 312}}, {"pk": 667, "model": "server.award", "fields": {"date": "2010-05-20 15:35:47", "badge": 2, "user": 334}}, {"pk": 668, "model": "server.award", "fields": {"date": "2010-05-21 00:05:47", "badge": 2, "user": 335}}, {"pk": 669, "model": "server.award", "fields": {"date": "2010-05-21 01:50:46", "badge": 6, "user": 265}}, {"pk": 670, "model": "server.award", "fields": {"date": "2010-05-21 02:50:46", "badge": 2, "user": 324}}, {"pk": 671, "model": "server.award", "fields": {"date": "2010-05-21 09:50:47", "badge": 22, "user": 85}}, {"pk": 672, "model": "server.award", "fields": {"date": "2010-05-21 10:05:46", "badge": 6, "user": 334}}, {"pk": 673, "model": "server.award", "fields": {"date": "2010-05-21 13:35:48", "badge": 6, "user": 338}}, {"pk": 674, "model": "server.award", "fields": {"date": "2010-05-21 13:50:46", "badge": 2, "user": 339}}, {"pk": 675, "model": "server.award", "fields": {"date": "2010-05-21 13:50:46", "badge": 9, "user": 340}}, {"pk": 676, "model": "server.award", "fields": {"date": "2010-05-21 14:05:46", "badge": 1, "user": 337}}, {"pk": 677, "model": "server.award", "fields": {"date": "2010-05-21 14:05:46", "badge": 1, "user": 338}}, {"pk": 678, "model": "server.award", "fields": {"date": "2010-05-21 14:20:47", "badge": 2, "user": 338}}, {"pk": 679, "model": "server.award", "fields": {"date": "2010-05-21 14:20:47", "badge": 9, "user": 338}}, {"pk": 680, "model": "server.award", "fields": {"date": "2010-05-21 14:20:47", "badge": 30, "user": 215}}, {"pk": 681, "model": "server.award", "fields": {"date": "2010-05-21 14:35:46", "badge": 3, "user": 339}}, {"pk": 682, "model": "server.award", "fields": {"date": "2010-05-21 15:35:50", "badge": 3, "user": 338}}, {"pk": 683, "model": "server.award", "fields": {"date": "2010-05-22 09:05:48", "badge": 6, "user": 341}}, {"pk": 684, "model": "server.award", "fields": {"date": "2010-05-22 09:05:48", "badge": 9, "user": 341}}, {"pk": 685, "model": "server.award", "fields": {"date": "2010-05-22 16:20:47", "badge": 2, "user": 342}}, {"pk": 686, "model": "server.award", "fields": {"date": "2010-05-22 16:20:47", "badge": 9, "user": 85}}, {"pk": 687, "model": "server.award", "fields": {"date": "2010-05-22 19:05:47", "badge": 1, "user": 343}}, {"pk": 688, "model": "server.award", "fields": {"date": "2010-05-23 21:50:46", "badge": 1, "user": 344}}, {"pk": 689, "model": "server.award", "fields": {"date": "2010-05-24 06:50:49", "badge": 37, "user": 156}}, {"pk": 690, "model": "server.award", "fields": {"date": "2010-05-24 08:50:47", "badge": 3, "user": 345}}, {"pk": 691, "model": "server.award", "fields": {"date": "2010-05-24 12:35:48", "badge": 2, "user": 345}}, {"pk": 692, "model": "server.award", "fields": {"date": "2010-05-24 12:35:48", "badge": 2, "user": 348}}, {"pk": 693, "model": "server.award", "fields": {"date": "2010-05-24 19:35:47", "badge": 3, "user": 199}}, {"pk": 694, "model": "server.award", "fields": {"date": "2010-05-24 21:05:48", "badge": 6, "user": 312}}, {"pk": 695, "model": "server.award", "fields": {"date": "2010-05-24 21:05:48", "badge": 10, "user": 312}}, {"pk": 696, "model": "server.award", "fields": {"date": "2010-05-25 00:20:47", "badge": 2, "user": 350}}, {"pk": 697, "model": "server.award", "fields": {"date": "2010-05-25 00:20:47", "badge": 3, "user": 348}}, {"pk": 698, "model": "server.award", "fields": {"date": "2010-05-25 08:50:48", "badge": 2, "user": 320}}, {"pk": 699, "model": "server.award", "fields": {"date": "2010-05-25 10:50:49", "badge": 1, "user": 353}}, {"pk": 700, "model": "server.award", "fields": {"date": "2010-05-25 11:50:47", "badge": 6, "user": 333}}, {"pk": 701, "model": "server.award", "fields": {"date": "2010-05-25 11:50:47", "badge": 10, "user": 333}}, {"pk": 702, "model": "server.award", "fields": {"date": "2010-05-25 13:35:47", "badge": 9, "user": 356}}, {"pk": 703, "model": "server.award", "fields": {"date": "2010-05-25 14:35:47", "badge": 1, "user": 355}}, {"pk": 704, "model": "server.award", "fields": {"date": "2010-05-25 14:50:47", "badge": 6, "user": 339}}, {"pk": 705, "model": "server.award", "fields": {"date": "2010-05-25 22:20:49", "badge": 1, "user": 351}}, {"pk": 706, "model": "server.award", "fields": {"date": "2010-05-25 23:35:47", "badge": 2, "user": 358}}, {"pk": 707, "model": "server.award", "fields": {"date": "2010-05-26 03:35:47", "badge": 5, "user": 351}}, {"pk": 708, "model": "server.award", "fields": {"date": "2010-05-26 05:20:47", "badge": 6, "user": 351}}, {"pk": 709, "model": "server.award", "fields": {"date": "2010-05-26 07:05:46", "badge": 10, "user": 358}}, {"pk": 710, "model": "server.award", "fields": {"date": "2010-05-26 09:35:47", "badge": 22, "user": 37}}, {"pk": 711, "model": "server.award", "fields": {"date": "2010-05-26 10:20:45", "badge": 1, "user": 328}}, {"pk": 712, "model": "server.award", "fields": {"date": "2010-05-26 14:05:48", "badge": 22, "user": 65}}, {"pk": 713, "model": "server.award", "fields": {"date": "2010-05-26 14:35:48", "badge": 2, "user": 359}}, {"pk": 714, "model": "server.award", "fields": {"date": "2010-05-26 21:50:48", "badge": 22, "user": 58}}, {"pk": 715, "model": "server.award", "fields": {"date": "2010-05-26 23:20:46", "badge": 1, "user": 360}}, {"pk": 716, "model": "server.award", "fields": {"date": "2010-05-27 03:20:47", "badge": 5, "user": 85}}, {"pk": 717, "model": "server.award", "fields": {"date": "2010-05-27 04:50:47", "badge": 3, "user": 65}}, {"pk": 718, "model": "server.award", "fields": {"date": "2010-05-27 07:35:48", "badge": 14, "user": 320}}, {"pk": 719, "model": "server.award", "fields": {"date": "2010-05-27 11:05:46", "badge": 1, "user": 361}}, {"pk": 720, "model": "server.award", "fields": {"date": "2010-05-27 12:05:51", "badge": 38, "user": 22}}, {"pk": 721, "model": "server.award", "fields": {"date": "2010-05-27 12:35:46", "badge": 9, "user": 362}}, {"pk": 722, "model": "server.award", "fields": {"date": "2010-05-27 13:50:47", "badge": 9, "user": 6}}, {"pk": 723, "model": "server.award", "fields": {"date": "2010-05-27 14:35:49", "badge": 1, "user": 364}}, {"pk": 724, "model": "server.award", "fields": {"date": "2010-05-27 15:20:46", "badge": 29, "user": 324}}, {"pk": 725, "model": "server.award", "fields": {"date": "2010-05-27 16:05:46", "badge": 6, "user": 361}}, {"pk": 726, "model": "server.award", "fields": {"date": "2010-05-27 16:20:47", "badge": 2, "user": 202}}, {"pk": 727, "model": "server.award", "fields": {"date": "2010-05-27 19:50:47", "badge": 3, "user": 234}}, {"pk": 728, "model": "server.award", "fields": {"date": "2010-05-27 23:35:48", "badge": 3, "user": 19}}, {"pk": 729, "model": "server.award", "fields": {"date": "2010-05-27 23:50:49", "badge": 2, "user": 204}}, {"pk": 730, "model": "server.award", "fields": {"date": "2010-05-28 03:05:47", "badge": 1, "user": 365}}, {"pk": 731, "model": "server.award", "fields": {"date": "2010-05-28 05:35:48", "badge": 29, "user": 284}}, {"pk": 732, "model": "server.award", "fields": {"date": "2010-05-28 06:50:47", "badge": 9, "user": 366}}, {"pk": 733, "model": "server.award", "fields": {"date": "2010-05-28 07:35:47", "badge": 3, "user": 186}}, {"pk": 734, "model": "server.award", "fields": {"date": "2010-05-28 13:05:46", "badge": 29, "user": 37}}, {"pk": 735, "model": "server.award", "fields": {"date": "2010-05-28 16:50:47", "badge": 1, "user": 247}}, {"pk": 736, "model": "server.award", "fields": {"date": "2010-05-31 11:05:47", "badge": 1, "user": 370}}, {"pk": 737, "model": "server.award", "fields": {"date": "2010-05-31 14:05:47", "badge": 7, "user": 199}}, {"pk": 738, "model": "server.award", "fields": {"date": "2010-05-31 14:05:47", "badge": 29, "user": 145}}, {"pk": 739, "model": "server.award", "fields": {"date": "2010-05-31 15:20:46", "badge": 9, "user": 371}}, {"pk": 740, "model": "server.award", "fields": {"date": "2010-06-01 07:50:47", "badge": 1, "user": 374}}, {"pk": 741, "model": "server.award", "fields": {"date": "2010-06-01 07:50:47", "badge": 9, "user": 374}}, {"pk": 742, "model": "server.award", "fields": {"date": "2010-06-01 08:35:48", "badge": 6, "user": 374}}, {"pk": 743, "model": "server.award", "fields": {"date": "2010-06-01 09:20:48", "badge": 2, "user": 375}}, {"pk": 744, "model": "server.award", "fields": {"date": "2010-06-01 10:35:47", "badge": 6, "user": 373}}, {"pk": 745, "model": "server.award", "fields": {"date": "2010-06-01 12:35:48", "badge": 1, "user": 284}}, {"pk": 746, "model": "server.award", "fields": {"date": "2010-06-01 12:50:46", "badge": 6, "user": 376}}, {"pk": 747, "model": "server.award", "fields": {"date": "2010-06-01 13:20:47", "badge": 2, "user": 376}}, {"pk": 748, "model": "server.award", "fields": {"date": "2010-06-01 13:20:47", "badge": 6, "user": 377}}, {"pk": 749, "model": "server.award", "fields": {"date": "2010-06-01 13:20:47", "badge": 29, "user": 121}}, {"pk": 750, "model": "server.award", "fields": {"date": "2010-06-01 14:05:47", "badge": 3, "user": 69}}, {"pk": 751, "model": "server.award", "fields": {"date": "2010-06-01 18:05:48", "badge": 5, "user": 61}}, {"pk": 752, "model": "server.award", "fields": {"date": "2010-06-01 21:35:49", "badge": 14, "user": 224}}, {"pk": 753, "model": "server.award", "fields": {"date": "2010-06-01 23:05:47", "badge": 6, "user": 379}}, {"pk": 754, "model": "server.award", "fields": {"date": "2010-06-02 03:50:48", "badge": 19, "user": 22}}, {"pk": 755, "model": "server.award", "fields": {"date": "2010-06-02 10:05:47", "badge": 7, "user": 69}}, {"pk": 756, "model": "server.award", "fields": {"date": "2010-06-02 12:05:52", "badge": 10, "user": 376}}, {"pk": 757, "model": "server.award", "fields": {"date": "2010-06-02 13:35:49", "badge": 2, "user": 137}}, {"pk": 758, "model": "server.award", "fields": {"date": "2010-06-02 14:20:48", "badge": 5, "user": 69}}, {"pk": 759, "model": "server.award", "fields": {"date": "2010-06-02 15:05:47", "badge": 1, "user": 380}}, {"pk": 760, "model": "server.award", "fields": {"date": "2010-06-02 15:05:47", "badge": 6, "user": 380}}, {"pk": 761, "model": "server.award", "fields": {"date": "2010-06-02 15:05:47", "badge": 7, "user": 3}}, {"pk": 762, "model": "server.award", "fields": {"date": "2010-06-02 18:20:47", "badge": 3, "user": 299}}, {"pk": 763, "model": "server.award", "fields": {"date": "2010-06-03 09:35:47", "badge": 3, "user": 374}}, {"pk": 764, "model": "server.award", "fields": {"date": "2010-06-03 12:20:48", "badge": 10, "user": 137}}, {"pk": 765, "model": "server.award", "fields": {"date": "2010-06-03 15:20:47", "badge": 3, "user": 3}}, {"pk": 766, "model": "server.award", "fields": {"date": "2010-06-04 03:50:46", "badge": 6, "user": 385}}, {"pk": 767, "model": "server.award", "fields": {"date": "2010-06-04 03:50:46", "badge": 22, "user": 35}}, {"pk": 768, "model": "server.award", "fields": {"date": "2010-06-04 13:50:48", "badge": 10, "user": 199}}, {"pk": 769, "model": "server.award", "fields": {"date": "2010-06-04 16:05:48", "badge": 3, "user": 165}}, {"pk": 770, "model": "server.award", "fields": {"date": "2010-06-05 02:50:48", "badge": 3, "user": 387}}, {"pk": 771, "model": "server.award", "fields": {"date": "2010-06-05 04:50:47", "badge": 2, "user": 387}}, {"pk": 772, "model": "server.award", "fields": {"date": "2010-06-05 15:20:45", "badge": 6, "user": 387}}, {"pk": 773, "model": "server.award", "fields": {"date": "2010-06-06 09:50:46", "badge": 2, "user": 388}}, {"pk": 774, "model": "server.award", "fields": {"date": "2010-06-06 15:05:46", "badge": 22, "user": 55}}, {"pk": 775, "model": "server.award", "fields": {"date": "2010-06-08 00:35:47", "badge": 37, "user": 65}}, {"pk": 776, "model": "server.award", "fields": {"date": "2010-06-08 08:20:47", "badge": 6, "user": 363}}, {"pk": 777, "model": "server.award", "fields": {"date": "2010-06-08 13:05:46", "badge": 1, "user": 36}}, {"pk": 778, "model": "server.award", "fields": {"date": "2010-06-08 13:05:46", "badge": 1, "user": 394}}, {"pk": 779, "model": "server.award", "fields": {"date": "2010-06-08 13:05:46", "badge": 2, "user": 393}}, {"pk": 780, "model": "server.award", "fields": {"date": "2010-06-08 14:50:47", "badge": 2, "user": 397}}, {"pk": 781, "model": "server.award", "fields": {"date": "2010-06-08 16:20:47", "badge": 10, "user": 397}}, {"pk": 782, "model": "server.award", "fields": {"date": "2010-06-08 17:05:46", "badge": 1, "user": 396}}, {"pk": 783, "model": "server.award", "fields": {"date": "2010-06-09 05:20:47", "badge": 2, "user": 313}}, {"pk": 784, "model": "server.award", "fields": {"date": "2010-06-09 05:20:47", "badge": 2, "user": 398}}, {"pk": 785, "model": "server.award", "fields": {"date": "2010-06-09 05:35:47", "badge": 9, "user": 399}}, {"pk": 786, "model": "server.award", "fields": {"date": "2010-06-09 06:20:46", "badge": 37, "user": 247}}, {"pk": 787, "model": "server.award", "fields": {"date": "2010-06-09 09:05:47", "badge": 3, "user": 343}}, {"pk": 788, "model": "server.award", "fields": {"date": "2010-06-09 09:50:47", "badge": 6, "user": 343}}, {"pk": 789, "model": "server.award", "fields": {"date": "2010-06-09 10:05:46", "badge": 6, "user": 400}}, {"pk": 790, "model": "server.award", "fields": {"date": "2010-06-09 12:05:52", "badge": 3, "user": 400}}, {"pk": 791, "model": "server.award", "fields": {"date": "2010-06-09 12:20:47", "badge": 1, "user": 401}}, {"pk": 792, "model": "server.award", "fields": {"date": "2010-06-09 12:20:47", "badge": 7, "user": 234}}, {"pk": 793, "model": "server.award", "fields": {"date": "2010-06-09 13:20:47", "badge": 7, "user": 217}}, {"pk": 794, "model": "server.award", "fields": {"date": "2010-06-09 16:20:47", "badge": 3, "user": 404}}, {"pk": 795, "model": "server.award", "fields": {"date": "2010-06-09 20:50:50", "badge": 2, "user": 404}}, {"pk": 796, "model": "server.award", "fields": {"date": "2010-06-10 10:50:47", "badge": 10, "user": 339}}, {"pk": 797, "model": "server.award", "fields": {"date": "2010-06-10 11:20:46", "badge": 9, "user": 397}}, {"pk": 798, "model": "server.award", "fields": {"date": "2010-06-10 12:05:50", "badge": 10, "user": 141}}, {"pk": 799, "model": "server.award", "fields": {"date": "2010-06-10 13:05:47", "badge": 7, "user": 224}}, {"pk": 800, "model": "server.award", "fields": {"date": "2010-06-10 14:50:46", "badge": 1, "user": 406}}, {"pk": 801, "model": "server.award", "fields": {"date": "2010-06-10 20:35:47", "badge": 9, "user": 122}}, {"pk": 802, "model": "server.award", "fields": {"date": "2010-06-11 05:20:45", "badge": 2, "user": 400}}, {"pk": 803, "model": "server.award", "fields": {"date": "2010-06-11 06:50:46", "badge": 3, "user": 397}}, {"pk": 804, "model": "server.award", "fields": {"date": "2010-06-11 11:35:46", "badge": 2, "user": 409}}, {"pk": 805, "model": "server.award", "fields": {"date": "2010-06-11 14:20:46", "badge": 6, "user": 401}}, {"pk": 806, "model": "server.award", "fields": {"date": "2010-06-11 14:35:46", "badge": 2, "user": 408}}, {"pk": 807, "model": "server.award", "fields": {"date": "2010-06-11 21:35:47", "badge": 25, "user": 15}}, {"pk": 808, "model": "server.award", "fields": {"date": "2010-06-13 15:20:48", "badge": 2, "user": 123}}, {"pk": 809, "model": "server.award", "fields": {"date": "2010-06-14 06:35:47", "badge": 2, "user": 134}}, {"pk": 810, "model": "server.award", "fields": {"date": "2010-06-14 07:35:48", "badge": 29, "user": 233}}, {"pk": 811, "model": "server.award", "fields": {"date": "2010-06-14 11:05:47", "badge": 2, "user": 410}}, {"pk": 812, "model": "server.award", "fields": {"date": "2010-06-14 15:20:47", "badge": 6, "user": 416}}, {"pk": 813, "model": "server.award", "fields": {"date": "2010-06-14 17:35:47", "badge": 6, "user": 123}}, {"pk": 814, "model": "server.award", "fields": {"date": "2010-06-14 18:50:48", "badge": 6, "user": 134}}, {"pk": 815, "model": "server.award", "fields": {"date": "2010-06-15 08:35:47", "badge": 2, "user": 65}}, {"pk": 816, "model": "server.award", "fields": {"date": "2010-06-15 11:35:47", "badge": 3, "user": 396}}, {"pk": 817, "model": "server.award", "fields": {"date": "2010-06-15 14:35:46", "badge": 2, "user": 418}}, {"pk": 818, "model": "server.award", "fields": {"date": "2010-06-15 19:05:46", "badge": 2, "user": 46}}, {"pk": 819, "model": "server.award", "fields": {"date": "2010-06-15 19:20:47", "badge": 2, "user": 234}}, {"pk": 820, "model": "server.award", "fields": {"date": "2010-06-15 19:20:47", "badge": 2, "user": 415}}, {"pk": 821, "model": "server.award", "fields": {"date": "2010-06-15 19:20:47", "badge": 10, "user": 116}}, {"pk": 822, "model": "server.award", "fields": {"date": "2010-06-15 22:50:47", "badge": 19, "user": 199}}, {"pk": 823, "model": "server.award", "fields": {"date": "2010-06-16 04:20:46", "badge": 10, "user": 328}}, {"pk": 824, "model": "server.award", "fields": {"date": "2010-06-16 08:50:47", "badge": 29, "user": 186}}, {"pk": 825, "model": "server.award", "fields": {"date": "2010-06-16 15:05:47", "badge": 1, "user": 421}}, {"pk": 826, "model": "server.award", "fields": {"date": "2010-06-16 17:35:48", "badge": 5, "user": 116}}, {"pk": 827, "model": "server.award", "fields": {"date": "2010-06-16 17:35:48", "badge": 29, "user": 397}}, {"pk": 828, "model": "server.award", "fields": {"date": "2010-06-17 08:05:48", "badge": 6, "user": 397}}, {"pk": 829, "model": "server.award", "fields": {"date": "2010-06-17 15:20:49", "badge": 2, "user": 424}}, {"pk": 830, "model": "server.award", "fields": {"date": "2010-06-17 20:20:48", "badge": 22, "user": 63}}, {"pk": 831, "model": "server.award", "fields": {"date": "2010-06-18 02:05:48", "badge": 2, "user": 426}}, {"pk": 832, "model": "server.award", "fields": {"date": "2010-06-18 11:20:47", "badge": 1, "user": 397}}, {"pk": 833, "model": "server.award", "fields": {"date": "2010-06-19 02:35:48", "badge": 1, "user": 429}}, {"pk": 834, "model": "server.award", "fields": {"date": "2010-06-21 04:20:48", "badge": 6, "user": 430}}, {"pk": 835, "model": "server.award", "fields": {"date": "2010-06-21 13:20:48", "badge": 37, "user": 37}}, {"pk": 836, "model": "server.award", "fields": {"date": "2010-06-21 15:05:47", "badge": 2, "user": 73}}, {"pk": 837, "model": "server.award", "fields": {"date": "2010-06-21 15:50:47", "badge": 7, "user": 343}}, {"pk": 838, "model": "server.award", "fields": {"date": "2010-06-21 18:35:47", "badge": 10, "user": 73}}, {"pk": 839, "model": "server.award", "fields": {"date": "2010-06-22 21:05:48", "badge": 1, "user": 433}}, {"pk": 840, "model": "server.award", "fields": {"date": "2010-06-22 21:50:49", "badge": 1, "user": 435}}, {"pk": 841, "model": "server.award", "fields": {"date": "2010-06-23 01:50:47", "badge": 37, "user": 351}}, {"pk": 842, "model": "server.award", "fields": {"date": "2010-06-23 10:20:47", "badge": 2, "user": 343}}, {"pk": 843, "model": "server.award", "fields": {"date": "2010-06-23 12:35:47", "badge": 10, "user": 343}}, {"pk": 844, "model": "server.award", "fields": {"date": "2010-06-24 02:35:46", "badge": 38, "user": 126}}, {"pk": 845, "model": "server.award", "fields": {"date": "2010-06-24 04:20:48", "badge": 29, "user": 328}}, {"pk": 846, "model": "server.award", "fields": {"date": "2010-06-24 04:35:46", "badge": 1, "user": 438}}, {"pk": 847, "model": "server.award", "fields": {"date": "2010-06-24 20:50:48", "badge": 3, "user": 441}}, {"pk": 848, "model": "server.award", "fields": {"date": "2010-06-24 21:20:46", "badge": 1, "user": 441}}, {"pk": 849, "model": "server.award", "fields": {"date": "2010-06-25 00:50:46", "badge": 2, "user": 55}}, {"pk": 850, "model": "server.award", "fields": {"date": "2010-06-27 06:35:46", "badge": 6, "user": 166}}, {"pk": 851, "model": "server.award", "fields": {"date": "2010-06-27 06:35:46", "badge": 19, "user": 73}}, {"pk": 852, "model": "server.award", "fields": {"date": "2010-06-28 00:50:47", "badge": 7, "user": 151}}, {"pk": 853, "model": "server.award", "fields": {"date": "2010-06-28 11:05:46", "badge": 22, "user": 85}}, {"pk": 854, "model": "server.award", "fields": {"date": "2010-06-29 11:05:46", "badge": 3, "user": 418}}, {"pk": 855, "model": "server.award", "fields": {"date": "2010-06-29 11:20:47", "badge": 1, "user": 418}}, {"pk": 856, "model": "server.award", "fields": {"date": "2010-06-29 11:20:47", "badge": 1, "user": 443}}, {"pk": 857, "model": "server.award", "fields": {"date": "2010-06-29 11:20:47", "badge": 2, "user": 444}}, {"pk": 858, "model": "server.award", "fields": {"date": "2010-06-29 11:35:47", "badge": 10, "user": 55}}, {"pk": 859, "model": "server.award", "fields": {"date": "2010-06-29 14:05:49", "badge": 29, "user": 299}}, {"pk": 860, "model": "server.award", "fields": {"date": "2010-06-29 15:20:47", "badge": 6, "user": 445}}, {"pk": 861, "model": "server.award", "fields": {"date": "2010-06-29 19:05:46", "badge": 2, "user": 446}}, {"pk": 862, "model": "server.award", "fields": {"date": "2010-06-30 00:05:48", "badge": 2, "user": 447}}, {"pk": 863, "model": "server.award", "fields": {"date": "2010-06-30 06:05:48", "badge": 19, "user": 58}}, {"pk": 864, "model": "server.award", "fields": {"date": "2010-06-30 07:20:47", "badge": 1, "user": 414}}, {"pk": 865, "model": "server.award", "fields": {"date": "2010-06-30 08:05:46", "badge": 3, "user": 444}}, {"pk": 866, "model": "server.award", "fields": {"date": "2010-06-30 08:50:47", "badge": 30, "user": 58}}, {"pk": 867, "model": "server.award", "fields": {"date": "2010-06-30 17:35:48", "badge": 10, "user": 447}}, {"pk": 868, "model": "server.award", "fields": {"date": "2010-06-30 19:50:48", "badge": 6, "user": 232}}, {"pk": 869, "model": "server.award", "fields": {"date": "2010-06-30 20:20:50", "badge": 6, "user": 418}}, {"pk": 870, "model": "server.award", "fields": {"date": "2010-07-01 05:20:47", "badge": 6, "user": 414}}, {"pk": 871, "model": "server.award", "fields": {"date": "2010-07-01 06:50:48", "badge": 1, "user": 299}}, {"pk": 872, "model": "server.award", "fields": {"date": "2010-07-01 07:20:47", "badge": 2, "user": 450}}, {"pk": 873, "model": "server.award", "fields": {"date": "2010-07-01 12:50:49", "badge": 2, "user": 452}}, {"pk": 874, "model": "server.award", "fields": {"date": "2010-07-01 13:20:49", "badge": 22, "user": 58}}, {"pk": 875, "model": "server.award", "fields": {"date": "2010-07-01 13:35:47", "badge": 2, "user": 451}}, {"pk": 876, "model": "server.award", "fields": {"date": "2010-07-01 15:05:48", "badge": 29, "user": 199}}, {"pk": 877, "model": "server.award", "fields": {"date": "2010-07-01 19:20:48", "badge": 2, "user": 346}}, {"pk": 878, "model": "server.award", "fields": {"date": "2010-07-01 23:05:49", "badge": 3, "user": 453}}, {"pk": 879, "model": "server.award", "fields": {"date": "2010-07-01 23:35:47", "badge": 2, "user": 454}}, {"pk": 880, "model": "server.award", "fields": {"date": "2010-07-02 00:35:50", "badge": 1, "user": 453}}, {"pk": 881, "model": "server.award", "fields": {"date": "2010-07-02 01:20:48", "badge": 37, "user": 324}}, {"pk": 882, "model": "server.award", "fields": {"date": "2010-07-02 07:50:48", "badge": 10, "user": 444}}, {"pk": 883, "model": "server.award", "fields": {"date": "2010-07-02 13:50:48", "badge": 6, "user": 451}}, {"pk": 884, "model": "server.award", "fields": {"date": "2010-07-02 13:50:48", "badge": 10, "user": 451}}, {"pk": 885, "model": "server.award", "fields": {"date": "2010-07-02 17:20:47", "badge": 1, "user": 451}}, {"pk": 886, "model": "server.award", "fields": {"date": "2010-07-02 18:35:48", "badge": 18, "user": 58}}, {"pk": 887, "model": "server.award", "fields": {"date": "2010-07-02 22:20:47", "badge": 1, "user": 457}}, {"pk": 888, "model": "server.award", "fields": {"date": "2010-07-02 22:20:47", "badge": 6, "user": 453}}, {"pk": 889, "model": "server.award", "fields": {"date": "2010-07-04 12:20:48", "badge": 37, "user": 69}}, {"pk": 890, "model": "server.award", "fields": {"date": "2010-07-05 07:35:47", "badge": 1, "user": 341}}, {"pk": 891, "model": "server.award", "fields": {"date": "2010-07-05 07:35:47", "badge": 2, "user": 341}}, {"pk": 892, "model": "server.award", "fields": {"date": "2010-07-05 12:20:47", "badge": 6, "user": 460}}, {"pk": 893, "model": "server.award", "fields": {"date": "2010-07-05 12:50:48", "badge": 1, "user": 460}}, {"pk": 894, "model": "server.award", "fields": {"date": "2010-07-05 16:50:50", "badge": 1, "user": 459}}, {"pk": 895, "model": "server.award", "fields": {"date": "2010-07-06 01:05:48", "badge": 3, "user": 341}}, {"pk": 896, "model": "server.award", "fields": {"date": "2010-07-06 09:35:51", "badge": 2, "user": 463}}, {"pk": 897, "model": "server.award", "fields": {"date": "2010-07-06 09:50:48", "badge": 10, "user": 463}}, {"pk": 898, "model": "server.award", "fields": {"date": "2010-07-06 15:20:47", "badge": 2, "user": 458}}, {"pk": 899, "model": "server.award", "fields": {"date": "2010-07-06 21:50:48", "badge": 10, "user": 230}}, {"pk": 900, "model": "server.award", "fields": {"date": "2010-07-06 22:50:48", "badge": 1, "user": 199}}, {"pk": 901, "model": "server.award", "fields": {"date": "2010-07-06 22:50:48", "badge": 1, "user": 230}}, {"pk": 902, "model": "server.award", "fields": {"date": "2010-07-07 02:35:49", "badge": 2, "user": 467}}, {"pk": 903, "model": "server.award", "fields": {"date": "2010-07-07 11:20:47", "badge": 2, "user": 468}}, {"pk": 904, "model": "server.award", "fields": {"date": "2010-07-07 23:20:48", "badge": 14, "user": 199}}, {"pk": 905, "model": "server.award", "fields": {"date": "2010-07-08 10:05:49", "badge": 2, "user": 470}}, {"pk": 906, "model": "server.award", "fields": {"date": "2010-07-08 13:20:49", "badge": 10, "user": 338}}, {"pk": 907, "model": "server.award", "fields": {"date": "2010-07-08 15:50:51", "badge": 14, "user": 35}}, {"pk": 908, "model": "server.award", "fields": {"date": "2010-07-08 20:50:48", "badge": 6, "user": 471}}, {"pk": 909, "model": "server.award", "fields": {"date": "2010-07-09 02:20:49", "badge": 2, "user": 221}}, {"pk": 910, "model": "server.award", "fields": {"date": "2010-07-09 04:05:52", "badge": 2, "user": 106}}, {"pk": 911, "model": "server.award", "fields": {"date": "2010-07-09 15:05:49", "badge": 6, "user": 474}}, {"pk": 912, "model": "server.award", "fields": {"date": "2010-07-09 17:05:49", "badge": 22, "user": 86}}, {"pk": 913, "model": "server.award", "fields": {"date": "2010-07-09 22:20:51", "badge": 3, "user": 106}}, {"pk": 914, "model": "server.award", "fields": {"date": "2010-07-10 08:35:47", "badge": 1, "user": 474}}, {"pk": 915, "model": "server.award", "fields": {"date": "2010-07-11 13:50:48", "badge": 1, "user": 477}}, {"pk": 916, "model": "server.award", "fields": {"date": "2010-07-12 13:35:50", "badge": 2, "user": 478}}, {"pk": 917, "model": "server.award", "fields": {"date": "2010-07-12 17:50:50", "badge": 1, "user": 479}}, {"pk": 918, "model": "server.award", "fields": {"date": "2010-07-12 21:05:50", "badge": 1, "user": 257}}, {"pk": 919, "model": "server.award", "fields": {"date": "2010-07-13 10:50:47", "badge": 37, "user": 234}}, {"pk": 920, "model": "server.award", "fields": {"date": "2010-07-13 16:35:48", "badge": 6, "user": 291}}, {"pk": 921, "model": "server.award", "fields": {"date": "2010-07-13 17:50:50", "badge": 10, "user": 35}}, {"pk": 922, "model": "server.award", "fields": {"date": "2010-07-13 18:50:49", "badge": 1, "user": 485}}, {"pk": 923, "model": "server.award", "fields": {"date": "2010-07-13 19:35:51", "badge": 1, "user": 486}}, {"pk": 924, "model": "server.award", "fields": {"date": "2010-07-13 21:20:50", "badge": 10, "user": 142}}, {"pk": 925, "model": "server.award", "fields": {"date": "2010-07-13 22:50:48", "badge": 2, "user": 488}}, {"pk": 926, "model": "server.award", "fields": {"date": "2010-07-14 11:50:49", "badge": 3, "user": 460}}, {"pk": 927, "model": "server.award", "fields": {"date": "2010-07-15 14:20:49", "badge": 2, "user": 490}}, {"pk": 928, "model": "server.award", "fields": {"date": "2010-07-15 15:05:50", "badge": 10, "user": 490}}, {"pk": 929, "model": "server.award", "fields": {"date": "2010-07-15 15:20:49", "badge": 6, "user": 488}}, {"pk": 930, "model": "server.award", "fields": {"date": "2010-07-15 15:20:49", "badge": 10, "user": 488}}, {"pk": 931, "model": "server.award", "fields": {"date": "2010-07-15 17:20:49", "badge": 9, "user": 491}}, {"pk": 932, "model": "server.award", "fields": {"date": "2010-07-15 17:35:51", "badge": 2, "user": 491}}, {"pk": 933, "model": "server.award", "fields": {"date": "2010-07-15 17:35:51", "badge": 6, "user": 364}}, {"pk": 934, "model": "server.award", "fields": {"date": "2010-07-15 17:50:49", "badge": 6, "user": 492}}, {"pk": 935, "model": "server.award", "fields": {"date": "2010-07-15 18:35:49", "badge": 19, "user": 491}}, {"pk": 936, "model": "server.award", "fields": {"date": "2010-07-15 23:20:49", "badge": 1, "user": 493}}, {"pk": 937, "model": "server.award", "fields": {"date": "2010-07-16 02:50:48", "badge": 9, "user": 65}}, {"pk": 938, "model": "server.award", "fields": {"date": "2010-07-16 17:05:48", "badge": 2, "user": 496}}, {"pk": 939, "model": "server.award", "fields": {"date": "2010-07-17 06:05:47", "badge": 10, "user": 303}}, {"pk": 940, "model": "server.award", "fields": {"date": "2010-07-17 10:35:49", "badge": 7, "user": 418}}, {"pk": 941, "model": "server.award", "fields": {"date": "2010-07-17 23:05:48", "badge": 6, "user": 191}}, {"pk": 942, "model": "server.award", "fields": {"date": "2010-07-17 23:20:48", "badge": 2, "user": 191}}, {"pk": 943, "model": "server.award", "fields": {"date": "2010-07-18 00:05:47", "badge": 6, "user": 498}}, {"pk": 944, "model": "server.award", "fields": {"date": "2010-07-18 00:05:47", "badge": 9, "user": 498}}, {"pk": 945, "model": "server.award", "fields": {"date": "2010-07-18 01:35:48", "badge": 3, "user": 191}}, {"pk": 946, "model": "server.award", "fields": {"date": "2010-07-18 11:05:48", "badge": 37, "user": 418}}, {"pk": 947, "model": "server.award", "fields": {"date": "2010-07-18 16:20:48", "badge": 9, "user": 418}}, {"pk": 948, "model": "server.award", "fields": {"date": "2010-07-19 02:05:49", "badge": 1, "user": 389}}, {"pk": 949, "model": "server.award", "fields": {"date": "2010-07-19 07:35:50", "badge": 37, "user": 58}}, {"pk": 950, "model": "server.award", "fields": {"date": "2010-07-19 09:20:49", "badge": 9, "user": 445}}, {"pk": 951, "model": "server.award", "fields": {"date": "2010-07-19 17:50:49", "badge": 29, "user": 418}}, {"pk": 952, "model": "server.award", "fields": {"date": "2010-07-19 20:35:49", "badge": 6, "user": 491}}, {"pk": 953, "model": "server.award", "fields": {"date": "2010-07-19 20:35:49", "badge": 10, "user": 491}}, {"pk": 954, "model": "server.award", "fields": {"date": "2010-07-20 01:50:49", "badge": 10, "user": 191}}, {"pk": 955, "model": "server.award", "fields": {"date": "2010-07-20 09:50:47", "badge": 1, "user": 463}}, {"pk": 956, "model": "server.award", "fields": {"date": "2010-07-20 13:20:51", "badge": 29, "user": 137}}, {"pk": 957, "model": "server.award", "fields": {"date": "2010-07-20 19:35:49", "badge": 6, "user": 201}}, {"pk": 958, "model": "server.award", "fields": {"date": "2010-07-20 19:35:49", "badge": 22, "user": 119}}, {"pk": 959, "model": "server.award", "fields": {"date": "2010-07-20 20:35:49", "badge": 2, "user": 457}}, {"pk": 960, "model": "server.award", "fields": {"date": "2010-07-20 20:35:49", "badge": 6, "user": 457}}, {"pk": 961, "model": "server.award", "fields": {"date": "2010-07-20 20:35:49", "badge": 6, "user": 496}}, {"pk": 962, "model": "server.award", "fields": {"date": "2010-07-20 20:35:49", "badge": 10, "user": 457}}, {"pk": 963, "model": "server.award", "fields": {"date": "2010-07-20 20:50:50", "badge": 3, "user": 389}}, {"pk": 964, "model": "server.award", "fields": {"date": "2010-07-21 01:05:48", "badge": 3, "user": 351}}, {"pk": 965, "model": "server.award", "fields": {"date": "2010-07-21 01:05:48", "badge": 29, "user": 55}}, {"pk": 966, "model": "server.award", "fields": {"date": "2010-07-21 02:20:48", "badge": 3, "user": 320}}, {"pk": 967, "model": "server.award", "fields": {"date": "2010-07-21 03:05:49", "badge": 1, "user": 496}}, {"pk": 968, "model": "server.award", "fields": {"date": "2010-07-21 09:20:47", "badge": 3, "user": 119}}, {"pk": 969, "model": "server.award", "fields": {"date": "2010-07-21 10:05:49", "badge": 5, "user": 418}}, {"pk": 970, "model": "server.award", "fields": {"date": "2010-07-21 14:05:51", "badge": 1, "user": 98}}, {"pk": 971, "model": "server.award", "fields": {"date": "2010-07-21 20:35:48", "badge": 41, "user": 65}}, {"pk": 972, "model": "server.award", "fields": {"date": "2010-07-21 21:35:48", "badge": 8, "user": 199}}, {"pk": 973, "model": "server.award", "fields": {"date": "2010-07-22 15:20:48", "badge": 22, "user": 89}}, {"pk": 974, "model": "server.award", "fields": {"date": "2010-07-22 19:20:48", "badge": 6, "user": 357}}, {"pk": 975, "model": "server.award", "fields": {"date": "2010-07-22 20:05:51", "badge": 19, "user": 215}}, {"pk": 976, "model": "server.award", "fields": {"date": "2010-07-23 07:35:47", "badge": 22, "user": 71}}, {"pk": 977, "model": "server.award", "fields": {"date": "2010-07-24 11:35:49", "badge": 10, "user": 70}}, {"pk": 978, "model": "server.award", "fields": {"date": "2010-07-24 17:20:48", "badge": 1, "user": 221}}, {"pk": 979, "model": "server.award", "fields": {"date": "2010-07-24 20:50:47", "badge": 10, "user": 418}}, {"pk": 980, "model": "server.award", "fields": {"date": "2010-07-26 14:35:50", "badge": 3, "user": 130}}, {"pk": 981, "model": "server.award", "fields": {"date": "2010-07-26 16:20:49", "badge": 6, "user": 389}}, {"pk": 982, "model": "server.award", "fields": {"date": "2010-07-26 16:35:49", "badge": 1, "user": 378}}, {"pk": 983, "model": "server.award", "fields": {"date": "2010-07-26 16:35:49", "badge": 3, "user": 378}}, {"pk": 984, "model": "server.award", "fields": {"date": "2010-07-26 16:35:49", "badge": 6, "user": 378}}, {"pk": 985, "model": "server.award", "fields": {"date": "2010-07-27 16:50:49", "badge": 10, "user": 468}}, {"pk": 986, "model": "server.award", "fields": {"date": "2010-07-27 20:05:51", "badge": 2, "user": 487}}, {"pk": 987, "model": "server.award", "fields": {"date": "2010-07-27 20:50:51", "badge": 22, "user": 35}}, {"pk": 988, "model": "server.award", "fields": {"date": "2010-07-28 06:20:49", "badge": 5, "user": 341}}, {"pk": 989, "model": "server.award", "fields": {"date": "2010-07-28 06:35:47", "badge": 3, "user": 151}}, {"pk": 990, "model": "server.award", "fields": {"date": "2010-07-28 16:05:50", "badge": 6, "user": 475}}, {"pk": 991, "model": "server.award", "fields": {"date": "2010-07-29 06:50:47", "badge": 22, "user": 65}}, {"pk": 992, "model": "server.award", "fields": {"date": "2010-07-29 07:05:47", "badge": 22, "user": 65}}, {"pk": 993, "model": "server.award", "fields": {"date": "2010-07-29 16:20:47", "badge": 22, "user": 65}}, {"pk": 994, "model": "server.award", "fields": {"date": "2010-07-29 17:35:48", "badge": 33, "user": 215}}, {"pk": 995, "model": "server.award", "fields": {"date": "2010-07-29 18:50:48", "badge": 2, "user": 420}}, {"pk": 996, "model": "server.award", "fields": {"date": "2010-07-29 21:35:47", "badge": 7, "user": 225}}, {"pk": 997, "model": "server.award", "fields": {"date": "2010-07-30 08:05:47", "badge": 2, "user": 430}}, {"pk": 998, "model": "server.award", "fields": {"date": "2010-07-30 14:35:47", "badge": 19, "user": 215}}, {"pk": 999, "model": "server.award", "fields": {"date": "2010-07-31 10:20:48", "badge": 19, "user": 54}}, {"pk": 1000, "model": "server.award", "fields": {"date": "2010-08-02 13:50:48", "badge": 1, "user": 369}}, {"pk": 1001, "model": "server.award", "fields": {"date": "2010-08-02 19:20:48", "badge": 1, "user": 122}}, {"pk": 1002, "model": "server.award", "fields": {"date": "2010-08-03 14:50:49", "badge": 22, "user": 65}}, {"pk": 1003, "model": "server.award", "fields": {"date": "2010-08-04 01:35:48", "badge": 6, "user": 487}}, {"pk": 1004, "model": "server.award", "fields": {"date": "2010-08-04 06:50:50", "badge": 30, "user": 86}}, {"pk": 1005, "model": "server.award", "fields": {"date": "2010-08-04 08:05:48", "badge": 22, "user": 86}}, {"pk": 1006, "model": "server.award", "fields": {"date": "2010-08-04 08:20:50", "badge": 1, "user": 305}}, {"pk": 1007, "model": "server.award", "fields": {"date": "2010-08-04 08:20:50", "badge": 22, "user": 65}}, {"pk": 1008, "model": "server.award", "fields": {"date": "2010-08-04 10:50:48", "badge": 3, "user": 274}}, {"pk": 1009, "model": "server.award", "fields": {"date": "2010-08-04 11:35:48", "badge": 2, "user": 445}}, {"pk": 1010, "model": "server.award", "fields": {"date": "2010-08-04 11:50:51", "badge": 19, "user": 299}}, {"pk": 1011, "model": "server.award", "fields": {"date": "2010-08-04 22:50:48", "badge": 1, "user": 487}}, {"pk": 1012, "model": "server.award", "fields": {"date": "2010-08-05 11:35:48", "badge": 29, "user": 445}}, {"pk": 1013, "model": "server.award", "fields": {"date": "2010-08-05 14:35:49", "badge": 29, "user": 119}}, {"pk": 1014, "model": "server.award", "fields": {"date": "2010-08-05 15:35:49", "badge": 6, "user": 420}}, {"pk": 1015, "model": "server.award", "fields": {"date": "2010-08-05 15:35:49", "badge": 10, "user": 420}}, {"pk": 1016, "model": "server.award", "fields": {"date": "2010-08-05 23:50:51", "badge": 6, "user": 399}}, {"pk": 1017, "model": "server.award", "fields": {"date": "2010-08-06 08:50:49", "badge": 22, "user": 65}}, {"pk": 1018, "model": "server.award", "fields": {"date": "2010-08-06 16:05:50", "badge": 29, "user": 274}}, {"pk": 1019, "model": "server.award", "fields": {"date": "2010-08-06 16:50:48", "badge": 1, "user": 445}}, {"pk": 1020, "model": "server.award", "fields": {"date": "2010-08-06 17:50:47", "badge": 10, "user": 445}}, {"pk": 1021, "model": "server.award", "fields": {"date": "2010-08-07 18:05:48", "badge": 6, "user": 122}}, {"pk": 1022, "model": "server.award", "fields": {"date": "2010-08-07 18:20:48", "badge": 10, "user": 273}}, {"pk": 1023, "model": "server.award", "fields": {"date": "2010-08-09 07:20:47", "badge": 30, "user": 29}}, {"pk": 1024, "model": "server.award", "fields": {"date": "2010-08-09 08:35:48", "badge": 22, "user": 65}}, {"pk": 1025, "model": "server.award", "fields": {"date": "2010-08-09 22:20:48", "badge": 18, "user": 86}}, {"pk": 1026, "model": "server.award", "fields": {"date": "2010-08-10 00:35:48", "badge": 1, "user": 142}}, {"pk": 1027, "model": "server.award", "fields": {"date": "2010-08-10 03:05:51", "badge": 37, "user": 55}}, {"pk": 1028, "model": "server.award", "fields": {"date": "2010-08-10 05:35:50", "badge": 6, "user": 473}}, {"pk": 1029, "model": "server.award", "fields": {"date": "2010-08-10 12:05:53", "badge": 2, "user": 473}}, {"pk": 1030, "model": "server.award", "fields": {"date": "2010-08-10 14:50:49", "badge": 14, "user": 65}}, {"pk": 1031, "model": "server.award", "fields": {"date": "2010-08-11 02:20:48", "badge": 10, "user": 341}}, {"pk": 1032, "model": "server.award", "fields": {"date": "2010-08-11 11:35:48", "badge": 10, "user": 415}}, {"pk": 1033, "model": "server.award", "fields": {"date": "2010-08-11 12:20:49", "badge": 22, "user": 116}}, {"pk": 1034, "model": "server.award", "fields": {"date": "2010-08-11 13:35:49", "badge": 10, "user": 109}}, {"pk": 1035, "model": "server.award", "fields": {"date": "2010-08-14 07:50:49", "badge": 7, "user": 98}}, {"pk": 1036, "model": "server.award", "fields": {"date": "2010-08-17 03:35:48", "badge": 37, "user": 122}}, {"pk": 1037, "model": "server.award", "fields": {"date": "2010-08-17 04:05:57", "badge": 7, "user": 303}}, {"pk": 1038, "model": "server.award", "fields": {"date": "2010-08-18 03:20:50", "badge": 37, "user": 106}}, {"pk": 1039, "model": "server.award", "fields": {"date": "2010-08-19 00:36:10", "badge": 19, "user": 22}}, {"pk": 1040, "model": "server.award", "fields": {"date": "2010-08-19 12:20:49", "badge": 7, "user": 328}}, {"pk": 1041, "model": "server.award", "fields": {"date": "2010-08-19 20:50:49", "badge": 2, "user": 389}}, {"pk": 1042, "model": "server.award", "fields": {"date": "2010-08-19 21:20:48", "badge": 6, "user": 313}}, {"pk": 1043, "model": "server.award", "fields": {"date": "2010-08-19 23:50:50", "badge": 10, "user": 389}}, {"pk": 1044, "model": "server.award", "fields": {"date": "2010-08-20 04:06:04", "badge": 6, "user": 60}}, {"pk": 1045, "model": "server.award", "fields": {"date": "2010-08-23 15:50:50", "badge": 29, "user": 320}}, {"pk": 1046, "model": "server.award", "fields": {"date": "2010-08-24 00:50:48", "badge": 22, "user": 13}}, {"pk": 1047, "model": "server.award", "fields": {"date": "2010-08-24 04:06:05", "badge": 18, "user": 13}}, {"pk": 1048, "model": "server.award", "fields": {"date": "2010-08-25 13:50:49", "badge": 6, "user": 317}}, {"pk": 1049, "model": "server.award", "fields": {"date": "2010-08-25 13:50:49", "badge": 30, "user": 54}}, {"pk": 1050, "model": "server.award", "fields": {"date": "2010-08-25 14:50:50", "badge": 6, "user": 170}}, {"pk": 1051, "model": "server.award", "fields": {"date": "2010-08-26 21:05:52", "badge": 8, "user": 37}}, {"pk": 1052, "model": "server.award", "fields": {"date": "2010-08-29 11:50:48", "badge": 22, "user": 65}}, {"pk": 1053, "model": "server.award", "fields": {"date": "2010-08-30 07:20:47", "badge": 7, "user": 324}}, {"pk": 1054, "model": "server.award", "fields": {"date": "2010-08-30 17:20:49", "badge": 18, "user": 65}}, {"pk": 1055, "model": "server.award", "fields": {"date": "2010-08-31 16:05:50", "badge": 14, "user": 221}}, {"pk": 1056, "model": "server.award", "fields": {"date": "2010-08-31 17:50:48", "badge": 7, "user": 338}}, {"pk": 1057, "model": "server.award", "fields": {"date": "2010-09-01 16:05:51", "badge": 3, "user": 91}}, {"pk": 1058, "model": "server.award", "fields": {"date": "2010-09-01 19:50:48", "badge": 3, "user": 221}}, {"pk": 1059, "model": "server.award", "fields": {"date": "2010-09-01 19:50:48", "badge": 10, "user": 221}}, {"pk": 1060, "model": "server.award", "fields": {"date": "2010-09-02 04:50:51", "badge": 3, "user": 457}}, {"pk": 1061, "model": "server.award", "fields": {"date": "2010-09-02 16:20:51", "badge": 3, "user": 52}}, {"pk": 1062, "model": "server.award", "fields": {"date": "2010-09-04 12:05:53", "badge": 10, "user": 78}}, {"pk": 1063, "model": "server.award", "fields": {"date": "2010-09-05 14:35:48", "badge": 16, "user": 217}}, {"pk": 1064, "model": "server.award", "fields": {"date": "2010-09-06 12:35:47", "badge": 10, "user": 123}}, {"pk": 1065, "model": "server.award", "fields": {"date": "2010-09-06 22:20:48", "badge": 2, "user": 485}}, {"pk": 1066, "model": "server.award", "fields": {"date": "2010-09-07 19:50:50", "badge": 4, "user": 86}}, {"pk": 1067, "model": "server.award", "fields": {"date": "2010-09-08 10:35:48", "badge": 3, "user": 145}}, {"pk": 1068, "model": "server.award", "fields": {"date": "2010-09-08 10:35:48", "badge": 5, "user": 145}}, {"pk": 1069, "model": "server.award", "fields": {"date": "2010-09-08 15:35:54", "badge": 2, "user": 220}}, {"pk": 1070, "model": "server.award", "fields": {"date": "2010-09-08 15:35:55", "badge": 19, "user": 168}}, {"pk": 1071, "model": "server.award", "fields": {"date": "2010-09-08 15:50:55", "badge": 1, "user": 167}}, {"pk": 1072, "model": "server.award", "fields": {"date": "2010-09-08 18:50:51", "badge": 29, "user": 457}}, {"pk": 1073, "model": "server.award", "fields": {"date": "2010-09-09 20:50:50", "badge": 19, "user": 121}}, {"pk": 1074, "model": "server.award", "fields": {"date": "2010-09-09 20:50:50", "badge": 22, "user": 86}}, {"pk": 1075, "model": "server.award", "fields": {"date": "2010-09-09 23:35:50", "badge": 20, "user": 491}}, {"pk": 1076, "model": "server.award", "fields": {"date": "2010-09-10 06:05:53", "badge": 25, "user": 29}}, {"pk": 1077, "model": "server.award", "fields": {"date": "2010-09-11 06:50:48", "badge": 29, "user": 374}}, {"pk": 1078, "model": "server.award", "fields": {"date": "2010-09-11 07:35:47", "badge": 11, "user": 11}}, {"pk": 1079, "model": "server.award", "fields": {"date": "2010-09-12 12:35:48", "badge": 7, "user": 140}}, {"pk": 1080, "model": "server.award", "fields": {"date": "2010-09-12 12:35:48", "badge": 29, "user": 140}}, {"pk": 1081, "model": "server.award", "fields": {"date": "2010-09-13 05:05:51", "badge": 3, "user": 230}}, {"pk": 1082, "model": "server.award", "fields": {"date": "2010-09-15 15:05:52", "badge": 29, "user": 221}}, {"pk": 1083, "model": "server.award", "fields": {"date": "2010-09-17 00:50:49", "badge": 37, "user": 260}}, {"pk": 1084, "model": "server.award", "fields": {"date": "2010-09-21 07:05:50", "badge": 22, "user": 65}}, {"pk": 1085, "model": "server.award", "fields": {"date": "2010-09-21 07:20:52", "badge": 22, "user": 65}}, {"pk": 1086, "model": "server.award", "fields": {"date": "2010-09-21 07:20:52", "badge": 18, "user": 65}}, {"pk": 1087, "model": "server.award", "fields": {"date": "2010-09-21 15:05:56", "badge": 1, "user": 109}}, {"pk": 1088, "model": "server.award", "fields": {"date": "2010-09-21 17:05:50", "badge": 14, "user": 67}}, {"pk": 1089, "model": "server.award", "fields": {"date": "2010-09-21 20:06:00", "badge": 19, "user": 116}}, {"pk": 1090, "model": "server.award", "fields": {"date": "2010-09-22 22:35:48", "badge": 29, "user": 241}}, {"pk": 1091, "model": "server.award", "fields": {"date": "2010-09-23 16:50:49", "badge": 19, "user": 22}}, {"pk": 1092, "model": "server.award", "fields": {"date": "2010-09-23 19:50:50", "badge": 22, "user": 29}}, {"pk": 1093, "model": "server.award", "fields": {"date": "2010-09-24 10:35:47", "badge": 2, "user": 8}}, {"pk": 1094, "model": "server.award", "fields": {"date": "2010-09-24 13:50:48", "badge": 16, "user": 44}}, {"pk": 1095, "model": "server.award", "fields": {"date": "2010-09-24 13:50:48", "badge": 16, "user": 217}}, {"pk": 1096, "model": "server.award", "fields": {"date": "2010-09-24 14:20:50", "badge": 6, "user": 485}}, {"pk": 1097, "model": "server.award", "fields": {"date": "2010-09-24 18:50:49", "badge": 1, "user": 177}}, {"pk": 1098, "model": "server.award", "fields": {"date": "2010-09-24 18:50:49", "badge": 1, "user": 243}}, {"pk": 1099, "model": "server.award", "fields": {"date": "2010-09-25 12:35:48", "badge": 2, "user": 374}}, {"pk": 1100, "model": "server.award", "fields": {"date": "2010-09-26 08:35:48", "badge": 2, "user": 81}}, {"pk": 1101, "model": "server.award", "fields": {"date": "2010-09-27 10:20:48", "badge": 38, "user": 58}}, {"pk": 1102, "model": "server.award", "fields": {"date": "2010-09-28 04:35:47", "badge": 10, "user": 81}}, {"pk": 1103, "model": "server.award", "fields": {"date": "2010-09-28 07:05:48", "badge": 37, "user": 374}}, {"pk": 1104, "model": "server.award", "fields": {"date": "2010-09-28 11:50:49", "badge": 3, "user": 451}}, {"pk": 1105, "model": "server.award", "fields": {"date": "2010-09-28 14:35:49", "badge": 16, "user": 29}}, {"pk": 1106, "model": "server.award", "fields": {"date": "2010-09-29 11:05:48", "badge": 22, "user": 55}}, {"pk": 1107, "model": "server.award", "fields": {"date": "2010-09-29 12:35:48", "badge": 7, "user": 414}}, {"pk": 1108, "model": "server.award", "fields": {"date": "2010-09-29 13:50:48", "badge": 25, "user": 22}}, {"pk": 1109, "model": "server.award", "fields": {"date": "2010-09-29 15:35:49", "badge": 2, "user": 79}}, {"pk": 1110, "model": "server.award", "fields": {"date": "2010-09-29 15:35:49", "badge": 2, "user": 492}}, {"pk": 1111, "model": "server.award", "fields": {"date": "2010-09-29 17:20:47", "badge": 1, "user": 492}}, {"pk": 1112, "model": "server.award", "fields": {"date": "2010-09-29 17:50:48", "badge": 29, "user": 237}}, {"pk": 1113, "model": "server.award", "fields": {"date": "2010-09-30 07:05:48", "badge": 6, "user": 40}}, {"pk": 1114, "model": "server.award", "fields": {"date": "2010-10-01 01:35:49", "badge": 13, "user": 1}}, {"pk": 1115, "model": "server.award", "fields": {"date": "2010-10-01 01:35:49", "badge": 13, "user": 6}}, {"pk": 1116, "model": "server.award", "fields": {"date": "2010-10-02 08:35:48", "badge": 10, "user": 79}}, {"pk": 1117, "model": "server.award", "fields": {"date": "2010-10-03 05:05:47", "badge": 7, "user": 273}}, {"pk": 1118, "model": "server.award", "fields": {"date": "2010-10-04 18:50:48", "badge": 10, "user": 492}}, {"pk": 1119, "model": "server.award", "fields": {"date": "2010-10-05 08:20:48", "badge": 29, "user": 225}}, {"pk": 1120, "model": "server.award", "fields": {"date": "2010-10-05 13:35:49", "badge": 22, "user": 1}}, {"pk": 1121, "model": "server.award", "fields": {"date": "2010-10-05 23:50:48", "badge": 22, "user": 1}}, {"pk": 1122, "model": "server.award", "fields": {"date": "2010-10-06 00:05:49", "badge": 13, "user": 9}}, {"pk": 1123, "model": "server.award", "fields": {"date": "2010-10-06 01:20:48", "badge": 38, "user": 65}}, {"pk": 1124, "model": "server.award", "fields": {"date": "2010-10-06 22:35:50", "badge": 22, "user": 37}}, {"pk": 1125, "model": "server.award", "fields": {"date": "2010-10-07 10:50:49", "badge": 29, "user": 451}}, {"pk": 1126, "model": "server.award", "fields": {"date": "2010-10-07 12:35:48", "badge": 25, "user": 22}}, {"pk": 1127, "model": "server.award", "fields": {"date": "2010-10-07 16:35:48", "badge": 14, "user": 37}}, {"pk": 1128, "model": "server.award", "fields": {"date": "2010-10-07 18:50:49", "badge": 22, "user": 343}}, {"pk": 1129, "model": "server.award", "fields": {"date": "2010-10-08 05:35:47", "badge": 22, "user": 378}}, {"pk": 1130, "model": "server.award", "fields": {"date": "2010-10-08 07:20:48", "badge": 18, "user": 378}}, {"pk": 1131, "model": "server.award", "fields": {"date": "2010-10-08 07:50:47", "badge": 22, "user": 215}}, {"pk": 1132, "model": "server.award", "fields": {"date": "2010-10-08 18:35:47", "badge": 3, "user": 73}}, {"pk": 1133, "model": "server.award", "fields": {"date": "2010-10-08 18:35:47", "badge": 29, "user": 73}}, {"pk": 1134, "model": "server.award", "fields": {"date": "2010-10-08 20:35:48", "badge": 22, "user": 58}}, {"pk": 1135, "model": "server.award", "fields": {"date": "2010-10-09 16:35:48", "badge": 22, "user": 65}}, {"pk": 1136, "model": "server.award", "fields": {"date": "2010-10-09 19:50:48", "badge": 18, "user": 65}}, {"pk": 1137, "model": "server.award", "fields": {"date": "2010-10-09 22:35:50", "badge": 19, "user": 299}}, {"pk": 1138, "model": "server.award", "fields": {"date": "2010-10-10 00:05:49", "badge": 13, "user": 13}}, {"pk": 1139, "model": "server.award", "fields": {"date": "2010-10-10 15:20:48", "badge": 3, "user": 53}}, {"pk": 1140, "model": "server.award", "fields": {"date": "2010-10-10 18:35:48", "badge": 1, "user": 260}}, {"pk": 1141, "model": "server.award", "fields": {"date": "2010-10-10 18:50:47", "badge": 25, "user": 88}}, {"pk": 1142, "model": "server.award", "fields": {"date": "2010-10-11 05:50:47", "badge": 1, "user": 390}}, {"pk": 1143, "model": "server.award", "fields": {"date": "2010-10-11 07:50:47", "badge": 8, "user": 65}}, {"pk": 1144, "model": "server.award", "fields": {"date": "2010-10-11 09:35:47", "badge": 9, "user": 140}}, {"pk": 1145, "model": "server.award", "fields": {"date": "2010-10-11 10:35:49", "badge": 30, "user": 233}}, {"pk": 1146, "model": "server.award", "fields": {"date": "2010-10-11 12:05:52", "badge": 19, "user": 70}}, {"pk": 1147, "model": "server.award", "fields": {"date": "2010-10-11 12:05:52", "badge": 19, "user": 313}}, {"pk": 1148, "model": "server.award", "fields": {"date": "2010-10-11 12:05:52", "badge": 30, "user": 126}}, {"pk": 1149, "model": "server.award", "fields": {"date": "2010-10-11 19:50:48", "badge": 10, "user": 274}}, {"pk": 1150, "model": "server.award", "fields": {"date": "2010-10-11 20:50:47", "badge": 22, "user": 115}}, {"pk": 1151, "model": "server.award", "fields": {"date": "2010-10-12 06:05:49", "badge": 3, "user": 328}}, {"pk": 1152, "model": "server.award", "fields": {"date": "2010-10-12 11:20:47", "badge": 6, "user": 150}}, {"pk": 1153, "model": "server.award", "fields": {"date": "2010-10-12 13:35:48", "badge": 2, "user": 150}}, {"pk": 1154, "model": "server.award", "fields": {"date": "2010-10-12 14:35:48", "badge": 3, "user": 216}}, {"pk": 1155, "model": "server.award", "fields": {"date": "2010-10-12 15:05:49", "badge": 29, "user": 53}}, {"pk": 1156, "model": "server.award", "fields": {"date": "2010-10-12 17:05:48", "badge": 22, "user": 6}}, {"pk": 1157, "model": "server.award", "fields": {"date": "2010-10-13 15:35:51", "badge": 25, "user": 199}}, {"pk": 1158, "model": "server.award", "fields": {"date": "2010-10-13 22:35:50", "badge": 22, "user": 457}}, {"pk": 1159, "model": "server.award", "fields": {"date": "2010-10-13 23:50:48", "badge": 29, "user": 273}}, {"pk": 1160, "model": "server.award", "fields": {"date": "2010-10-14 11:05:47", "badge": 1, "user": 53}}, {"pk": 1161, "model": "server.award", "fields": {"date": "2010-10-14 18:50:49", "badge": 16, "user": 86}}, {"pk": 1162, "model": "server.award", "fields": {"date": "2010-10-15 15:20:46", "badge": 2, "user": 475}}, {"pk": 1163, "model": "server.award", "fields": {"date": "2010-10-17 17:50:47", "badge": 2, "user": 57}}, {"pk": 1164, "model": "server.award", "fields": {"date": "2010-10-18 03:20:46", "badge": 1, "user": 155}}, {"pk": 1165, "model": "server.award", "fields": {"date": "2010-10-18 10:05:47", "badge": 10, "user": 53}}, {"pk": 1166, "model": "server.award", "fields": {"date": "2010-10-18 15:05:47", "badge": 7, "user": 451}}, {"pk": 1167, "model": "server.award", "fields": {"date": "2010-10-19 00:35:48", "badge": 22, "user": 35}}, {"pk": 1168, "model": "server.award", "fields": {"date": "2010-10-19 02:50:46", "badge": 38, "user": 86}}, {"pk": 1169, "model": "server.award", "fields": {"date": "2010-10-19 12:50:46", "badge": 3, "user": 225}}, {"pk": 1170, "model": "server.award", "fields": {"date": "2010-10-19 15:35:47", "badge": 22, "user": 86}}, {"pk": 1171, "model": "server.award", "fields": {"date": "2010-10-19 16:05:46", "badge": 19, "user": 57}}, {"pk": 1172, "model": "server.award", "fields": {"date": "2010-10-19 16:50:46", "badge": 19, "user": 15}}, {"pk": 1173, "model": "server.award", "fields": {"date": "2010-10-20 15:50:46", "badge": 25, "user": 311}}, {"pk": 1174, "model": "server.award", "fields": {"date": "2010-10-20 18:50:46", "badge": 2, "user": 230}}, {"pk": 1175, "model": "server.award", "fields": {"date": "2010-10-21 12:50:45", "badge": 22, "user": 35}}, {"pk": 1176, "model": "server.award", "fields": {"date": "2010-10-21 16:35:46", "badge": 2, "user": 113}}, {"pk": 1177, "model": "server.award", "fields": {"date": "2010-10-21 21:35:46", "badge": 19, "user": 492}}, {"pk": 1178, "model": "server.award", "fields": {"date": "2010-10-22 11:20:45", "badge": 3, "user": 51}}, {"pk": 1179, "model": "server.award", "fields": {"date": "2010-10-22 11:35:45", "badge": 5, "user": 221}}, {"pk": 1180, "model": "server.award", "fields": {"date": "2010-10-22 12:20:46", "badge": 6, "user": 51}}, {"pk": 1181, "model": "server.award", "fields": {"date": "2010-10-22 12:35:46", "badge": 25, "user": 313}}, {"pk": 1182, "model": "server.award", "fields": {"date": "2010-10-22 13:35:45", "badge": 2, "user": 51}}, {"pk": 1183, "model": "server.award", "fields": {"date": "2010-10-23 21:20:45", "badge": 3, "user": 122}}, {"pk": 1184, "model": "server.award", "fields": {"date": "2010-10-24 17:05:45", "badge": 37, "user": 66}}, {"pk": 1185, "model": "server.award", "fields": {"date": "2010-10-24 18:05:46", "badge": 1, "user": 113}}, {"pk": 1186, "model": "server.award", "fields": {"date": "2010-10-25 05:50:45", "badge": 37, "user": 70}}, {"pk": 1187, "model": "server.award", "fields": {"date": "2010-10-25 06:05:45", "badge": 1, "user": 212}}, {"pk": 1188, "model": "server.award", "fields": {"date": "2010-10-25 12:35:45", "badge": 19, "user": 85}}, {"pk": 1189, "model": "server.award", "fields": {"date": "2010-10-25 13:05:46", "badge": 29, "user": 492}}, {"pk": 1190, "model": "server.award", "fields": {"date": "2010-10-25 15:20:46", "badge": 1, "user": 51}}, {"pk": 1191, "model": "server.award", "fields": {"date": "2010-10-25 15:20:46", "badge": 19, "user": 121}}, {"pk": 1192, "model": "server.award", "fields": {"date": "2010-10-25 15:20:46", "badge": 22, "user": 37}}, {"pk": 1193, "model": "server.award", "fields": {"date": "2010-10-25 16:50:46", "badge": 18, "user": 37}}, {"pk": 1194, "model": "server.award", "fields": {"date": "2010-10-26 14:20:46", "badge": 29, "user": 303}}, {"pk": 1195, "model": "server.award", "fields": {"date": "2010-10-26 19:05:46", "badge": 5, "user": 225}}, {"pk": 1196, "model": "server.award", "fields": {"date": "2010-10-26 20:05:50", "badge": 22, "user": 121}}, {"pk": 1197, "model": "server.award", "fields": {"date": "2010-10-26 20:35:46", "badge": 11, "user": 9}}, {"pk": 1198, "model": "server.award", "fields": {"date": "2010-10-26 22:35:47", "badge": 41, "user": 29}}, {"pk": 1199, "model": "server.award", "fields": {"date": "2010-10-27 10:20:45", "badge": 3, "user": 313}}, {"pk": 1200, "model": "server.award", "fields": {"date": "2010-10-27 14:20:46", "badge": 6, "user": 155}}, {"pk": 1201, "model": "server.award", "fields": {"date": "2010-10-27 18:35:45", "badge": 25, "user": 61}}, {"pk": 1202, "model": "server.award", "fields": {"date": "2010-10-27 20:20:46", "badge": 16, "user": 457}}, {"pk": 1203, "model": "server.award", "fields": {"date": "2010-10-28 02:05:47", "badge": 22, "user": 87}}, {"pk": 1204, "model": "server.award", "fields": {"date": "2010-10-28 14:50:45", "badge": 10, "user": 475}}, {"pk": 1205, "model": "server.award", "fields": {"date": "2010-10-28 17:50:45", "badge": 19, "user": 313}}, {"pk": 1206, "model": "server.award", "fields": {"date": "2010-10-29 06:20:46", "badge": 7, "user": 313}}, {"pk": 1207, "model": "server.award", "fields": {"date": "2010-10-29 12:20:46", "badge": 19, "user": 54}}, {"pk": 1208, "model": "server.award", "fields": {"date": "2010-10-29 13:35:46", "badge": 16, "user": 453}}, {"pk": 1209, "model": "server.award", "fields": {"date": "2010-10-29 15:35:46", "badge": 25, "user": 29}}, {"pk": 1210, "model": "server.award", "fields": {"date": "2010-10-29 21:35:46", "badge": 6, "user": 182}}, {"pk": 1211, "model": "server.award", "fields": {"date": "2010-10-30 11:05:45", "badge": 5, "user": 313}}, {"pk": 1212, "model": "server.award", "fields": {"date": "2010-10-30 17:50:45", "badge": 22, "user": 1}}, {"pk": 1213, "model": "server.award", "fields": {"date": "2010-11-01 15:05:45", "badge": 37, "user": 225}}, {"pk": 1214, "model": "server.award", "fields": {"date": "2010-11-02 06:05:45", "badge": 5, "user": 324}}, {"pk": 1215, "model": "server.award", "fields": {"date": "2010-11-02 13:05:45", "badge": 9, "user": 313}}, {"pk": 1216, "model": "server.award", "fields": {"date": "2010-11-02 19:20:50", "badge": 25, "user": 86}}, {"pk": 1217, "model": "server.award", "fields": {"date": "2010-11-03 21:35:48", "badge": 3, "user": 100}}, {"pk": 1218, "model": "server.award", "fields": {"date": "2010-11-03 21:50:46", "badge": 2, "user": 100}}, {"pk": 1219, "model": "server.award", "fields": {"date": "2010-11-04 13:50:49", "badge": 22, "user": 65}}, {"pk": 1220, "model": "server.award", "fields": {"date": "2010-11-04 14:05:47", "badge": 18, "user": 65}}, {"pk": 1221, "model": "server.award", "fields": {"date": "2010-11-04 14:35:46", "badge": 7, "user": 492}}, {"pk": 1222, "model": "server.award", "fields": {"date": "2010-11-04 15:35:46", "badge": 10, "user": 473}}, {"pk": 1223, "model": "server.award", "fields": {"date": "2010-11-04 16:20:46", "badge": 29, "user": 313}}, {"pk": 1224, "model": "server.award", "fields": {"date": "2010-11-04 23:20:45", "badge": 9, "user": 100}}, {"pk": 1225, "model": "server.award", "fields": {"date": "2010-11-05 07:50:46", "badge": 29, "user": 198}}, {"pk": 1226, "model": "server.award", "fields": {"date": "2010-11-05 15:35:46", "badge": 25, "user": 397}}, {"pk": 1227, "model": "server.award", "fields": {"date": "2010-11-06 03:05:46", "badge": 37, "user": 273}}, {"pk": 1228, "model": "server.award", "fields": {"date": "2010-11-07 15:35:47", "badge": 25, "user": 215}}, {"pk": 1229, "model": "server.award", "fields": {"date": "2010-11-08 13:05:51", "badge": 3, "user": 286}}, {"pk": 1230, "model": "server.award", "fields": {"date": "2010-11-08 15:05:45", "badge": 22, "user": 86}}, {"pk": 1231, "model": "server.award", "fields": {"date": "2010-11-08 15:05:45", "badge": 18, "user": 86}}, {"pk": 1232, "model": "server.award", "fields": {"date": "2010-11-08 20:20:48", "badge": 26, "user": 15}}, {"pk": 1233, "model": "server.award", "fields": {"date": "2010-11-09 03:05:45", "badge": 2, "user": 419}}, {"pk": 1234, "model": "server.award", "fields": {"date": "2010-11-09 04:50:47", "badge": 37, "user": 457}}, {"pk": 1235, "model": "server.award", "fields": {"date": "2010-11-09 07:50:47", "badge": 10, "user": 65}}, {"pk": 1236, "model": "server.award", "fields": {"date": "2010-11-09 08:20:47", "badge": 7, "user": 198}}, {"pk": 1237, "model": "server.award", "fields": {"date": "2010-11-09 12:05:46", "badge": 19, "user": 29}}, {"pk": 1238, "model": "server.award", "fields": {"date": "2010-11-09 14:20:46", "badge": 3, "user": 46}}, {"pk": 1239, "model": "server.award", "fields": {"date": "2010-11-10 00:05:46", "badge": 7, "user": 457}}, {"pk": 1240, "model": "server.award", "fields": {"date": "2010-11-10 10:05:45", "badge": 7, "user": 485}}, {"pk": 1241, "model": "server.award", "fields": {"date": "2010-11-10 12:50:45", "badge": 10, "user": 51}}, {"pk": 1242, "model": "server.award", "fields": {"date": "2010-11-10 14:05:45", "badge": 1, "user": 419}}, {"pk": 1243, "model": "server.award", "fields": {"date": "2010-11-10 14:05:46", "badge": 6, "user": 46}}, {"pk": 1244, "model": "server.award", "fields": {"date": "2010-11-10 14:35:46", "badge": 3, "user": 419}}, {"pk": 1245, "model": "server.award", "fields": {"date": "2010-11-10 16:35:45", "badge": 14, "user": 46}}, {"pk": 1246, "model": "server.award", "fields": {"date": "2010-11-10 18:05:47", "badge": 6, "user": 306}}, {"pk": 1247, "model": "server.award", "fields": {"date": "2010-11-11 07:50:45", "badge": 22, "user": 37}}, {"pk": 1248, "model": "server.award", "fields": {"date": "2010-11-11 08:05:48", "badge": 18, "user": 37}}, {"pk": 1249, "model": "server.award", "fields": {"date": "2010-11-11 12:20:46", "badge": 14, "user": 113}}, {"pk": 1250, "model": "server.award", "fields": {"date": "2010-11-11 16:20:46", "badge": 25, "user": 29}}, {"pk": 1251, "model": "server.award", "fields": {"date": "2010-11-11 23:35:46", "badge": 1, "user": 472}}, {"pk": 1252, "model": "server.award", "fields": {"date": "2010-11-11 23:50:49", "badge": 7, "user": 445}}, {"pk": 1253, "model": "server.award", "fields": {"date": "2010-11-12 08:35:45", "badge": 11, "user": 63}}, {"pk": 1254, "model": "server.award", "fields": {"date": "2010-11-12 14:20:47", "badge": 1, "user": 123}}, {"pk": 1255, "model": "server.award", "fields": {"date": "2010-11-12 20:20:45", "badge": 25, "user": 52}}, {"pk": 1256, "model": "server.award", "fields": {"date": "2010-11-12 20:35:46", "badge": 6, "user": 472}}, {"pk": 1257, "model": "server.award", "fields": {"date": "2010-11-12 20:35:46", "badge": 22, "user": 22}}, {"pk": 1258, "model": "server.award", "fields": {"date": "2010-11-13 03:05:46", "badge": 3, "user": 71}}, {"pk": 1259, "model": "server.award", "fields": {"date": "2010-11-13 17:50:46", "badge": 3, "user": 445}}, {"pk": 1260, "model": "server.award", "fields": {"date": "2010-11-14 11:35:45", "badge": 19, "user": 328}}, {"pk": 1261, "model": "server.award", "fields": {"date": "2010-11-14 13:05:48", "badge": 6, "user": 260}}, {"pk": 1262, "model": "server.award", "fields": {"date": "2010-11-14 13:05:48", "badge": 10, "user": 260}}, {"pk": 1263, "model": "server.award", "fields": {"date": "2010-11-14 13:05:48", "badge": 19, "user": 70}}, {"pk": 1264, "model": "server.award", "fields": {"date": "2010-11-14 17:20:55", "badge": 2, "user": 260}}, {"pk": 1265, "model": "server.award", "fields": {"date": "2010-11-15 02:35:45", "badge": 3, "user": 123}}, {"pk": 1266, "model": "server.award", "fields": {"date": "2010-11-15 10:05:50", "badge": 22, "user": 123}}, {"pk": 1267, "model": "server.award", "fields": {"date": "2010-11-15 12:05:46", "badge": 29, "user": 234}}, {"pk": 1268, "model": "server.award", "fields": {"date": "2010-11-16 15:35:45", "badge": 5, "user": 445}}, {"pk": 1269, "model": "server.award", "fields": {"date": "2010-11-16 21:05:49", "badge": 3, "user": 475}}, {"pk": 1270, "model": "server.award", "fields": {"date": "2010-11-17 06:35:45", "badge": 25, "user": 1}}, {"pk": 1271, "model": "server.award", "fields": {"date": "2010-11-17 14:35:45", "badge": 7, "user": 221}}, {"pk": 1272, "model": "server.award", "fields": {"date": "2010-11-18 04:50:46", "badge": 7, "user": 419}}, {"pk": 1273, "model": "server.award", "fields": {"date": "2010-11-18 14:05:45", "badge": 3, "user": 473}}, {"pk": 1274, "model": "server.award", "fields": {"date": "2010-11-18 17:20:48", "badge": 22, "user": 418}}, {"pk": 1275, "model": "server.award", "fields": {"date": "2010-11-18 17:50:46", "badge": 18, "user": 418}}, {"pk": 1276, "model": "server.award", "fields": {"date": "2010-11-19 10:50:46", "badge": 7, "user": 46}}, {"pk": 1277, "model": "server.award", "fields": {"date": "2010-11-19 12:50:45", "badge": 7, "user": 312}}, {"pk": 1278, "model": "server.award", "fields": {"date": "2010-11-19 13:50:46", "badge": 7, "user": 216}}, {"pk": 1279, "model": "server.award", "fields": {"date": "2010-11-19 14:50:47", "badge": 6, "user": 169}}, {"pk": 1280, "model": "server.award", "fields": {"date": "2010-11-19 21:20:49", "badge": 22, "user": 116}}, {"pk": 1281, "model": "server.award", "fields": {"date": "2010-11-19 21:35:47", "badge": 22, "user": 116}}, {"pk": 1282, "model": "server.award", "fields": {"date": "2010-11-20 14:20:45", "badge": 7, "user": 57}}, {"pk": 1283, "model": "server.award", "fields": {"date": "2010-11-20 16:50:45", "badge": 22, "user": 65}}, {"pk": 1284, "model": "server.award", "fields": {"date": "2010-11-20 19:05:46", "badge": 18, "user": 65}}, {"pk": 1285, "model": "server.award", "fields": {"date": "2010-11-22 09:05:45", "badge": 6, "user": 349}}, {"pk": 1286, "model": "server.award", "fields": {"date": "2010-11-22 17:20:46", "badge": 22, "user": 225}}, {"pk": 1287, "model": "server.award", "fields": {"date": "2010-11-22 18:20:47", "badge": 11, "user": 215}}, {"pk": 1288, "model": "server.award", "fields": {"date": "2010-11-23 07:50:46", "badge": 19, "user": 147}}, {"pk": 1289, "model": "server.award", "fields": {"date": "2010-11-23 16:50:46", "badge": 6, "user": 263}}, {"pk": 1290, "model": "server.award", "fields": {"date": "2010-11-23 17:20:45", "badge": 9, "user": 35}}, {"pk": 1291, "model": "server.award", "fields": {"date": "2010-11-24 08:05:47", "badge": 5, "user": 204}}, {"pk": 1292, "model": "server.award", "fields": {"date": "2010-11-24 09:05:45", "badge": 1, "user": 232}}, {"pk": 1293, "model": "server.award", "fields": {"date": "2010-11-25 11:50:46", "badge": 18, "user": 55}}, {"pk": 1294, "model": "server.award", "fields": {"date": "2010-11-29 06:50:46", "badge": 29, "user": 39}}, {"pk": 1295, "model": "server.award", "fields": {"date": "2010-11-29 22:05:46", "badge": 29, "user": 89}}, {"pk": 1296, "model": "server.award", "fields": {"date": "2010-11-30 09:50:47", "badge": 37, "user": 90}}, {"pk": 1297, "model": "server.award", "fields": {"date": "2010-11-30 14:35:47", "badge": 22, "user": 65}}, {"pk": 1298, "model": "server.award", "fields": {"date": "2010-11-30 18:35:45", "badge": 18, "user": 65}}, {"pk": 1299, "model": "server.award", "fields": {"date": "2010-12-01 15:05:45", "badge": 22, "user": 29}}, {"pk": 1300, "model": "server.award", "fields": {"date": "2010-12-02 19:50:45", "badge": 25, "user": 1}}, {"pk": 1301, "model": "server.award", "fields": {"date": "2010-12-02 21:20:45", "badge": 19, "user": 1}}, {"pk": 1302, "model": "server.award", "fields": {"date": "2010-12-03 08:35:46", "badge": 11, "user": 29}}, {"pk": 1303, "model": "server.award", "fields": {"date": "2010-12-04 17:05:46", "badge": 19, "user": 343}}, {"pk": 1304, "model": "server.award", "fields": {"date": "2010-12-04 22:05:45", "badge": 29, "user": 473}}, {"pk": 1305, "model": "server.award", "fields": {"date": "2010-12-06 15:05:45", "badge": 29, "user": 90}}, {"pk": 1306, "model": "server.award", "fields": {"date": "2010-12-06 18:05:45", "badge": 22, "user": 116}}, {"pk": 1307, "model": "server.award", "fields": {"date": "2010-12-06 21:50:45", "badge": 25, "user": 35}}, {"pk": 1308, "model": "server.award", "fields": {"date": "2010-12-07 09:05:46", "badge": 25, "user": 29}}, {"pk": 1309, "model": "server.award", "fields": {"date": "2010-12-08 09:50:46", "badge": 25, "user": 9}}, {"pk": 1310, "model": "server.award", "fields": {"date": "2010-12-08 21:05:50", "badge": 11, "user": 84}}, {"pk": 1311, "model": "server.award", "fields": {"date": "2010-12-09 17:50:46", "badge": 7, "user": 274}}, {"pk": 1312, "model": "server.award", "fields": {"date": "2010-12-09 22:35:45", "badge": 22, "user": 141}}, {"pk": 1313, "model": "server.award", "fields": {"date": "2010-12-10 01:35:46", "badge": 18, "user": 141}}, {"pk": 1314, "model": "server.award", "fields": {"date": "2010-12-10 11:05:46", "badge": 4, "user": 22}}, {"pk": 1315, "model": "server.award", "fields": {"date": "2010-12-10 11:20:45", "badge": 25, "user": 199}}, {"pk": 1316, "model": "server.award", "fields": {"date": "2010-12-10 12:05:45", "badge": 6, "user": 459}}, {"pk": 1317, "model": "server.award", "fields": {"date": "2010-12-10 20:35:47", "badge": 22, "user": 65}}, {"pk": 1318, "model": "server.award", "fields": {"date": "2010-12-11 14:35:45", "badge": 30, "user": 55}}, {"pk": 1319, "model": "server.award", "fields": {"date": "2010-12-13 00:50:48", "badge": 18, "user": 65}}, {"pk": 1320, "model": "server.award", "fields": {"date": "2010-12-13 15:35:47", "badge": 16, "user": 73}}, {"pk": 1321, "model": "server.award", "fields": {"date": "2010-12-13 17:05:48", "badge": 16, "user": 234}}, {"pk": 1322, "model": "server.award", "fields": {"date": "2010-12-14 09:50:46", "badge": 19, "user": 85}}, {"pk": 1323, "model": "server.award", "fields": {"date": "2010-12-14 15:20:46", "badge": 38, "user": 1}}, {"pk": 1324, "model": "server.award", "fields": {"date": "2010-12-14 17:05:47", "badge": 22, "user": 29}}, {"pk": 1325, "model": "server.award", "fields": {"date": "2010-12-14 22:50:46", "badge": 22, "user": 29}}, {"pk": 1326, "model": "server.award", "fields": {"date": "2010-12-15 03:20:47", "badge": 19, "user": 72}}, {"pk": 1327, "model": "server.award", "fields": {"date": "2010-12-15 04:20:45", "badge": 22, "user": 55}}, {"pk": 1328, "model": "server.award", "fields": {"date": "2010-12-15 04:35:45", "badge": 19, "user": 215}}, {"pk": 1329, "model": "server.award", "fields": {"date": "2010-12-15 04:35:45", "badge": 22, "user": 1}}, {"pk": 1330, "model": "server.award", "fields": {"date": "2010-12-15 04:35:45", "badge": 22, "user": 55}}, {"pk": 1331, "model": "server.award", "fields": {"date": "2010-12-17 01:35:45", "badge": 1, "user": 183}}, {"pk": 1332, "model": "server.award", "fields": {"date": "2010-12-17 14:50:45", "badge": 29, "user": 389}}, {"pk": 1333, "model": "server.award", "fields": {"date": "2010-12-17 17:50:45", "badge": 30, "user": 418}}, {"pk": 1334, "model": "server.award", "fields": {"date": "2010-12-18 03:50:45", "badge": 38, "user": 156}}, {"pk": 1335, "model": "server.award", "fields": {"date": "2010-12-19 14:50:46", "badge": 6, "user": 413}}, {"pk": 1336, "model": "server.award", "fields": {"date": "2010-12-21 06:05:46", "badge": 22, "user": 155}}, {"pk": 1337, "model": "server.award", "fields": {"date": "2010-12-21 06:20:46", "badge": 18, "user": 155}}, {"pk": 1338, "model": "server.award", "fields": {"date": "2010-12-21 06:35:46", "badge": 25, "user": 199}}, {"pk": 1339, "model": "server.award", "fields": {"date": "2010-12-21 09:35:46", "badge": 22, "user": 35}}, {"pk": 1340, "model": "server.award", "fields": {"date": "2010-12-21 18:05:47", "badge": 29, "user": 124}}, {"pk": 1341, "model": "server.award", "fields": {"date": "2010-12-23 22:50:45", "badge": 5, "user": 155}}, {"pk": 1342, "model": "server.award", "fields": {"date": "2010-12-24 03:20:48", "badge": 7, "user": 155}}, {"pk": 1343, "model": "server.award", "fields": {"date": "2010-12-24 04:20:45", "badge": 6, "user": 468}}, {"pk": 1344, "model": "server.award", "fields": {"date": "2010-12-24 16:35:46", "badge": 9, "user": 155}}, {"pk": 1345, "model": "server.award", "fields": {"date": "2010-12-24 20:35:45", "badge": 22, "user": 22}}, {"pk": 1346, "model": "server.award", "fields": {"date": "2010-12-25 02:05:47", "badge": 18, "user": 22}}, {"pk": 1347, "model": "server.award", "fields": {"date": "2010-12-27 09:20:47", "badge": 5, "user": 374}}, {"pk": 1348, "model": "server.award", "fields": {"date": "2010-12-28 15:20:45", "badge": 7, "user": 374}}, {"pk": 1349, "model": "server.award", "fields": {"date": "2010-12-29 13:35:49", "badge": 37, "user": 313}}, {"pk": 1350, "model": "server.award", "fields": {"date": "2010-12-29 20:05:46", "badge": 10, "user": 204}}, {"pk": 1351, "model": "server.award", "fields": {"date": "2010-12-31 11:35:45", "badge": 19, "user": 72}}, {"pk": 1352, "model": "server.award", "fields": {"date": "2010-12-31 15:20:47", "badge": 20, "user": 29}}, {"pk": 1353, "model": "server.award", "fields": {"date": "2010-12-31 15:35:45", "badge": 37, "user": 312}}, {"pk": 1354, "model": "server.award", "fields": {"date": "2011-01-01 15:05:45", "badge": 10, "user": 57}}, {"pk": 1355, "model": "server.award", "fields": {"date": "2011-01-01 19:05:48", "badge": 22, "user": 204}}, {"pk": 1356, "model": "server.award", "fields": {"date": "2011-01-03 06:35:48", "badge": 37, "user": 204}}, {"pk": 1357, "model": "server.award", "fields": {"date": "2011-01-03 22:05:47", "badge": 22, "user": 29}}, {"pk": 1358, "model": "server.award", "fields": {"date": "2011-01-03 22:05:47", "badge": 22, "user": 374}}, {"pk": 1359, "model": "server.award", "fields": {"date": "2011-01-04 03:20:45", "badge": 38, "user": 54}}, {"pk": 1360, "model": "server.award", "fields": {"date": "2011-01-04 16:05:49", "badge": 1, "user": 159}}, {"pk": 1361, "model": "server.award", "fields": {"date": "2011-01-05 09:35:46", "badge": 1, "user": 192}}, {"pk": 1362, "model": "server.award", "fields": {"date": "2011-01-05 14:50:47", "badge": 25, "user": 29}}, {"pk": 1363, "model": "server.award", "fields": {"date": "2011-01-07 04:20:46", "badge": 3, "user": 155}}, {"pk": 1364, "model": "server.award", "fields": {"date": "2011-01-07 07:20:48", "badge": 22, "user": 155}}, {"pk": 1365, "model": "server.award", "fields": {"date": "2011-01-07 08:05:47", "badge": 25, "user": 9}}, {"pk": 1366, "model": "server.award", "fields": {"date": "2011-01-07 22:20:45", "badge": 10, "user": 313}}, {"pk": 1367, "model": "server.award", "fields": {"date": "2011-01-08 15:35:45", "badge": 22, "user": 58}}, {"pk": 1368, "model": "server.award", "fields": {"date": "2011-01-11 19:50:46", "badge": 19, "user": 29}}, {"pk": 1369, "model": "server.award", "fields": {"date": "2011-01-12 06:35:47", "badge": 25, "user": 215}}, {"pk": 1370, "model": "server.award", "fields": {"date": "2011-01-12 11:20:45", "badge": 7, "user": 159}}, {"pk": 1371, "model": "server.award", "fields": {"date": "2011-01-12 14:05:46", "badge": 22, "user": 313}}, {"pk": 1372, "model": "server.award", "fields": {"date": "2011-01-12 23:50:47", "badge": 11, "user": 120}}, {"pk": 1373, "model": "server.award", "fields": {"date": "2011-01-13 04:20:47", "badge": 10, "user": 113}}, {"pk": 1374, "model": "server.award", "fields": {"date": "2011-01-13 21:35:46", "badge": 3, "user": 492}}, {"pk": 1375, "model": "server.award", "fields": {"date": "2011-01-13 22:50:45", "badge": 6, "user": 192}}, {"pk": 1376, "model": "server.award", "fields": {"date": "2011-01-17 01:35:48", "badge": 37, "user": 155}}, {"pk": 1377, "model": "server.award", "fields": {"date": "2011-01-17 17:05:45", "badge": 25, "user": 1}}, {"pk": 1378, "model": "server.award", "fields": {"date": "2011-01-17 22:05:47", "badge": 22, "user": 65}}, {"pk": 1379, "model": "server.award", "fields": {"date": "2011-01-18 13:35:46", "badge": 29, "user": 286}}, {"pk": 1380, "model": "server.award", "fields": {"date": "2011-01-18 15:05:46", "badge": 11, "user": 1}}, {"pk": 1381, "model": "server.award", "fields": {"date": "2011-01-18 16:50:47", "badge": 1, "user": 218}}, {"pk": 1382, "model": "server.award", "fields": {"date": "2011-01-19 00:20:45", "badge": 13, "user": 22}}, {"pk": 1383, "model": "server.award", "fields": {"date": "2011-01-19 14:20:45", "badge": 7, "user": 123}}, {"pk": 1384, "model": "server.award", "fields": {"date": "2011-01-19 20:50:46", "badge": 22, "user": 65}}, {"pk": 1385, "model": "server.award", "fields": {"date": "2011-01-20 09:20:45", "badge": 7, "user": 473}}, {"pk": 1386, "model": "server.award", "fields": {"date": "2011-01-20 13:35:48", "badge": 22, "user": 324}}, {"pk": 1387, "model": "server.award", "fields": {"date": "2011-01-21 22:35:47", "badge": 5, "user": 167}}, {"pk": 1388, "model": "server.award", "fields": {"date": "2011-01-21 22:35:47", "badge": 9, "user": 167}}, {"pk": 1389, "model": "server.award", "fields": {"date": "2011-01-22 02:05:45", "badge": 37, "user": 123}}, {"pk": 1390, "model": "server.award", "fields": {"date": "2011-01-22 04:35:45", "badge": 22, "user": 6}}, {"pk": 1391, "model": "server.award", "fields": {"date": "2011-01-22 13:35:45", "badge": 7, "user": 39}}, {"pk": 1392, "model": "server.award", "fields": {"date": "2011-01-22 20:50:45", "badge": 29, "user": 155}}, {"pk": 1393, "model": "server.award", "fields": {"date": "2011-01-24 00:20:45", "badge": 13, "user": 23}}, {"pk": 1394, "model": "server.award", "fields": {"date": "2011-01-24 09:50:46", "badge": 8, "user": 58}}, {"pk": 1395, "model": "server.award", "fields": {"date": "2011-01-25 07:05:45", "badge": 38, "user": 37}}, {"pk": 1396, "model": "server.award", "fields": {"date": "2011-01-25 09:35:47", "badge": 2, "user": 25}}, {"pk": 1397, "model": "server.award", "fields": {"date": "2011-01-25 11:50:47", "badge": 4, "user": 58}}, {"pk": 1398, "model": "server.award", "fields": {"date": "2011-01-25 15:50:47", "badge": 2, "user": 155}}, {"pk": 1399, "model": "server.award", "fields": {"date": "2011-01-26 02:50:45", "badge": 1, "user": 430}}, {"pk": 1400, "model": "server.award", "fields": {"date": "2011-01-26 07:50:46", "badge": 37, "user": 118}}, {"pk": 1401, "model": "server.award", "fields": {"date": "2011-01-26 10:05:45", "badge": 22, "user": 123}}, {"pk": 1402, "model": "server.award", "fields": {"date": "2011-01-26 11:20:46", "badge": 10, "user": 25}}, {"pk": 1403, "model": "server.award", "fields": {"date": "2011-01-26 12:50:45", "badge": 10, "user": 155}}, {"pk": 1404, "model": "server.award", "fields": {"date": "2011-01-26 23:05:47", "badge": 29, "user": 79}}, {"pk": 1405, "model": "server.award", "fields": {"date": "2011-01-27 10:50:46", "badge": 19, "user": 198}}, {"pk": 1406, "model": "server.award", "fields": {"date": "2011-01-29 23:20:46", "badge": 5, "user": 457}}, {"pk": 1407, "model": "server.award", "fields": {"date": "2011-01-31 10:05:47", "badge": 22, "user": 70}}, {"pk": 1408, "model": "server.award", "fields": {"date": "2011-01-31 11:50:45", "badge": 9, "user": 198}}, {"pk": 1409, "model": "server.award", "fields": {"date": "2011-02-01 13:20:46", "badge": 25, "user": 53}}, {"pk": 1410, "model": "server.award", "fields": {"date": "2011-02-02 11:35:46", "badge": 11, "user": 22}}, {"pk": 1411, "model": "server.award", "fields": {"date": "2011-02-04 14:35:45", "badge": 9, "user": 312}}, {"pk": 1412, "model": "server.award", "fields": {"date": "2011-02-04 15:35:46", "badge": 19, "user": 86}}, {"pk": 1413, "model": "server.award", "fields": {"date": "2011-02-05 08:35:46", "badge": 5, "user": 312}}, {"pk": 1414, "model": "server.award", "fields": {"date": "2011-02-05 11:05:46", "badge": 5, "user": 198}}, {"pk": 1415, "model": "server.award", "fields": {"date": "2011-02-05 18:50:45", "badge": 3, "user": 198}}, {"pk": 1416, "model": "server.award", "fields": {"date": "2011-02-06 17:50:45", "badge": 22, "user": 65}}, {"pk": 1417, "model": "server.award", "fields": {"date": "2011-02-06 19:50:46", "badge": 18, "user": 65}}, {"pk": 1418, "model": "server.award", "fields": {"date": "2011-02-07 21:35:48", "badge": 33, "user": 312}}, {"pk": 1419, "model": "server.award", "fields": {"date": "2011-02-07 23:35:45", "badge": 26, "user": 29}}, {"pk": 1420, "model": "server.award", "fields": {"date": "2011-02-08 08:35:48", "badge": 37, "user": 72}}, {"pk": 1421, "model": "server.award", "fields": {"date": "2011-02-08 22:35:50", "badge": 1, "user": 82}}, {"pk": 1422, "model": "server.award", "fields": {"date": "2011-02-09 06:50:45", "badge": 19, "user": 73}}, {"pk": 1423, "model": "server.award", "fields": {"date": "2011-02-09 12:50:45", "badge": 25, "user": 186}}, {"pk": 1424, "model": "server.award", "fields": {"date": "2011-02-09 22:20:47", "badge": 25, "user": 237}}, {"pk": 1425, "model": "server.award", "fields": {"date": "2011-02-10 07:05:45", "badge": 25, "user": 121}}, {"pk": 1426, "model": "server.award", "fields": {"date": "2011-02-10 12:05:46", "badge": 22, "user": 82}}, {"pk": 1427, "model": "server.award", "fields": {"date": "2011-02-12 15:50:45", "badge": 22, "user": 234}}, {"pk": 1428, "model": "server.award", "fields": {"date": "2011-02-12 17:50:45", "badge": 18, "user": 234}}, {"pk": 1429, "model": "server.award", "fields": {"date": "2011-02-13 00:20:45", "badge": 13, "user": 25}}, {"pk": 1430, "model": "server.award", "fields": {"date": "2011-02-14 11:50:46", "badge": 9, "user": 70}}, {"pk": 1431, "model": "server.award", "fields": {"date": "2011-02-15 01:20:46", "badge": 3, "user": 25}}, {"pk": 1432, "model": "server.award", "fields": {"date": "2011-02-15 09:50:45", "badge": 25, "user": 29}}, {"pk": 1433, "model": "server.award", "fields": {"date": "2011-02-15 17:05:46", "badge": 3, "user": 305}}, {"pk": 1434, "model": "server.award", "fields": {"date": "2011-02-16 10:35:46", "badge": 6, "user": 98}}, {"pk": 1435, "model": "server.award", "fields": {"date": "2011-02-16 16:20:46", "badge": 4, "user": 126}}, {"pk": 1436, "model": "server.award", "fields": {"date": "2011-02-16 16:20:46", "badge": 33, "user": 126}}, {"pk": 1437, "model": "server.award", "fields": {"date": "2011-02-17 16:50:46", "badge": 26, "user": 199}}, {"pk": 1438, "model": "server.award", "fields": {"date": "2011-02-18 11:50:46", "badge": 22, "user": 65}}, {"pk": 1439, "model": "server.award", "fields": {"date": "2011-02-18 11:50:46", "badge": 20, "user": 35}}, {"pk": 1440, "model": "server.award", "fields": {"date": "2011-02-18 12:05:45", "badge": 10, "user": 400}}, {"pk": 1441, "model": "server.award", "fields": {"date": "2011-02-18 12:05:45", "badge": 16, "user": 29}}, {"pk": 1442, "model": "server.award", "fields": {"date": "2011-02-18 19:05:47", "badge": 25, "user": 224}}, {"pk": 1443, "model": "server.award", "fields": {"date": "2011-02-20 13:50:47", "badge": 12, "user": 65}}, {"pk": 1444, "model": "server.award", "fields": {"date": "2011-02-21 11:05:45", "badge": 3, "user": 241}}, {"pk": 1445, "model": "server.award", "fields": {"date": "2011-02-21 13:35:46", "badge": 25, "user": 199}}, {"pk": 1446, "model": "server.award", "fields": {"date": "2011-02-23 00:35:48", "badge": 23, "user": 22}}, {"pk": 1447, "model": "server.award", "fields": {"date": "2011-02-23 09:05:45", "badge": 11, "user": 168}}, {"pk": 1448, "model": "server.award", "fields": {"date": "2011-02-23 16:20:50", "badge": 19, "user": 29}}, {"pk": 1449, "model": "server.award", "fields": {"date": "2011-02-23 21:05:49", "badge": 7, "user": 468}}, {"pk": 1450, "model": "server.award", "fields": {"date": "2011-02-23 21:50:48", "badge": 25, "user": 328}}, {"pk": 1451, "model": "server.award", "fields": {"date": "2011-02-24 09:05:45", "badge": 25, "user": 447}}, {"pk": 1452, "model": "server.award", "fields": {"date": "2011-02-24 15:35:45", "badge": 19, "user": 141}}, {"pk": 1453, "model": "server.award", "fields": {"date": "2011-02-25 13:20:47", "badge": 22, "user": 364}}, {"pk": 1454, "model": "server.award", "fields": {"date": "2011-02-25 14:35:46", "badge": 6, "user": 8}}, {"pk": 1455, "model": "server.award", "fields": {"date": "2011-02-25 16:05:45", "badge": 19, "user": 339}}, {"pk": 1456, "model": "server.award", "fields": {"date": "2011-02-25 23:50:45", "badge": 25, "user": 29}}, {"pk": 1457, "model": "server.award", "fields": {"date": "2011-02-26 00:20:46", "badge": 13, "user": 29}}, {"pk": 1458, "model": "server.award", "fields": {"date": "2011-02-26 00:20:46", "badge": 13, "user": 35}}, {"pk": 1459, "model": "server.award", "fields": {"date": "2011-02-27 00:20:45", "badge": 13, "user": 37}}, {"pk": 1460, "model": "server.award", "fields": {"date": "2011-02-27 00:20:45", "badge": 13, "user": 39}}, {"pk": 1461, "model": "server.award", "fields": {"date": "2011-02-27 00:20:45", "badge": 13, "user": 46}}, {"pk": 1462, "model": "server.award", "fields": {"date": "2011-02-27 00:20:45", "badge": 13, "user": 52}}, {"pk": 1463, "model": "server.award", "fields": {"date": "2011-02-27 16:50:46", "badge": 19, "user": 320}}, {"pk": 1464, "model": "server.award", "fields": {"date": "2011-02-28 00:20:45", "badge": 13, "user": 54}}, {"pk": 1465, "model": "server.award", "fields": {"date": "2011-02-28 02:05:46", "badge": 29, "user": 333}}, {"pk": 1466, "model": "server.award", "fields": {"date": "2011-02-28 02:05:46", "badge": 25, "user": 58}}, {"pk": 1467, "model": "server.award", "fields": {"date": "2011-02-28 16:35:46", "badge": 7, "user": 305}}, {"pk": 1468, "model": "server.award", "fields": {"date": "2011-02-28 20:35:48", "badge": 22, "user": 70}}, {"pk": 1469, "model": "server.award", "fields": {"date": "2011-03-01 01:35:45", "badge": 13, "user": 55}}, {"pk": 1470, "model": "server.award", "fields": {"date": "2011-03-01 13:35:47", "badge": 29, "user": 343}}, {"pk": 1471, "model": "server.award", "fields": {"date": "2011-03-01 15:50:45", "badge": 6, "user": 452}}, {"pk": 1472, "model": "server.award", "fields": {"date": "2011-03-01 19:50:47", "badge": 30, "user": 312}}, {"pk": 1473, "model": "server.award", "fields": {"date": "2011-03-02 00:05:46", "badge": 13, "user": 57}}, {"pk": 1474, "model": "server.award", "fields": {"date": "2011-03-02 00:05:46", "badge": 13, "user": 58}}, {"pk": 1475, "model": "server.award", "fields": {"date": "2011-03-02 01:50:46", "badge": 6, "user": 183}}, {"pk": 1476, "model": "server.award", "fields": {"date": "2011-03-03 00:20:47", "badge": 13, "user": 61}}, {"pk": 1477, "model": "server.award", "fields": {"date": "2011-03-03 01:20:48", "badge": 29, "user": 351}}, {"pk": 1478, "model": "server.award", "fields": {"date": "2011-03-03 02:50:47", "badge": 5, "user": 260}}, {"pk": 1479, "model": "server.award", "fields": {"date": "2011-03-03 15:05:47", "badge": 22, "user": 116}}, {"pk": 1480, "model": "server.award", "fields": {"date": "2011-03-03 18:05:45", "badge": 5, "user": 305}}, {"pk": 1481, "model": "server.award", "fields": {"date": "2011-03-04 10:20:45", "badge": 25, "user": 29}}, {"pk": 1482, "model": "server.award", "fields": {"date": "2011-03-04 13:35:45", "badge": 22, "user": 1}}, {"pk": 1483, "model": "server.award", "fields": {"date": "2011-03-05 00:35:47", "badge": 13, "user": 65}}, {"pk": 1484, "model": "server.award", "fields": {"date": "2011-03-05 00:35:47", "badge": 13, "user": 67}}, {"pk": 1485, "model": "server.award", "fields": {"date": "2011-03-05 00:35:47", "badge": 13, "user": 69}}, {"pk": 1486, "model": "server.award", "fields": {"date": "2011-03-05 00:35:47", "badge": 13, "user": 70}}, {"pk": 1487, "model": "server.award", "fields": {"date": "2011-03-05 00:35:47", "badge": 13, "user": 71}}, {"pk": 1488, "model": "server.award", "fields": {"date": "2011-03-05 00:35:47", "badge": 13, "user": 72}}, {"pk": 1489, "model": "server.award", "fields": {"date": "2011-03-05 00:35:47", "badge": 13, "user": 73}}, {"pk": 1490, "model": "server.award", "fields": {"date": "2011-03-05 00:35:47", "badge": 13, "user": 78}}, {"pk": 1491, "model": "server.award", "fields": {"date": "2011-03-05 00:35:47", "badge": 13, "user": 85}}, {"pk": 1492, "model": "server.award", "fields": {"date": "2011-03-05 11:35:47", "badge": 22, "user": 29}}, {"pk": 1493, "model": "server.award", "fields": {"date": "2011-03-06 00:20:45", "badge": 13, "user": 86}}, {"pk": 1494, "model": "server.award", "fields": {"date": "2011-03-06 00:20:45", "badge": 13, "user": 87}}, {"pk": 1495, "model": "server.award", "fields": {"date": "2011-03-06 19:35:45", "badge": 2, "user": 114}}, {"pk": 1496, "model": "server.award", "fields": {"date": "2011-03-07 00:05:45", "badge": 13, "user": 88}}, {"pk": 1497, "model": "server.award", "fields": {"date": "2011-03-07 00:05:45", "badge": 13, "user": 89}}, {"pk": 1498, "model": "server.award", "fields": {"date": "2011-03-07 00:05:45", "badge": 13, "user": 90}}, {"pk": 1499, "model": "server.award", "fields": {"date": "2011-03-07 00:05:45", "badge": 13, "user": 98}}, {"pk": 1500, "model": "server.award", "fields": {"date": "2011-03-07 05:35:47", "badge": 25, "user": 9}}, {"pk": 1501, "model": "server.award", "fields": {"date": "2011-03-08 01:05:48", "badge": 8, "user": 202}}, {"pk": 1502, "model": "server.award", "fields": {"date": "2011-03-08 03:35:46", "badge": 19, "user": 155}}, {"pk": 1503, "model": "server.award", "fields": {"date": "2011-03-08 11:05:45", "badge": 22, "user": 126}}, {"pk": 1504, "model": "server.award", "fields": {"date": "2011-03-08 16:35:47", "badge": 18, "user": 126}}, {"pk": 1505, "model": "server.award", "fields": {"date": "2011-03-08 17:05:48", "badge": 13, "user": 81}}, {"pk": 1506, "model": "server.award", "fields": {"date": "2011-03-08 20:20:45", "badge": 19, "user": 29}}, {"pk": 1507, "model": "server.award", "fields": {"date": "2011-03-08 22:35:46", "badge": 25, "user": 9}}, {"pk": 1508, "model": "server.award", "fields": {"date": "2011-03-09 00:05:46", "badge": 13, "user": 109}}, {"pk": 1509, "model": "server.award", "fields": {"date": "2011-03-09 00:05:46", "badge": 13, "user": 112}}, {"pk": 1510, "model": "server.award", "fields": {"date": "2011-03-09 00:05:46", "badge": 13, "user": 115}}, {"pk": 1511, "model": "server.award", "fields": {"date": "2011-03-09 10:50:46", "badge": 25, "user": 284}}, {"pk": 1512, "model": "server.award", "fields": {"date": "2011-03-09 11:20:45", "badge": 10, "user": 114}}, {"pk": 1513, "model": "server.award", "fields": {"date": "2011-03-09 17:20:46", "badge": 1, "user": 209}}, {"pk": 1514, "model": "server.award", "fields": {"date": "2011-03-09 17:50:48", "badge": 1, "user": 256}}, {"pk": 1515, "model": "server.award", "fields": {"date": "2011-03-10 00:35:45", "badge": 13, "user": 116}}, {"pk": 1516, "model": "server.award", "fields": {"date": "2011-03-10 00:35:45", "badge": 13, "user": 118}}, {"pk": 1517, "model": "server.award", "fields": {"date": "2011-03-10 15:05:49", "badge": 22, "user": 37}}, {"pk": 1518, "model": "server.award", "fields": {"date": "2011-03-10 18:20:45", "badge": 16, "user": 54}}, {"pk": 1519, "model": "server.award", "fields": {"date": "2011-03-11 00:05:46", "badge": 14, "user": 9}}, {"pk": 1520, "model": "server.award", "fields": {"date": "2011-03-11 00:05:46", "badge": 13, "user": 119}}, {"pk": 1521, "model": "server.award", "fields": {"date": "2011-03-11 05:50:45", "badge": 3, "user": 430}}, {"pk": 1522, "model": "server.award", "fields": {"date": "2011-03-11 11:05:46", "badge": 22, "user": 65}}, {"pk": 1523, "model": "server.award", "fields": {"date": "2011-03-11 11:35:47", "badge": 18, "user": 65}}, {"pk": 1524, "model": "server.award", "fields": {"date": "2011-03-11 16:05:47", "badge": 19, "user": 312}}, {"pk": 1525, "model": "server.award", "fields": {"date": "2011-03-11 17:50:46", "badge": 38, "user": 312}}, {"pk": 1526, "model": "server.award", "fields": {"date": "2011-03-12 00:20:47", "badge": 13, "user": 121}}, {"pk": 1527, "model": "server.award", "fields": {"date": "2011-03-12 06:35:50", "badge": 10, "user": 8}}, {"pk": 1528, "model": "server.award", "fields": {"date": "2011-03-12 08:20:45", "badge": 10, "user": 430}}, {"pk": 1529, "model": "server.award", "fields": {"date": "2011-03-13 01:05:44", "badge": 13, "user": 123}}, {"pk": 1530, "model": "server.award", "fields": {"date": "2011-03-13 12:35:44", "badge": 22, "user": 29}}, {"pk": 1531, "model": "server.award", "fields": {"date": "2011-03-13 12:50:46", "badge": 22, "user": 55}}, {"pk": 1532, "model": "server.award", "fields": {"date": "2011-03-13 16:05:45", "badge": 18, "user": 55}}, {"pk": 1533, "model": "server.award", "fields": {"date": "2011-03-14 00:05:47", "badge": 13, "user": 126}}, {"pk": 1534, "model": "server.award", "fields": {"date": "2011-03-14 09:20:45", "badge": 22, "user": 313}}, {"pk": 1535, "model": "server.award", "fields": {"date": "2011-03-14 10:35:46", "badge": 38, "user": 204}}, {"pk": 1536, "model": "server.award", "fields": {"date": "2011-03-15 00:05:47", "badge": 22, "user": 116}}, {"pk": 1537, "model": "server.award", "fields": {"date": "2011-03-15 01:05:45", "badge": 13, "user": 130}}, {"pk": 1538, "model": "server.award", "fields": {"date": "2011-03-15 08:50:45", "badge": 6, "user": 19}}, {"pk": 1539, "model": "server.award", "fields": {"date": "2011-03-15 13:20:46", "badge": 4, "user": 65}}, {"pk": 1540, "model": "server.award", "fields": {"date": "2011-03-16 00:05:47", "badge": 13, "user": 137}}, {"pk": 1541, "model": "server.award", "fields": {"date": "2011-03-16 00:05:47", "badge": 13, "user": 140}}, {"pk": 1542, "model": "server.award", "fields": {"date": "2011-03-16 00:05:47", "badge": 13, "user": 141}}, {"pk": 1543, "model": "server.award", "fields": {"date": "2011-03-16 09:05:47", "badge": 19, "user": 52}}, {"pk": 1544, "model": "server.award", "fields": {"date": "2011-03-16 11:35:45", "badge": 6, "user": 209}}, {"pk": 1545, "model": "server.award", "fields": {"date": "2011-03-16 12:50:45", "badge": 25, "user": 217}}, {"pk": 1546, "model": "server.award", "fields": {"date": "2011-03-16 20:20:45", "badge": 16, "user": 140}}, {"pk": 1547, "model": "server.award", "fields": {"date": "2011-03-16 23:05:45", "badge": 6, "user": 120}}, {"pk": 1548, "model": "server.award", "fields": {"date": "2011-03-16 23:05:45", "badge": 7, "user": 120}}, {"pk": 1549, "model": "server.award", "fields": {"date": "2011-03-17 00:05:46", "badge": 13, "user": 145}}, {"pk": 1550, "model": "server.award", "fields": {"date": "2011-03-17 00:05:46", "badge": 13, "user": 147}}, {"pk": 1551, "model": "server.award", "fields": {"date": "2011-03-17 06:05:45", "badge": 6, "user": 100}}, {"pk": 1552, "model": "server.award", "fields": {"date": "2011-03-17 10:50:48", "badge": 22, "user": 389}}, {"pk": 1553, "model": "server.award", "fields": {"date": "2011-03-17 22:35:45", "badge": 22, "user": 37}}, {"pk": 1554, "model": "server.award", "fields": {"date": "2011-03-18 18:35:46", "badge": 4, "user": 116}}, {"pk": 1555, "model": "server.award", "fields": {"date": "2011-03-19 15:20:45", "badge": 22, "user": 72}}, {"pk": 1556, "model": "server.award", "fields": {"date": "2011-03-19 17:05:46", "badge": 18, "user": 72}}, {"pk": 1557, "model": "server.award", "fields": {"date": "2011-03-20 00:05:45", "badge": 13, "user": 151}}, {"pk": 1558, "model": "server.award", "fields": {"date": "2011-03-20 02:05:45", "badge": 22, "user": 65}}, {"pk": 1559, "model": "server.award", "fields": {"date": "2011-03-20 02:35:44", "badge": 18, "user": 65}}, {"pk": 1560, "model": "server.award", "fields": {"date": "2011-03-20 13:50:44", "badge": 25, "user": 22}}, {"pk": 1561, "model": "server.award", "fields": {"date": "2011-03-20 17:20:44", "badge": 4, "user": 54}}, {"pk": 1562, "model": "server.award", "fields": {"date": "2011-03-21 00:20:45", "badge": 13, "user": 155}}, {"pk": 1563, "model": "server.award", "fields": {"date": "2011-03-21 02:50:45", "badge": 25, "user": 86}}, {"pk": 1564, "model": "server.award", "fields": {"date": "2011-03-22 11:20:44", "badge": 29, "user": 217}}, {"pk": 1565, "model": "server.award", "fields": {"date": "2011-03-22 15:50:49", "badge": 6, "user": 370}}, {"pk": 1566, "model": "server.award", "fields": {"date": "2011-03-22 17:50:46", "badge": 19, "user": 116}}, {"pk": 1567, "model": "server.award", "fields": {"date": "2011-03-22 19:50:48", "badge": 14, "user": 116}}, {"pk": 1568, "model": "server.award", "fields": {"date": "2011-03-22 21:50:46", "badge": 19, "user": 6}}, {"pk": 1569, "model": "server.award", "fields": {"date": "2011-03-23 09:20:45", "badge": 14, "user": 70}}, {"pk": 1570, "model": "server.award", "fields": {"date": "2011-03-23 09:20:46", "badge": 22, "user": 286}}, {"pk": 1571, "model": "server.award", "fields": {"date": "2011-03-23 13:20:48", "badge": 18, "user": 286}}, {"pk": 1572, "model": "server.award", "fields": {"date": "2011-03-23 17:35:46", "badge": 19, "user": 88}}, {"pk": 1573, "model": "server.award", "fields": {"date": "2011-03-23 17:35:46", "badge": 22, "user": 86}}, {"pk": 1574, "model": "server.award", "fields": {"date": "2011-03-24 00:20:45", "badge": 13, "user": 168}}, {"pk": 1575, "model": "server.award", "fields": {"date": "2011-03-24 10:05:47", "badge": 5, "user": 473}}, {"pk": 1576, "model": "server.award", "fields": {"date": "2011-03-24 17:20:46", "badge": 2, "user": 4}}, {"pk": 1577, "model": "server.award", "fields": {"date": "2011-03-25 01:35:45", "badge": 13, "user": 170}}, {"pk": 1578, "model": "server.award", "fields": {"date": "2011-03-25 18:20:47", "badge": 25, "user": 61}}, {"pk": 1579, "model": "server.award", "fields": {"date": "2011-03-25 21:35:48", "badge": 26, "user": 199}}, {"pk": 1580, "model": "server.award", "fields": {"date": "2011-03-26 10:35:45", "badge": 22, "user": 65}}, {"pk": 1581, "model": "server.award", "fields": {"date": "2011-03-27 00:05:46", "badge": 13, "user": 186}}, {"pk": 1582, "model": "server.award", "fields": {"date": "2011-03-27 12:20:45", "badge": 23, "user": 65}}, {"pk": 1583, "model": "server.award", "fields": {"date": "2011-03-27 21:35:46", "badge": 25, "user": 109}}, {"pk": 1584, "model": "server.award", "fields": {"date": "2011-03-28 01:35:46", "badge": 19, "user": 151}}, {"pk": 1585, "model": "server.award", "fields": {"date": "2011-03-28 02:20:45", "badge": 38, "user": 155}}, {"pk": 1586, "model": "server.award", "fields": {"date": "2011-03-28 05:35:49", "badge": 26, "user": 29}}, {"pk": 1587, "model": "server.award", "fields": {"date": "2011-03-28 17:20:45", "badge": 1, "user": 475}}, {"pk": 1588, "model": "server.award", "fields": {"date": "2011-03-28 23:35:46", "badge": 30, "user": 65}}, {"pk": 1589, "model": "server.award", "fields": {"date": "2011-03-30 05:50:44", "badge": 25, "user": 202}}, {"pk": 1590, "model": "server.award", "fields": {"date": "2011-03-30 12:35:45", "badge": 11, "user": 225}}, {"pk": 1591, "model": "server.award", "fields": {"date": "2011-03-30 13:20:46", "badge": 25, "user": 54}}, {"pk": 1592, "model": "server.award", "fields": {"date": "2011-03-30 15:05:46", "badge": 22, "user": 37}}, {"pk": 1593, "model": "server.award", "fields": {"date": "2011-03-30 18:05:49", "badge": 22, "user": 305}}, {"pk": 1594, "model": "server.award", "fields": {"date": "2011-03-31 00:05:46", "badge": 13, "user": 198}}, {"pk": 1595, "model": "server.award", "fields": {"date": "2011-03-31 09:05:45", "badge": 29, "user": 401}}, {"pk": 1596, "model": "server.award", "fields": {"date": "2011-04-01 00:05:49", "badge": 13, "user": 199}}, {"pk": 1597, "model": "server.award", "fields": {"date": "2011-04-01 04:05:48", "badge": 25, "user": 478}}, {"pk": 1598, "model": "server.award", "fields": {"date": "2011-04-01 15:20:45", "badge": 7, "user": 30}}, {"pk": 1599, "model": "server.award", "fields": {"date": "2011-04-01 20:05:49", "badge": 22, "user": 29}}, {"pk": 1600, "model": "server.award", "fields": {"date": "2011-04-01 23:35:45", "badge": 16, "user": 401}}, {"pk": 1601, "model": "server.award", "fields": {"date": "2011-04-02 04:20:47", "badge": 25, "user": 473}}, {"pk": 1602, "model": "server.award", "fields": {"date": "2011-04-02 17:20:45", "badge": 1, "user": 156}}, {"pk": 1603, "model": "server.award", "fields": {"date": "2011-04-03 00:20:44", "badge": 13, "user": 204}}, {"pk": 1604, "model": "server.award", "fields": {"date": "2011-04-03 21:35:46", "badge": 1, "user": 190}}, {"pk": 1605, "model": "server.award", "fields": {"date": "2011-04-04 04:20:45", "badge": 6, "user": 156}}, {"pk": 1606, "model": "server.award", "fields": {"date": "2011-04-04 05:35:47", "badge": 38, "user": 70}}, {"pk": 1607, "model": "server.award", "fields": {"date": "2011-04-04 06:35:45", "badge": 38, "user": 29}}, {"pk": 1608, "model": "server.award", "fields": {"date": "2011-04-04 07:50:45", "badge": 6, "user": 344}}, {"pk": 1609, "model": "server.award", "fields": {"date": "2011-04-04 14:35:45", "badge": 6, "user": 158}}, {"pk": 1610, "model": "server.award", "fields": {"date": "2011-04-04 16:21:03", "badge": 22, "user": 35}}, {"pk": 1611, "model": "server.award", "fields": {"date": "2011-04-04 18:35:45", "badge": 22, "user": 65}}, {"pk": 1612, "model": "server.award", "fields": {"date": "2011-04-04 20:20:46", "badge": 22, "user": 141}}, {"pk": 1613, "model": "server.award", "fields": {"date": "2011-04-04 20:35:49", "badge": 14, "user": 72}}, {"pk": 1614, "model": "server.award", "fields": {"date": "2011-04-04 20:50:48", "badge": 22, "user": 118}}, {"pk": 1615, "model": "server.award", "fields": {"date": "2011-04-04 22:35:46", "badge": 25, "user": 215}}, {"pk": 1616, "model": "server.award", "fields": {"date": "2011-04-05 01:20:45", "badge": 29, "user": 120}}, {"pk": 1617, "model": "server.award", "fields": {"date": "2011-04-05 12:35:46", "badge": 4, "user": 451}}, {"pk": 1618, "model": "server.award", "fields": {"date": "2011-04-05 14:20:46", "badge": 6, "user": 114}}, {"pk": 1619, "model": "server.award", "fields": {"date": "2011-04-05 20:20:49", "badge": 13, "user": 120}}, {"pk": 1620, "model": "server.award", "fields": {"date": "2011-04-06 13:05:46", "badge": 26, "user": 313}}, {"pk": 1621, "model": "server.award", "fields": {"date": "2011-04-06 16:20:47", "badge": 6, "user": 465}}, {"pk": 1622, "model": "server.award", "fields": {"date": "2011-04-06 20:05:48", "badge": 16, "user": 119}}, {"pk": 1623, "model": "server.award", "fields": {"date": "2011-04-07 03:20:45", "badge": 22, "user": 35}}, {"pk": 1624, "model": "server.award", "fields": {"date": "2011-04-07 10:20:46", "badge": 2, "user": 38}}, {"pk": 1625, "model": "server.award", "fields": {"date": "2011-04-07 14:50:47", "badge": 10, "user": 38}}, {"pk": 1626, "model": "server.award", "fields": {"date": "2011-04-07 17:35:46", "badge": 22, "user": 37}}, {"pk": 1627, "model": "server.award", "fields": {"date": "2011-04-07 19:05:47", "badge": 22, "user": 65}}, {"pk": 1628, "model": "server.award", "fields": {"date": "2011-04-07 19:05:47", "badge": 30, "user": 313}}, {"pk": 1629, "model": "server.award", "fields": {"date": "2011-04-07 22:50:47", "badge": 1, "user": 465}}, {"pk": 1630, "model": "server.award", "fields": {"date": "2011-04-08 16:20:46", "badge": 29, "user": 305}}, {"pk": 1631, "model": "server.award", "fields": {"date": "2011-04-08 19:20:46", "badge": 3, "user": 115}}, {"pk": 1632, "model": "server.award", "fields": {"date": "2011-04-08 20:20:47", "badge": 6, "user": 132}}, {"pk": 1633, "model": "server.award", "fields": {"date": "2011-04-09 00:20:45", "badge": 13, "user": 215}}, {"pk": 1634, "model": "server.award", "fields": {"date": "2011-04-09 00:20:45", "badge": 13, "user": 216}}, {"pk": 1635, "model": "server.award", "fields": {"date": "2011-04-09 00:20:45", "badge": 13, "user": 217}}, {"pk": 1636, "model": "server.award", "fields": {"date": "2011-04-09 05:20:47", "badge": 37, "user": 389}}, {"pk": 1637, "model": "server.award", "fields": {"date": "2011-04-10 00:20:45", "badge": 25, "user": 35}}, {"pk": 1638, "model": "server.award", "fields": {"date": "2011-04-11 08:35:48", "badge": 19, "user": 9}}, {"pk": 1639, "model": "server.award", "fields": {"date": "2011-04-11 12:50:45", "badge": 7, "user": 389}}, {"pk": 1640, "model": "server.award", "fields": {"date": "2011-04-11 14:05:45", "badge": 25, "user": 215}}, {"pk": 1641, "model": "server.award", "fields": {"date": "2011-04-11 18:35:47", "badge": 25, "user": 88}}, {"pk": 1642, "model": "server.award", "fields": {"date": "2011-04-12 18:20:45", "badge": 22, "user": 29}}, {"pk": 1643, "model": "server.award", "fields": {"date": "2011-04-12 18:20:45", "badge": 22, "user": 35}}, {"pk": 1644, "model": "server.award", "fields": {"date": "2011-04-12 18:20:45", "badge": 22, "user": 85}}, {"pk": 1645, "model": "server.award", "fields": {"date": "2011-04-12 18:50:46", "badge": 30, "user": 35}}, {"pk": 1646, "model": "server.award", "fields": {"date": "2011-04-12 21:50:47", "badge": 29, "user": 3}}, {"pk": 1647, "model": "server.award", "fields": {"date": "2011-04-13 00:05:46", "badge": 13, "user": 221}}, {"pk": 1648, "model": "server.award", "fields": {"date": "2011-04-13 09:05:45", "badge": 26, "user": 311}}, {"pk": 1649, "model": "server.award", "fields": {"date": "2011-04-13 13:35:45", "badge": 22, "user": 54}}, {"pk": 1650, "model": "server.award", "fields": {"date": "2011-04-13 13:50:47", "badge": 5, "user": 78}}, {"pk": 1651, "model": "server.award", "fields": {"date": "2011-04-13 15:20:48", "badge": 13, "user": 3}}, {"pk": 1652, "model": "server.award", "fields": {"date": "2011-04-13 17:35:48", "badge": 18, "user": 54}}, {"pk": 1653, "model": "server.award", "fields": {"date": "2011-04-14 00:05:46", "badge": 13, "user": 224}}, {"pk": 1654, "model": "server.award", "fields": {"date": "2011-04-14 00:05:46", "badge": 13, "user": 225}}, {"pk": 1655, "model": "server.award", "fields": {"date": "2011-04-14 00:20:44", "badge": 22, "user": 313}}, {"pk": 1656, "model": "server.award", "fields": {"date": "2011-04-14 15:50:48", "badge": 2, "user": 169}}, {"pk": 1657, "model": "server.award", "fields": {"date": "2011-04-14 15:50:48", "badge": 3, "user": 169}}, {"pk": 1658, "model": "server.award", "fields": {"date": "2011-04-15 00:20:48", "badge": 13, "user": 233}}, {"pk": 1659, "model": "server.award", "fields": {"date": "2011-04-15 00:20:48", "badge": 13, "user": 234}}, {"pk": 1660, "model": "server.award", "fields": {"date": "2011-04-15 00:20:48", "badge": 13, "user": 237}}, {"pk": 1661, "model": "server.award", "fields": {"date": "2011-04-15 03:35:46", "badge": 18, "user": 313}}, {"pk": 1662, "model": "server.award", "fields": {"date": "2011-04-15 08:35:47", "badge": 22, "user": 37}}, {"pk": 1663, "model": "server.award", "fields": {"date": "2011-04-15 08:35:47", "badge": 22, "user": 457}}, {"pk": 1664, "model": "server.award", "fields": {"date": "2011-04-15 11:50:45", "badge": 10, "user": 169}}, {"pk": 1665, "model": "server.award", "fields": {"date": "2011-04-15 14:50:46", "badge": 22, "user": 86}}, {"pk": 1666, "model": "server.award", "fields": {"date": "2011-04-15 14:50:47", "badge": 18, "user": 457}}, {"pk": 1667, "model": "server.award", "fields": {"date": "2011-04-17 14:05:46", "badge": 26, "user": 397}}, {"pk": 1668, "model": "server.award", "fields": {"date": "2011-04-18 00:05:45", "badge": 13, "user": 244}}, {"pk": 1669, "model": "server.award", "fields": {"date": "2011-04-18 20:05:49", "badge": 6, "user": 419}}, {"pk": 1670, "model": "server.award", "fields": {"date": "2011-04-19 02:50:46", "badge": 5, "user": 389}}, {"pk": 1671, "model": "server.award", "fields": {"date": "2011-04-19 14:50:46", "badge": 10, "user": 98}}, {"pk": 1672, "model": "server.award", "fields": {"date": "2011-04-19 15:05:51", "badge": 1, "user": 165}}, {"pk": 1673, "model": "server.award", "fields": {"date": "2011-04-19 18:20:49", "badge": 19, "user": 72}}, {"pk": 1674, "model": "server.award", "fields": {"date": "2011-04-19 20:50:48", "badge": 19, "user": 58}}, {"pk": 1675, "model": "server.award", "fields": {"date": "2011-04-20 03:05:46", "badge": 22, "user": 72}}, {"pk": 1676, "model": "server.award", "fields": {"date": "2011-04-20 16:20:44", "badge": 22, "user": 86}}, {"pk": 1677, "model": "server.award", "fields": {"date": "2011-04-20 18:50:45", "badge": 16, "user": 70}}, {"pk": 1678, "model": "server.award", "fields": {"date": "2011-04-20 20:50:45", "badge": 22, "user": 65}}, {"pk": 1679, "model": "server.award", "fields": {"date": "2011-04-21 00:35:45", "badge": 13, "user": 252}}, {"pk": 1680, "model": "server.award", "fields": {"date": "2011-04-21 08:35:47", "badge": 19, "user": 72}}, {"pk": 1681, "model": "server.award", "fields": {"date": "2011-04-21 15:20:45", "badge": 25, "user": 29}}, {"pk": 1682, "model": "server.award", "fields": {"date": "2011-04-21 21:50:45", "badge": 19, "user": 29}}, {"pk": 1683, "model": "server.award", "fields": {"date": "2011-04-25 00:20:46", "badge": 13, "user": 270}}, {"pk": 1684, "model": "server.award", "fields": {"date": "2011-04-25 19:05:45", "badge": 22, "user": 389}}, {"pk": 1685, "model": "server.award", "fields": {"date": "2011-04-26 00:05:46", "badge": 13, "user": 273}}, {"pk": 1686, "model": "server.award", "fields": {"date": "2011-04-26 02:35:45", "badge": 25, "user": 88}}, {"pk": 1687, "model": "server.award", "fields": {"date": "2011-04-26 05:20:45", "badge": 22, "user": 29}}, {"pk": 1688, "model": "server.award", "fields": {"date": "2011-04-26 15:50:44", "badge": 3, "user": 98}}, {"pk": 1689, "model": "server.award", "fields": {"date": "2011-04-26 19:05:44", "badge": 25, "user": 116}}, {"pk": 1690, "model": "server.award", "fields": {"date": "2011-04-27 00:20:46", "badge": 13, "user": 274}}, {"pk": 1691, "model": "server.award", "fields": {"date": "2011-04-27 08:35:45", "badge": 1, "user": 68}}, {"pk": 1692, "model": "server.award", "fields": {"date": "2011-04-27 13:50:45", "badge": 1, "user": 473}}, {"pk": 1693, "model": "server.award", "fields": {"date": "2011-04-28 09:35:44", "badge": 6, "user": 87}}, {"pk": 1694, "model": "server.award", "fields": {"date": "2011-04-28 13:20:45", "badge": 22, "user": 98}}, {"pk": 1695, "model": "server.award", "fields": {"date": "2011-04-28 17:35:50", "badge": 18, "user": 98}}, {"pk": 1696, "model": "server.award", "fields": {"date": "2011-04-28 23:05:46", "badge": 4, "user": 72}}, {"pk": 1697, "model": "server.award", "fields": {"date": "2011-04-30 00:20:45", "badge": 13, "user": 284}}, {"pk": 1698, "model": "server.award", "fields": {"date": "2011-04-30 00:20:45", "badge": 13, "user": 286}}, {"pk": 1699, "model": "server.award", "fields": {"date": "2011-04-30 22:20:45", "badge": 14, "user": 457}}, {"pk": 1700, "model": "server.award", "fields": {"date": "2011-05-01 12:50:44", "badge": 6, "user": 111}}, {"pk": 1701, "model": "server.award", "fields": {"date": "2011-05-01 23:05:44", "badge": 2, "user": 111}}, {"pk": 1702, "model": "server.award", "fields": {"date": "2011-05-02 12:20:45", "badge": 26, "user": 199}}, {"pk": 1703, "model": "server.award", "fields": {"date": "2011-05-03 09:05:45", "badge": 38, "user": 313}}, {"pk": 1704, "model": "server.award", "fields": {"date": "2011-05-03 17:50:45", "badge": 16, "user": 313}}, {"pk": 1705, "model": "server.award", "fields": {"date": "2011-05-04 09:05:45", "badge": 29, "user": 98}}, {"pk": 1706, "model": "server.award", "fields": {"date": "2011-05-04 18:50:45", "badge": 25, "user": 445}}, {"pk": 1707, "model": "server.award", "fields": {"date": "2011-05-05 06:35:45", "badge": 19, "user": 445}}, {"pk": 1708, "model": "server.award", "fields": {"date": "2011-05-06 01:05:45", "badge": 13, "user": 299}}, {"pk": 1709, "model": "server.award", "fields": {"date": "2011-05-07 00:05:47", "badge": 13, "user": 303}}, {"pk": 1710, "model": "server.award", "fields": {"date": "2011-05-07 00:05:47", "badge": 13, "user": 305}}, {"pk": 1711, "model": "server.award", "fields": {"date": "2011-05-07 07:35:44", "badge": 11, "user": 98}}, {"pk": 1712, "model": "server.award", "fields": {"date": "2011-05-07 15:50:44", "badge": 19, "user": 86}}, {"pk": 1713, "model": "server.award", "fields": {"date": "2011-05-08 03:50:44", "badge": 22, "user": 273}}, {"pk": 1714, "model": "server.award", "fields": {"date": "2011-05-09 13:20:45", "badge": 25, "user": 72}}, {"pk": 1715, "model": "server.award", "fields": {"date": "2011-05-09 20:35:45", "badge": 1, "user": 180}}, {"pk": 1716, "model": "server.award", "fields": {"date": "2011-05-11 13:05:45", "badge": 25, "user": 321}}, {"pk": 1717, "model": "server.award", "fields": {"date": "2011-05-11 14:20:44", "badge": 9, "user": 165}}, {"pk": 1718, "model": "server.award", "fields": {"date": "2011-05-12 00:05:45", "badge": 13, "user": 312}}, {"pk": 1719, "model": "server.award", "fields": {"date": "2011-05-12 00:05:45", "badge": 13, "user": 313}}, {"pk": 1720, "model": "server.award", "fields": {"date": "2011-05-12 06:50:44", "badge": 1, "user": 182}}, {"pk": 1721, "model": "server.award", "fields": {"date": "2011-05-12 13:50:45", "badge": 6, "user": 165}}, {"pk": 1722, "model": "server.award", "fields": {"date": "2011-05-12 18:35:45", "badge": 5, "user": 98}}, {"pk": 1723, "model": "server.award", "fields": {"date": "2011-05-13 21:05:46", "badge": 10, "user": 165}}, {"pk": 1724, "model": "server.award", "fields": {"date": "2011-05-15 00:05:46", "badge": 13, "user": 320}}, {"pk": 1725, "model": "server.award", "fields": {"date": "2011-05-15 16:50:44", "badge": 22, "user": 37}}, {"pk": 1726, "model": "server.award", "fields": {"date": "2011-05-16 17:50:44", "badge": 19, "user": 463}}, {"pk": 1727, "model": "server.award", "fields": {"date": "2011-05-17 02:50:45", "badge": 37, "user": 190}}, {"pk": 1728, "model": "server.award", "fields": {"date": "2011-05-17 07:50:45", "badge": 11, "user": 89}}, {"pk": 1729, "model": "server.award", "fields": {"date": "2011-05-18 00:20:45", "badge": 13, "user": 324}}, {"pk": 1730, "model": "server.award", "fields": {"date": "2011-05-18 14:05:44", "badge": 25, "user": 199}}, {"pk": 1731, "model": "server.award", "fields": {"date": "2011-05-18 18:50:45", "badge": 25, "user": 22}}, {"pk": 1732, "model": "server.award", "fields": {"date": "2011-05-19 00:20:45", "badge": 13, "user": 328}}, {"pk": 1733, "model": "server.award", "fields": {"date": "2011-05-19 06:35:45", "badge": 25, "user": 163}}, {"pk": 1734, "model": "server.award", "fields": {"date": "2011-05-19 08:50:44", "badge": 6, "user": 108}}, {"pk": 1735, "model": "server.award", "fields": {"date": "2011-05-19 11:35:45", "badge": 1, "user": 108}}, {"pk": 1736, "model": "server.award", "fields": {"date": "2011-05-20 00:05:44", "badge": 13, "user": 333}}, {"pk": 1737, "model": "server.award", "fields": {"date": "2011-05-21 10:05:46", "badge": 26, "user": 88}}, {"pk": 1738, "model": "server.award", "fields": {"date": "2011-05-22 00:20:45", "badge": 13, "user": 338}}, {"pk": 1739, "model": "server.award", "fields": {"date": "2011-05-22 17:35:44", "badge": 22, "user": 58}}, {"pk": 1740, "model": "server.award", "fields": {"date": "2011-05-23 00:05:46", "badge": 13, "user": 341}}, {"pk": 1741, "model": "server.award", "fields": {"date": "2011-05-23 00:05:46", "badge": 13, "user": 343}}, {"pk": 1742, "model": "server.award", "fields": {"date": "2011-05-24 02:35:47", "badge": 18, "user": 29}}, {"pk": 1743, "model": "server.award", "fields": {"date": "2011-05-24 07:20:46", "badge": 25, "user": 312}}, {"pk": 1744, "model": "server.award", "fields": {"date": "2011-05-24 14:50:45", "badge": 38, "user": 55}}, {"pk": 1745, "model": "server.award", "fields": {"date": "2011-05-24 15:35:45", "badge": 25, "user": 299}}, {"pk": 1746, "model": "server.award", "fields": {"date": "2011-05-24 19:20:45", "badge": 26, "user": 22}}, {"pk": 1747, "model": "server.award", "fields": {"date": "2011-05-24 23:05:47", "badge": 5, "user": 121}}, {"pk": 1748, "model": "server.award", "fields": {"date": "2011-05-26 00:35:45", "badge": 13, "user": 351}}, {"pk": 1749, "model": "server.award", "fields": {"date": "2011-05-26 16:35:44", "badge": 5, "user": 263}}, {"pk": 1750, "model": "server.award", "fields": {"date": "2011-05-26 20:50:45", "badge": 6, "user": 190}}, {"pk": 1751, "model": "server.award", "fields": {"date": "2011-05-27 08:05:45", "badge": 22, "user": 457}}, {"pk": 1752, "model": "server.award", "fields": {"date": "2011-05-29 03:35:46", "badge": 19, "user": 89}}, {"pk": 1753, "model": "server.award", "fields": {"date": "2011-05-30 13:20:48", "badge": 22, "user": 126}}, {"pk": 1754, "model": "server.award", "fields": {"date": "2011-05-30 17:05:46", "badge": 18, "user": 126}}, {"pk": 1755, "model": "server.award", "fields": {"date": "2011-05-30 17:35:47", "badge": 19, "user": 22}}, {"pk": 1756, "model": "server.award", "fields": {"date": "2011-06-01 02:05:45", "badge": 1, "user": 158}}, {"pk": 1757, "model": "server.award", "fields": {"date": "2011-06-01 09:35:46", "badge": 11, "user": 37}}, {"pk": 1758, "model": "server.award", "fields": {"date": "2011-06-01 10:35:46", "badge": 7, "user": 90}}, {"pk": 1759, "model": "server.award", "fields": {"date": "2011-06-01 12:50:47", "badge": 7, "user": 190}}, {"pk": 1760, "model": "server.award", "fields": {"date": "2011-06-02 00:35:47", "badge": 13, "user": 374}}, {"pk": 1761, "model": "server.award", "fields": {"date": "2011-06-02 00:35:47", "badge": 13, "user": 378}}, {"pk": 1762, "model": "server.award", "fields": {"date": "2011-06-03 12:05:49", "badge": 22, "user": 35}}, {"pk": 1763, "model": "server.award", "fields": {"date": "2011-06-03 21:50:48", "badge": 22, "user": 29}}, {"pk": 1764, "model": "server.award", "fields": {"date": "2011-06-05 05:35:47", "badge": 2, "user": 370}}, {"pk": 1765, "model": "server.award", "fields": {"date": "2011-06-06 13:20:46", "badge": 30, "user": 37}}, {"pk": 1766, "model": "server.award", "fields": {"date": "2011-06-07 00:35:46", "badge": 13, "user": 389}}, {"pk": 1767, "model": "server.award", "fields": {"date": "2011-06-07 01:20:46", "badge": 25, "user": 91}}, {"pk": 1768, "model": "server.award", "fields": {"date": "2011-06-07 09:05:48", "badge": 37, "user": 98}}, {"pk": 1769, "model": "server.award", "fields": {"date": "2011-06-07 15:50:50", "badge": 1, "user": 497}}, {"pk": 1770, "model": "server.award", "fields": {"date": "2011-06-07 19:20:46", "badge": 2, "user": 497}}, {"pk": 1771, "model": "server.award", "fields": {"date": "2011-06-07 20:35:47", "badge": 25, "user": 1}}, {"pk": 1772, "model": "server.award", "fields": {"date": "2011-06-08 08:20:46", "badge": 22, "user": 65}}, {"pk": 1773, "model": "server.award", "fields": {"date": "2011-06-08 10:05:46", "badge": 4, "user": 29}}, {"pk": 1774, "model": "server.award", "fields": {"date": "2011-06-08 18:36:23", "badge": 19, "user": 35}}, {"pk": 1775, "model": "server.award", "fields": {"date": "2011-06-08 20:51:10", "badge": 3, "user": 497}}, {"pk": 1776, "model": "server.award", "fields": {"date": "2011-06-09 00:21:02", "badge": 13, "user": 397}}, {"pk": 1777, "model": "server.award", "fields": {"date": "2011-06-09 17:35:44", "badge": 11, "user": 35}}, {"pk": 1778, "model": "server.award", "fields": {"date": "2011-06-09 23:35:47", "badge": 23, "user": 457}}, {"pk": 1779, "model": "server.award", "fields": {"date": "2011-06-10 00:05:46", "badge": 13, "user": 401}}, {"pk": 1780, "model": "server.award", "fields": {"date": "2011-06-10 07:50:47", "badge": 11, "user": 3}}, {"pk": 1781, "model": "server.award", "fields": {"date": "2011-06-10 15:05:45", "badge": 16, "user": 204}}, {"pk": 1782, "model": "server.award", "fields": {"date": "2011-06-11 11:05:44", "badge": 8, "user": 70}}, {"pk": 1783, "model": "server.award", "fields": {"date": "2011-06-13 04:20:44", "badge": 9, "user": 457}}, {"pk": 1784, "model": "server.award", "fields": {"date": "2011-06-13 08:35:45", "badge": 25, "user": 217}}, {"pk": 1785, "model": "server.award", "fields": {"date": "2011-06-13 12:35:44", "badge": 6, "user": 130}}, {"pk": 1786, "model": "server.award", "fields": {"date": "2011-06-13 19:20:45", "badge": 6, "user": 277}}, {"pk": 1787, "model": "server.award", "fields": {"date": "2011-06-14 08:35:46", "badge": 6, "user": 463}}, {"pk": 1788, "model": "server.award", "fields": {"date": "2011-06-14 18:20:50", "badge": 19, "user": 22}}, {"pk": 1789, "model": "server.award", "fields": {"date": "2011-06-15 11:05:51", "badge": 19, "user": 198}}, {"pk": 1790, "model": "server.award", "fields": {"date": "2011-06-15 15:05:49", "badge": 19, "user": 29}}, {"pk": 1791, "model": "server.award", "fields": {"date": "2011-06-15 16:05:47", "badge": 5, "user": 52}}, {"pk": 1792, "model": "server.award", "fields": {"date": "2011-06-15 18:20:47", "badge": 22, "user": 86}}, {"pk": 1793, "model": "server.award", "fields": {"date": "2011-06-15 22:05:47", "badge": 25, "user": 313}}, {"pk": 1794, "model": "server.award", "fields": {"date": "2011-06-16 00:05:47", "badge": 13, "user": 418}}, {"pk": 1795, "model": "server.award", "fields": {"date": "2011-06-16 00:05:47", "badge": 13, "user": 419}}, {"pk": 1796, "model": "server.award", "fields": {"date": "2011-06-17 06:05:47", "badge": 22, "user": 65}}, {"pk": 1797, "model": "server.award", "fields": {"date": "2011-06-17 08:50:47", "badge": 2, "user": 254}}, {"pk": 1798, "model": "server.award", "fields": {"date": "2011-06-17 12:05:46", "badge": 1, "user": 40}}, {"pk": 1799, "model": "server.award", "fields": {"date": "2011-06-17 18:05:48", "badge": 1, "user": 263}}, {"pk": 1800, "model": "server.award", "fields": {"date": "2011-06-17 18:20:49", "badge": 26, "user": 61}}, {"pk": 1801, "model": "server.award", "fields": {"date": "2011-06-17 20:20:47", "badge": 22, "user": 72}}, {"pk": 1802, "model": "server.award", "fields": {"date": "2011-06-17 20:35:47", "badge": 23, "user": 35}}, {"pk": 1803, "model": "server.award", "fields": {"date": "2011-06-17 23:05:45", "badge": 20, "user": 1}}, {"pk": 1804, "model": "server.award", "fields": {"date": "2011-06-18 02:20:47", "badge": 2, "user": 228}}, {"pk": 1805, "model": "server.award", "fields": {"date": "2011-06-18 03:05:47", "badge": 11, "user": 199}}, {"pk": 1806, "model": "server.award", "fields": {"date": "2011-06-18 06:35:47", "badge": 3, "user": 205}}, {"pk": 1807, "model": "server.award", "fields": {"date": "2011-06-18 08:05:46", "badge": 1, "user": 205}}, {"pk": 1808, "model": "server.award", "fields": {"date": "2011-06-18 11:05:45", "badge": 25, "user": 451}}, {"pk": 1809, "model": "server.award", "fields": {"date": "2011-06-19 03:05:47", "badge": 22, "user": 67}}, {"pk": 1810, "model": "server.award", "fields": {"date": "2011-06-19 04:20:45", "badge": 22, "user": 94}}, {"pk": 1811, "model": "server.award", "fields": {"date": "2011-06-20 02:05:45", "badge": 3, "user": 113}}, {"pk": 1812, "model": "server.award", "fields": {"date": "2011-06-20 06:20:46", "badge": 38, "user": 457}}, {"pk": 1813, "model": "server.award", "fields": {"date": "2011-06-20 07:05:45", "badge": 31, "user": 29}}, {"pk": 1814, "model": "server.award", "fields": {"date": "2011-06-20 08:20:44", "badge": 6, "user": 254}}, {"pk": 1815, "model": "server.award", "fields": {"date": "2011-06-20 10:05:44", "badge": 1, "user": 169}}, {"pk": 1816, "model": "server.award", "fields": {"date": "2011-06-20 12:05:49", "badge": 1, "user": 254}}, {"pk": 1817, "model": "server.award", "fields": {"date": "2011-06-21 04:35:45", "badge": 5, "user": 254}}, {"pk": 1818, "model": "server.award", "fields": {"date": "2011-06-21 09:20:46", "badge": 37, "user": 38}}, {"pk": 1819, "model": "server.award", "fields": {"date": "2011-06-21 14:35:49", "badge": 29, "user": 78}}, {"pk": 1820, "model": "server.award", "fields": {"date": "2011-06-21 16:05:45", "badge": 29, "user": 113}}, {"pk": 1821, "model": "server.award", "fields": {"date": "2011-06-22 02:35:45", "badge": 10, "user": 151}}, {"pk": 1822, "model": "server.award", "fields": {"date": "2011-06-23 14:35:45", "badge": 25, "user": 61}}, {"pk": 1823, "model": "server.award", "fields": {"date": "2011-06-24 03:35:48", "badge": 1, "user": 228}}, {"pk": 1824, "model": "server.award", "fields": {"date": "2011-06-24 09:50:46", "badge": 6, "user": 497}}, {"pk": 1825, "model": "server.award", "fields": {"date": "2011-06-24 11:05:45", "badge": 2, "user": 263}}, {"pk": 1826, "model": "server.award", "fields": {"date": "2011-06-24 11:35:48", "badge": 2, "user": 286}}, {"pk": 1827, "model": "server.award", "fields": {"date": "2011-06-24 12:50:46", "badge": 10, "user": 263}}, {"pk": 1828, "model": "server.award", "fields": {"date": "2011-06-24 13:05:47", "badge": 9, "user": 263}}, {"pk": 1829, "model": "server.award", "fields": {"date": "2011-06-24 14:20:45", "badge": 22, "user": 389}}, {"pk": 1830, "model": "server.award", "fields": {"date": "2011-06-24 18:35:47", "badge": 26, "user": 29}}, {"pk": 1831, "model": "server.award", "fields": {"date": "2011-06-25 02:50:45", "badge": 3, "user": 192}}, {"pk": 1832, "model": "server.award", "fields": {"date": "2011-06-25 20:35:45", "badge": 9, "user": 90}}, {"pk": 1833, "model": "server.award", "fields": {"date": "2011-06-25 22:05:45", "badge": 22, "user": 233}}, {"pk": 1834, "model": "server.award", "fields": {"date": "2011-06-25 22:35:44", "badge": 10, "user": 286}}, {"pk": 1835, "model": "server.award", "fields": {"date": "2011-06-26 20:50:45", "badge": 14, "user": 228}}, {"pk": 1836, "model": "server.award", "fields": {"date": "2011-06-27 04:50:45", "badge": 19, "user": 29}}, {"pk": 1837, "model": "server.award", "fields": {"date": "2011-06-27 18:05:46", "badge": 25, "user": 389}}, {"pk": 1838, "model": "server.award", "fields": {"date": "2011-06-28 17:35:45", "badge": 3, "user": 228}}, {"pk": 1839, "model": "server.award", "fields": {"date": "2011-06-29 07:50:44", "badge": 25, "user": 338}}, {"pk": 1840, "model": "server.award", "fields": {"date": "2011-06-29 10:20:44", "badge": 22, "user": 313}}, {"pk": 1841, "model": "server.award", "fields": {"date": "2011-06-29 18:50:45", "badge": 10, "user": 228}}, {"pk": 1842, "model": "server.award", "fields": {"date": "2011-06-30 00:35:45", "badge": 13, "user": 445}}, {"pk": 1843, "model": "server.award", "fields": {"date": "2011-06-30 05:35:45", "badge": 6, "user": 228}}, {"pk": 1844, "model": "server.award", "fields": {"date": "2011-06-30 05:35:45", "badge": 7, "user": 228}}, {"pk": 1845, "model": "server.award", "fields": {"date": "2011-06-30 05:50:44", "badge": 30, "user": 70}}, {"pk": 1846, "model": "server.award", "fields": {"date": "2011-07-01 15:05:45", "badge": 11, "user": 468}}, {"pk": 1847, "model": "server.award", "fields": {"date": "2011-07-02 00:20:45", "badge": 13, "user": 451}}, {"pk": 1848, "model": "server.award", "fields": {"date": "2011-07-03 00:50:47", "badge": 13, "user": 457}}, {"pk": 1849, "model": "server.award", "fields": {"date": "2011-07-03 13:05:44", "badge": 19, "user": 98}}, {"pk": 1850, "model": "server.award", "fields": {"date": "2011-07-04 07:50:44", "badge": 19, "user": 497}}, {"pk": 1851, "model": "server.award", "fields": {"date": "2011-07-04 19:20:44", "badge": 22, "user": 185}}, {"pk": 1852, "model": "server.award", "fields": {"date": "2011-07-05 11:50:44", "badge": 1, "user": 354}}, {"pk": 1853, "model": "server.award", "fields": {"date": "2011-07-05 16:05:45", "badge": 7, "user": 145}}, {"pk": 1854, "model": "server.award", "fields": {"date": "2011-07-06 12:50:44", "badge": 10, "user": 497}}, {"pk": 1855, "model": "server.award", "fields": {"date": "2011-07-06 18:50:44", "badge": 22, "user": 121}}, {"pk": 1856, "model": "server.award", "fields": {"date": "2011-07-06 20:35:44", "badge": 12, "user": 29}}, {"pk": 1857, "model": "server.award", "fields": {"date": "2011-07-07 15:05:45", "badge": 22, "user": 170}}, {"pk": 1858, "model": "server.award", "fields": {"date": "2011-07-07 15:35:44", "badge": 30, "user": 98}}, {"pk": 1859, "model": "server.award", "fields": {"date": "2011-07-07 16:35:45", "badge": 13, "user": 190}}, {"pk": 1860, "model": "server.award", "fields": {"date": "2011-07-08 00:50:46", "badge": 13, "user": 468}}, {"pk": 1861, "model": "server.award", "fields": {"date": "2011-07-08 13:20:46", "badge": 22, "user": 233}}, {"pk": 1862, "model": "server.award", "fields": {"date": "2011-07-08 13:20:46", "badge": 18, "user": 233}}, {"pk": 1863, "model": "server.award", "fields": {"date": "2011-07-09 06:20:43", "badge": 31, "user": 199}}, {"pk": 1864, "model": "server.award", "fields": {"date": "2011-07-10 00:50:43", "badge": 13, "user": 473}}, {"pk": 1865, "model": "server.award", "fields": {"date": "2011-07-10 00:50:43", "badge": 13, "user": 475}}, {"pk": 1866, "model": "server.award", "fields": {"date": "2011-07-10 07:50:43", "badge": 7, "user": 167}}, {"pk": 1867, "model": "server.award", "fields": {"date": "2011-07-11 08:05:43", "badge": 22, "user": 38}}, {"pk": 1868, "model": "server.award", "fields": {"date": "2011-07-11 11:20:42", "badge": 13, "user": 38}}, {"pk": 1869, "model": "server.award", "fields": {"date": "2011-07-12 00:35:45", "badge": 25, "user": 342}}, {"pk": 1870, "model": "server.award", "fields": {"date": "2011-07-12 12:05:44", "badge": 26, "user": 22}}, {"pk": 1871, "model": "server.award", "fields": {"date": "2011-07-13 05:50:45", "badge": 1, "user": 8}}, {"pk": 1872, "model": "server.award", "fields": {"date": "2011-07-13 18:50:44", "badge": 22, "user": 98}}, {"pk": 1873, "model": "server.award", "fields": {"date": "2011-07-14 00:20:44", "badge": 13, "user": 485}}, {"pk": 1874, "model": "server.award", "fields": {"date": "2011-07-14 00:20:44", "badge": 13, "user": 487}}, {"pk": 1875, "model": "server.award", "fields": {"date": "2011-07-14 04:20:43", "badge": 9, "user": 8}}, {"pk": 1876, "model": "server.award", "fields": {"date": "2011-07-14 12:50:46", "badge": 22, "user": 457}}, {"pk": 1877, "model": "server.award", "fields": {"date": "2011-07-14 13:05:45", "badge": 18, "user": 457}}, {"pk": 1878, "model": "server.award", "fields": {"date": "2011-07-14 16:50:42", "badge": 22, "user": 29}}, {"pk": 1879, "model": "server.award", "fields": {"date": "2011-07-14 16:50:42", "badge": 25, "user": 398}}, {"pk": 1880, "model": "server.award", "fields": {"date": "2011-07-14 18:35:42", "badge": 18, "user": 29}}, {"pk": 1881, "model": "server.award", "fields": {"date": "2011-07-15 16:20:44", "badge": 22, "user": 35}}, {"pk": 1882, "model": "server.award", "fields": {"date": "2011-07-16 00:20:43", "badge": 13, "user": 491}}, {"pk": 1883, "model": "server.award", "fields": {"date": "2011-07-16 00:20:43", "badge": 13, "user": 492}}, {"pk": 1884, "model": "server.award", "fields": {"date": "2011-07-18 13:50:43", "badge": 22, "user": 1}}, {"pk": 1885, "model": "server.award", "fields": {"date": "2011-07-19 07:20:45", "badge": 25, "user": 119}}, {"pk": 1886, "model": "server.award", "fields": {"date": "2011-07-19 14:05:45", "badge": 22, "user": 457}}, {"pk": 1887, "model": "server.award", "fields": {"date": "2011-07-19 14:05:46", "badge": 30, "user": 141}}, {"pk": 1888, "model": "server.award", "fields": {"date": "2011-07-19 19:35:42", "badge": 11, "user": 278}}, {"pk": 1889, "model": "server.award", "fields": {"date": "2011-07-19 22:35:44", "badge": 41, "user": 35}}, {"pk": 1890, "model": "server.award", "fields": {"date": "2011-07-20 08:50:42", "badge": 2, "user": 94}}, {"pk": 1891, "model": "server.award", "fields": {"date": "2011-07-20 14:05:42", "badge": 25, "user": 109}}, {"pk": 1892, "model": "server.award", "fields": {"date": "2011-07-20 16:35:42", "badge": 25, "user": 252}}, {"pk": 1893, "model": "server.award", "fields": {"date": "2011-07-21 09:20:42", "badge": 33, "user": 418}}, {"pk": 1894, "model": "server.award", "fields": {"date": "2011-07-21 09:50:42", "badge": 11, "user": 130}}, {"pk": 1895, "model": "server.award", "fields": {"date": "2011-07-22 08:20:43", "badge": 3, "user": 158}}, {"pk": 1896, "model": "server.award", "fields": {"date": "2011-07-22 11:20:43", "badge": 8, "user": 29}}, {"pk": 1897, "model": "server.award", "fields": {"date": "2011-07-22 12:50:43", "badge": 25, "user": 35}}, {"pk": 1898, "model": "server.award", "fields": {"date": "2011-07-22 16:35:43", "badge": 25, "user": 409}}, {"pk": 1899, "model": "server.award", "fields": {"date": "2011-07-26 04:50:45", "badge": 26, "user": 29}}, {"pk": 1900, "model": "server.award", "fields": {"date": "2011-07-26 18:50:43", "badge": 3, "user": 190}}, {"pk": 1901, "model": "server.award", "fields": {"date": "2011-07-27 05:50:43", "badge": 25, "user": 147}}, {"pk": 1902, "model": "server.award", "fields": {"date": "2011-07-27 09:20:42", "badge": 22, "user": 457}}, {"pk": 1903, "model": "server.award", "fields": {"date": "2011-07-27 13:35:42", "badge": 5, "user": 451}}, {"pk": 1904, "model": "server.award", "fields": {"date": "2011-07-28 07:35:42", "badge": 25, "user": 22}}, {"pk": 1905, "model": "server.award", "fields": {"date": "2011-07-29 13:35:43", "badge": 25, "user": 127}}, {"pk": 1906, "model": "server.award", "fields": {"date": "2011-07-30 02:35:43", "badge": 29, "user": 244}}, {"pk": 1907, "model": "server.award", "fields": {"date": "2011-07-30 11:05:42", "badge": 37, "user": 263}}, {"pk": 1908, "model": "server.award", "fields": {"date": "2011-08-01 01:20:43", "badge": 25, "user": 29}}, {"pk": 1909, "model": "server.award", "fields": {"date": "2011-08-01 02:20:45", "badge": 19, "user": 70}}, {"pk": 1910, "model": "server.award", "fields": {"date": "2011-08-01 17:20:42", "badge": 25, "user": 490}}, {"pk": 1911, "model": "server.award", "fields": {"date": "2011-08-02 14:50:42", "badge": 6, "user": 354}}, {"pk": 1912, "model": "server.award", "fields": {"date": "2011-08-02 22:35:52", "badge": 5, "user": 57}}, {"pk": 1913, "model": "server.award", "fields": {"date": "2011-08-03 17:05:43", "badge": 20, "user": 199}}, {"pk": 1914, "model": "server.award", "fields": {"date": "2011-08-03 20:20:44", "badge": 22, "user": 72}}, {"pk": 1915, "model": "server.award", "fields": {"date": "2011-08-04 15:05:44", "badge": 16, "user": 274}}, {"pk": 1916, "model": "server.award", "fields": {"date": "2011-08-05 09:35:44", "badge": 19, "user": 215}}, {"pk": 1917, "model": "server.award", "fields": {"date": "2011-08-06 14:35:46", "badge": 29, "user": 190}}, {"pk": 1918, "model": "server.award", "fields": {"date": "2011-08-07 00:05:44", "badge": 18, "user": 37}}, {"pk": 1919, "model": "server.award", "fields": {"date": "2011-08-07 04:05:43", "badge": 5, "user": 190}}, {"pk": 1920, "model": "server.award", "fields": {"date": "2011-08-07 19:35:43", "badge": 19, "user": 9}}, {"pk": 1921, "model": "server.award", "fields": {"date": "2011-08-08 15:20:44", "badge": 22, "user": 35}}, {"pk": 1922, "model": "server.award", "fields": {"date": "2011-08-08 20:20:43", "badge": 25, "user": 225}}, {"pk": 1923, "model": "server.award", "fields": {"date": "2011-08-09 16:05:42", "badge": 22, "user": 70}}, {"pk": 1924, "model": "server.award", "fields": {"date": "2011-08-10 00:20:42", "badge": 10, "user": 252}}, {"pk": 1925, "model": "server.award", "fields": {"date": "2011-08-10 08:05:42", "badge": 1, "user": 255}}, {"pk": 1926, "model": "server.award", "fields": {"date": "2011-08-11 14:05:43", "badge": 22, "user": 35}}, {"pk": 1927, "model": "server.award", "fields": {"date": "2011-08-11 14:35:42", "badge": 14, "user": 313}}, {"pk": 1928, "model": "server.award", "fields": {"date": "2011-08-11 15:35:43", "badge": 22, "user": 116}}, {"pk": 1929, "model": "server.award", "fields": {"date": "2011-08-11 18:50:42", "badge": 3, "user": 30}}, {"pk": 1930, "model": "server.award", "fields": {"date": "2011-08-12 08:20:43", "badge": 19, "user": 215}}, {"pk": 1931, "model": "server.award", "fields": {"date": "2011-08-12 19:20:46", "badge": 26, "user": 237}}, {"pk": 1932, "model": "server.award", "fields": {"date": "2011-08-13 07:20:42", "badge": 22, "user": 457}}, {"pk": 1933, "model": "server.award", "fields": {"date": "2011-08-13 19:20:43", "badge": 22, "user": 389}}, {"pk": 1934, "model": "server.award", "fields": {"date": "2011-08-14 00:50:42", "badge": 25, "user": 186}}, {"pk": 1935, "model": "server.award", "fields": {"date": "2011-08-15 09:05:43", "badge": 25, "user": 320}}, {"pk": 1936, "model": "server.award", "fields": {"date": "2011-08-17 12:50:44", "badge": 25, "user": 168}}, {"pk": 1937, "model": "server.award", "fields": {"date": "2011-08-17 22:05:45", "badge": 22, "user": 274}}, {"pk": 1938, "model": "server.award", "fields": {"date": "2011-08-18 08:20:43", "badge": 30, "user": 473}}, {"pk": 1939, "model": "server.award", "fields": {"date": "2011-08-18 11:35:43", "badge": 29, "user": 247}}, {"pk": 1940, "model": "server.award", "fields": {"date": "2011-08-18 16:20:43", "badge": 11, "user": 58}}, {"pk": 1941, "model": "server.award", "fields": {"date": "2011-08-19 21:35:44", "badge": 22, "user": 35}}, {"pk": 1942, "model": "server.award", "fields": {"date": "2011-08-19 23:50:45", "badge": 18, "user": 35}}, {"pk": 1943, "model": "server.award", "fields": {"date": "2011-08-20 11:35:43", "badge": 22, "user": 119}}, {"pk": 1944, "model": "server.award", "fields": {"date": "2011-08-20 11:50:42", "badge": 22, "user": 6}}, {"pk": 1945, "model": "server.award", "fields": {"date": "2011-08-20 19:50:44", "badge": 19, "user": 186}}, {"pk": 1946, "model": "server.award", "fields": {"date": "2011-08-21 10:35:43", "badge": 16, "user": 237}}, {"pk": 1947, "model": "server.award", "fields": {"date": "2011-08-21 10:35:43", "badge": 16, "user": 324}}, {"pk": 1948, "model": "server.award", "fields": {"date": "2011-08-23 08:50:43", "badge": 25, "user": 142}}, {"pk": 1949, "model": "server.award", "fields": {"date": "2011-08-23 09:05:43", "badge": 25, "user": 3}}, {"pk": 1950, "model": "server.award", "fields": {"date": "2011-08-23 15:05:42", "badge": 38, "user": 418}}, {"pk": 1951, "model": "server.award", "fields": {"date": "2011-08-23 21:05:42", "badge": 30, "user": 72}}, {"pk": 1952, "model": "server.award", "fields": {"date": "2011-08-24 12:35:43", "badge": 22, "user": 29}}, {"pk": 1953, "model": "server.award", "fields": {"date": "2011-08-24 15:35:43", "badge": 22, "user": 313}}, {"pk": 1954, "model": "server.award", "fields": {"date": "2011-08-24 23:35:42", "badge": 1, "user": 105}}, {"pk": 1955, "model": "server.award", "fields": {"date": "2011-08-26 07:50:46", "badge": 11, "user": 65}}, {"pk": 1956, "model": "server.award", "fields": {"date": "2011-08-26 15:35:42", "badge": 19, "user": 37}}, {"pk": 1957, "model": "server.award", "fields": {"date": "2011-08-26 15:35:42", "badge": 19, "user": 86}}, {"pk": 1958, "model": "server.award", "fields": {"date": "2011-08-26 15:35:42", "badge": 19, "user": 88}}, {"pk": 1959, "model": "server.award", "fields": {"date": "2011-08-26 15:35:42", "badge": 19, "user": 116}}, {"pk": 1960, "model": "server.award", "fields": {"date": "2011-08-26 15:35:42", "badge": 19, "user": 141}}, {"pk": 1961, "model": "server.award", "fields": {"date": "2011-08-26 15:35:42", "badge": 19, "user": 199}}, {"pk": 1962, "model": "server.award", "fields": {"date": "2011-08-26 15:35:42", "badge": 19, "user": 215}}, {"pk": 1963, "model": "server.award", "fields": {"date": "2011-08-26 15:35:42", "badge": 19, "user": 233}}, {"pk": 1964, "model": "server.award", "fields": {"date": "2011-08-26 15:35:42", "badge": 19, "user": 273}}, {"pk": 1965, "model": "server.award", "fields": {"date": "2011-08-26 15:35:42", "badge": 19, "user": 327}}, {"pk": 1966, "model": "server.award", "fields": {"date": "2011-08-26 15:35:43", "badge": 19, "user": 63}}, {"pk": 1967, "model": "server.award", "fields": {"date": "2011-08-26 15:35:43", "badge": 19, "user": 311}}, {"pk": 1968, "model": "server.award", "fields": {"date": "2011-08-26 15:35:43", "badge": 19, "user": 87}}, {"pk": 1969, "model": "server.award", "fields": {"date": "2011-08-26 15:35:43", "badge": 19, "user": 284}}, {"pk": 1970, "model": "server.award", "fields": {"date": "2011-08-26 15:35:43", "badge": 19, "user": 389}}, {"pk": 1971, "model": "server.award", "fields": {"date": "2011-08-27 10:50:43", "badge": 19, "user": 215}}, {"pk": 1972, "model": "server.award", "fields": {"date": "2011-08-27 10:50:43", "badge": 19, "user": 313}}, {"pk": 1973, "model": "server.award", "fields": {"date": "2011-08-27 10:50:43", "badge": 19, "user": 221}}, {"pk": 1974, "model": "server.award", "fields": {"date": "2011-08-27 10:50:43", "badge": 19, "user": 96}}, {"pk": 1975, "model": "server.award", "fields": {"date": "2011-08-27 19:20:42", "badge": 20, "user": 116}}, {"pk": 1976, "model": "server.award", "fields": {"date": "2011-08-28 08:35:45", "badge": 11, "user": 54}}, {"pk": 1977, "model": "server.award", "fields": {"date": "2011-08-29 07:50:42", "badge": 8, "user": 233}}, {"pk": 1978, "model": "server.award", "fields": {"date": "2011-08-29 18:35:43", "badge": 18, "user": 72}}, {"pk": 1979, "model": "server.award", "fields": {"date": "2011-08-29 23:05:43", "badge": 25, "user": 320}}, {"pk": 1980, "model": "server.award", "fields": {"date": "2011-08-30 15:05:42", "badge": 19, "user": 312}}, {"pk": 1981, "model": "server.award", "fields": {"date": "2011-08-31 15:05:42", "badge": 22, "user": 65}}, {"pk": 1982, "model": "server.award", "fields": {"date": "2011-08-31 20:35:45", "badge": 16, "user": 493}}, {"pk": 1983, "model": "server.award", "fields": {"date": "2011-09-02 13:50:43", "badge": 19, "user": 270}}, {"pk": 1984, "model": "server.award", "fields": {"date": "2011-09-02 13:50:43", "badge": 22, "user": 72}}, {"pk": 1985, "model": "server.award", "fields": {"date": "2011-09-05 15:20:45", "badge": 22, "user": 29}}, {"pk": 1986, "model": "server.award", "fields": {"date": "2011-09-05 16:05:43", "badge": 18, "user": 29}}, {"pk": 1987, "model": "server.award", "fields": {"date": "2011-09-06 19:50:42", "badge": 22, "user": 1}}, {"pk": 1988, "model": "server.award", "fields": {"date": "2011-09-07 05:35:43", "badge": 25, "user": 1}}, {"pk": 1989, "model": "server.award", "fields": {"date": "2011-09-07 11:50:46", "badge": 25, "user": 225}}, {"pk": 1990, "model": "server.award", "fields": {"date": "2011-09-08 00:05:42", "badge": 26, "user": 1}}, {"pk": 1991, "model": "server.award", "fields": {"date": "2011-09-08 11:35:42", "badge": 25, "user": 468}}, {"pk": 1992, "model": "server.award", "fields": {"date": "2011-09-08 18:05:42", "badge": 14, "user": 418}}, {"pk": 1993, "model": "server.award", "fields": {"date": "2011-09-09 01:35:42", "badge": 22, "user": 73}}, {"pk": 1994, "model": "server.award", "fields": {"date": "2011-09-09 09:05:46", "badge": 2, "user": 108}}, {"pk": 1995, "model": "server.award", "fields": {"date": "2011-09-09 10:35:45", "badge": 3, "user": 108}}, {"pk": 1996, "model": "server.award", "fields": {"date": "2011-09-09 10:35:45", "badge": 9, "user": 108}}, {"pk": 1997, "model": "server.award", "fields": {"date": "2011-09-09 13:05:43", "badge": 20, "user": 22}}, {"pk": 1998, "model": "server.award", "fields": {"date": "2011-09-09 15:35:47", "badge": 19, "user": 108}}, {"pk": 1999, "model": "server.award", "fields": {"date": "2011-09-09 17:50:44", "badge": 22, "user": 286}}, {"pk": 2000, "model": "server.award", "fields": {"date": "2011-09-09 18:05:42", "badge": 10, "user": 108}}, {"pk": 2001, "model": "server.award", "fields": {"date": "2011-09-09 20:50:43", "badge": 25, "user": 215}}, {"pk": 2002, "model": "server.award", "fields": {"date": "2011-09-10 15:35:42", "badge": 25, "user": 186}}, {"pk": 2003, "model": "server.award", "fields": {"date": "2011-09-10 22:50:42", "badge": 7, "user": 474}}, {"pk": 2004, "model": "server.award", "fields": {"date": "2011-09-12 12:20:43", "badge": 22, "user": 418}}, {"pk": 2005, "model": "server.award", "fields": {"date": "2011-09-12 19:35:44", "badge": 25, "user": 215}}, {"pk": 2006, "model": "server.award", "fields": {"date": "2011-09-13 15:05:43", "badge": 10, "user": 320}}, {"pk": 2007, "model": "server.award", "fields": {"date": "2011-09-13 15:05:43", "badge": 25, "user": 221}}, {"pk": 2008, "model": "server.award", "fields": {"date": "2011-09-13 17:50:43", "badge": 7, "user": 108}}, {"pk": 2009, "model": "server.award", "fields": {"date": "2011-09-14 11:20:43", "badge": 7, "user": 263}}, {"pk": 2010, "model": "server.award", "fields": {"date": "2011-09-14 21:50:45", "badge": 22, "user": 22}}, {"pk": 2011, "model": "server.award", "fields": {"date": "2011-09-15 05:05:43", "badge": 11, "user": 165}}, {"pk": 2012, "model": "server.award", "fields": {"date": "2011-09-15 07:05:43", "badge": 29, "user": 228}}, {"pk": 2013, "model": "server.award", "fields": {"date": "2011-09-16 20:35:42", "badge": 26, "user": 35}}, {"pk": 2014, "model": "server.award", "fields": {"date": "2011-09-17 02:50:42", "badge": 25, "user": 144}}, {"pk": 2015, "model": "server.award", "fields": {"date": "2011-09-17 03:50:42", "badge": 2, "user": 351}}, {"pk": 2016, "model": "server.award", "fields": {"date": "2011-09-18 00:20:43", "badge": 10, "user": 351}}, {"pk": 2017, "model": "server.award", "fields": {"date": "2011-09-18 20:50:43", "badge": 22, "user": 221}}, {"pk": 2018, "model": "server.award", "fields": {"date": "2011-09-20 16:20:46", "badge": 25, "user": 303}}, {"pk": 2019, "model": "server.award", "fields": {"date": "2011-09-21 18:50:45", "badge": 3, "user": 75}}, {"pk": 2020, "model": "server.award", "fields": {"date": "2011-09-21 19:35:43", "badge": 26, "user": 199}}, {"pk": 2021, "model": "server.award", "fields": {"date": "2011-09-22 12:05:48", "badge": 10, "user": 75}}, {"pk": 2022, "model": "server.award", "fields": {"date": "2011-09-22 17:20:42", "badge": 13, "user": 108}}, {"pk": 2023, "model": "server.award", "fields": {"date": "2011-09-22 19:05:43", "badge": 11, "user": 85}}, {"pk": 2024, "model": "server.award", "fields": {"date": "2011-09-25 16:35:43", "badge": 7, "user": 38}}, {"pk": 2025, "model": "server.award", "fields": {"date": "2011-09-25 20:05:47", "badge": 19, "user": 35}}, {"pk": 2026, "model": "server.award", "fields": {"date": "2011-09-26 00:05:42", "badge": 25, "user": 198}}, {"pk": 2027, "model": "server.award", "fields": {"date": "2011-09-26 09:35:43", "badge": 25, "user": 284}}, {"pk": 2028, "model": "server.award", "fields": {"date": "2011-09-27 02:50:44", "badge": 25, "user": 140}}, {"pk": 2029, "model": "server.award", "fields": {"date": "2011-09-27 14:20:43", "badge": 25, "user": 374}}, {"pk": 2030, "model": "server.award", "fields": {"date": "2011-09-27 15:35:43", "badge": 22, "user": 58}}, {"pk": 2031, "model": "server.award", "fields": {"date": "2011-09-27 20:35:42", "badge": 29, "user": 338}}, {"pk": 2032, "model": "server.award", "fields": {"date": "2011-09-30 14:20:42", "badge": 22, "user": 457}}, {"pk": 2033, "model": "server.award", "fields": {"date": "2011-10-01 00:05:42", "badge": 13, "user": 1}}, {"pk": 2034, "model": "server.award", "fields": {"date": "2011-10-01 00:05:42", "badge": 13, "user": 6}}, {"pk": 2035, "model": "server.award", "fields": {"date": "2011-10-01 06:05:42", "badge": 19, "user": 29}}, {"pk": 2036, "model": "server.award", "fields": {"date": "2011-10-03 09:50:43", "badge": 22, "user": 72}}, {"pk": 2037, "model": "server.award", "fields": {"date": "2011-10-04 09:20:42", "badge": 22, "user": 86}}, {"pk": 2038, "model": "server.award", "fields": {"date": "2011-10-04 19:20:42", "badge": 26, "user": 473}}, {"pk": 2039, "model": "server.award", "fields": {"date": "2011-10-04 20:05:44", "badge": 10, "user": 111}}, {"pk": 2040, "model": "server.award", "fields": {"date": "2011-10-05 15:50:42", "badge": 2, "user": 349}}, {"pk": 2041, "model": "server.award", "fields": {"date": "2011-10-06 00:05:42", "badge": 13, "user": 9}}, {"pk": 2042, "model": "server.award", "fields": {"date": "2011-10-06 05:35:43", "badge": 10, "user": 419}}, {"pk": 2043, "model": "server.award", "fields": {"date": "2011-10-07 11:35:42", "badge": 3, "user": 263}}, {"pk": 2044, "model": "server.award", "fields": {"date": "2011-10-07 15:50:43", "badge": 22, "user": 54}}, {"pk": 2045, "model": "server.award", "fields": {"date": "2011-10-07 16:35:44", "badge": 25, "user": 217}}, {"pk": 2046, "model": "server.award", "fields": {"date": "2011-10-08 11:50:42", "badge": 19, "user": 29}}, {"pk": 2047, "model": "server.award", "fields": {"date": "2011-10-09 14:35:46", "badge": 25, "user": 121}}, {"pk": 2048, "model": "server.award", "fields": {"date": "2011-10-10 01:05:42", "badge": 22, "user": 22}}, {"pk": 2049, "model": "server.award", "fields": {"date": "2011-10-11 11:05:43", "badge": 25, "user": 312}}, {"pk": 2050, "model": "server.award", "fields": {"date": "2011-10-11 19:35:43", "badge": 25, "user": 274}}, {"pk": 2051, "model": "server.award", "fields": {"date": "2011-10-12 10:20:43", "badge": 2, "user": 417}}, {"pk": 2052, "model": "server.award", "fields": {"date": "2011-10-12 17:50:43", "badge": 26, "user": 217}}, {"pk": 2053, "model": "server.award", "fields": {"date": "2011-10-13 13:35:42", "badge": 22, "user": 35}}, {"pk": 2054, "model": "server.award", "fields": {"date": "2011-10-13 13:50:45", "badge": 22, "user": 67}}, {"pk": 2055, "model": "server.award", "fields": {"date": "2011-10-17 15:20:42", "badge": 22, "user": 237}}, {"pk": 2056, "model": "server.award", "fields": {"date": "2011-10-17 16:50:43", "badge": 22, "user": 44}}, {"pk": 2057, "model": "server.award", "fields": {"date": "2011-10-17 17:50:43", "badge": 7, "user": 114}}, {"pk": 2058, "model": "server.award", "fields": {"date": "2011-10-17 18:05:42", "badge": 16, "user": 68}}, {"pk": 2059, "model": "server.award", "fields": {"date": "2011-10-17 22:20:43", "badge": 22, "user": 29}}, {"pk": 2060, "model": "server.award", "fields": {"date": "2011-10-18 13:35:45", "badge": 11, "user": 137}}, {"pk": 2061, "model": "server.award", "fields": {"date": "2011-10-19 08:50:45", "badge": 22, "user": 313}}, {"pk": 2062, "model": "server.award", "fields": {"date": "2011-10-19 11:35:43", "badge": 25, "user": 186}}, {"pk": 2063, "model": "server.award", "fields": {"date": "2011-10-19 16:35:42", "badge": 22, "user": 65}}, {"pk": 2064, "model": "server.award", "fields": {"date": "2011-10-19 16:50:43", "badge": 7, "user": 137}}, {"pk": 2065, "model": "server.award", "fields": {"date": "2011-10-20 03:20:43", "badge": 25, "user": 468}}, {"pk": 2066, "model": "server.award", "fields": {"date": "2011-10-20 17:50:42", "badge": 22, "user": 1}}, {"pk": 2067, "model": "server.award", "fields": {"date": "2011-10-20 20:20:43", "badge": 22, "user": 233}}, {"pk": 2068, "model": "server.award", "fields": {"date": "2011-10-21 12:20:45", "badge": 25, "user": 199}}, {"pk": 2069, "model": "server.award", "fields": {"date": "2011-10-21 14:50:42", "badge": 22, "user": 52}}, {"pk": 2070, "model": "server.award", "fields": {"date": "2011-10-21 23:35:43", "badge": 14, "user": 351}}, {"pk": 2071, "model": "server.award", "fields": {"date": "2011-10-23 12:05:47", "badge": 25, "user": 274}}, {"pk": 2072, "model": "server.award", "fields": {"date": "2011-10-25 18:35:47", "badge": 22, "user": 378}}, {"pk": 2073, "model": "server.award", "fields": {"date": "2011-10-25 21:35:47", "badge": 22, "user": 313}}, {"pk": 2074, "model": "server.award", "fields": {"date": "2011-10-26 22:35:42", "badge": 22, "user": 313}}, {"pk": 2075, "model": "server.award", "fields": {"date": "2011-10-26 22:50:43", "badge": 18, "user": 313}}, {"pk": 2076, "model": "server.award", "fields": {"date": "2011-10-27 13:50:43", "badge": 19, "user": 313}}, {"pk": 2077, "model": "server.award", "fields": {"date": "2011-10-27 14:35:44", "badge": 19, "user": 215}}, {"pk": 2078, "model": "server.award", "fields": {"date": "2011-10-27 21:05:44", "badge": 16, "user": 29}}, {"pk": 2079, "model": "server.award", "fields": {"date": "2011-10-28 07:35:44", "badge": 6, "user": 177}}, {"pk": 2080, "model": "server.award", "fields": {"date": "2011-10-28 12:50:44", "badge": 13, "user": 263}}, {"pk": 2081, "model": "server.award", "fields": {"date": "2011-10-29 11:05:43", "badge": 10, "user": 46}}, {"pk": 2082, "model": "server.award", "fields": {"date": "2011-10-30 14:50:46", "badge": 1, "user": 223}}, {"pk": 2083, "model": "server.award", "fields": {"date": "2011-10-30 14:50:46", "badge": 22, "user": 54}}, {"pk": 2084, "model": "server.award", "fields": {"date": "2011-10-30 14:50:46", "badge": 22, "user": 389}}, {"pk": 2085, "model": "server.award", "fields": {"date": "2011-10-31 08:20:43", "badge": 6, "user": 366}}, {"pk": 2086, "model": "server.award", "fields": {"date": "2011-10-31 09:50:42", "badge": 1, "user": 366}}, {"pk": 2087, "model": "server.award", "fields": {"date": "2011-10-31 16:50:44", "badge": 22, "user": 65}}, {"pk": 2088, "model": "server.award", "fields": {"date": "2011-10-31 21:50:43", "badge": 26, "user": 328}}, {"pk": 2089, "model": "server.award", "fields": {"date": "2011-11-01 06:50:43", "badge": 22, "user": 215}}, {"pk": 2090, "model": "server.award", "fields": {"date": "2011-11-01 12:05:45", "badge": 18, "user": 215}}, {"pk": 2091, "model": "server.award", "fields": {"date": "2011-11-01 15:50:44", "badge": 38, "user": 90}}, {"pk": 2092, "model": "server.award", "fields": {"date": "2011-11-01 18:20:42", "badge": 6, "user": 296}}, {"pk": 2093, "model": "server.award", "fields": {"date": "2011-11-01 18:20:42", "badge": 10, "user": 296}}, {"pk": 2094, "model": "server.award", "fields": {"date": "2011-11-02 17:05:43", "badge": 30, "user": 457}}, {"pk": 2095, "model": "server.award", "fields": {"date": "2011-11-03 22:20:00", "badge": 22, "user": 54}}, {"pk": 2096, "model": "server.award", "fields": {"date": "2011-11-04 14:50:00", "badge": 22, "user": 26}}, {"pk": 2097, "model": "server.award", "fields": {"date": "2011-11-04 15:20:00", "badge": 19, "user": 1}}, {"pk": 2098, "model": "server.award", "fields": {"date": "2011-11-04 16:50:00", "badge": 14, "user": 54}}, {"pk": 2099, "model": "server.award", "fields": {"date": "2011-11-04 20:05:01", "badge": 20, "user": 1}}, {"pk": 2100, "model": "server.award", "fields": {"date": "2011-11-04 20:50:00", "badge": 6, "user": 257}}, {"pk": 2101, "model": "server.award", "fields": {"date": "2011-11-05 03:20:00", "badge": 22, "user": 116}}, {"pk": 2102, "model": "server.award", "fields": {"date": "2011-11-05 14:50:00", "badge": 22, "user": 22}}, {"pk": 2103, "model": "server.award", "fields": {"date": "2011-11-05 14:50:00", "badge": 22, "user": 37}}, {"pk": 2104, "model": "server.award", "fields": {"date": "2011-11-06 14:20:00", "badge": 9, "user": 223}}, {"pk": 2105, "model": "server.award", "fields": {"date": "2011-11-06 17:35:00", "badge": 6, "user": 223}}, {"pk": 2106, "model": "server.award", "fields": {"date": "2011-11-06 19:35:01", "badge": 25, "user": 186}}, {"pk": 2107, "model": "server.award", "fields": {"date": "2011-11-07 04:05:00", "badge": 26, "user": 52}}, {"pk": 2108, "model": "server.award", "fields": {"date": "2011-11-07 19:35:01", "badge": 6, "user": 412}}, {"pk": 2109, "model": "server.award", "fields": {"date": "2011-11-07 20:35:01", "badge": 19, "user": 1}}, {"pk": 2110, "model": "server.award", "fields": {"date": "2011-11-07 22:05:00", "badge": 22, "user": 313}}, {"pk": 2111, "model": "server.award", "fields": {"date": "2011-11-07 22:05:00", "badge": 26, "user": 86}}, {"pk": 2112, "model": "server.award", "fields": {"date": "2011-11-07 23:35:00", "badge": 8, "user": 23}}, {"pk": 2113, "model": "server.award", "fields": {"date": "2011-11-08 07:05:00", "badge": 7, "user": 244}}, {"pk": 2114, "model": "server.award", "fields": {"date": "2011-11-08 16:50:00", "badge": 5, "user": 354}}, {"pk": 2115, "model": "server.award", "fields": {"date": "2011-11-09 02:20:00", "badge": 6, "user": 268}}, {"pk": 2116, "model": "server.award", "fields": {"date": "2011-11-09 04:20:00", "badge": 31, "user": 1}}, {"pk": 2117, "model": "server.award", "fields": {"date": "2011-11-09 08:20:00", "badge": 8, "user": 114}}, {"pk": 2118, "model": "server.award", "fields": {"date": "2011-11-10 04:50:00", "badge": 25, "user": 329}}, {"pk": 2119, "model": "server.award", "fields": {"date": "2011-11-10 11:50:00", "badge": 25, "user": 445}}, {"pk": 2120, "model": "server.award", "fields": {"date": "2011-11-10 18:20:00", "badge": 9, "user": 73}}, {"pk": 2121, "model": "server.award", "fields": {"date": "2011-11-10 19:35:00", "badge": 25, "user": 52}}, {"pk": 2122, "model": "server.award", "fields": {"date": "2011-11-11 04:50:00", "badge": 26, "user": 9}}, {"pk": 2123, "model": "server.award", "fields": {"date": "2011-11-11 13:05:00", "badge": 22, "user": 22}}, {"pk": 2124, "model": "server.award", "fields": {"date": "2011-11-13 18:20:00", "badge": 29, "user": 57}}, {"pk": 2125, "model": "server.award", "fields": {"date": "2011-11-14 14:20:00", "badge": 1, "user": 383}}, {"pk": 2126, "model": "server.award", "fields": {"date": "2011-11-15 23:05:00", "badge": 19, "user": 199}}, {"pk": 2127, "model": "server.award", "fields": {"date": "2011-11-16 02:20:00", "badge": 22, "user": 85}}, {"pk": 2128, "model": "server.award", "fields": {"date": "2011-11-16 09:35:00", "badge": 25, "user": 91}}, {"pk": 2129, "model": "server.award", "fields": {"date": "2011-11-17 00:20:00", "badge": 11, "user": 13}}, {"pk": 2130, "model": "server.award", "fields": {"date": "2011-11-17 04:05:01", "badge": 23, "user": 58}}, {"pk": 2131, "model": "server.award", "fields": {"date": "2011-11-17 12:05:00", "badge": 19, "user": 313}}, {"pk": 2132, "model": "server.award", "fields": {"date": "2011-11-17 19:20:00", "badge": 14, "user": 274}}, {"pk": 2133, "model": "server.award", "fields": {"date": "2011-11-19 09:35:00", "badge": 27, "user": 15}}, {"pk": 2134, "model": "server.award", "fields": {"date": "2011-11-19 13:50:01", "badge": 2, "user": 194}}, {"pk": 2135, "model": "server.award", "fields": {"date": "2011-11-20 09:05:00", "badge": 26, "user": 29}}, {"pk": 2136, "model": "server.award", "fields": {"date": "2011-11-20 09:50:00", "badge": 17, "user": 22}}, {"pk": 2137, "model": "server.award", "fields": {"date": "2011-11-21 20:20:00", "badge": 22, "user": 55}}, {"pk": 2138, "model": "server.award", "fields": {"date": "2011-11-21 21:20:00", "badge": 1, "user": 412}}, {"pk": 2139, "model": "server.award", "fields": {"date": "2011-11-21 22:05:00", "badge": 18, "user": 55}}, {"pk": 2140, "model": "server.award", "fields": {"date": "2011-11-21 23:35:00", "badge": 14, "user": 151}}, {"pk": 2141, "model": "server.award", "fields": {"date": "2011-11-22 00:20:00", "badge": 22, "user": 52}}, {"pk": 2142, "model": "server.award", "fields": {"date": "2011-11-22 00:20:01", "badge": 31, "user": 116}}, {"pk": 2143, "model": "server.award", "fields": {"date": "2011-11-22 03:05:00", "badge": 5, "user": 412}}, {"pk": 2144, "model": "server.award", "fields": {"date": "2011-11-22 04:50:00", "badge": 25, "user": 46}}, {"pk": 2145, "model": "server.award", "fields": {"date": "2011-11-22 19:35:01", "badge": 22, "user": 343}}]